{"time": "2024-06-03T12:10:54.471799", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Using device: cpu"}
{"time": "2024-06-03T12:10:56.061302", "name": "__main__", "level": "INFO", "message": "DataVisualizer initialized with Seaborn style set to 'whitegrid'."}
{"time": "2024-06-03T12:10:56.261209", "name": "__main__", "level": "INFO", "message": "Environment reset and takeoff completed."}
{"time": "2024-06-03T12:10:57.399463", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 6 selected."}
{"time": "2024-06-03T12:11:03.945105", "name": "__main__", "level": "INFO", "message": "Action: 6, Reward: tensor([-19.8890], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T12:11:04.709957", "name": "__main__", "level": "INFO", "message": "Epoch 0, Iteration 0: Reward: tensor([-19.8890], grad_fn=<AddBackward0>), Policy Loss: None, Value Loss: None, Total Loss: None, Entropy: None"}
{"time": "2024-06-03T12:11:05.050801", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 8 selected."}
{"time": "2024-06-03T12:11:16.274101", "name": "__main__", "level": "INFO", "message": "Action: 8, Reward: tensor([-22.7541], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T12:11:16.645190", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 12 selected."}
{"time": "2024-06-03T12:11:28.860024", "name": "__main__", "level": "INFO", "message": "Action: 12, Reward: tensor([-74.5007], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T12:11:29.576003", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 0 selected."}
{"time": "2024-06-03T12:11:41.570678", "name": "__main__", "level": "INFO", "message": "Action: 0, Reward: tensor([-24.6277], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T12:11:41.868139", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 16 selected."}
{"time": "2024-06-03T12:11:52.679713", "name": "__main__", "level": "INFO", "message": "Action: 16, Reward: tensor([-24.7108], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T12:11:53.753899", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 15 selected."}
{"time": "2024-06-03T12:12:06.035791", "name": "__main__", "level": "INFO", "message": "Action: 15, Reward: tensor([-24.8546], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T12:12:07.171952", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 6 selected."}
{"time": "2024-06-03T12:12:12.569048", "name": "__main__", "level": "INFO", "message": "Action: 6, Reward: tensor([-24.9427], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T12:12:13.286015", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 0 selected."}
{"time": "2024-06-03T12:12:25.769836", "name": "__main__", "level": "INFO", "message": "Action: 0, Reward: tensor([-25.0380], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T12:12:26.960140", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 14 selected."}
{"time": "2024-06-03T12:12:38.650899", "name": "__main__", "level": "INFO", "message": "Action: 14, Reward: tensor([-25.1980], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T12:12:39.426295", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 7 selected."}
{"time": "2024-06-03T12:12:46.140224", "name": "__main__", "level": "INFO", "message": "Action: 7, Reward: tensor([-75.2582], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T12:12:47.136035", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 11 selected."}
{"time": "2024-06-03T12:12:52.948802", "name": "__main__", "level": "INFO", "message": "Action: 11, Reward: tensor([-24.3718], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T12:12:52.971920", "name": "__main__", "level": "INFO", "message": "Epoch 0, Iteration 10: Reward: tensor([-366.1457], grad_fn=<AddBackward0>), Policy Loss: None, Value Loss: None, Total Loss: None, Entropy: None"}
{"time": "2024-06-03T12:12:53.196106", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 1 selected."}
{"time": "2024-06-03T12:13:05.026777", "name": "__main__", "level": "INFO", "message": "Episode timed out."}
{"time": "2024-06-03T12:13:05.481032", "name": "__main__", "level": "INFO", "message": "Action: 1, Reward: tensor([-22.8578], grad_fn=<AddBackward0>), Done: True"}
{"time": "2024-06-03T12:13:06.570168", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Model saved at e:\\Project\\models/checkpoints\\ppo_agent_epoch_0.pt"}
{"time": "2024-06-03T12:13:06.991151", "name": "__main__", "level": "INFO", "message": "Checkpoint saved at epoch 0"}
{"time": "2024-06-03T12:13:07.396073", "name": "__main__", "level": "INFO", "message": "Environment reset and takeoff completed."}
{"time": "2024-06-03T12:13:08.760772", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 4 selected."}
{"time": "2024-06-03T12:13:21.151561", "name": "__main__", "level": "INFO", "message": "Action: 4, Reward: tensor([-22.5970], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T12:13:21.885748", "name": "__main__", "level": "INFO", "message": "Epoch 1, Iteration 0: Reward: tensor([-22.5970], grad_fn=<AddBackward0>), Policy Loss: None, Value Loss: None, Total Loss: None, Entropy: None"}
{"time": "2024-06-03T12:13:22.858331", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 10 selected."}
{"time": "2024-06-03T12:13:29.289408", "name": "__main__", "level": "INFO", "message": "Action: 10, Reward: tensor([-23.7592], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T12:13:30.084271", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 9 selected."}
{"time": "2024-06-03T12:13:42.356988", "name": "__main__", "level": "INFO", "message": "Action: 9, Reward: tensor([-22.7700], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T12:13:43.737634", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 4 selected."}
{"time": "2024-06-03T12:13:56.205003", "name": "__main__", "level": "INFO", "message": "Action: 4, Reward: tensor([-22.8452], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T12:13:57.508360", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 6 selected."}
{"time": "2024-06-03T12:14:04.117536", "name": "__main__", "level": "INFO", "message": "Action: 6, Reward: tensor([-23.0838], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T12:14:05.315472", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 15 selected."}
{"time": "2024-06-03T12:14:18.153360", "name": "__main__", "level": "INFO", "message": "Action: 15, Reward: tensor([-24.3568], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T12:14:19.435133", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 15 selected."}
{"time": "2024-06-03T12:14:32.036922", "name": "__main__", "level": "INFO", "message": "Action: 15, Reward: tensor([-26.5830], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T12:14:33.106328", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 1 selected."}
{"time": "2024-06-03T12:14:45.868343", "name": "__main__", "level": "INFO", "message": "Action: 1, Reward: tensor([-28.6251], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T12:14:47.066115", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 12 selected."}
{"time": "2024-06-03T12:14:59.661954", "name": "__main__", "level": "INFO", "message": "Action: 12, Reward: tensor([-30.7287], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T12:15:00.892667", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 6 selected."}
{"time": "2024-06-03T12:15:07.475630", "name": "__main__", "level": "INFO", "message": "Action: 6, Reward: tensor([-31.6827], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T12:15:08.482782", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 4 selected."}
{"time": "2024-06-03T12:15:20.112785", "name": "__main__", "level": "INFO", "message": "Episode timed out."}
{"time": "2024-06-03T12:15:20.333025", "name": "__main__", "level": "INFO", "message": "Action: 4, Reward: tensor([-34.4819], grad_fn=<AddBackward0>), Done: True"}
{"time": "2024-06-03T12:15:20.736935", "name": "__main__", "level": "INFO", "message": "Epoch 1, Iteration 10: Reward: tensor([-291.5134], grad_fn=<AddBackward0>), Policy Loss: None, Value Loss: None, Total Loss: None, Entropy: None"}
{"time": "2024-06-03T12:15:21.000728", "name": "__main__", "level": "INFO", "message": "Environment reset and takeoff completed."}
{"time": "2024-06-03T12:15:21.729509", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 10 selected."}
{"time": "2024-06-03T12:15:28.307424", "name": "__main__", "level": "INFO", "message": "Action: 10, Reward: tensor([-16.5137], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T12:15:29.093976", "name": "__main__", "level": "INFO", "message": "Epoch 2, Iteration 0: Reward: tensor([-16.5137], grad_fn=<AddBackward0>), Policy Loss: None, Value Loss: None, Total Loss: None, Entropy: None"}
{"time": "2024-06-03T12:15:30.061583", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 8 selected."}
{"time": "2024-06-03T12:15:41.633183", "name": "__main__", "level": "INFO", "message": "Action: 8, Reward: tensor([-20.5039], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T12:15:41.892442", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 3 selected."}
{"time": "2024-06-03T12:15:47.591176", "name": "__main__", "level": "INFO", "message": "Action: 3, Reward: tensor([-21.5602], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T12:15:48.280778", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 15 selected."}
{"time": "2024-06-03T12:16:00.725142", "name": "__main__", "level": "INFO", "message": "Action: 15, Reward: tensor([-23.4707], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T12:16:01.427712", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 14 selected."}
{"time": "2024-06-03T12:16:14.158532", "name": "__main__", "level": "INFO", "message": "Action: 14, Reward: tensor([-74.1754], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T12:16:15.031184", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 11 selected."}
{"time": "2024-06-03T12:16:21.555438", "name": "__main__", "level": "INFO", "message": "Action: 11, Reward: tensor([-23.5138], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T12:16:22.912002", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 0 selected."}
{"time": "2024-06-03T12:16:34.989877", "name": "__main__", "level": "INFO", "message": "Action: 0, Reward: tensor([-22.3746], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T12:16:35.659178", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 10 selected."}
{"time": "2024-06-03T12:16:41.325376", "name": "__main__", "level": "INFO", "message": "Action: 10, Reward: tensor([-23.2680], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T12:16:41.885602", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 14 selected."}
{"time": "2024-06-03T12:16:53.451570", "name": "__main__", "level": "INFO", "message": "Action: 14, Reward: tensor([-24.6421], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T12:16:54.573556", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 2 selected."}
{"time": "2024-06-03T12:17:00.783831", "name": "__main__", "level": "INFO", "message": "Action: 2, Reward: tensor([-24.9542], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T12:17:01.909116", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 6 selected."}
{"time": "2024-06-03T12:17:08.579450", "name": "__main__", "level": "INFO", "message": "Action: 6, Reward: tensor([-75.0038], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T12:17:09.334880", "name": "__main__", "level": "INFO", "message": "Epoch 2, Iteration 10: Reward: tensor([-349.9803], grad_fn=<AddBackward0>), Policy Loss: None, Value Loss: None, Total Loss: None, Entropy: None"}
{"time": "2024-06-03T12:17:09.631580", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 4 selected."}
{"time": "2024-06-03T12:17:21.439155", "name": "__main__", "level": "INFO", "message": "Episode timed out."}
{"time": "2024-06-03T12:17:22.047447", "name": "__main__", "level": "INFO", "message": "Action: 4, Reward: tensor([-25.1570], grad_fn=<AddBackward0>), Done: True"}
{"time": "2024-06-03T12:17:22.622257", "name": "__main__", "level": "INFO", "message": "Environment reset and takeoff completed."}
{"time": "2024-06-03T12:17:23.464830", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 1 selected."}
{"time": "2024-06-03T12:17:36.245620", "name": "__main__", "level": "INFO", "message": "Action: 1, Reward: tensor([-17.0775], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T12:17:36.969628", "name": "__main__", "level": "INFO", "message": "Epoch 3, Iteration 0: Reward: tensor([-17.0775], grad_fn=<AddBackward0>), Policy Loss: None, Value Loss: None, Total Loss: None, Entropy: None"}
{"time": "2024-06-03T12:17:37.823708", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 10 selected."}
{"time": "2024-06-03T12:17:44.451771", "name": "__main__", "level": "INFO", "message": "Action: 10, Reward: tensor([-18.2853], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T12:17:45.020320", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 0 selected."}
{"time": "2024-06-03T12:17:57.046724", "name": "__main__", "level": "INFO", "message": "Action: 0, Reward: tensor([-19.6392], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T12:17:58.214683", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 16 selected."}
{"time": "2024-06-03T12:18:10.682471", "name": "__main__", "level": "INFO", "message": "Action: 16, Reward: tensor([-20.5892], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T12:18:11.914903", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 8 selected."}
{"time": "2024-06-03T12:18:24.595238", "name": "__main__", "level": "INFO", "message": "Action: 8, Reward: tensor([-23.6994], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T12:18:25.919199", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 6 selected."}
{"time": "2024-06-03T12:18:32.604405", "name": "__main__", "level": "INFO", "message": "Action: 6, Reward: tensor([-74.4044], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T12:18:34.097677", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 15 selected."}
{"time": "2024-06-03T12:18:46.469646", "name": "__main__", "level": "INFO", "message": "Action: 15, Reward: tensor([-24.5843], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T12:18:46.905437", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 3 selected."}
{"time": "2024-06-03T12:18:52.773312", "name": "__main__", "level": "INFO", "message": "Action: 3, Reward: tensor([-24.6401], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T12:18:53.659382", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 4 selected."}
{"time": "2024-06-03T12:19:05.926135", "name": "__main__", "level": "INFO", "message": "Action: 4, Reward: tensor([-24.7601], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T12:19:07.146976", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 3 selected."}
{"time": "2024-06-03T12:19:13.474034", "name": "__main__", "level": "INFO", "message": "Action: 3, Reward: tensor([-24.8369], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T12:19:14.623312", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 3 selected."}
{"time": "2024-06-03T12:19:20.867097", "name": "__main__", "level": "INFO", "message": "Action: 3, Reward: tensor([-24.9209], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T12:19:21.613945", "name": "__main__", "level": "INFO", "message": "Epoch 3, Iteration 10: Reward: tensor([-297.4372], grad_fn=<AddBackward0>), Policy Loss: None, Value Loss: None, Total Loss: None, Entropy: None"}
{"time": "2024-06-03T12:19:22.719870", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 12 selected."}
{"time": "2024-06-03T12:19:34.539364", "name": "__main__", "level": "INFO", "message": "Episode timed out."}
{"time": "2024-06-03T12:19:34.617507", "name": "__main__", "level": "INFO", "message": "Action: 12, Reward: tensor([-25.0386], grad_fn=<AddBackward0>), Done: True"}
{"time": "2024-06-03T12:19:35.084646", "name": "__main__", "level": "INFO", "message": "Environment reset and takeoff completed."}
{"time": "2024-06-03T12:19:36.151269", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 0 selected."}
{"time": "2024-06-03T12:19:48.684257", "name": "__main__", "level": "INFO", "message": "Action: 0, Reward: tensor([-19.3565], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T12:19:49.540992", "name": "__main__", "level": "INFO", "message": "Epoch 4, Iteration 0: Reward: tensor([-19.3565], grad_fn=<AddBackward0>), Policy Loss: None, Value Loss: None, Total Loss: None, Entropy: None"}
{"time": "2024-06-03T12:19:50.398942", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 0 selected."}
{"time": "2024-06-03T12:20:02.693881", "name": "__main__", "level": "INFO", "message": "Action: 0, Reward: tensor([-19.7765], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T12:20:03.611509", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 0 selected."}
{"time": "2024-06-03T12:20:15.861376", "name": "__main__", "level": "INFO", "message": "Action: 0, Reward: tensor([-20.8344], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T12:20:17.157723", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 3 selected."}
{"time": "2024-06-03T12:20:23.530293", "name": "__main__", "level": "INFO", "message": "Action: 3, Reward: tensor([-20.8634], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T12:20:24.679601", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 13 selected."}
{"time": "2024-06-03T12:20:37.059891", "name": "__main__", "level": "INFO", "message": "Action: 13, Reward: tensor([-20.6910], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T12:20:37.792733", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 9 selected."}
{"time": "2024-06-03T12:20:49.576904", "name": "__main__", "level": "INFO", "message": "Action: 9, Reward: tensor([-18.4716], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T12:20:50.669155", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 11 selected."}
{"time": "2024-06-03T12:20:56.346534", "name": "__main__", "level": "INFO", "message": "Action: 11, Reward: tensor([-17.3052], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T12:20:57.249733", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 8 selected."}
{"time": "2024-06-03T12:21:09.513179", "name": "__main__", "level": "INFO", "message": "Action: 8, Reward: tensor([-18.1812], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T12:21:10.303716", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 2 selected."}
{"time": "2024-06-03T12:21:16.470842", "name": "__main__", "level": "INFO", "message": "Action: 2, Reward: tensor([-18.7459], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T12:21:17.466818", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 0 selected."}
{"time": "2024-06-03T12:21:29.796281", "name": "__main__", "level": "INFO", "message": "Action: 0, Reward: tensor([-20.3025], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T12:21:31.104810", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 14 selected."}
{"time": "2024-06-03T12:21:42.658648", "name": "__main__", "level": "INFO", "message": "Episode timed out."}
{"time": "2024-06-03T12:21:42.736620", "name": "__main__", "level": "INFO", "message": "Action: 14, Reward: tensor([-23.1933], grad_fn=<AddBackward0>), Done: True"}
{"time": "2024-06-03T12:21:43.330139", "name": "__main__", "level": "INFO", "message": "Epoch 4, Iteration 10: Reward: tensor([-217.7215], grad_fn=<AddBackward0>), Policy Loss: None, Value Loss: None, Total Loss: None, Entropy: None"}
{"time": "2024-06-03T12:21:43.688274", "name": "__main__", "level": "INFO", "message": "Environment reset and takeoff completed."}
{"time": "2024-06-03T12:21:44.328802", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 14 selected."}
{"time": "2024-06-03T12:21:56.663967", "name": "__main__", "level": "INFO", "message": "Action: 14, Reward: tensor([-16.4346], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T12:21:57.458110", "name": "__main__", "level": "INFO", "message": "Epoch 5, Iteration 0: Reward: tensor([-16.4346], grad_fn=<AddBackward0>), Policy Loss: None, Value Loss: None, Total Loss: None, Entropy: None"}
{"time": "2024-06-03T12:21:58.615006", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 9 selected."}
{"time": "2024-06-03T12:22:11.232329", "name": "__main__", "level": "INFO", "message": "Action: 9, Reward: tensor([-14.8396], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T12:22:12.326927", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 11 selected."}
{"time": "2024-06-03T12:22:18.713969", "name": "__main__", "level": "INFO", "message": "Action: 11, Reward: tensor([-13.7488], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T12:22:19.259689", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 4 selected."}
{"time": "2024-06-03T12:22:31.364262", "name": "__main__", "level": "INFO", "message": "Action: 4, Reward: tensor([-11.4678], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T12:22:32.345866", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 11 selected."}
{"time": "2024-06-03T12:22:37.930401", "name": "__main__", "level": "INFO", "message": "Action: 11, Reward: tensor([-10.2464], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T12:22:38.894291", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 12 selected."}
{"time": "2024-06-03T12:22:51.275934", "name": "__main__", "level": "INFO", "message": "Action: 12, Reward: tensor([-9.8550], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T12:22:52.162809", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 1 selected."}
{"time": "2024-06-03T12:23:04.415569", "name": "__main__", "level": "INFO", "message": "Action: 1, Reward: tensor([-9.3453], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T12:23:05.478156", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 4 selected."}
{"time": "2024-06-03T12:23:17.883638", "name": "__main__", "level": "INFO", "message": "Action: 4, Reward: tensor([-10.6159], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T12:23:19.288080", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 15 selected."}
{"time": "2024-06-03T12:23:30.513270", "name": "__main__", "level": "INFO", "message": "Action: 15, Reward: tensor([-12.8370], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T12:23:31.214414", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 2 selected."}
{"time": "2024-06-03T12:23:36.863008", "name": "__main__", "level": "INFO", "message": "Action: 2, Reward: tensor([-13.3480], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T12:23:38.242177", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 4 selected."}
{"time": "2024-06-03T12:23:50.169504", "name": "__main__", "level": "INFO", "message": "Episode timed out."}
{"time": "2024-06-03T12:23:50.202447", "name": "__main__", "level": "INFO", "message": "Action: 4, Reward: tensor([-16.1083], grad_fn=<AddBackward0>), Done: True"}
{"time": "2024-06-03T12:23:50.787283", "name": "__main__", "level": "INFO", "message": "Epoch 5, Iteration 10: Reward: tensor([-138.8469], grad_fn=<AddBackward0>), Policy Loss: None, Value Loss: None, Total Loss: None, Entropy: None"}
{"time": "2024-06-03T12:23:51.020025", "name": "__main__", "level": "INFO", "message": "Environment reset and takeoff completed."}
{"time": "2024-06-03T12:23:51.938053", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 1 selected."}
{"time": "2024-06-03T12:24:04.482225", "name": "__main__", "level": "INFO", "message": "Action: 1, Reward: tensor([-20.6464], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T12:24:05.137877", "name": "__main__", "level": "INFO", "message": "Epoch 6, Iteration 0: Reward: tensor([-20.6464], grad_fn=<AddBackward0>), Policy Loss: None, Value Loss: None, Total Loss: None, Entropy: None"}
{"time": "2024-06-03T12:24:05.654277", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 0 selected."}
{"time": "2024-06-03T12:24:17.734485", "name": "__main__", "level": "INFO", "message": "Action: 0, Reward: tensor([-21.0850], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T12:24:18.921844", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 6 selected."}
{"time": "2024-06-03T12:24:25.382797", "name": "__main__", "level": "INFO", "message": "Action: 6, Reward: tensor([-21.3626], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T12:24:26.753058", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 4 selected."}
{"time": "2024-06-03T12:24:38.849412", "name": "__main__", "level": "INFO", "message": "Action: 4, Reward: tensor([-22.2967], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T12:24:39.679278", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 12 selected."}
{"time": "2024-06-03T12:24:52.403656", "name": "__main__", "level": "INFO", "message": "Action: 12, Reward: tensor([-23.6358], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T12:24:53.232045", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 0 selected."}
{"time": "2024-06-03T12:25:05.679520", "name": "__main__", "level": "INFO", "message": "Action: 0, Reward: tensor([-25.0558], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T12:25:06.973861", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 10 selected."}
{"time": "2024-06-03T12:25:13.325460", "name": "__main__", "level": "INFO", "message": "Action: 10, Reward: tensor([-26.3295], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T12:25:14.439383", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 4 selected."}
{"time": "2024-06-03T12:25:27.075514", "name": "__main__", "level": "INFO", "message": "Action: 4, Reward: tensor([-77.3545], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T12:25:28.461431", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 13 selected."}
{"time": "2024-06-03T12:25:41.037969", "name": "__main__", "level": "INFO", "message": "Action: 13, Reward: tensor([-77.4649], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T12:25:41.756074", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 0 selected."}
{"time": "2024-06-03T12:25:53.935984", "name": "__main__", "level": "INFO", "message": "Episode timed out."}
{"time": "2024-06-03T12:25:54.510170", "name": "__main__", "level": "INFO", "message": "Action: 0, Reward: tensor([-27.2230], grad_fn=<AddBackward0>), Done: True"}
{"time": "2024-06-03T12:25:55.199809", "name": "__main__", "level": "INFO", "message": "Environment reset and takeoff completed."}
{"time": "2024-06-03T12:25:56.854728", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 12 selected."}
{"time": "2024-06-03T12:26:09.642896", "name": "__main__", "level": "INFO", "message": "Action: 12, Reward: tensor([-73.8171], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T12:26:10.451287", "name": "__main__", "level": "INFO", "message": "Epoch 7, Iteration 0: Reward: tensor([-73.8171], grad_fn=<AddBackward0>), Policy Loss: None, Value Loss: None, Total Loss: None, Entropy: None"}
{"time": "2024-06-03T12:26:11.324419", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 13 selected."}
{"time": "2024-06-03T12:26:22.727061", "name": "__main__", "level": "INFO", "message": "Action: 13, Reward: tensor([-73.9549], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T12:26:23.864512", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 2 selected."}
{"time": "2024-06-03T12:26:30.111567", "name": "__main__", "level": "INFO", "message": "Action: 2, Reward: tensor([-74.0372], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T12:26:31.381010", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 10 selected."}
{"time": "2024-06-03T12:26:38.183123", "name": "__main__", "level": "INFO", "message": "Action: 10, Reward: tensor([-24.1289], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T12:26:39.507769", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 8 selected."}
{"time": "2024-06-03T12:26:52.051578", "name": "__main__", "level": "INFO", "message": "Action: 8, Reward: tensor([-24.2899], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T12:26:53.281162", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 14 selected."}
{"time": "2024-06-03T12:27:06.012440", "name": "__main__", "level": "INFO", "message": "Action: 14, Reward: tensor([-24.4363], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T12:27:06.712056", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 5 selected."}
{"time": "2024-06-03T12:27:19.673399", "name": "__main__", "level": "INFO", "message": "Action: 5, Reward: tensor([-24.5686], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T12:27:20.716449", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 8 selected."}
{"time": "2024-06-03T12:27:33.339188", "name": "__main__", "level": "INFO", "message": "Action: 8, Reward: tensor([-24.6968], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T12:27:34.306492", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 0 selected."}
{"time": "2024-06-03T12:27:47.100140", "name": "__main__", "level": "INFO", "message": "Action: 0, Reward: tensor([-24.8280], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T12:27:48.381770", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 14 selected."}
{"time": "2024-06-03T12:28:00.683497", "name": "__main__", "level": "INFO", "message": "Episode timed out."}
{"time": "2024-06-03T12:28:01.090894", "name": "__main__", "level": "INFO", "message": "Action: 14, Reward: tensor([-25.0019], grad_fn=<AddBackward0>), Done: True"}
{"time": "2024-06-03T12:28:01.822479", "name": "__main__", "level": "INFO", "message": "Environment reset and takeoff completed."}
{"time": "2024-06-03T12:28:02.775416", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 10 selected."}
{"time": "2024-06-03T12:28:09.314035", "name": "__main__", "level": "INFO", "message": "Action: 10, Reward: tensor([-20.4511], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T12:28:10.194311", "name": "__main__", "level": "INFO", "message": "Epoch 8, Iteration 0: Reward: tensor([-20.4511], grad_fn=<AddBackward0>), Policy Loss: None, Value Loss: None, Total Loss: None, Entropy: None"}
{"time": "2024-06-03T12:28:11.003641", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 10 selected."}
{"time": "2024-06-03T12:28:16.596330", "name": "__main__", "level": "INFO", "message": "Action: 10, Reward: tensor([-22.1368], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T12:28:17.731078", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 0 selected."}
{"time": "2024-06-03T12:28:30.291295", "name": "__main__", "level": "INFO", "message": "Action: 0, Reward: tensor([-74.0579], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T12:28:31.620709", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 1 selected."}
{"time": "2024-06-03T12:28:43.542725", "name": "__main__", "level": "INFO", "message": "Action: 1, Reward: tensor([-24.1627], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T12:28:44.437757", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 8 selected."}
{"time": "2024-06-03T12:28:56.422993", "name": "__main__", "level": "INFO", "message": "Action: 8, Reward: tensor([-24.3239], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T12:28:57.368570", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 11 selected."}
{"time": "2024-06-03T12:29:03.032243", "name": "__main__", "level": "INFO", "message": "Action: 11, Reward: tensor([-23.9985], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T12:29:03.604918", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 2 selected."}
{"time": "2024-06-03T12:29:09.931156", "name": "__main__", "level": "INFO", "message": "Action: 2, Reward: tensor([-24.1018], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T12:29:10.489383", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 1 selected."}
{"time": "2024-06-03T12:29:21.901397", "name": "__main__", "level": "INFO", "message": "Action: 1, Reward: tensor([-23.9316], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T12:29:22.413753", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 2 selected."}
{"time": "2024-06-03T12:29:29.011331", "name": "__main__", "level": "INFO", "message": "Action: 2, Reward: tensor([-24.0417], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T12:29:30.346092", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 6 selected."}
{"time": "2024-06-03T12:29:36.384588", "name": "__main__", "level": "INFO", "message": "Action: 6, Reward: tensor([-24.1445], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T12:29:37.594461", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 0 selected."}
{"time": "2024-06-03T12:29:49.529169", "name": "__main__", "level": "INFO", "message": "Action: 0, Reward: tensor([-24.2832], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T12:29:50.457557", "name": "__main__", "level": "INFO", "message": "Epoch 8, Iteration 10: Reward: tensor([-309.6338], grad_fn=<AddBackward0>), Policy Loss: None, Value Loss: None, Total Loss: None, Entropy: None"}
{"time": "2024-06-03T12:29:51.250672", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 0 selected."}
{"time": "2024-06-03T12:30:03.073207", "name": "__main__", "level": "INFO", "message": "Episode timed out."}
{"time": "2024-06-03T12:30:03.351442", "name": "__main__", "level": "INFO", "message": "Action: 0, Reward: tensor([-24.9155], grad_fn=<AddBackward0>), Done: True"}
{"time": "2024-06-03T12:30:03.914466", "name": "__main__", "level": "INFO", "message": "Environment reset and takeoff completed."}
{"time": "2024-06-03T12:30:05.187576", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 3 selected."}
{"time": "2024-06-03T12:30:11.230829", "name": "__main__", "level": "INFO", "message": "Action: 3, Reward: tensor([-20.6662], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T12:30:11.683516", "name": "__main__", "level": "INFO", "message": "Epoch 9, Iteration 0: Reward: tensor([-20.6662], grad_fn=<AddBackward0>), Policy Loss: None, Value Loss: None, Total Loss: None, Entropy: None"}
{"time": "2024-06-03T12:30:12.210291", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 3 selected."}
{"time": "2024-06-03T12:30:18.008624", "name": "__main__", "level": "INFO", "message": "Action: 3, Reward: tensor([-21.0325], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T12:30:19.058070", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 8 selected."}
{"time": "2024-06-03T12:30:30.822662", "name": "__main__", "level": "INFO", "message": "Action: 8, Reward: tensor([-74.0322], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T12:30:31.551370", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 2 selected."}
{"time": "2024-06-03T12:30:37.936048", "name": "__main__", "level": "INFO", "message": "Action: 2, Reward: tensor([-74.0917], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T12:30:39.340482", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 2 selected."}
{"time": "2024-06-03T12:30:46.003287", "name": "__main__", "level": "INFO", "message": "Action: 2, Reward: tensor([-24.1971], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T12:30:47.064377", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 14 selected."}
{"time": "2024-06-03T12:30:59.284459", "name": "__main__", "level": "INFO", "message": "Action: 14, Reward: tensor([-24.3629], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T12:31:00.324903", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 6 selected."}
{"time": "2024-06-03T12:31:07.088352", "name": "__main__", "level": "INFO", "message": "Action: 6, Reward: tensor([-24.3841], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T12:31:08.258787", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 11 selected."}
{"time": "2024-06-03T12:31:15.092852", "name": "__main__", "level": "INFO", "message": "Action: 11, Reward: tensor([-23.5534], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T12:31:16.467093", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 9 selected."}
{"time": "2024-06-03T12:31:29.171011", "name": "__main__", "level": "INFO", "message": "Action: 9, Reward: tensor([-20.1364], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T12:31:30.209944", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 1 selected."}
{"time": "2024-06-03T12:31:42.964333", "name": "__main__", "level": "INFO", "message": "Action: 1, Reward: tensor([-19.1860], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T12:31:44.168721", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 3 selected."}
{"time": "2024-06-03T12:31:50.956995", "name": "__main__", "level": "INFO", "message": "Action: 3, Reward: tensor([-19.2350], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T12:31:51.645123", "name": "__main__", "level": "INFO", "message": "Epoch 9, Iteration 10: Reward: tensor([-344.8773], grad_fn=<AddBackward0>), Policy Loss: None, Value Loss: None, Total Loss: None, Entropy: None"}
{"time": "2024-06-03T12:31:52.751424", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 11 selected."}
{"time": "2024-06-03T12:31:59.123738", "name": "__main__", "level": "INFO", "message": "Action: 11, Reward: tensor([-18.3667], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T12:32:00.311963", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 9 selected."}
{"time": "2024-06-03T12:32:12.245008", "name": "__main__", "level": "INFO", "message": "Episode timed out."}
{"time": "2024-06-03T12:32:12.713793", "name": "__main__", "level": "INFO", "message": "Action: 9, Reward: tensor([-15.2723], grad_fn=<AddBackward0>), Done: True"}
{"time": "2024-06-03T12:32:14.027458", "name": "__main__", "level": "INFO", "message": "Dropped rows with NA values."}
{"time": "2024-06-03T12:34:02.146260", "name": "__main__", "level": "INFO", "message": "Time Series plot created successfully for steps vs values."}
{"time": "2024-06-03T12:34:28.748316", "name": "__main__", "level": "INFO", "message": "Histogram plotted successfully for column: values."}
{"time": "2024-06-03T12:34:47.149306", "name": "__main__", "level": "INFO", "message": "Correlation matrix heatmap generated successfully."}
{"time": "2024-06-03T12:35:04.709196", "name": "__main__", "level": "INFO", "message": "Scatter plot created successfully for steps vs values."}
{"time": "2024-06-03T12:40:43.811032", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Using device: cpu"}
{"time": "2024-06-03T12:40:46.705193", "name": "__main__", "level": "INFO", "message": "DataVisualizer initialized with Seaborn style set to 'whitegrid'."}
{"time": "2024-06-03T12:40:46.782247", "name": "__main__", "level": "INFO", "message": "Loading checkpoint from e:\\Project\\models/checkpoints\\ppo_agent_checkpoint.pt"}
{"time": "2024-06-03T12:40:49.451079", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Model loaded"}
{"time": "2024-06-03T12:40:49.466925", "name": "__main__", "level": "INFO", "message": "Resuming training from epoch 1"}
{"time": "2024-06-03T12:40:49.512081", "name": "__main__", "level": "INFO", "message": "Environment reset and takeoff completed."}
{"time": "2024-06-03T12:40:50.807579", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 2 selected."}
{"time": "2024-06-03T12:40:57.646173", "name": "__main__", "level": "INFO", "message": "Action: 2, Reward: tensor([-21.9299], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T12:40:58.548726", "name": "__main__", "level": "INFO", "message": "Epoch 1, Iteration 0: Reward: tensor([-21.9299], grad_fn=<AddBackward0>), Policy Loss: None, Value Loss: None, Total Loss: None, Entropy: None"}
{"time": "2024-06-03T12:40:59.588847", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 12 selected."}
{"time": "2024-06-03T12:41:12.464754", "name": "__main__", "level": "INFO", "message": "Action: 12, Reward: tensor([-22.6393], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T12:41:13.608835", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 5 selected."}
{"time": "2024-06-03T12:41:26.454219", "name": "__main__", "level": "INFO", "message": "Action: 5, Reward: tensor([-23.0668], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T12:41:27.824142", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 9 selected."}
{"time": "2024-06-03T12:41:40.314921", "name": "__main__", "level": "INFO", "message": "Action: 9, Reward: tensor([-21.1836], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T12:41:41.309888", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 4 selected."}
{"time": "2024-06-03T12:41:53.557793", "name": "__main__", "level": "INFO", "message": "Action: 4, Reward: tensor([-20.4096], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T12:41:54.550306", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 7 selected."}
{"time": "2024-06-03T12:42:00.583733", "name": "__main__", "level": "INFO", "message": "Action: 7, Reward: tensor([-20.2180], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T12:42:01.270876", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 12 selected."}
{"time": "2024-06-03T12:42:13.426404", "name": "__main__", "level": "INFO", "message": "Action: 12, Reward: tensor([-21.0988], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T12:42:14.485778", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 14 selected."}
{"time": "2024-06-03T12:42:27.008812", "name": "__main__", "level": "INFO", "message": "Action: 14, Reward: tensor([-22.0579], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T12:42:28.334402", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 15 selected."}
{"time": "2024-06-03T12:42:40.950369", "name": "__main__", "level": "INFO", "message": "Action: 15, Reward: tensor([-22.2747], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T12:42:42.356162", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 16 selected."}
{"time": "2024-06-03T12:42:54.492359", "name": "__main__", "level": "INFO", "message": "Episode timed out."}
{"time": "2024-06-03T12:42:54.869196", "name": "__main__", "level": "INFO", "message": "Action: 16, Reward: tensor([-22.4385], grad_fn=<AddBackward0>), Done: True"}
{"time": "2024-06-03T12:42:55.573024", "name": "__main__", "level": "INFO", "message": "Environment reset and takeoff completed."}
{"time": "2024-06-03T12:42:56.439124", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 8 selected."}
{"time": "2024-06-03T12:43:08.834473", "name": "__main__", "level": "INFO", "message": "Action: 8, Reward: tensor([-20.8966], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T12:43:09.595923", "name": "__main__", "level": "INFO", "message": "Epoch 2, Iteration 0: Reward: tensor([-20.8966], grad_fn=<AddBackward0>), Policy Loss: None, Value Loss: None, Total Loss: None, Entropy: None"}
{"time": "2024-06-03T12:43:10.232177", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 5 selected."}
{"time": "2024-06-03T12:43:23.066268", "name": "__main__", "level": "INFO", "message": "Action: 5, Reward: tensor([-22.6262], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T12:43:24.237940", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 12 selected."}
{"time": "2024-06-03T12:43:36.692572", "name": "__main__", "level": "INFO", "message": "Action: 12, Reward: tensor([-23.4417], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T12:43:38.029387", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 2 selected."}
{"time": "2024-06-03T12:43:44.584843", "name": "__main__", "level": "INFO", "message": "Action: 2, Reward: tensor([-23.6734], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T12:43:45.974166", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 2 selected."}
{"time": "2024-06-03T12:43:52.471398", "name": "__main__", "level": "INFO", "message": "Action: 2, Reward: tensor([-23.9301], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T12:43:53.879328", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 8 selected."}
{"time": "2024-06-03T12:44:06.433734", "name": "__main__", "level": "INFO", "message": "Action: 8, Reward: tensor([-74.7434], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T12:44:07.572832", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 4 selected."}
{"time": "2024-06-03T12:44:19.476712", "name": "__main__", "level": "INFO", "message": "Action: 4, Reward: tensor([-24.8769], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T12:44:20.930285", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 4 selected."}
{"time": "2024-06-03T12:44:33.683415", "name": "__main__", "level": "INFO", "message": "Action: 4, Reward: tensor([-25.0319], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T12:44:34.958873", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 8 selected."}
{"time": "2024-06-03T12:44:47.814704", "name": "__main__", "level": "INFO", "message": "Action: 8, Reward: tensor([-25.1625], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T12:44:49.233404", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 0 selected."}
{"time": "2024-06-03T12:45:01.585044", "name": "__main__", "level": "INFO", "message": "Episode timed out."}
{"time": "2024-06-03T12:45:02.151848", "name": "__main__", "level": "INFO", "message": "Action: 0, Reward: tensor([-25.2963], grad_fn=<AddBackward0>), Done: True"}
{"time": "2024-06-03T12:45:02.918267", "name": "__main__", "level": "INFO", "message": "Environment reset and takeoff completed."}
{"time": "2024-06-03T12:45:04.463871", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 1 selected."}
{"time": "2024-06-03T12:45:16.979756", "name": "__main__", "level": "INFO", "message": "Action: 1, Reward: tensor([-73.2076], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T12:45:17.728724", "name": "__main__", "level": "INFO", "message": "Epoch 3, Iteration 0: Reward: tensor([-73.2076], grad_fn=<AddBackward0>), Policy Loss: None, Value Loss: None, Total Loss: None, Entropy: None"}
{"time": "2024-06-03T12:45:18.665012", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 5 selected."}
{"time": "2024-06-03T12:45:31.300918", "name": "__main__", "level": "INFO", "message": "Action: 5, Reward: tensor([-23.7042], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T12:45:32.478620", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 14 selected."}
{"time": "2024-06-03T12:45:44.290241", "name": "__main__", "level": "INFO", "message": "Action: 14, Reward: tensor([-24.6020], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T12:45:45.506886", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 5 selected."}
{"time": "2024-06-03T12:45:57.849649", "name": "__main__", "level": "INFO", "message": "Action: 5, Reward: tensor([-25.8698], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T12:45:59.146219", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 7 selected."}
{"time": "2024-06-03T12:46:05.648450", "name": "__main__", "level": "INFO", "message": "Action: 7, Reward: tensor([-26.5121], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T12:46:06.866650", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 5 selected."}
{"time": "2024-06-03T12:46:19.445107", "name": "__main__", "level": "INFO", "message": "Action: 5, Reward: tensor([-27.9847], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T12:46:20.639295", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 3 selected."}
{"time": "2024-06-03T12:46:27.388604", "name": "__main__", "level": "INFO", "message": "Action: 3, Reward: tensor([-28.3049], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T12:46:28.719177", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 15 selected."}
{"time": "2024-06-03T12:46:41.441165", "name": "__main__", "level": "INFO", "message": "Action: 15, Reward: tensor([-28.1955], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T12:46:42.855043", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 2 selected."}
{"time": "2024-06-03T12:46:49.475223", "name": "__main__", "level": "INFO", "message": "Action: 2, Reward: tensor([-28.3694], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T12:46:50.407053", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 0 selected."}
{"time": "2024-06-03T12:47:02.595219", "name": "__main__", "level": "INFO", "message": "Action: 0, Reward: tensor([-28.1251], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T12:47:03.876039", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 11 selected."}
{"time": "2024-06-03T12:47:09.710288", "name": "__main__", "level": "INFO", "message": "Episode timed out."}
{"time": "2024-06-03T12:47:10.117983", "name": "__main__", "level": "INFO", "message": "Action: 11, Reward: tensor([-27.3610], grad_fn=<AddBackward0>), Done: True"}
{"time": "2024-06-03T12:47:10.879259", "name": "__main__", "level": "INFO", "message": "Epoch 3, Iteration 10: Reward: tensor([-342.2364], grad_fn=<AddBackward0>), Policy Loss: None, Value Loss: None, Total Loss: None, Entropy: None"}
{"time": "2024-06-03T12:47:11.238840", "name": "__main__", "level": "INFO", "message": "Environment reset and takeoff completed."}
{"time": "2024-06-03T12:47:12.920077", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 0 selected."}
{"time": "2024-06-03T12:47:25.853939", "name": "__main__", "level": "INFO", "message": "Action: 0, Reward: tensor([-73.4598], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T12:47:26.386070", "name": "__main__", "level": "INFO", "message": "Epoch 4, Iteration 0: Reward: tensor([-73.4598], grad_fn=<AddBackward0>), Policy Loss: None, Value Loss: None, Total Loss: None, Entropy: None"}
{"time": "2024-06-03T12:47:27.398565", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 14 selected."}
{"time": "2024-06-03T12:47:40.159071", "name": "__main__", "level": "INFO", "message": "Action: 14, Reward: tensor([-24.2943], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T12:47:41.386266", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 13 selected."}
{"time": "2024-06-03T12:47:53.891918", "name": "__main__", "level": "INFO", "message": "Action: 13, Reward: tensor([-24.5271], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T12:47:55.203676", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 13 selected."}
{"time": "2024-06-03T12:48:07.958421", "name": "__main__", "level": "INFO", "message": "Action: 13, Reward: tensor([-24.9323], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T12:48:09.350334", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 14 selected."}
{"time": "2024-06-03T12:48:22.232816", "name": "__main__", "level": "INFO", "message": "Action: 14, Reward: tensor([-26.6796], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T12:48:23.735674", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 5 selected."}
{"time": "2024-06-03T12:48:36.314092", "name": "__main__", "level": "INFO", "message": "Action: 5, Reward: tensor([-28.8332], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T12:48:37.577835", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 12 selected."}
{"time": "2024-06-03T12:48:50.319499", "name": "__main__", "level": "INFO", "message": "Action: 12, Reward: tensor([-29.2838], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T12:48:51.741487", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 2 selected."}
{"time": "2024-06-03T12:48:58.417619", "name": "__main__", "level": "INFO", "message": "Action: 2, Reward: tensor([-29.6062], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T12:48:59.774726", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 6 selected."}
{"time": "2024-06-03T12:49:06.545524", "name": "__main__", "level": "INFO", "message": "Action: 6, Reward: tensor([-29.5435], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T12:49:07.881786", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 0 selected."}
{"time": "2024-06-03T12:49:20.117255", "name": "__main__", "level": "INFO", "message": "Episode timed out."}
{"time": "2024-06-03T12:49:20.676416", "name": "__main__", "level": "INFO", "message": "Action: 0, Reward: tensor([-30.3778], grad_fn=<AddBackward0>), Done: True"}
{"time": "2024-06-03T12:49:21.406462", "name": "__main__", "level": "INFO", "message": "Environment reset and takeoff completed."}
{"time": "2024-06-03T12:49:23.039649", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 5 selected."}
{"time": "2024-06-03T12:49:35.151446", "name": "__main__", "level": "INFO", "message": "Action: 5, Reward: tensor([-73.8184], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T12:49:35.791120", "name": "__main__", "level": "INFO", "message": "Epoch 5, Iteration 0: Reward: tensor([-73.8184], grad_fn=<AddBackward0>), Policy Loss: None, Value Loss: None, Total Loss: None, Entropy: None"}
{"time": "2024-06-03T12:49:36.270970", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 11 selected."}
{"time": "2024-06-03T12:49:42.992563", "name": "__main__", "level": "INFO", "message": "Action: 11, Reward: tensor([-22.9771], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T12:49:44.209718", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 0 selected."}
{"time": "2024-06-03T12:49:56.862470", "name": "__main__", "level": "INFO", "message": "Action: 0, Reward: tensor([-22.0366], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T12:49:58.297674", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 2 selected."}
{"time": "2024-06-03T12:50:05.120356", "name": "__main__", "level": "INFO", "message": "Action: 2, Reward: tensor([-22.1583], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T12:50:06.381081", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 0 selected."}
{"time": "2024-06-03T12:50:18.998528", "name": "__main__", "level": "INFO", "message": "Action: 0, Reward: tensor([-22.8756], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T12:50:20.342353", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 1 selected."}
{"time": "2024-06-03T12:50:33.065222", "name": "__main__", "level": "INFO", "message": "Action: 1, Reward: tensor([-22.8173], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T12:50:34.293933", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 2 selected."}
{"time": "2024-06-03T12:50:39.848990", "name": "__main__", "level": "INFO", "message": "Action: 2, Reward: tensor([-23.1356], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T12:50:41.062275", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 1 selected."}
{"time": "2024-06-03T12:50:53.695396", "name": "__main__", "level": "INFO", "message": "Action: 1, Reward: tensor([-22.8391], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T12:50:54.961020", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 3 selected."}
{"time": "2024-06-03T12:51:01.466734", "name": "__main__", "level": "INFO", "message": "Action: 3, Reward: tensor([-22.6859], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T12:51:02.764946", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 15 selected."}
{"time": "2024-06-03T12:51:15.027225", "name": "__main__", "level": "INFO", "message": "Action: 15, Reward: tensor([-21.8917], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T12:51:16.401139", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 11 selected."}
{"time": "2024-06-03T12:51:22.625765", "name": "__main__", "level": "INFO", "message": "Episode timed out."}
{"time": "2024-06-03T12:51:23.205354", "name": "__main__", "level": "INFO", "message": "Action: 11, Reward: tensor([-20.9171], grad_fn=<AddBackward0>), Done: True"}
{"time": "2024-06-03T12:51:23.970507", "name": "__main__", "level": "INFO", "message": "Epoch 5, Iteration 10: Reward: tensor([-298.1526], grad_fn=<AddBackward0>), Policy Loss: None, Value Loss: None, Total Loss: None, Entropy: None"}
{"time": "2024-06-03T12:51:24.500547", "name": "__main__", "level": "INFO", "message": "Environment reset and takeoff completed."}
{"time": "2024-06-03T12:51:26.189622", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 14 selected."}
{"time": "2024-06-03T12:51:38.843640", "name": "__main__", "level": "INFO", "message": "Action: 14, Reward: tensor([-73.8977], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T12:51:39.642498", "name": "__main__", "level": "INFO", "message": "Epoch 6, Iteration 0: Reward: tensor([-73.8977], grad_fn=<AddBackward0>), Policy Loss: None, Value Loss: None, Total Loss: None, Entropy: None"}
{"time": "2024-06-03T12:51:39.929256", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 8 selected."}
{"time": "2024-06-03T12:51:52.497967", "name": "__main__", "level": "INFO", "message": "Action: 8, Reward: tensor([-24.0279], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T12:51:53.810985", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 4 selected."}
{"time": "2024-06-03T12:52:06.536213", "name": "__main__", "level": "INFO", "message": "Action: 4, Reward: tensor([-24.1535], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T12:52:07.940727", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 9 selected."}
{"time": "2024-06-03T12:52:20.211807", "name": "__main__", "level": "INFO", "message": "Action: 9, Reward: tensor([-23.1420], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T12:52:21.587430", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 4 selected."}
{"time": "2024-06-03T12:52:35.422935", "name": "__main__", "level": "INFO", "message": "Action: 4, Reward: tensor([-22.3097], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T12:52:36.745176", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 14 selected."}
{"time": "2024-06-03T12:52:49.092281", "name": "__main__", "level": "INFO", "message": "Action: 14, Reward: tensor([-21.7945], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T12:52:50.394662", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 3 selected."}
{"time": "2024-06-03T12:52:56.823811", "name": "__main__", "level": "INFO", "message": "Action: 3, Reward: tensor([-21.4972], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T12:52:57.902868", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 10 selected."}
{"time": "2024-06-03T12:53:04.257327", "name": "__main__", "level": "INFO", "message": "Action: 10, Reward: tensor([-22.4390], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T12:53:04.955103", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 16 selected."}
{"time": "2024-06-03T12:53:17.387867", "name": "__main__", "level": "INFO", "message": "Action: 16, Reward: tensor([-23.1504], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T12:53:18.553331", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 6 selected."}
{"time": "2024-06-03T12:53:23.748224", "name": "__main__", "level": "INFO", "message": "Action: 6, Reward: tensor([-23.7152], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T12:53:24.678012", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 3 selected."}
{"time": "2024-06-03T12:53:30.789538", "name": "__main__", "level": "INFO", "message": "Episode timed out."}
{"time": "2024-06-03T12:53:31.289485", "name": "__main__", "level": "INFO", "message": "Action: 3, Reward: tensor([-23.9484], grad_fn=<AddBackward0>), Done: True"}
{"time": "2024-06-03T12:53:32.178840", "name": "__main__", "level": "INFO", "message": "Epoch 6, Iteration 10: Reward: tensor([-304.0754], grad_fn=<AddBackward0>), Policy Loss: None, Value Loss: None, Total Loss: None, Entropy: None"}
{"time": "2024-06-03T12:53:32.256288", "name": "__main__", "level": "INFO", "message": "Early stopping triggered after 7 epochs."}
{"time": "2024-06-03T12:53:33.846556", "name": "__main__", "level": "INFO", "message": "Dropped rows with NA values."}
{"time": "2024-06-03T12:54:36.165148", "name": "__main__", "level": "INFO", "message": "Time Series plot created successfully for steps vs values."}
{"time": "2024-06-03T12:57:04.515622", "name": "__main__", "level": "INFO", "message": "Histogram plotted successfully for column: values."}
{"time": "2024-06-03T12:57:55.363411", "name": "__main__", "level": "INFO", "message": "Correlation matrix heatmap generated successfully."}
{"time": "2024-06-03T13:00:14.758046", "name": "__main__", "level": "INFO", "message": "Scatter plot created successfully for steps vs values."}
{"time": "2024-06-03T13:10:45.081491", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Using device: cpu"}
{"time": "2024-06-03T13:10:47.956879", "name": "__main__", "level": "INFO", "message": "DataVisualizer initialized with Seaborn style set to 'whitegrid'."}
{"time": "2024-06-03T13:10:48.110619", "name": "__main__", "level": "INFO", "message": "Loading checkpoint from e:\\Project\\models/checkpoints\\ppo_agent_checkpoint.pt"}
{"time": "2024-06-03T13:10:52.170179", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Model loaded"}
{"time": "2024-06-03T13:10:52.215644", "name": "__main__", "level": "INFO", "message": "Resuming training from epoch 1"}
{"time": "2024-06-03T13:10:52.513921", "name": "__main__", "level": "INFO", "message": "Environment reset and takeoff completed."}
{"time": "2024-06-03T13:10:54.251479", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 5 selected."}
{"time": "2024-06-03T13:14:07.523133", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Using device: cpu"}
{"time": "2024-06-03T13:14:10.055199", "name": "__main__", "level": "INFO", "message": "DataVisualizer initialized with Seaborn style set to 'whitegrid'."}
{"time": "2024-06-03T13:14:10.177648", "name": "__main__", "level": "INFO", "message": "Loading checkpoint from e:\\Project\\models/checkpoints\\ppo_agent_checkpoint.pt"}
{"time": "2024-06-03T13:14:13.377085", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Model loaded"}
{"time": "2024-06-03T13:14:13.485510", "name": "__main__", "level": "INFO", "message": "Resuming training from epoch 1"}
{"time": "2024-06-03T13:14:13.888224", "name": "__main__", "level": "INFO", "message": "Environment reset and takeoff completed."}
{"time": "2024-06-03T13:14:15.466923", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 8 selected."}
{"time": "2024-06-03T13:14:28.299720", "name": "__main__", "level": "INFO", "message": "Action: 8, Reward: tensor([-73.8770], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T13:14:29.125746", "name": "__main__", "level": "INFO", "message": "Epoch 1, Iteration 0: Reward: tensor([-73.8770], grad_fn=<AddBackward0>), Policy Loss: None, Value Loss: None, Total Loss: None, Entropy: None"}
{"time": "2024-06-03T13:14:30.127903", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 3 selected."}
{"time": "2024-06-03T13:14:36.812260", "name": "__main__", "level": "INFO", "message": "Action: 3, Reward: tensor([-23.9703], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T13:14:37.859280", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 9 selected."}
{"time": "2024-06-03T13:14:50.583383", "name": "__main__", "level": "INFO", "message": "Action: 9, Reward: tensor([-22.2869], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T13:14:51.385382", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 5 selected."}
{"time": "2024-06-03T13:15:03.721263", "name": "__main__", "level": "INFO", "message": "Action: 5, Reward: tensor([-21.4110], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T13:15:04.664710", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 15 selected."}
{"time": "2024-06-03T13:15:17.567280", "name": "__main__", "level": "INFO", "message": "Action: 15, Reward: tensor([-21.3748], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T13:15:19.033664", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 8 selected."}
{"time": "2024-06-03T13:15:31.764890", "name": "__main__", "level": "INFO", "message": "Action: 8, Reward: tensor([-24.0044], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T13:15:33.216132", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 14 selected."}
{"time": "2024-06-03T13:15:45.706629", "name": "__main__", "level": "INFO", "message": "Action: 14, Reward: tensor([-74.9845], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T13:15:46.680668", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 12 selected."}
{"time": "2024-06-03T13:15:59.427521", "name": "__main__", "level": "INFO", "message": "Action: 12, Reward: tensor([-25.1309], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T13:16:00.299660", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 0 selected."}
{"time": "2024-06-03T13:16:12.552663", "name": "__main__", "level": "INFO", "message": "Action: 0, Reward: tensor([-25.2769], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T13:16:13.739506", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 15 selected."}
{"time": "2024-06-03T13:16:25.440818", "name": "__main__", "level": "INFO", "message": "Episode timed out."}
{"time": "2024-06-03T13:16:25.500553", "name": "__main__", "level": "INFO", "message": "Action: 15, Reward: tensor([-25.3827], grad_fn=<AddBackward0>), Done: True"}
{"time": "2024-06-03T13:16:26.187187", "name": "__main__", "level": "INFO", "message": "Environment reset and takeoff completed."}
{"time": "2024-06-03T13:16:27.572745", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 16 selected."}
{"time": "2024-06-03T13:16:40.051973", "name": "__main__", "level": "INFO", "message": "Action: 16, Reward: tensor([-23.3492], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T13:16:40.691895", "name": "__main__", "level": "INFO", "message": "Epoch 2, Iteration 0: Reward: tensor([-23.3492], grad_fn=<AddBackward0>), Policy Loss: None, Value Loss: None, Total Loss: None, Entropy: None"}
{"time": "2024-06-03T13:16:41.050456", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 16 selected."}
{"time": "2024-06-03T13:16:53.281201", "name": "__main__", "level": "INFO", "message": "Action: 16, Reward: tensor([-23.4702], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T13:16:53.579892", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 2 selected."}
{"time": "2024-06-03T13:17:00.025302", "name": "__main__", "level": "INFO", "message": "Action: 2, Reward: tensor([-23.6086], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T13:17:00.869308", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 14 selected."}
{"time": "2024-06-03T13:17:13.570197", "name": "__main__", "level": "INFO", "message": "Action: 14, Reward: tensor([-23.7759], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T13:17:14.805413", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 12 selected."}
{"time": "2024-06-03T13:17:26.621044", "name": "__main__", "level": "INFO", "message": "Action: 12, Reward: tensor([-24.7972], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T13:17:27.628536", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 16 selected."}
{"time": "2024-06-03T13:17:40.165288", "name": "__main__", "level": "INFO", "message": "Action: 16, Reward: tensor([-25.3602], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T13:17:41.540936", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 12 selected."}
{"time": "2024-06-03T13:17:53.971803", "name": "__main__", "level": "INFO", "message": "Action: 12, Reward: tensor([-26.8760], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T13:17:55.278150", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 4 selected."}
{"time": "2024-06-03T13:18:07.837051", "name": "__main__", "level": "INFO", "message": "Action: 4, Reward: tensor([-28.2464], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T13:18:08.998439", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 12 selected."}
{"time": "2024-06-03T13:18:21.175139", "name": "__main__", "level": "INFO", "message": "Action: 12, Reward: tensor([-30.6605], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T13:18:22.174440", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 0 selected."}
{"time": "2024-06-03T13:18:34.151922", "name": "__main__", "level": "INFO", "message": "Episode timed out."}
{"time": "2024-06-03T13:18:34.638439", "name": "__main__", "level": "INFO", "message": "Action: 0, Reward: tensor([-33.1924], grad_fn=<AddBackward0>), Done: True"}
{"time": "2024-06-03T13:18:35.356056", "name": "__main__", "level": "INFO", "message": "Environment reset and takeoff completed."}
{"time": "2024-06-03T13:18:36.765890", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 11 selected."}
{"time": "2024-06-03T13:18:43.326758", "name": "__main__", "level": "INFO", "message": "Action: 11, Reward: tensor([-72.9635], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T13:18:43.779110", "name": "__main__", "level": "INFO", "message": "Epoch 3, Iteration 0: Reward: tensor([-72.9635], grad_fn=<AddBackward0>), Policy Loss: None, Value Loss: None, Total Loss: None, Entropy: None"}
{"time": "2024-06-03T13:18:44.855345", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 5 selected."}
{"time": "2024-06-03T13:18:57.431927", "name": "__main__", "level": "INFO", "message": "Action: 5, Reward: tensor([-21.7229], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T13:18:58.649812", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 13 selected."}
{"time": "2024-06-03T13:19:11.108831", "name": "__main__", "level": "INFO", "message": "Action: 13, Reward: tensor([-22.0833], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T13:19:12.313755", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 7 selected."}
{"time": "2024-06-03T13:19:17.613797", "name": "__main__", "level": "INFO", "message": "Action: 7, Reward: tensor([-22.4088], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T13:19:18.873799", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 10 selected."}
{"time": "2024-06-03T13:19:25.581379", "name": "__main__", "level": "INFO", "message": "Action: 10, Reward: tensor([-23.5560], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T13:19:26.543567", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 15 selected."}
{"time": "2024-06-03T13:19:38.278485", "name": "__main__", "level": "INFO", "message": "Action: 15, Reward: tensor([-24.6303], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T13:19:38.812514", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 0 selected."}
{"time": "2024-06-03T13:19:51.206962", "name": "__main__", "level": "INFO", "message": "Action: 0, Reward: tensor([-24.9146], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T13:19:52.530124", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 3 selected."}
{"time": "2024-06-03T13:19:59.231009", "name": "__main__", "level": "INFO", "message": "Action: 3, Reward: tensor([-25.3120], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T13:20:00.544995", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 1 selected."}
{"time": "2024-06-03T13:20:12.629561", "name": "__main__", "level": "INFO", "message": "Action: 1, Reward: tensor([-75.7144], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T13:20:13.667912", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 4 selected."}
{"time": "2024-06-03T13:20:26.302363", "name": "__main__", "level": "INFO", "message": "Action: 4, Reward: tensor([-25.8395], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T13:20:27.192260", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 16 selected."}
{"time": "2024-06-03T13:20:38.920334", "name": "__main__", "level": "INFO", "message": "Episode timed out."}
{"time": "2024-06-03T13:20:38.937816", "name": "__main__", "level": "INFO", "message": "Action: 16, Reward: tensor([-25.9471], grad_fn=<AddBackward0>), Done: True"}
{"time": "2024-06-03T13:20:39.513503", "name": "__main__", "level": "INFO", "message": "Epoch 3, Iteration 10: Reward: tensor([-365.0925], grad_fn=<AddBackward0>), Policy Loss: None, Value Loss: None, Total Loss: None, Entropy: None"}
{"time": "2024-06-03T13:20:39.905564", "name": "__main__", "level": "INFO", "message": "Environment reset and takeoff completed."}
{"time": "2024-06-03T13:20:41.250103", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 0 selected."}
{"time": "2024-06-03T13:20:53.021196", "name": "__main__", "level": "INFO", "message": "Action: 0, Reward: tensor([-73.5036], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T13:20:53.723554", "name": "__main__", "level": "INFO", "message": "Epoch 4, Iteration 0: Reward: tensor([-73.5036], grad_fn=<AddBackward0>), Policy Loss: None, Value Loss: None, Total Loss: None, Entropy: None"}
{"time": "2024-06-03T13:20:54.358526", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 14 selected."}
{"time": "2024-06-03T13:21:06.853866", "name": "__main__", "level": "INFO", "message": "Action: 14, Reward: tensor([-24.3959], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T13:21:07.756549", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 7 selected."}
{"time": "2024-06-03T13:21:13.781728", "name": "__main__", "level": "INFO", "message": "Action: 7, Reward: tensor([-24.6870], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T13:21:14.880243", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 6 selected."}
{"time": "2024-06-03T13:21:21.376406", "name": "__main__", "level": "INFO", "message": "Action: 6, Reward: tensor([-74.9528], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T13:21:22.339071", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 8 selected."}
{"time": "2024-06-03T13:21:35.069896", "name": "__main__", "level": "INFO", "message": "Action: 8, Reward: tensor([-75.1211], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T13:21:36.392648", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 11 selected."}
{"time": "2024-06-03T13:21:43.065941", "name": "__main__", "level": "INFO", "message": "Action: 11, Reward: tensor([-24.8045], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T13:21:44.551400", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 14 selected."}
{"time": "2024-06-03T13:21:57.361198", "name": "__main__", "level": "INFO", "message": "Action: 14, Reward: tensor([-25.2265], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T13:21:58.639291", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 7 selected."}
{"time": "2024-06-03T13:22:05.530384", "name": "__main__", "level": "INFO", "message": "Action: 7, Reward: tensor([-25.5168], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T13:22:06.878228", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 10 selected."}
{"time": "2024-06-03T13:22:12.541030", "name": "__main__", "level": "INFO", "message": "Action: 10, Reward: tensor([-26.5632], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T13:22:13.515758", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 14 selected."}
{"time": "2024-06-03T13:22:25.903522", "name": "__main__", "level": "INFO", "message": "Action: 14, Reward: tensor([-76.7314], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T13:22:26.591739", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 13 selected."}
{"time": "2024-06-03T13:22:38.734857", "name": "__main__", "level": "INFO", "message": "Action: 13, Reward: tensor([-26.8631], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T13:22:38.966024", "name": "__main__", "level": "INFO", "message": "Epoch 4, Iteration 10: Reward: tensor([-478.3659], grad_fn=<AddBackward0>), Policy Loss: None, Value Loss: None, Total Loss: None, Entropy: None"}
{"time": "2024-06-03T13:22:39.502211", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 5 selected."}
{"time": "2024-06-03T13:22:51.200635", "name": "__main__", "level": "INFO", "message": "Episode timed out."}
{"time": "2024-06-03T13:22:51.635293", "name": "__main__", "level": "INFO", "message": "Action: 5, Reward: tensor([-26.9949], grad_fn=<AddBackward0>), Done: True"}
{"time": "2024-06-03T13:22:52.338432", "name": "__main__", "level": "INFO", "message": "Environment reset and takeoff completed."}
{"time": "2024-06-03T13:22:53.692730", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 1 selected."}
{"time": "2024-06-03T13:23:06.600221", "name": "__main__", "level": "INFO", "message": "Action: 1, Reward: tensor([-73.4694], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T13:23:07.329076", "name": "__main__", "level": "INFO", "message": "Epoch 5, Iteration 0: Reward: tensor([-73.4694], grad_fn=<AddBackward0>), Policy Loss: None, Value Loss: None, Total Loss: None, Entropy: None"}
{"time": "2024-06-03T13:23:08.169790", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 15 selected."}
{"time": "2024-06-03T13:23:20.548578", "name": "__main__", "level": "INFO", "message": "Action: 15, Reward: tensor([-74.1694], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T13:23:21.533816", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 14 selected."}
{"time": "2024-06-03T13:23:34.322702", "name": "__main__", "level": "INFO", "message": "Action: 14, Reward: tensor([-23.9856], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T13:23:35.463841", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 14 selected."}
{"time": "2024-06-03T13:23:47.196251", "name": "__main__", "level": "INFO", "message": "Action: 14, Reward: tensor([-23.8372], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T13:23:47.724895", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 8 selected."}
{"time": "2024-06-03T13:24:00.179120", "name": "__main__", "level": "INFO", "message": "Action: 8, Reward: tensor([-74.5382], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T13:24:01.497027", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 2 selected."}
{"time": "2024-06-03T13:24:08.334167", "name": "__main__", "level": "INFO", "message": "Action: 2, Reward: tensor([-24.6262], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T13:24:09.705258", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 10 selected."}
{"time": "2024-06-03T13:24:16.138505", "name": "__main__", "level": "INFO", "message": "Action: 10, Reward: tensor([-24.7105], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T13:24:16.743118", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 7 selected."}
{"time": "2024-06-03T13:24:22.598865", "name": "__main__", "level": "INFO", "message": "Action: 7, Reward: tensor([-24.7693], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T13:24:23.151499", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 8 selected."}
{"time": "2024-06-03T13:24:35.399676", "name": "__main__", "level": "INFO", "message": "Action: 8, Reward: tensor([-24.9008], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T13:24:36.581260", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 11 selected."}
{"time": "2024-06-03T13:24:42.359079", "name": "__main__", "level": "INFO", "message": "Action: 11, Reward: tensor([-24.6694], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T13:24:42.594802", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 5 selected."}
{"time": "2024-06-03T13:24:54.639741", "name": "__main__", "level": "INFO", "message": "Episode timed out."}
{"time": "2024-06-03T13:24:54.688704", "name": "__main__", "level": "INFO", "message": "Action: 5, Reward: tensor([-24.4835], grad_fn=<AddBackward0>), Done: True"}
{"time": "2024-06-03T13:24:55.188537", "name": "__main__", "level": "INFO", "message": "Epoch 5, Iteration 10: Reward: tensor([-418.1597], grad_fn=<AddBackward0>), Policy Loss: None, Value Loss: None, Total Loss: None, Entropy: None"}
{"time": "2024-06-03T13:24:55.658651", "name": "__main__", "level": "INFO", "message": "Environment reset and takeoff completed."}
{"time": "2024-06-03T13:24:57.425302", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 0 selected."}
{"time": "2024-06-03T13:25:09.733166", "name": "__main__", "level": "INFO", "message": "Action: 0, Reward: tensor([-73.8234], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T13:25:10.540537", "name": "__main__", "level": "INFO", "message": "Epoch 6, Iteration 0: Reward: tensor([-73.8234], grad_fn=<AddBackward0>), Policy Loss: None, Value Loss: None, Total Loss: None, Entropy: None"}
{"time": "2024-06-03T13:25:10.607353", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 12 selected."}
{"time": "2024-06-03T13:25:22.503150", "name": "__main__", "level": "INFO", "message": "Action: 12, Reward: tensor([-24.4939], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T13:25:23.357023", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 0 selected."}
{"time": "2024-06-03T13:25:35.722945", "name": "__main__", "level": "INFO", "message": "Action: 0, Reward: tensor([-75.6006], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T13:25:36.891662", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 4 selected."}
{"time": "2024-06-03T13:25:48.268137", "name": "__main__", "level": "INFO", "message": "Action: 4, Reward: tensor([-75.7290], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T13:25:48.751130", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 3 selected."}
{"time": "2024-06-03T13:25:54.644671", "name": "__main__", "level": "INFO", "message": "Action: 3, Reward: tensor([-25.6895], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T13:25:55.954818", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 0 selected."}
{"time": "2024-06-03T13:26:08.148216", "name": "__main__", "level": "INFO", "message": "Action: 0, Reward: tensor([-26.1804], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T13:26:09.051342", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 2 selected."}
{"time": "2024-06-03T13:26:14.672521", "name": "__main__", "level": "INFO", "message": "Action: 2, Reward: tensor([-26.3731], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T13:26:15.906490", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 1 selected."}
{"time": "2024-06-03T13:26:27.527570", "name": "__main__", "level": "INFO", "message": "Action: 1, Reward: tensor([-25.4603], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T13:26:28.521489", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 14 selected."}
{"time": "2024-06-03T13:26:40.209805", "name": "__main__", "level": "INFO", "message": "Action: 14, Reward: tensor([-25.7706], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T13:26:41.176534", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 1 selected."}
{"time": "2024-06-03T13:26:53.527476", "name": "__main__", "level": "INFO", "message": "Action: 1, Reward: tensor([-25.5965], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T13:26:54.726977", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 2 selected."}
{"time": "2024-06-03T13:27:00.668763", "name": "__main__", "level": "INFO", "message": "Episode timed out."}
{"time": "2024-06-03T13:27:01.211766", "name": "__main__", "level": "INFO", "message": "Action: 2, Reward: tensor([-26.1000], grad_fn=<AddBackward0>), Done: True"}
{"time": "2024-06-03T13:27:01.838963", "name": "__main__", "level": "INFO", "message": "Epoch 6, Iteration 10: Reward: tensor([-430.8173], grad_fn=<AddBackward0>), Policy Loss: None, Value Loss: None, Total Loss: None, Entropy: None"}
{"time": "2024-06-03T13:27:02.229963", "name": "__main__", "level": "INFO", "message": "Environment reset and takeoff completed."}
{"time": "2024-06-03T13:27:03.771953", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 16 selected."}
{"time": "2024-06-03T13:27:15.300417", "name": "__main__", "level": "INFO", "message": "Action: 16, Reward: tensor([-73.4724], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T13:27:15.889350", "name": "__main__", "level": "INFO", "message": "Epoch 7, Iteration 0: Reward: tensor([-73.4724], grad_fn=<AddBackward0>), Policy Loss: None, Value Loss: None, Total Loss: None, Entropy: None"}
{"time": "2024-06-03T13:27:16.894830", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 1 selected."}
{"time": "2024-06-03T13:27:28.490156", "name": "__main__", "level": "INFO", "message": "Action: 1, Reward: tensor([-74.0937], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T13:27:28.956412", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 13 selected."}
{"time": "2024-06-03T13:27:40.555027", "name": "__main__", "level": "INFO", "message": "Action: 13, Reward: tensor([-24.2530], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T13:27:41.620352", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 0 selected."}
{"time": "2024-06-03T13:27:53.584962", "name": "__main__", "level": "INFO", "message": "Action: 0, Reward: tensor([-24.1083], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T13:27:54.318442", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 16 selected."}
{"time": "2024-06-03T13:28:07.017128", "name": "__main__", "level": "INFO", "message": "Action: 16, Reward: tensor([-23.9383], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T13:28:08.416769", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 4 selected."}
{"time": "2024-06-03T13:28:20.709160", "name": "__main__", "level": "INFO", "message": "Action: 4, Reward: tensor([-23.8820], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T13:28:21.809437", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 11 selected."}
{"time": "2024-06-03T13:28:28.123858", "name": "__main__", "level": "INFO", "message": "Action: 11, Reward: tensor([-23.0133], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T13:28:29.171774", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 13 selected."}
{"time": "2024-06-03T13:28:40.898789", "name": "__main__", "level": "INFO", "message": "Action: 13, Reward: tensor([-22.3513], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T13:28:42.097479", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 9 selected."}
{"time": "2024-06-03T13:28:54.322814", "name": "__main__", "level": "INFO", "message": "Action: 9, Reward: tensor([-19.7789], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T13:28:55.365423", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 2 selected."}
{"time": "2024-06-03T13:29:01.389137", "name": "__main__", "level": "INFO", "message": "Action: 2, Reward: tensor([-19.1672], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T13:29:02.689764", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 0 selected."}
{"time": "2024-06-03T13:29:14.861574", "name": "__main__", "level": "INFO", "message": "Episode timed out."}
{"time": "2024-06-03T13:29:15.330311", "name": "__main__", "level": "INFO", "message": "Action: 0, Reward: tensor([-18.6951], grad_fn=<AddBackward0>), Done: True"}
{"time": "2024-06-03T13:29:16.204353", "name": "__main__", "level": "INFO", "message": "Epoch 7, Iteration 10: Reward: tensor([-346.7535], grad_fn=<AddBackward0>), Policy Loss: None, Value Loss: None, Total Loss: None, Entropy: None"}
{"time": "2024-06-03T13:29:16.329893", "name": "__main__", "level": "INFO", "message": "Early stopping triggered after 8 epochs."}
{"time": "2024-06-03T13:29:20.950580", "name": "__main__", "level": "INFO", "message": "Dropped rows with NA values."}
{"time": "2024-06-03T13:29:55.186444", "name": "__main__", "level": "INFO", "message": "Time Series plot created successfully for steps vs values."}
{"time": "2024-06-03T13:30:21.461077", "name": "__main__", "level": "INFO", "message": "Histogram plotted successfully for column: values."}
{"time": "2024-06-03T13:30:40.512949", "name": "__main__", "level": "INFO", "message": "Correlation matrix heatmap generated successfully."}
{"time": "2024-06-03T13:31:15.314779", "name": "__main__", "level": "INFO", "message": "Scatter plot created successfully for steps vs values."}
{"time": "2024-06-03T13:36:44.230508", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Using device: cpu"}
{"time": "2024-06-03T13:36:47.253895", "name": "__main__", "level": "INFO", "message": "DataVisualizer initialized with Seaborn style set to 'whitegrid'."}
{"time": "2024-06-03T13:36:47.394807", "name": "__main__", "level": "INFO", "message": "Loading checkpoint from e:\\Project\\models/checkpoints\\ppo_agent_checkpoint.pt"}
{"time": "2024-06-03T13:36:50.944946", "name": "__main__", "level": "ERROR", "message": "Error loading checkpoint: Error(s) in loading state_dict for AdvancedPolicyNetwork:\n\tMissing key(s) in state_dict: \"attention_layers.0.context_vector\", \"attention_layers.0.fc.weight\", \"attention_layers.0.fc.bias\", \"attention_layers.1.context_vector\", \"attention_layers.1.fc.weight\", \"attention_layers.1.fc.bias\". "}
{"time": "2024-06-03T13:36:51.628497", "name": "__main__", "level": "INFO", "message": "Environment reset and takeoff completed."}
{"time": "2024-06-03T17:23:50.419665", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Using device: cpu"}
{"time": "2024-06-03T17:23:53.492300", "name": "__main__", "level": "INFO", "message": "DataVisualizer initialized with Seaborn style set to 'whitegrid'."}
{"time": "2024-06-03T17:23:53.647623", "name": "__main__", "level": "INFO", "message": "Loading checkpoint from e:\\Project\\models/checkpoints\\ppo_agent_checkpoint.pt"}
{"time": "2024-06-03T17:23:56.869286", "name": "__main__", "level": "ERROR", "message": "Error loading checkpoint: Error(s) in loading state_dict for AdvancedPolicyNetwork:\n\tMissing key(s) in state_dict: \"attention_layers.0.context_vector\", \"attention_layers.0.fc.weight\", \"attention_layers.0.fc.bias\", \"attention_layers.1.context_vector\", \"attention_layers.1.fc.weight\", \"attention_layers.1.fc.bias\". "}
{"time": "2024-06-03T17:23:57.371681", "name": "__main__", "level": "INFO", "message": "Environment reset and takeoff completed."}
{"time": "2024-06-03T17:31:24.330784", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Using device: cpu"}
{"time": "2024-06-03T17:31:28.399220", "name": "__main__", "level": "INFO", "message": "DataVisualizer initialized with Seaborn style set to 'whitegrid'."}
{"time": "2024-06-03T17:31:28.554554", "name": "__main__", "level": "INFO", "message": "Loading checkpoint from e:\\Project\\models/checkpoints\\ppo_agent_checkpoint.pt"}
{"time": "2024-06-03T17:31:31.847244", "name": "__main__", "level": "ERROR", "message": "Error loading checkpoint: Error(s) in loading state_dict for AdvancedPolicyNetwork:\n\tMissing key(s) in state_dict: \"attention_layers.0.context_vector\", \"attention_layers.0.fc.weight\", \"attention_layers.0.fc.bias\", \"attention_layers.1.context_vector\", \"attention_layers.1.fc.weight\", \"attention_layers.1.fc.bias\". "}
{"time": "2024-06-03T17:31:32.411880", "name": "__main__", "level": "INFO", "message": "Environment reset and takeoff completed."}
{"time": "2024-06-03T17:31:34.176912", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 2 selected."}
{"time": "2024-06-03T17:31:38.749691", "name": "__main__", "level": "INFO", "message": "Action: 2, Reward: tensor([-124.8774], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T17:31:39.640688", "name": "__main__", "level": "INFO", "message": "Epoch 0, Iteration 0: Reward: tensor([-124.8774], grad_fn=<AddBackward0>), Policy Loss: None, Value Loss: None, Total Loss: None, Entropy: None"}
{"time": "2024-06-03T17:31:40.780069", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 9 selected."}
{"time": "2024-06-03T17:31:49.303718", "name": "__main__", "level": "INFO", "message": "Action: 9, Reward: tensor([-123.6867], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T17:31:50.975437", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 9 selected."}
{"time": "2024-06-03T17:31:59.207762", "name": "__main__", "level": "INFO", "message": "Action: 9, Reward: tensor([-21.7931], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T17:32:00.425532", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 12 selected."}
{"time": "2024-06-03T17:32:08.775444", "name": "__main__", "level": "INFO", "message": "Action: 12, Reward: tensor([-21.0015], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T17:32:10.447837", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 0 selected."}
{"time": "2024-06-03T17:32:18.464019", "name": "__main__", "level": "INFO", "message": "Action: 0, Reward: tensor([-21.1119], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T17:32:19.306888", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 6 selected."}
{"time": "2024-06-03T17:32:23.535486", "name": "__main__", "level": "INFO", "message": "Action: 6, Reward: tensor([-21.3886], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T17:32:24.407476", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 5 selected."}
{"time": "2024-06-03T17:32:32.868933", "name": "__main__", "level": "INFO", "message": "Action: 5, Reward: tensor([-21.4900], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T17:32:33.940575", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 16 selected."}
{"time": "2024-06-03T17:32:43.000787", "name": "__main__", "level": "INFO", "message": "Action: 16, Reward: tensor([-21.5154], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T17:32:44.750516", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 14 selected."}
{"time": "2024-06-03T17:32:53.791223", "name": "__main__", "level": "INFO", "message": "Action: 14, Reward: tensor([-21.9326], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T17:32:55.355269", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 16 selected."}
{"time": "2024-06-03T17:33:04.434354", "name": "__main__", "level": "INFO", "message": "Action: 16, Reward: tensor([-22.3983], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T17:33:05.296438", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 14 selected."}
{"time": "2024-06-03T17:33:13.751229", "name": "__main__", "level": "INFO", "message": "Action: 14, Reward: tensor([-23.0391], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T17:33:14.412295", "name": "__main__", "level": "INFO", "message": "Epoch 0, Iteration 10: Reward: tensor([-444.2346], grad_fn=<AddBackward0>), Policy Loss: None, Value Loss: None, Total Loss: None, Entropy: None"}
{"time": "2024-06-03T17:33:15.834186", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 0 selected."}
{"time": "2024-06-03T17:33:24.610515", "name": "__main__", "level": "INFO", "message": "Action: 0, Reward: tensor([-24.0124], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T17:33:25.646378", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 14 selected."}
{"time": "2024-06-03T17:33:33.399992", "name": "__main__", "level": "INFO", "message": "Episode timed out."}
{"time": "2024-06-03T17:33:34.009120", "name": "__main__", "level": "INFO", "message": "Action: 14, Reward: tensor([-25.1596], grad_fn=<AddBackward0>), Done: True"}
{"time": "2024-06-03T17:33:34.943903", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Model saved at e:\\Project\\models/checkpoints\\ppo_agent_epoch_0.pt"}
{"time": "2024-06-03T17:33:35.742985", "name": "__main__", "level": "INFO", "message": "Checkpoint saved at epoch 0"}
{"time": "2024-06-03T17:33:36.151298", "name": "__main__", "level": "INFO", "message": "Environment reset and takeoff completed."}
{"time": "2024-06-03T17:33:37.936040", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 9 selected."}
{"time": "2024-06-03T17:33:47.110051", "name": "__main__", "level": "INFO", "message": "Action: 9, Reward: tensor([-123.5851], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T17:33:47.986951", "name": "__main__", "level": "INFO", "message": "Epoch 1, Iteration 0: Reward: tensor([-123.5851], grad_fn=<AddBackward0>), Policy Loss: None, Value Loss: None, Total Loss: None, Entropy: None"}
{"time": "2024-06-03T17:33:48.827919", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 5 selected."}
{"time": "2024-06-03T17:33:57.834847", "name": "__main__", "level": "INFO", "message": "Action: 5, Reward: tensor([-23.2442], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T17:33:58.869058", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 1 selected."}
{"time": "2024-06-03T17:34:07.464520", "name": "__main__", "level": "INFO", "message": "Action: 1, Reward: tensor([-23.3597], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T17:34:08.633124", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 9 selected."}
{"time": "2024-06-03T17:34:17.060232", "name": "__main__", "level": "INFO", "message": "Action: 9, Reward: tensor([-22.1373], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T17:34:18.747631", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 10 selected."}
{"time": "2024-06-03T17:34:23.615961", "name": "__main__", "level": "INFO", "message": "Action: 10, Reward: tensor([-22.5376], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T17:34:25.186186", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 16 selected."}
{"time": "2024-06-03T17:34:34.359071", "name": "__main__", "level": "INFO", "message": "Action: 16, Reward: tensor([-23.3814], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T17:34:35.890990", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 16 selected."}
{"time": "2024-06-03T17:34:44.753571", "name": "__main__", "level": "INFO", "message": "Action: 16, Reward: tensor([-24.0185], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T17:34:46.472342", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 7 selected."}
{"time": "2024-06-03T17:34:51.419280", "name": "__main__", "level": "INFO", "message": "Action: 7, Reward: tensor([-24.3664], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T17:34:52.891484", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 14 selected."}
{"time": "2024-06-03T17:35:02.026106", "name": "__main__", "level": "INFO", "message": "Action: 14, Reward: tensor([-24.8708], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T17:35:03.383058", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 3 selected."}
{"time": "2024-06-03T17:35:08.245739", "name": "__main__", "level": "INFO", "message": "Action: 3, Reward: tensor([-25.1214], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T17:35:09.815794", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 9 selected."}
{"time": "2024-06-03T17:35:18.449455", "name": "__main__", "level": "INFO", "message": "Action: 9, Reward: tensor([-24.1071], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T17:35:19.136894", "name": "__main__", "level": "INFO", "message": "Epoch 1, Iteration 10: Reward: tensor([-360.7294], grad_fn=<AddBackward0>), Policy Loss: None, Value Loss: None, Total Loss: None, Entropy: None"}
{"time": "2024-06-03T17:35:20.467898", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 4 selected."}
{"time": "2024-06-03T17:35:28.549855", "name": "__main__", "level": "INFO", "message": "Action: 4, Reward: tensor([-23.3953], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T17:35:30.142459", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 10 selected."}
{"time": "2024-06-03T17:35:34.283616", "name": "__main__", "level": "INFO", "message": "Action: 10, Reward: tensor([-23.8912], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T17:35:35.614566", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 8 selected."}
{"time": "2024-06-03T17:35:44.269332", "name": "__main__", "level": "INFO", "message": "Episode timed out."}
{"time": "2024-06-03T17:35:44.845528", "name": "__main__", "level": "INFO", "message": "Action: 8, Reward: tensor([-26.1680], grad_fn=<AddBackward0>), Done: True"}
{"time": "2024-06-03T17:35:45.645737", "name": "__main__", "level": "INFO", "message": "Environment reset and takeoff completed."}
{"time": "2024-06-03T17:35:46.921412", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 3 selected."}
{"time": "2024-06-03T17:35:51.569719", "name": "__main__", "level": "INFO", "message": "Action: 3, Reward: tensor([-23.1403], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T17:35:52.431397", "name": "__main__", "level": "INFO", "message": "Epoch 2, Iteration 0: Reward: tensor([-23.1403], grad_fn=<AddBackward0>), Policy Loss: None, Value Loss: None, Total Loss: None, Entropy: None"}
{"time": "2024-06-03T17:35:53.104135", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 12 selected."}
{"time": "2024-06-03T17:36:01.793247", "name": "__main__", "level": "INFO", "message": "Action: 12, Reward: tensor([-23.4525], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T17:36:03.421887", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 1 selected."}
{"time": "2024-06-03T17:36:12.299194", "name": "__main__", "level": "INFO", "message": "Action: 1, Reward: tensor([-23.7282], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T17:36:13.718776", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 3 selected."}
{"time": "2024-06-03T17:36:18.105416", "name": "__main__", "level": "INFO", "message": "Action: 3, Reward: tensor([-23.9074], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T17:36:19.684432", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 7 selected."}
{"time": "2024-06-03T17:36:24.617666", "name": "__main__", "level": "INFO", "message": "Action: 7, Reward: tensor([-24.0427], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T17:36:26.260850", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 14 selected."}
{"time": "2024-06-03T17:36:35.317082", "name": "__main__", "level": "INFO", "message": "Action: 14, Reward: tensor([-24.0669], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T17:36:36.915351", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 13 selected."}
{"time": "2024-06-03T17:36:46.081439", "name": "__main__", "level": "INFO", "message": "Action: 13, Reward: tensor([-23.8853], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T17:36:47.833016", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 5 selected."}
{"time": "2024-06-03T17:36:56.768132", "name": "__main__", "level": "INFO", "message": "Action: 5, Reward: tensor([-23.8923], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T17:36:58.130681", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 0 selected."}
{"time": "2024-06-03T17:37:07.092954", "name": "__main__", "level": "INFO", "message": "Action: 0, Reward: tensor([-24.1345], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T17:37:08.808832", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 14 selected."}
{"time": "2024-06-03T17:37:17.049343", "name": "__main__", "level": "INFO", "message": "Action: 14, Reward: tensor([-24.9217], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T17:37:18.423542", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 14 selected."}
{"time": "2024-06-03T17:37:27.055349", "name": "__main__", "level": "INFO", "message": "Action: 14, Reward: tensor([-25.9729], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T17:37:27.711356", "name": "__main__", "level": "INFO", "message": "Epoch 2, Iteration 10: Reward: tensor([-265.1446], grad_fn=<AddBackward0>), Policy Loss: None, Value Loss: None, Total Loss: None, Entropy: None"}
{"time": "2024-06-03T17:37:29.088871", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 15 selected."}
{"time": "2024-06-03T17:37:37.702249", "name": "__main__", "level": "INFO", "message": "Action: 15, Reward: tensor([-26.0410], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T17:37:39.327640", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 6 selected."}
{"time": "2024-06-03T17:37:43.969612", "name": "__main__", "level": "INFO", "message": "Action: 6, Reward: tensor([-26.1279], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T17:37:45.622217", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 13 selected."}
{"time": "2024-06-03T17:37:53.997319", "name": "__main__", "level": "INFO", "message": "Episode timed out."}
{"time": "2024-06-03T17:37:54.545076", "name": "__main__", "level": "INFO", "message": "Action: 13, Reward: tensor([-26.4828], grad_fn=<AddBackward0>), Done: True"}
{"time": "2024-06-03T17:37:55.297268", "name": "__main__", "level": "INFO", "message": "Environment reset and takeoff completed."}
{"time": "2024-06-03T17:37:57.244210", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 0 selected."}
{"time": "2024-06-03T17:38:05.995016", "name": "__main__", "level": "INFO", "message": "Action: 0, Reward: tensor([-124.9624], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T17:38:06.665262", "name": "__main__", "level": "INFO", "message": "Epoch 3, Iteration 0: Reward: tensor([-124.9624], grad_fn=<AddBackward0>), Policy Loss: None, Value Loss: None, Total Loss: None, Entropy: None"}
{"time": "2024-06-03T17:38:08.042270", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 0 selected."}
{"time": "2024-06-03T17:38:16.396121", "name": "__main__", "level": "INFO", "message": "Action: 0, Reward: tensor([-25.2289], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T17:38:17.910784", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 6 selected."}
{"time": "2024-06-03T17:38:22.884169", "name": "__main__", "level": "INFO", "message": "Action: 6, Reward: tensor([-25.3284], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T17:38:24.567287", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 5 selected."}
{"time": "2024-06-03T17:38:33.480493", "name": "__main__", "level": "INFO", "message": "Action: 5, Reward: tensor([-25.4902], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T17:38:34.743989", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 14 selected."}
{"time": "2024-06-03T17:38:43.703168", "name": "__main__", "level": "INFO", "message": "Action: 14, Reward: tensor([-125.7994], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T17:38:45.378741", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 4 selected."}
{"time": "2024-06-03T17:38:54.191590", "name": "__main__", "level": "INFO", "message": "Action: 4, Reward: tensor([-125.8758], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T17:38:55.830683", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 15 selected."}
{"time": "2024-06-03T17:39:04.603673", "name": "__main__", "level": "INFO", "message": "Action: 15, Reward: tensor([-26.0607], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T17:39:06.195702", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 12 selected."}
{"time": "2024-06-03T17:39:14.566194", "name": "__main__", "level": "INFO", "message": "Action: 12, Reward: tensor([-26.3205], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T17:39:16.128351", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 0 selected."}
{"time": "2024-06-03T17:39:25.023660", "name": "__main__", "level": "INFO", "message": "Action: 0, Reward: tensor([-26.8074], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T17:39:26.748410", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 0 selected."}
{"time": "2024-06-03T17:39:35.596437", "name": "__main__", "level": "INFO", "message": "Action: 0, Reward: tensor([-27.3212], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T17:39:37.166456", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 0 selected."}
{"time": "2024-06-03T17:39:45.924984", "name": "__main__", "level": "INFO", "message": "Action: 0, Reward: tensor([-128.1371], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T17:39:46.597700", "name": "__main__", "level": "INFO", "message": "Epoch 3, Iteration 10: Reward: tensor([-687.3320], grad_fn=<AddBackward0>), Policy Loss: None, Value Loss: None, Total Loss: None, Entropy: None"}
{"time": "2024-06-03T17:39:47.916609", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 2 selected."}
{"time": "2024-06-03T17:39:52.491481", "name": "__main__", "level": "INFO", "message": "Action: 2, Reward: tensor([-28.2860], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T17:39:53.885565", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 3 selected."}
{"time": "2024-06-03T17:39:57.961977", "name": "__main__", "level": "INFO", "message": "Episode timed out."}
{"time": "2024-06-03T17:39:57.965499", "name": "__main__", "level": "INFO", "message": "Action: 3, Reward: tensor([-28.2246], grad_fn=<AddBackward0>), Done: True"}
{"time": "2024-06-03T17:39:58.625551", "name": "__main__", "level": "INFO", "message": "Environment reset and takeoff completed."}
{"time": "2024-06-03T17:40:00.558421", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 9 selected."}
{"time": "2024-06-03T17:40:09.501425", "name": "__main__", "level": "INFO", "message": "Action: 9, Reward: tensor([-123.5880], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T17:40:10.204707", "name": "__main__", "level": "INFO", "message": "Epoch 4, Iteration 0: Reward: tensor([-123.5880], grad_fn=<AddBackward0>), Policy Loss: None, Value Loss: None, Total Loss: None, Entropy: None"}
{"time": "2024-06-03T17:40:11.507538", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 6 selected."}
{"time": "2024-06-03T17:40:16.001561", "name": "__main__", "level": "INFO", "message": "Action: 6, Reward: tensor([-23.5145], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T17:40:16.826329", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 1 selected."}
{"time": "2024-06-03T17:40:26.018271", "name": "__main__", "level": "INFO", "message": "Action: 1, Reward: tensor([-23.5565], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T17:40:27.619222", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 10 selected."}
{"time": "2024-06-03T17:40:32.295490", "name": "__main__", "level": "INFO", "message": "Action: 10, Reward: tensor([-24.2382], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T17:40:34.011268", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 10 selected."}
{"time": "2024-06-03T17:40:39.043581", "name": "__main__", "level": "INFO", "message": "Action: 10, Reward: tensor([-25.1888], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T17:40:40.680286", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 12 selected."}
{"time": "2024-06-03T17:40:49.024419", "name": "__main__", "level": "INFO", "message": "Action: 12, Reward: tensor([-125.8320], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T17:40:49.531917", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 0 selected."}
{"time": "2024-06-03T17:40:58.200232", "name": "__main__", "level": "INFO", "message": "Action: 0, Reward: tensor([-26.0123], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T17:40:59.856785", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 14 selected."}
{"time": "2024-06-03T17:41:08.773564", "name": "__main__", "level": "INFO", "message": "Action: 14, Reward: tensor([-26.2500], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T17:41:10.122011", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 8 selected."}
{"time": "2024-06-03T17:41:18.761674", "name": "__main__", "level": "INFO", "message": "Action: 8, Reward: tensor([-26.4088], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T17:41:20.404087", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 11 selected."}
{"time": "2024-06-03T17:41:25.114662", "name": "__main__", "level": "INFO", "message": "Action: 11, Reward: tensor([-26.3039], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T17:41:26.662805", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 11 selected."}
{"time": "2024-06-03T17:41:31.015673", "name": "__main__", "level": "INFO", "message": "Action: 11, Reward: tensor([-25.9270], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T17:41:31.796577", "name": "__main__", "level": "INFO", "message": "Epoch 4, Iteration 10: Reward: tensor([-476.8200], grad_fn=<AddBackward0>), Policy Loss: None, Value Loss: None, Total Loss: None, Entropy: None"}
{"time": "2024-06-03T17:41:33.141498", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 4 selected."}
{"time": "2024-06-03T17:41:42.041684", "name": "__main__", "level": "INFO", "message": "Action: 4, Reward: tensor([-25.1634], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T17:41:43.720005", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 14 selected."}
{"time": "2024-06-03T17:41:52.673352", "name": "__main__", "level": "INFO", "message": "Action: 14, Reward: tensor([-24.7226], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T17:41:54.297978", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 16 selected."}
{"time": "2024-06-03T17:42:02.305733", "name": "__main__", "level": "INFO", "message": "Episode timed out."}
{"time": "2024-06-03T17:42:02.916024", "name": "__main__", "level": "INFO", "message": "Action: 16, Reward: tensor([-24.5570], grad_fn=<AddBackward0>), Done: True"}
{"time": "2024-06-03T17:42:03.666099", "name": "__main__", "level": "INFO", "message": "Environment reset and takeoff completed."}
{"time": "2024-06-03T17:42:05.669555", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 4 selected."}
{"time": "2024-06-03T17:42:14.128676", "name": "__main__", "level": "INFO", "message": "Action: 4, Reward: tensor([-124.9585], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T17:42:14.826957", "name": "__main__", "level": "INFO", "message": "Epoch 5, Iteration 0: Reward: tensor([-124.9585], grad_fn=<AddBackward0>), Policy Loss: None, Value Loss: None, Total Loss: None, Entropy: None"}
{"time": "2024-06-03T17:42:15.829372", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 0 selected."}
{"time": "2024-06-03T17:42:23.882656", "name": "__main__", "level": "INFO", "message": "Action: 0, Reward: tensor([-25.1048], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T17:42:25.310546", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 15 selected."}
{"time": "2024-06-03T17:42:34.281103", "name": "__main__", "level": "INFO", "message": "Action: 15, Reward: tensor([-25.3481], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T17:42:35.872957", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 5 selected."}
{"time": "2024-06-03T17:42:44.950454", "name": "__main__", "level": "INFO", "message": "Action: 5, Reward: tensor([-125.5897], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T17:42:46.666366", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 15 selected."}
{"time": "2024-06-03T17:42:55.187500", "name": "__main__", "level": "INFO", "message": "Action: 15, Reward: tensor([-25.8942], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T17:42:56.859385", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 16 selected."}
{"time": "2024-06-03T17:43:05.632682", "name": "__main__", "level": "INFO", "message": "Action: 16, Reward: tensor([-26.0375], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T17:43:07.301873", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 1 selected."}
{"time": "2024-06-03T17:43:15.805312", "name": "__main__", "level": "INFO", "message": "Action: 1, Reward: tensor([-26.2979], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T17:43:17.153017", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 7 selected."}
{"time": "2024-06-03T17:43:21.981367", "name": "__main__", "level": "INFO", "message": "Action: 7, Reward: tensor([-26.3817], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T17:43:23.502054", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 12 selected."}
{"time": "2024-06-03T17:43:31.154059", "name": "__main__", "level": "INFO", "message": "Action: 12, Reward: tensor([-26.5829], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T17:43:32.360992", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 16 selected."}
{"time": "2024-06-03T17:43:40.661788", "name": "__main__", "level": "INFO", "message": "Action: 16, Reward: tensor([-26.7095], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T17:43:42.009951", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 1 selected."}
{"time": "2024-06-03T17:43:50.575296", "name": "__main__", "level": "INFO", "message": "Action: 1, Reward: tensor([-26.9457], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T17:43:51.244627", "name": "__main__", "level": "INFO", "message": "Epoch 5, Iteration 10: Reward: tensor([-485.8506], grad_fn=<AddBackward0>), Policy Loss: None, Value Loss: None, Total Loss: None, Entropy: None"}
{"time": "2024-06-03T17:43:52.385941", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 7 selected."}
{"time": "2024-06-03T17:43:57.166855", "name": "__main__", "level": "INFO", "message": "Action: 7, Reward: tensor([-27.0968], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T17:43:58.765224", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 2 selected."}
{"time": "2024-06-03T17:44:03.437688", "name": "__main__", "level": "INFO", "message": "Action: 2, Reward: tensor([-27.1910], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T17:44:05.096487", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 2 selected."}
{"time": "2024-06-03T17:44:09.407529", "name": "__main__", "level": "INFO", "message": "Episode timed out."}
{"time": "2024-06-03T17:44:09.957151", "name": "__main__", "level": "INFO", "message": "Action: 2, Reward: tensor([-27.3744], grad_fn=<AddBackward0>), Done: True"}
{"time": "2024-06-03T17:44:10.615039", "name": "__main__", "level": "INFO", "message": "Environment reset and takeoff completed."}
{"time": "2024-06-03T17:44:12.491463", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 7 selected."}
{"time": "2024-06-03T17:44:16.689955", "name": "__main__", "level": "INFO", "message": "Action: 7, Reward: tensor([-124.8812], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T17:44:17.419621", "name": "__main__", "level": "INFO", "message": "Epoch 6, Iteration 0: Reward: tensor([-124.8812], grad_fn=<AddBackward0>), Policy Loss: None, Value Loss: None, Total Loss: None, Entropy: None"}
{"time": "2024-06-03T17:44:18.841415", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 4 selected."}
{"time": "2024-06-03T17:44:27.484772", "name": "__main__", "level": "INFO", "message": "Action: 4, Reward: tensor([-25.0410], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T17:44:29.131021", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 0 selected."}
{"time": "2024-06-03T17:44:37.505547", "name": "__main__", "level": "INFO", "message": "Action: 0, Reward: tensor([-25.2990], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T17:44:38.833454", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 0 selected."}
{"time": "2024-06-03T17:44:47.530982", "name": "__main__", "level": "INFO", "message": "Action: 0, Reward: tensor([-25.5364], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T17:44:49.199589", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 1 selected."}
{"time": "2024-06-03T17:44:57.337996", "name": "__main__", "level": "INFO", "message": "Action: 1, Reward: tensor([-25.6276], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T17:44:58.983490", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 1 selected."}
{"time": "2024-06-03T17:45:07.835036", "name": "__main__", "level": "INFO", "message": "Action: 1, Reward: tensor([-25.9061], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T17:45:09.490519", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 0 selected."}
{"time": "2024-06-03T17:45:18.455406", "name": "__main__", "level": "INFO", "message": "Action: 0, Reward: tensor([-26.0484], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T17:45:19.530952", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 10 selected."}
{"time": "2024-06-03T17:45:24.494892", "name": "__main__", "level": "INFO", "message": "Action: 10, Reward: tensor([-26.2327], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T17:45:26.062527", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 10 selected."}
{"time": "2024-06-03T17:45:30.984336", "name": "__main__", "level": "INFO", "message": "Action: 10, Reward: tensor([-26.4104], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T17:45:32.594049", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 0 selected."}
{"time": "2024-06-03T17:49:24.868394", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Using device: cpu"}
{"time": "2024-06-03T17:49:29.090875", "name": "__main__", "level": "INFO", "message": "DataVisualizer initialized with Seaborn style set to 'whitegrid'."}
{"time": "2024-06-03T17:49:29.246067", "name": "__main__", "level": "INFO", "message": "Loading checkpoint from e:\\Project\\models/checkpoints\\ppo_agent_checkpoint.pt"}
{"time": "2024-06-03T17:49:33.186227", "name": "__main__", "level": "ERROR", "message": "Error loading checkpoint: 'icm_state_dict'"}
{"time": "2024-06-03T17:49:35.122251", "name": "__main__", "level": "INFO", "message": "Environment reset and takeoff completed."}
{"time": "2024-06-03T18:01:09.309847", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Using device: cpu"}
{"time": "2024-06-03T18:29:14.094718", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Using device: cpu"}
{"time": "2024-06-03T18:42:51.186702", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Using device: cpu"}
{"time": "2024-06-03T18:45:34.435252", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Using device: cpu"}
{"time": "2024-06-03T18:45:39.541358", "name": "__main__", "level": "INFO", "message": "DataVisualizer initialized with Seaborn style set to 'whitegrid'."}
{"time": "2024-06-03T18:45:39.696060", "name": "__main__", "level": "INFO", "message": "Loading checkpoint from e:\\Project\\models/checkpoints\\ppo_agent_checkpoint.pt"}
{"time": "2024-06-03T18:45:43.792010", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Model loaded"}
{"time": "2024-06-03T18:45:45.038802", "name": "__main__", "level": "INFO", "message": "Resuming training from epoch 1"}
{"time": "2024-06-03T18:45:45.448076", "name": "__main__", "level": "INFO", "message": "Environment reset and takeoff completed."}
{"time": "2024-06-03T18:45:47.275627", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 11 selected."}
{"time": "2024-06-03T18:45:51.972235", "name": "__main__", "level": "INFO", "message": "Action: 11, Reward: tensor([-124.3182], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T18:47:58.009776", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Using device: cpu"}
{"time": "2024-06-03T18:48:03.573252", "name": "__main__", "level": "INFO", "message": "DataVisualizer initialized with Seaborn style set to 'whitegrid'."}
{"time": "2024-06-03T18:48:03.714362", "name": "__main__", "level": "INFO", "message": "Loading checkpoint from e:\\Project\\models/checkpoints\\ppo_agent_checkpoint.pt"}
{"time": "2024-06-03T18:48:07.189625", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Model loaded"}
{"time": "2024-06-03T18:48:08.686003", "name": "__main__", "level": "INFO", "message": "Resuming training from epoch 1"}
{"time": "2024-06-03T18:48:09.092033", "name": "__main__", "level": "INFO", "message": "Environment reset and takeoff completed."}
{"time": "2024-06-03T18:48:11.121901", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 9 selected."}
{"time": "2024-06-03T18:48:19.801596", "name": "__main__", "level": "INFO", "message": "Action: 9, Reward: tensor([-123.5375], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T18:48:20.488478", "name": "__main__", "level": "INFO", "message": "Epoch 1, Iteration 0: Reward: tensor([-123.5375], grad_fn=<AddBackward0>), Policy Loss: None, Value Loss: None, Total Loss: None, Entropy: None"}
{"time": "2024-06-03T18:48:22.052468", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 9 selected."}
{"time": "2024-06-03T18:48:30.757292", "name": "__main__", "level": "INFO", "message": "Action: 9, Reward: tensor([-21.6875], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T18:48:32.732031", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 13 selected."}
{"time": "2024-06-03T18:48:41.566337", "name": "__main__", "level": "INFO", "message": "Action: 13, Reward: tensor([-20.9474], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T18:48:43.569595", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 0 selected."}
{"time": "2024-06-03T18:48:52.029345", "name": "__main__", "level": "INFO", "message": "Action: 0, Reward: tensor([-20.6387], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T18:48:53.845214", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 15 selected."}
{"time": "2024-06-03T18:49:02.609398", "name": "__main__", "level": "INFO", "message": "Action: 15, Reward: tensor([-20.9335], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T18:49:04.493921", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 15 selected."}
{"time": "2024-06-03T18:49:13.215148", "name": "__main__", "level": "INFO", "message": "Action: 15, Reward: tensor([-21.0516], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T18:49:15.061078", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 7 selected."}
{"time": "2024-06-03T18:49:19.541194", "name": "__main__", "level": "INFO", "message": "Action: 7, Reward: tensor([-21.0263], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T18:49:21.378073", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 14 selected."}
{"time": "2024-06-03T18:49:30.005094", "name": "__main__", "level": "INFO", "message": "Action: 14, Reward: tensor([-20.8035], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T18:49:31.929297", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 4 selected."}
{"time": "2024-06-03T18:49:40.720498", "name": "__main__", "level": "INFO", "message": "Action: 4, Reward: tensor([-20.7368], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T18:49:42.661883", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 9 selected."}
{"time": "2024-06-03T18:49:50.677064", "name": "__main__", "level": "INFO", "message": "Action: 9, Reward: tensor([-19.4768], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T18:49:52.444947", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 5 selected."}
{"time": "2024-06-03T18:50:01.304257", "name": "__main__", "level": "INFO", "message": "Action: 5, Reward: tensor([-19.0873], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T18:50:02.161796", "name": "__main__", "level": "INFO", "message": "Epoch 1, Iteration 10: Reward: tensor([-329.9269], grad_fn=<AddBackward0>), Policy Loss: None, Value Loss: None, Total Loss: None, Entropy: None"}
{"time": "2024-06-03T18:50:03.764288", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 12 selected."}
{"time": "2024-06-03T18:50:12.290354", "name": "__main__", "level": "INFO", "message": "Episode timed out."}
{"time": "2024-06-03T18:50:12.805061", "name": "__main__", "level": "INFO", "message": "Action: 12, Reward: tensor([-19.0988], grad_fn=<AddBackward0>), Done: True"}
{"time": "2024-06-03T18:50:13.522819", "name": "__main__", "level": "INFO", "message": "Environment reset and takeoff completed."}
{"time": "2024-06-03T18:50:15.435472", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 14 selected."}
{"time": "2024-06-03T18:50:24.147884", "name": "__main__", "level": "INFO", "message": "Action: 14, Reward: tensor([-124.8637], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T18:50:24.851517", "name": "__main__", "level": "INFO", "message": "Epoch 2, Iteration 0: Reward: tensor([-124.8637], grad_fn=<AddBackward0>), Policy Loss: None, Value Loss: None, Total Loss: None, Entropy: None"}
{"time": "2024-06-03T18:50:26.447851", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 8 selected."}
{"time": "2024-06-03T18:50:34.258629", "name": "__main__", "level": "INFO", "message": "Action: 8, Reward: tensor([-125.1672], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T18:50:36.161755", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 3 selected."}
{"time": "2024-06-03T18:50:40.958931", "name": "__main__", "level": "INFO", "message": "Action: 3, Reward: tensor([-25.2516], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T18:50:42.829699", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 16 selected."}
{"time": "2024-06-03T18:50:51.540732", "name": "__main__", "level": "INFO", "message": "Action: 16, Reward: tensor([-25.4276], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T18:50:53.487813", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 7 selected."}
{"time": "2024-06-03T18:50:58.273609", "name": "__main__", "level": "INFO", "message": "Action: 7, Reward: tensor([-25.6082], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T18:51:00.255630", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 6 selected."}
{"time": "2024-06-03T18:51:04.919516", "name": "__main__", "level": "INFO", "message": "Action: 6, Reward: tensor([-25.6930], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T18:51:06.878778", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 11 selected."}
{"time": "2024-06-03T18:51:11.615547", "name": "__main__", "level": "INFO", "message": "Action: 11, Reward: tensor([-25.4803], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T18:51:13.511175", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 15 selected."}
{"time": "2024-06-03T18:51:22.311885", "name": "__main__", "level": "INFO", "message": "Action: 15, Reward: tensor([-25.0998], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T18:51:24.219788", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 4 selected."}
{"time": "2024-06-03T18:51:33.001722", "name": "__main__", "level": "INFO", "message": "Action: 4, Reward: tensor([-25.2463], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T18:51:34.901937", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 5 selected."}
{"time": "2024-06-03T18:51:43.779257", "name": "__main__", "level": "INFO", "message": "Action: 5, Reward: tensor([-25.6765], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T18:51:45.782260", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 4 selected."}
{"time": "2024-06-03T18:51:54.637595", "name": "__main__", "level": "INFO", "message": "Action: 4, Reward: tensor([-26.0885], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T18:51:55.219098", "name": "__main__", "level": "INFO", "message": "Epoch 2, Iteration 10: Reward: tensor([-479.6028], grad_fn=<AddBackward0>), Policy Loss: None, Value Loss: None, Total Loss: None, Entropy: None"}
{"time": "2024-06-03T18:51:56.787326", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 10 selected."}
{"time": "2024-06-03T18:52:01.661472", "name": "__main__", "level": "INFO", "message": "Action: 10, Reward: tensor([-26.8418], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T18:52:03.493556", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 3 selected."}
{"time": "2024-06-03T18:52:08.427120", "name": "__main__", "level": "INFO", "message": "Action: 3, Reward: tensor([-127.0811], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T18:52:09.708373", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 16 selected."}
{"time": "2024-06-03T18:52:17.836246", "name": "__main__", "level": "INFO", "message": "Episode timed out."}
{"time": "2024-06-03T18:52:17.837245", "name": "__main__", "level": "INFO", "message": "Action: 16, Reward: tensor([-27.2313], grad_fn=<AddBackward0>), Done: True"}
{"time": "2024-06-03T18:52:18.433955", "name": "__main__", "level": "INFO", "message": "Environment reset and takeoff completed."}
{"time": "2024-06-03T18:52:20.608307", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 14 selected."}
{"time": "2024-06-03T18:52:29.488935", "name": "__main__", "level": "INFO", "message": "Action: 14, Reward: tensor([-124.8970], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T18:52:30.254435", "name": "__main__", "level": "INFO", "message": "Epoch 3, Iteration 0: Reward: tensor([-124.8970], grad_fn=<AddBackward0>), Policy Loss: None, Value Loss: None, Total Loss: None, Entropy: None"}
{"time": "2024-06-03T18:52:31.689483", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 4 selected."}
{"time": "2024-06-03T18:52:40.548634", "name": "__main__", "level": "INFO", "message": "Action: 4, Reward: tensor([-24.9968], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T18:52:42.219875", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 16 selected."}
{"time": "2024-06-03T18:52:50.711323", "name": "__main__", "level": "INFO", "message": "Action: 16, Reward: tensor([-24.8432], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T18:52:52.256333", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 7 selected."}
{"time": "2024-06-03T18:52:56.735205", "name": "__main__", "level": "INFO", "message": "Action: 7, Reward: tensor([-24.9844], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T18:52:58.416385", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 0 selected."}
{"time": "2024-06-03T18:53:07.074802", "name": "__main__", "level": "INFO", "message": "Action: 0, Reward: tensor([-24.9892], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T18:53:08.346070", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 0 selected."}
{"time": "2024-06-03T18:53:16.857177", "name": "__main__", "level": "INFO", "message": "Action: 0, Reward: tensor([-24.9755], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T18:53:18.537291", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 11 selected."}
{"time": "2024-06-03T18:53:22.937043", "name": "__main__", "level": "INFO", "message": "Action: 11, Reward: tensor([-24.6555], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T18:53:24.795973", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 5 selected."}
{"time": "2024-06-03T18:53:33.704440", "name": "__main__", "level": "INFO", "message": "Action: 5, Reward: tensor([-24.1067], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T18:53:35.629842", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 1 selected."}
{"time": "2024-06-03T18:53:44.369166", "name": "__main__", "level": "INFO", "message": "Action: 1, Reward: tensor([-24.0210], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T18:53:46.139193", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 4 selected."}
{"time": "2024-06-03T18:53:55.121020", "name": "__main__", "level": "INFO", "message": "Action: 4, Reward: tensor([-24.0400], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T18:53:56.640845", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 4 selected."}
{"time": "2024-06-03T18:54:04.960023", "name": "__main__", "level": "INFO", "message": "Action: 4, Reward: tensor([-24.2773], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T18:54:05.769940", "name": "__main__", "level": "INFO", "message": "Epoch 3, Iteration 10: Reward: tensor([-370.7867], grad_fn=<AddBackward0>), Policy Loss: None, Value Loss: None, Total Loss: None, Entropy: None"}
{"time": "2024-06-03T18:54:07.335273", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 5 selected."}
{"time": "2024-06-03T18:54:15.000350", "name": "__main__", "level": "INFO", "message": "Action: 5, Reward: tensor([-24.3969], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T18:54:16.092372", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 15 selected."}
{"time": "2024-06-03T18:54:23.970844", "name": "__main__", "level": "INFO", "message": "Episode timed out."}
{"time": "2024-06-03T18:54:24.024592", "name": "__main__", "level": "INFO", "message": "Action: 15, Reward: tensor([-24.4285], grad_fn=<AddBackward0>), Done: True"}
{"time": "2024-06-03T18:54:24.516646", "name": "__main__", "level": "INFO", "message": "Environment reset and takeoff completed."}
{"time": "2024-06-03T18:54:26.724928", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 13 selected."}
{"time": "2024-06-03T18:54:35.785736", "name": "__main__", "level": "INFO", "message": "Action: 13, Reward: tensor([-124.9566], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T18:54:36.538809", "name": "__main__", "level": "INFO", "message": "Epoch 4, Iteration 0: Reward: tensor([-124.9566], grad_fn=<AddBackward0>), Policy Loss: None, Value Loss: None, Total Loss: None, Entropy: None"}
{"time": "2024-06-03T18:54:38.178747", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 16 selected."}
{"time": "2024-06-03T18:54:47.133884", "name": "__main__", "level": "INFO", "message": "Action: 16, Reward: tensor([-25.1164], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T18:54:48.963931", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 0 selected."}
{"time": "2024-06-03T18:54:57.091376", "name": "__main__", "level": "INFO", "message": "Action: 0, Reward: tensor([-25.3210], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T18:54:58.728240", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 2 selected."}
{"time": "2024-06-03T18:55:03.625753", "name": "__main__", "level": "INFO", "message": "Action: 2, Reward: tensor([-25.5109], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T18:55:05.483430", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 3 selected."}
{"time": "2024-06-03T18:55:10.593894", "name": "__main__", "level": "INFO", "message": "Action: 3, Reward: tensor([-125.5480], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T18:55:12.483403", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 2 selected."}
{"time": "2024-06-03T18:55:17.280166", "name": "__main__", "level": "INFO", "message": "Action: 2, Reward: tensor([-25.6955], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T18:55:19.255408", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 5 selected."}
{"time": "2024-06-03T18:55:28.013757", "name": "__main__", "level": "INFO", "message": "Action: 5, Reward: tensor([-25.7750], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T18:55:29.779118", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 11 selected."}
{"time": "2024-06-03T18:55:34.611977", "name": "__main__", "level": "INFO", "message": "Action: 11, Reward: tensor([-25.4699], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T18:55:36.483108", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 3 selected."}
{"time": "2024-06-03T18:55:41.069379", "name": "__main__", "level": "INFO", "message": "Action: 3, Reward: tensor([-25.3986], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T18:55:42.884142", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 0 selected."}
{"time": "2024-06-03T18:55:51.480870", "name": "__main__", "level": "INFO", "message": "Action: 0, Reward: tensor([-25.2994], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T18:55:53.442573", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 3 selected."}
{"time": "2024-06-03T18:55:58.315612", "name": "__main__", "level": "INFO", "message": "Action: 3, Reward: tensor([-25.4328], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T18:55:59.115434", "name": "__main__", "level": "INFO", "message": "Epoch 4, Iteration 10: Reward: tensor([-479.5242], grad_fn=<AddBackward0>), Policy Loss: None, Value Loss: None, Total Loss: None, Entropy: None"}
{"time": "2024-06-03T18:56:00.743164", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 6 selected."}
{"time": "2024-06-03T18:56:05.584934", "name": "__main__", "level": "INFO", "message": "Action: 6, Reward: tensor([-25.5151], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T18:56:07.374710", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 10 selected."}
{"time": "2024-06-03T18:56:12.165133", "name": "__main__", "level": "INFO", "message": "Action: 10, Reward: tensor([-26.1468], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T18:56:13.979698", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 2 selected."}
{"time": "2024-06-03T18:56:18.792015", "name": "__main__", "level": "INFO", "message": "Action: 2, Reward: tensor([-26.5669], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T18:56:20.701365", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 6 selected."}
{"time": "2024-06-03T18:56:24.956780", "name": "__main__", "level": "INFO", "message": "Episode timed out."}
{"time": "2024-06-03T18:56:25.395551", "name": "__main__", "level": "INFO", "message": "Action: 6, Reward: tensor([-26.9326], grad_fn=<AddBackward0>), Done: True"}
{"time": "2024-06-03T18:56:25.926721", "name": "__main__", "level": "INFO", "message": "Environment reset and takeoff completed."}
{"time": "2024-06-03T18:56:28.109650", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 0 selected."}
{"time": "2024-06-03T18:56:36.860615", "name": "__main__", "level": "INFO", "message": "Action: 0, Reward: tensor([-124.9084], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T18:56:37.578563", "name": "__main__", "level": "INFO", "message": "Epoch 5, Iteration 0: Reward: tensor([-124.9084], grad_fn=<AddBackward0>), Policy Loss: None, Value Loss: None, Total Loss: None, Entropy: None"}
{"time": "2024-06-03T18:56:39.286221", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 4 selected."}
{"time": "2024-06-03T18:56:47.911848", "name": "__main__", "level": "INFO", "message": "Action: 4, Reward: tensor([-125.1381], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T18:56:49.889289", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 2 selected."}
{"time": "2024-06-03T18:56:54.454368", "name": "__main__", "level": "INFO", "message": "Action: 2, Reward: tensor([-25.3028], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T18:56:56.387879", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 8 selected."}
{"time": "2024-06-03T18:57:05.266563", "name": "__main__", "level": "INFO", "message": "Action: 8, Reward: tensor([-25.4947], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T18:57:07.222546", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 9 selected."}
{"time": "2024-06-03T18:57:15.996524", "name": "__main__", "level": "INFO", "message": "Action: 9, Reward: tensor([-25.0073], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T18:57:17.690449", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 15 selected."}
{"time": "2024-06-03T18:57:26.430131", "name": "__main__", "level": "INFO", "message": "Action: 15, Reward: tensor([-24.9869], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T18:57:28.299769", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 11 selected."}
{"time": "2024-06-03T18:57:33.273838", "name": "__main__", "level": "INFO", "message": "Action: 11, Reward: tensor([-24.6470], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T18:57:35.015136", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 4 selected."}
{"time": "2024-06-03T18:57:43.817958", "name": "__main__", "level": "INFO", "message": "Action: 4, Reward: tensor([-24.2960], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T18:57:45.604773", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 0 selected."}
{"time": "2024-06-03T18:57:54.377074", "name": "__main__", "level": "INFO", "message": "Action: 0, Reward: tensor([-24.3938], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T18:57:56.285937", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 2 selected."}
{"time": "2024-06-03T18:58:01.113745", "name": "__main__", "level": "INFO", "message": "Action: 2, Reward: tensor([-24.6113], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T18:58:02.863679", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 10 selected."}
{"time": "2024-06-03T18:58:07.566324", "name": "__main__", "level": "INFO", "message": "Action: 10, Reward: tensor([-25.2377], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T18:58:08.405388", "name": "__main__", "level": "INFO", "message": "Epoch 5, Iteration 10: Reward: tensor([-474.0241], grad_fn=<AddBackward0>), Policy Loss: None, Value Loss: None, Total Loss: None, Entropy: None"}
{"time": "2024-06-03T18:58:09.976389", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 0 selected."}
{"time": "2024-06-03T18:58:18.758584", "name": "__main__", "level": "INFO", "message": "Action: 0, Reward: tensor([-26.5905], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T18:58:20.562541", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 0 selected."}
{"time": "2024-06-03T18:58:28.219012", "name": "__main__", "level": "INFO", "message": "Episode timed out."}
{"time": "2024-06-03T18:58:28.812974", "name": "__main__", "level": "INFO", "message": "Action: 0, Reward: tensor([-127.7448], grad_fn=<AddBackward0>), Done: True"}
{"time": "2024-06-03T18:58:29.487917", "name": "__main__", "level": "INFO", "message": "Environment reset and takeoff completed."}
{"time": "2024-06-03T18:58:31.814212", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 3 selected."}
{"time": "2024-06-03T18:58:36.460094", "name": "__main__", "level": "INFO", "message": "Action: 3, Reward: tensor([-124.8358], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T18:58:37.228346", "name": "__main__", "level": "INFO", "message": "Epoch 6, Iteration 0: Reward: tensor([-124.8358], grad_fn=<AddBackward0>), Policy Loss: None, Value Loss: None, Total Loss: None, Entropy: None"}
{"time": "2024-06-03T18:58:38.832330", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 15 selected."}
{"time": "2024-06-03T18:58:47.428350", "name": "__main__", "level": "INFO", "message": "Action: 15, Reward: tensor([-25.1353], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T18:58:49.373932", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 0 selected."}
{"time": "2024-06-03T18:58:58.092396", "name": "__main__", "level": "INFO", "message": "Action: 0, Reward: tensor([-25.2151], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T18:58:59.895820", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 9 selected."}
{"time": "2024-06-03T18:59:08.537023", "name": "__main__", "level": "INFO", "message": "Action: 9, Reward: tensor([-24.2709], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T18:59:10.400932", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 5 selected."}
{"time": "2024-06-03T18:59:19.266472", "name": "__main__", "level": "INFO", "message": "Action: 5, Reward: tensor([-24.0182], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T18:59:21.086822", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 16 selected."}
{"time": "2024-06-03T18:59:29.722661", "name": "__main__", "level": "INFO", "message": "Action: 16, Reward: tensor([-23.6766], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T18:59:31.637838", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 7 selected."}
{"time": "2024-06-03T18:59:36.398896", "name": "__main__", "level": "INFO", "message": "Action: 7, Reward: tensor([-23.8591], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T18:59:38.021693", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 6 selected."}
{"time": "2024-06-03T18:59:42.863555", "name": "__main__", "level": "INFO", "message": "Action: 6, Reward: tensor([-23.8959], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T18:59:44.850876", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 7 selected."}
{"time": "2024-06-03T18:59:49.647174", "name": "__main__", "level": "INFO", "message": "Action: 7, Reward: tensor([-24.1227], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T18:59:51.559415", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 0 selected."}
{"time": "2024-06-03T19:00:00.189185", "name": "__main__", "level": "INFO", "message": "Action: 0, Reward: tensor([-24.6508], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T19:00:02.164080", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 0 selected."}
{"time": "2024-06-03T19:00:10.788447", "name": "__main__", "level": "INFO", "message": "Action: 0, Reward: tensor([-25.4066], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T19:00:11.522515", "name": "__main__", "level": "INFO", "message": "Epoch 6, Iteration 10: Reward: tensor([-369.0869], grad_fn=<AddBackward0>), Policy Loss: None, Value Loss: None, Total Loss: None, Entropy: None"}
{"time": "2024-06-03T19:00:12.997941", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 8 selected."}
{"time": "2024-06-03T19:00:21.530085", "name": "__main__", "level": "INFO", "message": "Action: 8, Reward: tensor([-127.3891], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T19:00:23.504714", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 12 selected."}
{"time": "2024-06-03T19:00:31.787301", "name": "__main__", "level": "INFO", "message": "Episode timed out."}
{"time": "2024-06-03T19:00:32.157674", "name": "__main__", "level": "INFO", "message": "Action: 12, Reward: tensor([-27.6410], grad_fn=<AddBackward0>), Done: True"}
{"time": "2024-06-03T19:00:32.545606", "name": "__main__", "level": "INFO", "message": "Early stopping triggered after 7 epochs."}
{"time": "2024-06-03T19:00:51.775587", "name": "__main__", "level": "INFO", "message": "Dropped rows with NA values. Shape changed from (424, 2) to (424, 2)."}
{"time": "2024-06-03T22:54:49.587680", "name": "__main__", "level": "INFO", "message": "Time Series plot created successfully for steps vs values."}
{"time": "2024-06-03T22:55:10.594630", "name": "__main__", "level": "INFO", "message": "Histogram plotted successfully for column: values."}
{"time": "2024-06-03T22:55:27.000830", "name": "__main__", "level": "INFO", "message": "Correlation matrix heatmap generated successfully."}
{"time": "2024-06-03T22:55:54.017094", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Using device: cpu"}
{"time": "2024-06-03T22:55:59.276453", "name": "__main__", "level": "INFO", "message": "DataVisualizer initialized with Seaborn style set to 'whitegrid'."}
{"time": "2024-06-03T22:55:59.417001", "name": "__main__", "level": "INFO", "message": "Loading checkpoint from e:\\Project\\models/checkpoints\\ppo_agent_checkpoint.pt"}
{"time": "2024-06-03T22:56:03.064653", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Model loaded"}
{"time": "2024-06-03T22:56:03.376916", "name": "__main__", "level": "INFO", "message": "Resuming training from epoch 1"}
{"time": "2024-06-03T22:56:03.749272", "name": "__main__", "level": "INFO", "message": "Environment reset and takeoff completed."}
{"time": "2024-06-03T22:56:06.114598", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 4 selected."}
{"time": "2024-06-03T22:56:15.040162", "name": "__main__", "level": "INFO", "message": "Action: 4, Reward: tensor([-124.9441], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T22:56:15.848756", "name": "__main__", "level": "INFO", "message": "Epoch 1, Iteration 0: Reward: tensor([-124.9441], grad_fn=<AddBackward0>), Policy Loss: None, Value Loss: None, Total Loss: None, Entropy: None"}
{"time": "2024-06-03T22:56:17.440584", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 9 selected."}
{"time": "2024-06-03T22:56:26.169780", "name": "__main__", "level": "INFO", "message": "Action: 9, Reward: tensor([-23.7795], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T22:56:28.152235", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 4 selected."}
{"time": "2024-06-03T22:56:37.014024", "name": "__main__", "level": "INFO", "message": "Action: 4, Reward: tensor([-23.5944], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T22:56:38.931847", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 13 selected."}
{"time": "2024-06-03T22:56:47.734802", "name": "__main__", "level": "INFO", "message": "Action: 13, Reward: tensor([-23.6331], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T22:56:49.596574", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 2 selected."}
{"time": "2024-06-03T22:56:54.116544", "name": "__main__", "level": "INFO", "message": "Action: 2, Reward: tensor([-23.7464], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T22:56:56.133342", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 7 selected."}
{"time": "2024-06-03T22:57:00.968174", "name": "__main__", "level": "INFO", "message": "Action: 7, Reward: tensor([-23.9713], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T22:57:02.740861", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 13 selected."}
{"time": "2024-06-03T22:57:11.464708", "name": "__main__", "level": "INFO", "message": "Action: 13, Reward: tensor([-24.4470], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T22:57:13.193465", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 7 selected."}
{"time": "2024-06-03T22:57:17.625877", "name": "__main__", "level": "INFO", "message": "Action: 7, Reward: tensor([-24.6821], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T22:57:19.470557", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 1 selected."}
{"time": "2024-06-03T22:57:28.174432", "name": "__main__", "level": "INFO", "message": "Action: 1, Reward: tensor([-25.2934], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T22:57:30.095687", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 11 selected."}
{"time": "2024-06-03T22:57:34.889284", "name": "__main__", "level": "INFO", "message": "Action: 11, Reward: tensor([-25.0735], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T22:57:36.772288", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 1 selected."}
{"time": "2024-06-03T22:57:45.375433", "name": "__main__", "level": "INFO", "message": "Action: 1, Reward: tensor([-25.0531], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T22:57:46.220733", "name": "__main__", "level": "INFO", "message": "Epoch 1, Iteration 10: Reward: tensor([-368.2179], grad_fn=<AddBackward0>), Policy Loss: None, Value Loss: None, Total Loss: None, Entropy: None"}
{"time": "2024-06-03T22:57:47.266086", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 14 selected."}
{"time": "2024-06-03T22:57:55.979283", "name": "__main__", "level": "INFO", "message": "Action: 14, Reward: tensor([-25.1631], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T22:57:57.775597", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 6 selected."}
{"time": "2024-06-03T22:58:02.605668", "name": "__main__", "level": "INFO", "message": "Action: 6, Reward: tensor([-25.1670], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T22:58:04.562893", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 9 selected."}
{"time": "2024-06-03T22:58:12.580673", "name": "__main__", "level": "INFO", "message": "Episode timed out."}
{"time": "2024-06-03T22:58:13.131804", "name": "__main__", "level": "INFO", "message": "Action: 9, Reward: tensor([-23.9102], grad_fn=<AddBackward0>), Done: True"}
{"time": "2024-06-03T22:58:13.807097", "name": "__main__", "level": "INFO", "message": "Environment reset and takeoff completed."}
{"time": "2024-06-03T22:58:15.800584", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 15 selected."}
{"time": "2024-06-03T22:58:24.366467", "name": "__main__", "level": "INFO", "message": "Action: 15, Reward: tensor([-124.9716], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T22:58:25.101797", "name": "__main__", "level": "INFO", "message": "Epoch 2, Iteration 0: Reward: tensor([-124.9716], grad_fn=<AddBackward0>), Policy Loss: None, Value Loss: None, Total Loss: None, Entropy: None"}
{"time": "2024-06-03T22:58:26.824488", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 1 selected."}
{"time": "2024-06-03T22:58:35.684071", "name": "__main__", "level": "INFO", "message": "Action: 1, Reward: tensor([-125.2090], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T22:58:37.404915", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 4 selected."}
{"time": "2024-06-03T22:58:46.467597", "name": "__main__", "level": "INFO", "message": "Action: 4, Reward: tensor([-25.4024], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T22:58:48.424338", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 7 selected."}
{"time": "2024-06-03T22:58:53.300560", "name": "__main__", "level": "INFO", "message": "Action: 7, Reward: tensor([-25.4537], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T22:58:55.020861", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 13 selected."}
{"time": "2024-06-03T22:59:03.722097", "name": "__main__", "level": "INFO", "message": "Action: 13, Reward: tensor([-25.7808], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T22:59:05.556611", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 5 selected."}
{"time": "2024-06-03T22:59:14.508704", "name": "__main__", "level": "INFO", "message": "Action: 5, Reward: tensor([-26.0037], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T22:59:16.268509", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 2 selected."}
{"time": "2024-06-03T22:59:21.271762", "name": "__main__", "level": "INFO", "message": "Action: 2, Reward: tensor([-26.0654], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T22:59:23.118460", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 11 selected."}
{"time": "2024-06-03T22:59:28.078719", "name": "__main__", "level": "INFO", "message": "Action: 11, Reward: tensor([-25.8075], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T22:59:29.944266", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 15 selected."}
{"time": "2024-06-03T22:59:39.025934", "name": "__main__", "level": "INFO", "message": "Action: 15, Reward: tensor([-25.3535], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T22:59:40.968305", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 0 selected."}
{"time": "2024-06-03T22:59:49.491632", "name": "__main__", "level": "INFO", "message": "Action: 0, Reward: tensor([-25.2500], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T22:59:51.417236", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 14 selected."}
{"time": "2024-06-03T23:00:00.026302", "name": "__main__", "level": "INFO", "message": "Action: 14, Reward: tensor([-25.4145], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T23:00:00.884935", "name": "__main__", "level": "INFO", "message": "Epoch 2, Iteration 10: Reward: tensor([-480.7121], grad_fn=<AddBackward0>), Policy Loss: None, Value Loss: None, Total Loss: None, Entropy: None"}
{"time": "2024-06-03T23:00:02.595281", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 4 selected."}
{"time": "2024-06-03T23:00:11.305907", "name": "__main__", "level": "INFO", "message": "Action: 4, Reward: tensor([-25.6069], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T23:00:13.215154", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 2 selected."}
{"time": "2024-06-03T23:00:17.589246", "name": "__main__", "level": "INFO", "message": "Episode timed out."}
{"time": "2024-06-03T23:00:18.120094", "name": "__main__", "level": "INFO", "message": "Action: 2, Reward: tensor([-25.8925], grad_fn=<AddBackward0>), Done: True"}
{"time": "2024-06-03T23:00:18.823805", "name": "__main__", "level": "INFO", "message": "Environment reset and takeoff completed."}
{"time": "2024-06-03T23:00:21.072531", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 2 selected."}
{"time": "2024-06-03T23:00:25.584883", "name": "__main__", "level": "INFO", "message": "Action: 2, Reward: tensor([-124.8542], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T23:00:26.380433", "name": "__main__", "level": "INFO", "message": "Epoch 3, Iteration 0: Reward: tensor([-124.8542], grad_fn=<AddBackward0>), Policy Loss: None, Value Loss: None, Total Loss: None, Entropy: None"}
{"time": "2024-06-03T23:00:27.964777", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 5 selected."}
{"time": "2024-06-03T23:00:36.785206", "name": "__main__", "level": "INFO", "message": "Action: 5, Reward: tensor([-25.0853], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T23:00:38.448627", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 12 selected."}
{"time": "2024-06-03T23:00:47.073224", "name": "__main__", "level": "INFO", "message": "Action: 12, Reward: tensor([-25.3158], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T23:00:49.059891", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 7 selected."}
{"time": "2024-06-03T23:00:53.978032", "name": "__main__", "level": "INFO", "message": "Action: 7, Reward: tensor([-125.4170], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T23:00:55.872812", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 1 selected."}
{"time": "2024-06-03T23:01:04.625011", "name": "__main__", "level": "INFO", "message": "Action: 1, Reward: tensor([-25.6124], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T23:01:06.461519", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 13 selected."}
{"time": "2024-06-03T23:01:15.008157", "name": "__main__", "level": "INFO", "message": "Action: 13, Reward: tensor([-25.9223], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T23:01:16.808863", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 15 selected."}
{"time": "2024-06-03T23:01:25.711468", "name": "__main__", "level": "INFO", "message": "Action: 15, Reward: tensor([-26.1256], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T23:01:27.681570", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 10 selected."}
{"time": "2024-06-03T23:01:32.500441", "name": "__main__", "level": "INFO", "message": "Action: 10, Reward: tensor([-26.2323], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T23:01:34.315097", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 8 selected."}
{"time": "2024-06-03T23:01:42.916063", "name": "__main__", "level": "INFO", "message": "Action: 8, Reward: tensor([-26.4599], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T23:01:44.797199", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 10 selected."}
{"time": "2024-06-03T23:01:49.641310", "name": "__main__", "level": "INFO", "message": "Action: 10, Reward: tensor([-26.6114], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T23:01:51.316985", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 5 selected."}
{"time": "2024-06-03T23:01:59.900056", "name": "__main__", "level": "INFO", "message": "Action: 5, Reward: tensor([-26.7613], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T23:02:00.435350", "name": "__main__", "level": "INFO", "message": "Epoch 3, Iteration 10: Reward: tensor([-484.3975], grad_fn=<AddBackward0>), Policy Loss: None, Value Loss: None, Total Loss: None, Entropy: None"}
{"time": "2024-06-03T23:02:02.077866", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 1 selected."}
{"time": "2024-06-03T23:02:10.986675", "name": "__main__", "level": "INFO", "message": "Action: 1, Reward: tensor([-26.9787], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T23:02:12.926711", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 3 selected."}
{"time": "2024-06-03T23:02:17.067841", "name": "__main__", "level": "INFO", "message": "Action: 3, Reward: tensor([-27.1528], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T23:02:18.888691", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 11 selected."}
{"time": "2024-06-03T23:02:23.120795", "name": "__main__", "level": "INFO", "message": "Episode timed out."}
{"time": "2024-06-03T23:02:23.621212", "name": "__main__", "level": "INFO", "message": "Action: 11, Reward: tensor([-26.8503], grad_fn=<AddBackward0>), Done: True"}
{"time": "2024-06-03T23:02:24.351178", "name": "__main__", "level": "INFO", "message": "Environment reset and takeoff completed."}
{"time": "2024-06-03T23:02:26.531314", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 15 selected."}
{"time": "2024-06-03T23:02:34.950139", "name": "__main__", "level": "INFO", "message": "Action: 15, Reward: tensor([-124.9780], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T23:02:35.602702", "name": "__main__", "level": "INFO", "message": "Epoch 4, Iteration 0: Reward: tensor([-124.9780], grad_fn=<AddBackward0>), Policy Loss: None, Value Loss: None, Total Loss: None, Entropy: None"}
{"time": "2024-06-03T23:02:37.311621", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 2 selected."}
{"time": "2024-06-03T23:02:42.116801", "name": "__main__", "level": "INFO", "message": "Action: 2, Reward: tensor([-25.0376], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T23:02:44.008409", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 5 selected."}
{"time": "2024-06-03T23:02:52.980625", "name": "__main__", "level": "INFO", "message": "Action: 5, Reward: tensor([-24.9643], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T23:02:54.715967", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 14 selected."}
{"time": "2024-06-03T23:03:03.463348", "name": "__main__", "level": "INFO", "message": "Action: 14, Reward: tensor([-25.2133], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T23:03:05.251529", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 12 selected."}
{"time": "2024-06-03T23:03:13.920797", "name": "__main__", "level": "INFO", "message": "Action: 12, Reward: tensor([-25.5709], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T23:03:15.855439", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 5 selected."}
{"time": "2024-06-03T23:03:24.637914", "name": "__main__", "level": "INFO", "message": "Action: 5, Reward: tensor([-26.1653], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T23:03:26.517566", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 11 selected."}
{"time": "2024-06-03T23:03:31.267314", "name": "__main__", "level": "INFO", "message": "Action: 11, Reward: tensor([-25.9879], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T23:03:33.146601", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 7 selected."}
{"time": "2024-06-03T23:03:37.912585", "name": "__main__", "level": "INFO", "message": "Action: 7, Reward: tensor([-26.0846], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T23:03:39.771420", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 14 selected."}
{"time": "2024-06-03T23:03:48.492834", "name": "__main__", "level": "INFO", "message": "Action: 14, Reward: tensor([-26.8218], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T23:03:50.302127", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 14 selected."}
{"time": "2024-06-03T23:03:59.123394", "name": "__main__", "level": "INFO", "message": "Action: 14, Reward: tensor([-28.1610], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T23:04:01.043802", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 0 selected."}
{"time": "2024-06-03T23:04:09.868649", "name": "__main__", "level": "INFO", "message": "Action: 0, Reward: tensor([-29.3359], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T23:04:10.663443", "name": "__main__", "level": "INFO", "message": "Epoch 4, Iteration 10: Reward: tensor([-388.3207], grad_fn=<AddBackward0>), Policy Loss: None, Value Loss: None, Total Loss: None, Entropy: None"}
{"time": "2024-06-03T23:04:12.265537", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 8 selected."}
{"time": "2024-06-03T23:04:21.067553", "name": "__main__", "level": "INFO", "message": "Action: 8, Reward: tensor([-130.0104], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T23:04:22.962081", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 13 selected."}
{"time": "2024-06-03T23:04:31.401596", "name": "__main__", "level": "INFO", "message": "Episode timed out."}
{"time": "2024-06-03T23:04:31.890879", "name": "__main__", "level": "INFO", "message": "Action: 13, Reward: tensor([-30.2247], grad_fn=<AddBackward0>), Done: True"}
{"time": "2024-06-03T23:04:32.651055", "name": "__main__", "level": "INFO", "message": "Environment reset and takeoff completed."}
{"time": "2024-06-03T23:04:34.751724", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 2 selected."}
{"time": "2024-06-03T23:04:39.494003", "name": "__main__", "level": "INFO", "message": "Action: 2, Reward: tensor([-124.8556], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T23:04:40.290945", "name": "__main__", "level": "INFO", "message": "Epoch 5, Iteration 0: Reward: tensor([-124.8556], grad_fn=<AddBackward0>), Policy Loss: None, Value Loss: None, Total Loss: None, Entropy: None"}
{"time": "2024-06-03T23:04:42.052094", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 3 selected."}
{"time": "2024-06-03T23:04:46.960021", "name": "__main__", "level": "INFO", "message": "Action: 3, Reward: tensor([-24.9511], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T23:04:48.862848", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 6 selected."}
{"time": "2024-06-03T23:04:53.493766", "name": "__main__", "level": "INFO", "message": "Action: 6, Reward: tensor([-25.1365], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T23:04:55.327260", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 3 selected."}
{"time": "2024-06-03T23:05:00.106267", "name": "__main__", "level": "INFO", "message": "Action: 3, Reward: tensor([-25.2912], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T23:05:02.075815", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 10 selected."}
{"time": "2024-06-03T23:05:07.032022", "name": "__main__", "level": "INFO", "message": "Action: 10, Reward: tensor([-25.4351], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T23:05:08.998702", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 11 selected."}
{"time": "2024-06-03T23:05:13.690713", "name": "__main__", "level": "INFO", "message": "Action: 11, Reward: tensor([-125.5134], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T23:05:15.547323", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 3 selected."}
{"time": "2024-06-03T23:05:20.537281", "name": "__main__", "level": "INFO", "message": "Action: 3, Reward: tensor([-25.6224], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T23:05:22.415537", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 5 selected."}
{"time": "2024-06-03T23:05:31.384210", "name": "__main__", "level": "INFO", "message": "Action: 5, Reward: tensor([-25.7305], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T23:05:33.243488", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 4 selected."}
{"time": "2024-06-03T23:05:41.630782", "name": "__main__", "level": "INFO", "message": "Action: 4, Reward: tensor([-126.0842], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T23:05:43.205532", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 4 selected."}
{"time": "2024-06-03T23:05:52.188573", "name": "__main__", "level": "INFO", "message": "Action: 4, Reward: tensor([-126.3581], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T23:05:53.766033", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 3 selected."}
{"time": "2024-06-03T23:05:58.593067", "name": "__main__", "level": "INFO", "message": "Action: 3, Reward: tensor([-26.4798], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T23:05:59.215099", "name": "__main__", "level": "INFO", "message": "Epoch 5, Iteration 10: Reward: tensor([-681.4578], grad_fn=<AddBackward0>), Policy Loss: None, Value Loss: None, Total Loss: None, Entropy: None"}
{"time": "2024-06-03T23:06:00.815206", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 10 selected."}
{"time": "2024-06-03T23:06:05.572883", "name": "__main__", "level": "INFO", "message": "Action: 10, Reward: tensor([-26.6190], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T23:06:07.448343", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 12 selected."}
{"time": "2024-06-03T23:06:16.168077", "name": "__main__", "level": "INFO", "message": "Action: 12, Reward: tensor([-26.8674], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T23:06:17.988814", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 15 selected."}
{"time": "2024-06-03T23:06:26.572604", "name": "__main__", "level": "INFO", "message": "Action: 15, Reward: tensor([-27.0949], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T23:06:27.912725", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 5 selected."}
{"time": "2024-06-03T23:06:35.996746", "name": "__main__", "level": "INFO", "message": "Episode timed out."}
{"time": "2024-06-03T23:06:36.559256", "name": "__main__", "level": "INFO", "message": "Action: 5, Reward: tensor([-27.1210], grad_fn=<AddBackward0>), Done: True"}
{"time": "2024-06-03T23:06:37.040309", "name": "__main__", "level": "INFO", "message": "Environment reset and takeoff completed."}
{"time": "2024-06-03T23:06:39.212569", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 4 selected."}
{"time": "2024-06-03T23:06:47.988365", "name": "__main__", "level": "INFO", "message": "Action: 4, Reward: tensor([-124.9249], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T23:06:48.613233", "name": "__main__", "level": "INFO", "message": "Epoch 6, Iteration 0: Reward: tensor([-124.9249], grad_fn=<AddBackward0>), Policy Loss: None, Value Loss: None, Total Loss: None, Entropy: None"}
{"time": "2024-06-03T23:06:50.160611", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 3 selected."}
{"time": "2024-06-03T23:06:54.892401", "name": "__main__", "level": "INFO", "message": "Action: 3, Reward: tensor([-125.0920], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T23:06:56.663521", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 12 selected."}
{"time": "2024-06-03T23:07:05.371781", "name": "__main__", "level": "INFO", "message": "Action: 12, Reward: tensor([-125.3327], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T23:07:07.321774", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 11 selected."}
{"time": "2024-06-03T23:07:12.199570", "name": "__main__", "level": "INFO", "message": "Action: 11, Reward: tensor([-25.0473], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T23:07:14.057708", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 3 selected."}
{"time": "2024-06-03T23:07:18.720305", "name": "__main__", "level": "INFO", "message": "Action: 3, Reward: tensor([-24.9509], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T23:07:20.565146", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 7 selected."}
{"time": "2024-06-03T23:07:25.235143", "name": "__main__", "level": "INFO", "message": "Action: 7, Reward: tensor([-25.0307], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T23:07:27.125022", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 13 selected."}
{"time": "2024-06-03T23:07:35.953680", "name": "__main__", "level": "INFO", "message": "Action: 13, Reward: tensor([-25.5300], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T23:07:36.706374", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 0 selected."}
{"time": "2024-06-03T23:07:45.235765", "name": "__main__", "level": "INFO", "message": "Action: 0, Reward: tensor([-25.8734], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T23:07:47.082788", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 14 selected."}
{"time": "2024-06-03T23:07:55.516705", "name": "__main__", "level": "INFO", "message": "Action: 14, Reward: tensor([-26.3254], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T23:07:57.515050", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 9 selected."}
{"time": "2024-06-03T23:08:06.630440", "name": "__main__", "level": "INFO", "message": "Action: 9, Reward: tensor([-25.2726], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T23:08:08.521758", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 8 selected."}
{"time": "2024-06-03T23:08:17.213131", "name": "__main__", "level": "INFO", "message": "Action: 8, Reward: tensor([-26.3476], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T23:08:18.072105", "name": "__main__", "level": "INFO", "message": "Epoch 6, Iteration 10: Reward: tensor([-579.7277], grad_fn=<AddBackward0>), Policy Loss: None, Value Loss: None, Total Loss: None, Entropy: None"}
{"time": "2024-06-03T23:08:19.649843", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 0 selected."}
{"time": "2024-06-03T23:08:28.237579", "name": "__main__", "level": "INFO", "message": "Action: 0, Reward: tensor([-27.1758], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-03T23:08:29.711830", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 15 selected."}
{"time": "2024-06-03T23:08:38.026246", "name": "__main__", "level": "INFO", "message": "Episode timed out."}
{"time": "2024-06-03T23:08:38.432908", "name": "__main__", "level": "INFO", "message": "Action: 15, Reward: tensor([-27.2904], grad_fn=<AddBackward0>), Done: True"}
{"time": "2024-06-03T23:08:38.730320", "name": "__main__", "level": "INFO", "message": "Early stopping triggered after 7 epochs."}
{"time": "2024-06-03T23:08:59.654052", "name": "__main__", "level": "INFO", "message": "Dropped rows with NA values. Shape changed from (506, 2) to (506, 2)."}
{"time": "2024-06-04T02:11:20.524132", "name": "__main__", "level": "INFO", "message": "Time Series plot created successfully for steps vs values."}
{"time": "2024-06-04T02:11:36.311012", "name": "__main__", "level": "INFO", "message": "Histogram plotted successfully for column: values."}
{"time": "2024-06-04T02:11:55.430413", "name": "__main__", "level": "INFO", "message": "Correlation matrix heatmap generated successfully."}
{"time": "2024-06-04T02:12:13.576215", "name": "__main__", "level": "INFO", "message": "Scatter plot created successfully for steps vs values."}
{"time": "2024-06-04T02:13:29.905076", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Using device: cpu"}
{"time": "2024-06-04T02:13:35.495286", "name": "__main__", "level": "INFO", "message": "DataVisualizer initialized with Seaborn style set to 'whitegrid'."}
{"time": "2024-06-04T02:13:35.665668", "name": "__main__", "level": "INFO", "message": "Loading checkpoint from e:\\Project\\models/checkpoints\\ppo_agent_checkpoint.pt"}
{"time": "2024-06-04T02:13:39.533587", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Model loaded"}
{"time": "2024-06-04T02:13:40.632782", "name": "__main__", "level": "INFO", "message": "Resuming training from epoch 1"}
{"time": "2024-06-04T02:13:40.979094", "name": "__main__", "level": "INFO", "message": "Environment reset and takeoff completed."}
{"time": "2024-06-04T02:13:43.150093", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 15 selected."}
{"time": "2024-06-04T02:13:51.700752", "name": "__main__", "level": "INFO", "message": "Action: 15, Reward: tensor([-124.8712], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T02:13:52.572621", "name": "__main__", "level": "INFO", "message": "Epoch 1, Iteration 0: Reward: tensor([-124.8712], grad_fn=<AddBackward0>), Policy Loss: None, Value Loss: None, Total Loss: None, Entropy: None"}
{"time": "2024-06-04T02:13:54.305555", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 8 selected."}
{"time": "2024-06-04T02:14:03.186738", "name": "__main__", "level": "INFO", "message": "Action: 8, Reward: tensor([-25.0924], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T02:14:04.934380", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 15 selected."}
{"time": "2024-06-04T02:14:13.656191", "name": "__main__", "level": "INFO", "message": "Action: 15, Reward: tensor([-25.3583], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T02:14:15.470488", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 3 selected."}
{"time": "2024-06-04T02:14:20.566236", "name": "__main__", "level": "INFO", "message": "Action: 3, Reward: tensor([-25.4832], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T02:14:22.469776", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 15 selected."}
{"time": "2024-06-04T02:14:31.398026", "name": "__main__", "level": "INFO", "message": "Action: 15, Reward: tensor([-25.7421], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T02:14:33.322195", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 2 selected."}
{"time": "2024-06-04T02:14:38.184351", "name": "__main__", "level": "INFO", "message": "Action: 2, Reward: tensor([-25.7129], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T02:14:40.200734", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 0 selected."}
{"time": "2024-06-04T02:14:49.039636", "name": "__main__", "level": "INFO", "message": "Action: 0, Reward: tensor([-25.8989], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T02:14:50.996180", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 12 selected."}
{"time": "2024-06-04T02:14:59.217314", "name": "__main__", "level": "INFO", "message": "Action: 12, Reward: tensor([-26.2957], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T02:15:00.982278", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 11 selected."}
{"time": "2024-06-04T02:15:05.597956", "name": "__main__", "level": "INFO", "message": "Action: 11, Reward: tensor([-26.0084], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T02:15:07.470338", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 4 selected."}
{"time": "2024-06-04T02:15:16.177544", "name": "__main__", "level": "INFO", "message": "Action: 4, Reward: tensor([-25.8115], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T02:15:17.993671", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 2 selected."}
{"time": "2024-06-04T02:15:22.976658", "name": "__main__", "level": "INFO", "message": "Action: 2, Reward: tensor([-26.0748], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T02:15:23.768977", "name": "__main__", "level": "INFO", "message": "Epoch 1, Iteration 10: Reward: tensor([-382.3494], grad_fn=<AddBackward0>), Policy Loss: None, Value Loss: None, Total Loss: None, Entropy: None"}
{"time": "2024-06-04T02:15:25.472441", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 9 selected."}
{"time": "2024-06-04T02:15:34.121962", "name": "__main__", "level": "INFO", "message": "Action: 9, Reward: tensor([-24.9760], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T02:15:35.933034", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 1 selected."}
{"time": "2024-06-04T02:15:44.255384", "name": "__main__", "level": "INFO", "message": "Episode timed out."}
{"time": "2024-06-04T02:15:44.646589", "name": "__main__", "level": "INFO", "message": "Action: 1, Reward: tensor([-24.2898], grad_fn=<AddBackward0>), Done: True"}
{"time": "2024-06-04T02:15:45.346347", "name": "__main__", "level": "INFO", "message": "Environment reset and takeoff completed."}
{"time": "2024-06-04T02:15:47.184077", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 16 selected."}
{"time": "2024-06-04T02:15:55.936376", "name": "__main__", "level": "INFO", "message": "Action: 16, Reward: tensor([-124.5046], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T02:15:56.642681", "name": "__main__", "level": "INFO", "message": "Epoch 2, Iteration 0: Reward: tensor([-124.5046], grad_fn=<AddBackward0>), Policy Loss: None, Value Loss: None, Total Loss: None, Entropy: None"}
{"time": "2024-06-04T02:15:58.226723", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 0 selected."}
{"time": "2024-06-04T02:16:06.768186", "name": "__main__", "level": "INFO", "message": "Action: 0, Reward: tensor([-24.6631], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T02:16:08.628073", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 8 selected."}
{"time": "2024-06-04T02:16:17.550450", "name": "__main__", "level": "INFO", "message": "Action: 8, Reward: tensor([-125.2922], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T02:16:19.518860", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 15 selected."}
{"time": "2024-06-04T02:16:28.456156", "name": "__main__", "level": "INFO", "message": "Action: 15, Reward: tensor([-25.5285], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T02:16:30.346181", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 1 selected."}
{"time": "2024-06-04T02:16:39.176173", "name": "__main__", "level": "INFO", "message": "Action: 1, Reward: tensor([-25.7651], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T02:16:40.757321", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 11 selected."}
{"time": "2024-06-04T02:16:45.340414", "name": "__main__", "level": "INFO", "message": "Action: 11, Reward: tensor([-25.4647], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T02:16:47.019625", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 14 selected."}
{"time": "2024-06-04T02:16:56.028489", "name": "__main__", "level": "INFO", "message": "Action: 14, Reward: tensor([-25.1145], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T02:16:57.801548", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 1 selected."}
{"time": "2024-06-04T02:17:06.660341", "name": "__main__", "level": "INFO", "message": "Action: 1, Reward: tensor([-25.1229], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T02:17:08.676770", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 12 selected."}
{"time": "2024-06-04T02:17:17.452343", "name": "__main__", "level": "INFO", "message": "Action: 12, Reward: tensor([-25.5076], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T02:17:19.281963", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 11 selected."}
{"time": "2024-06-04T02:17:23.844210", "name": "__main__", "level": "INFO", "message": "Action: 11, Reward: tensor([-25.2505], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T02:17:25.638967", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 11 selected."}
{"time": "2024-06-04T02:17:30.160331", "name": "__main__", "level": "INFO", "message": "Action: 11, Reward: tensor([-24.7565], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T02:17:30.911258", "name": "__main__", "level": "INFO", "message": "Epoch 2, Iteration 10: Reward: tensor([-476.9703], grad_fn=<AddBackward0>), Policy Loss: None, Value Loss: None, Total Loss: None, Entropy: None"}
{"time": "2024-06-04T02:17:32.505433", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 2 selected."}
{"time": "2024-06-04T02:17:37.162113", "name": "__main__", "level": "INFO", "message": "Action: 2, Reward: tensor([-24.6035], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T02:17:38.988821", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 0 selected."}
{"time": "2024-06-04T02:17:47.503737", "name": "__main__", "level": "INFO", "message": "Episode timed out."}
{"time": "2024-06-04T02:17:48.048499", "name": "__main__", "level": "INFO", "message": "Action: 0, Reward: tensor([-24.4970], grad_fn=<AddBackward0>), Done: True"}
{"time": "2024-06-04T02:17:48.689267", "name": "__main__", "level": "INFO", "message": "Environment reset and takeoff completed."}
{"time": "2024-06-04T02:17:50.957453", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 13 selected."}
{"time": "2024-06-04T02:17:59.904583", "name": "__main__", "level": "INFO", "message": "Action: 13, Reward: tensor([-124.8738], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T02:18:00.670024", "name": "__main__", "level": "INFO", "message": "Epoch 3, Iteration 0: Reward: tensor([-124.8738], grad_fn=<AddBackward0>), Policy Loss: None, Value Loss: None, Total Loss: None, Entropy: None"}
{"time": "2024-06-04T02:18:02.359282", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 0 selected."}
{"time": "2024-06-04T02:18:11.241036", "name": "__main__", "level": "INFO", "message": "Action: 0, Reward: tensor([-25.0205], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T02:18:13.078426", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 2 selected."}
{"time": "2024-06-04T02:18:17.871324", "name": "__main__", "level": "INFO", "message": "Action: 2, Reward: tensor([-25.2197], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T02:18:19.301703", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 2 selected."}
{"time": "2024-06-04T02:18:24.118656", "name": "__main__", "level": "INFO", "message": "Action: 2, Reward: tensor([-125.3805], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T02:18:25.946393", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 16 selected."}
{"time": "2024-06-04T02:18:34.516574", "name": "__main__", "level": "INFO", "message": "Action: 16, Reward: tensor([-25.5239], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T02:18:36.287647", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 7 selected."}
{"time": "2024-06-04T02:18:41.094006", "name": "__main__", "level": "INFO", "message": "Action: 7, Reward: tensor([-25.6723], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T02:18:42.927102", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 14 selected."}
{"time": "2024-06-04T02:18:51.647710", "name": "__main__", "level": "INFO", "message": "Action: 14, Reward: tensor([-25.8620], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T02:18:53.556920", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 14 selected."}
{"time": "2024-06-04T02:19:02.509686", "name": "__main__", "level": "INFO", "message": "Action: 14, Reward: tensor([-26.2588], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T02:19:04.368231", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 2 selected."}
{"time": "2024-06-04T02:19:09.307881", "name": "__main__", "level": "INFO", "message": "Action: 2, Reward: tensor([-26.4480], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T02:19:11.347668", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 0 selected."}
{"time": "2024-06-04T02:19:20.247990", "name": "__main__", "level": "INFO", "message": "Action: 0, Reward: tensor([-26.9535], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T02:19:22.080852", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 15 selected."}
{"time": "2024-06-04T02:19:31.156064", "name": "__main__", "level": "INFO", "message": "Action: 15, Reward: tensor([-27.1655], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T02:19:31.839894", "name": "__main__", "level": "INFO", "message": "Epoch 3, Iteration 10: Reward: tensor([-484.3785], grad_fn=<AddBackward0>), Policy Loss: None, Value Loss: None, Total Loss: None, Entropy: None"}
{"time": "2024-06-04T02:19:33.403070", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 5 selected."}
{"time": "2024-06-04T02:19:42.125265", "name": "__main__", "level": "INFO", "message": "Action: 5, Reward: tensor([-27.1543], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T02:19:44.014867", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 3 selected."}
{"time": "2024-06-04T02:19:48.634845", "name": "__main__", "level": "INFO", "message": "Action: 3, Reward: tensor([-27.3107], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T02:19:50.539485", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 2 selected."}
{"time": "2024-06-04T02:19:54.935661", "name": "__main__", "level": "INFO", "message": "Episode timed out."}
{"time": "2024-06-04T02:19:55.124396", "name": "__main__", "level": "INFO", "message": "Action: 2, Reward: tensor([-27.5594], grad_fn=<AddBackward0>), Done: True"}
{"time": "2024-06-04T02:19:55.857881", "name": "__main__", "level": "INFO", "message": "Environment reset and takeoff completed."}
{"time": "2024-06-04T02:19:58.026763", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 11 selected."}
{"time": "2024-06-04T02:20:02.750721", "name": "__main__", "level": "INFO", "message": "Action: 11, Reward: tensor([-124.3435], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T02:20:03.596226", "name": "__main__", "level": "INFO", "message": "Epoch 4, Iteration 0: Reward: tensor([-124.3435], grad_fn=<AddBackward0>), Policy Loss: None, Value Loss: None, Total Loss: None, Entropy: None"}
{"time": "2024-06-04T02:20:05.162966", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 3 selected."}
{"time": "2024-06-04T02:20:10.146409", "name": "__main__", "level": "INFO", "message": "Action: 3, Reward: tensor([-24.2980], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T02:20:12.021384", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 0 selected."}
{"time": "2024-06-04T02:20:20.976710", "name": "__main__", "level": "INFO", "message": "Action: 0, Reward: tensor([-24.2763], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T02:20:22.947058", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 5 selected."}
{"time": "2024-06-04T02:20:31.646152", "name": "__main__", "level": "INFO", "message": "Action: 5, Reward: tensor([-24.3023], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T02:20:33.185570", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 12 selected."}
{"time": "2024-06-04T02:20:41.851824", "name": "__main__", "level": "INFO", "message": "Action: 12, Reward: tensor([-24.4531], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T02:20:43.471280", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 10 selected."}
{"time": "2024-06-04T02:20:48.198718", "name": "__main__", "level": "INFO", "message": "Action: 10, Reward: tensor([-25.1221], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T02:20:49.966081", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 3 selected."}
{"time": "2024-06-04T02:20:54.527201", "name": "__main__", "level": "INFO", "message": "Action: 3, Reward: tensor([-25.4018], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T02:20:56.517400", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 3 selected."}
{"time": "2024-06-04T02:21:01.334861", "name": "__main__", "level": "INFO", "message": "Action: 3, Reward: tensor([-25.5778], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T02:21:03.163325", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 6 selected."}
{"time": "2024-06-04T02:21:07.867859", "name": "__main__", "level": "INFO", "message": "Action: 6, Reward: tensor([-25.7038], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T02:21:09.761648", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 4 selected."}
{"time": "2024-06-04T02:21:18.807713", "name": "__main__", "level": "INFO", "message": "Action: 4, Reward: tensor([-25.9649], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T02:21:20.852955", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 0 selected."}
{"time": "2024-06-04T02:21:29.631288", "name": "__main__", "level": "INFO", "message": "Action: 0, Reward: tensor([-26.5366], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T02:21:30.362731", "name": "__main__", "level": "INFO", "message": "Epoch 4, Iteration 10: Reward: tensor([-375.9802], grad_fn=<AddBackward0>), Policy Loss: None, Value Loss: None, Total Loss: None, Entropy: None"}
{"time": "2024-06-04T02:21:32.016212", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 5 selected."}
{"time": "2024-06-04T02:21:41.107738", "name": "__main__", "level": "INFO", "message": "Action: 5, Reward: tensor([-126.9125], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T02:21:43.078695", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 1 selected."}
{"time": "2024-06-04T02:21:51.999346", "name": "__main__", "level": "INFO", "message": "Action: 1, Reward: tensor([-27.1244], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T02:21:53.971342", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 1 selected."}
{"time": "2024-06-04T02:22:02.325282", "name": "__main__", "level": "INFO", "message": "Episode timed out."}
{"time": "2024-06-04T02:22:02.808056", "name": "__main__", "level": "INFO", "message": "Action: 1, Reward: tensor([-27.4002], grad_fn=<AddBackward0>), Done: True"}
{"time": "2024-06-04T02:22:03.436620", "name": "__main__", "level": "INFO", "message": "Environment reset and takeoff completed."}
{"time": "2024-06-04T02:22:05.725214", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 2 selected."}
{"time": "2024-06-04T02:22:10.780919", "name": "__main__", "level": "INFO", "message": "Action: 2, Reward: tensor([-124.7547], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T02:22:11.622743", "name": "__main__", "level": "INFO", "message": "Epoch 5, Iteration 0: Reward: tensor([-124.7547], grad_fn=<AddBackward0>), Policy Loss: None, Value Loss: None, Total Loss: None, Entropy: None"}
{"time": "2024-06-04T02:22:13.394056", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 0 selected."}
{"time": "2024-06-04T02:22:22.010202", "name": "__main__", "level": "INFO", "message": "Action: 0, Reward: tensor([-125.0353], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T02:22:23.813502", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 1 selected."}
{"time": "2024-06-04T02:22:32.913763", "name": "__main__", "level": "INFO", "message": "Action: 1, Reward: tensor([-25.1242], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T02:22:34.528162", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 1 selected."}
{"time": "2024-06-04T02:22:42.678420", "name": "__main__", "level": "INFO", "message": "Action: 1, Reward: tensor([-25.4245], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T02:22:44.682026", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 0 selected."}
{"time": "2024-06-04T02:22:53.140162", "name": "__main__", "level": "INFO", "message": "Action: 0, Reward: tensor([-25.5531], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T02:22:54.272197", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 11 selected."}
{"time": "2024-06-04T02:22:58.970870", "name": "__main__", "level": "INFO", "message": "Action: 11, Reward: tensor([-25.3365], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T02:23:00.809212", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 6 selected."}
{"time": "2024-06-04T02:23:05.777370", "name": "__main__", "level": "INFO", "message": "Action: 6, Reward: tensor([-25.3402], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T02:23:07.612970", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 6 selected."}
{"time": "2024-06-04T02:23:12.481000", "name": "__main__", "level": "INFO", "message": "Action: 6, Reward: tensor([-25.5209], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T02:23:14.406757", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 9 selected."}
{"time": "2024-06-04T02:23:23.091925", "name": "__main__", "level": "INFO", "message": "Action: 9, Reward: tensor([-24.2906], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T02:23:25.057868", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 0 selected."}
{"time": "2024-06-04T02:23:34.091500", "name": "__main__", "level": "INFO", "message": "Action: 0, Reward: tensor([-23.5452], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T02:23:35.963108", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 0 selected."}
{"time": "2024-06-04T02:23:44.953915", "name": "__main__", "level": "INFO", "message": "Action: 0, Reward: tensor([-23.4205], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T02:23:45.780070", "name": "__main__", "level": "INFO", "message": "Epoch 5, Iteration 10: Reward: tensor([-473.3457], grad_fn=<AddBackward0>), Policy Loss: None, Value Loss: None, Total Loss: None, Entropy: None"}
{"time": "2024-06-04T02:23:47.208089", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 10 selected."}
{"time": "2024-06-04T02:23:51.765849", "name": "__main__", "level": "INFO", "message": "Action: 10, Reward: tensor([-24.0467], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T02:23:53.734910", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 0 selected."}
{"time": "2024-06-04T02:24:02.451058", "name": "__main__", "level": "INFO", "message": "Action: 0, Reward: tensor([-25.2198], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T02:24:04.406073", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 3 selected."}
{"time": "2024-06-04T02:24:08.741368", "name": "__main__", "level": "INFO", "message": "Episode timed out."}
{"time": "2024-06-04T02:24:09.238513", "name": "__main__", "level": "INFO", "message": "Action: 3, Reward: tensor([-25.4527], grad_fn=<AddBackward0>), Done: True"}
{"time": "2024-06-04T02:24:09.941489", "name": "__main__", "level": "INFO", "message": "Environment reset and takeoff completed."}
{"time": "2024-06-04T02:24:12.254163", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 5 selected."}
{"time": "2024-06-04T02:24:21.143108", "name": "__main__", "level": "INFO", "message": "Action: 5, Reward: tensor([-124.8389], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T02:24:22.082820", "name": "__main__", "level": "INFO", "message": "Epoch 6, Iteration 0: Reward: tensor([-124.8389], grad_fn=<AddBackward0>), Policy Loss: None, Value Loss: None, Total Loss: None, Entropy: None"}
{"time": "2024-06-04T02:24:23.763431", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 14 selected."}
{"time": "2024-06-04T02:24:32.566464", "name": "__main__", "level": "INFO", "message": "Action: 14, Reward: tensor([-25.1454], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T02:24:34.509552", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 3 selected."}
{"time": "2024-06-04T02:24:39.364855", "name": "__main__", "level": "INFO", "message": "Action: 3, Reward: tensor([-25.1896], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T02:24:41.125158", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 5 selected."}
{"time": "2024-06-04T02:24:49.990081", "name": "__main__", "level": "INFO", "message": "Action: 5, Reward: tensor([-25.4529], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T02:24:52.092380", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 0 selected."}
{"time": "2024-06-04T02:25:00.838420", "name": "__main__", "level": "INFO", "message": "Action: 0, Reward: tensor([-25.6417], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T02:25:02.899609", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 4 selected."}
{"time": "2024-06-04T02:25:11.353679", "name": "__main__", "level": "INFO", "message": "Action: 4, Reward: tensor([-25.8226], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T02:25:13.369586", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 9 selected."}
{"time": "2024-06-04T02:25:22.227058", "name": "__main__", "level": "INFO", "message": "Action: 9, Reward: tensor([-24.7780], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T02:25:24.092623", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 13 selected."}
{"time": "2024-06-04T02:25:32.779496", "name": "__main__", "level": "INFO", "message": "Action: 13, Reward: tensor([-24.1221], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T02:25:34.766924", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 0 selected."}
{"time": "2024-06-04T02:25:43.591676", "name": "__main__", "level": "INFO", "message": "Action: 0, Reward: tensor([-24.2300], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T02:25:45.354522", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 0 selected."}
{"time": "2024-06-04T02:25:54.246764", "name": "__main__", "level": "INFO", "message": "Action: 0, Reward: tensor([-24.6337], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T02:25:56.198261", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 0 selected."}
{"time": "2024-06-04T02:26:04.976185", "name": "__main__", "level": "INFO", "message": "Action: 0, Reward: tensor([-25.1081], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T02:26:05.566276", "name": "__main__", "level": "INFO", "message": "Epoch 6, Iteration 10: Reward: tensor([-374.9631], grad_fn=<AddBackward0>), Policy Loss: None, Value Loss: None, Total Loss: None, Entropy: None"}
{"time": "2024-06-04T02:26:07.257645", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 0 selected."}
{"time": "2024-06-04T02:26:15.707215", "name": "__main__", "level": "INFO", "message": "Episode timed out."}
{"time": "2024-06-04T02:26:16.303623", "name": "__main__", "level": "INFO", "message": "Action: 0, Reward: tensor([-25.8144], grad_fn=<AddBackward0>), Done: True"}
{"time": "2024-06-04T02:26:16.994024", "name": "__main__", "level": "INFO", "message": "Environment reset and takeoff completed."}
{"time": "2024-06-04T02:26:19.261232", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 13 selected."}
{"time": "2024-06-04T02:26:27.774979", "name": "__main__", "level": "INFO", "message": "Action: 13, Reward: tensor([-124.8785], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T02:26:28.634671", "name": "__main__", "level": "INFO", "message": "Epoch 7, Iteration 0: Reward: tensor([-124.8785], grad_fn=<AddBackward0>), Policy Loss: None, Value Loss: None, Total Loss: None, Entropy: None"}
{"time": "2024-06-04T02:26:30.215893", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 0 selected."}
{"time": "2024-06-04T02:26:39.029283", "name": "__main__", "level": "INFO", "message": "Action: 0, Reward: tensor([-125.0350], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T02:26:40.872175", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 8 selected."}
{"time": "2024-06-04T02:26:49.481000", "name": "__main__", "level": "INFO", "message": "Action: 8, Reward: tensor([-25.2803], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T02:26:51.383258", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 0 selected."}
{"time": "2024-06-04T02:27:00.156143", "name": "__main__", "level": "INFO", "message": "Action: 0, Reward: tensor([-25.5095], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T02:27:02.114025", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 0 selected."}
{"time": "2024-06-04T02:27:11.027795", "name": "__main__", "level": "INFO", "message": "Action: 0, Reward: tensor([-25.7587], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T02:27:13.118929", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 0 selected."}
{"time": "2024-06-04T02:27:21.982492", "name": "__main__", "level": "INFO", "message": "Action: 0, Reward: tensor([-25.9958], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T02:27:23.965341", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 16 selected."}
{"time": "2024-06-04T02:27:32.915085", "name": "__main__", "level": "INFO", "message": "Action: 16, Reward: tensor([-26.1081], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T02:27:34.848155", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 2 selected."}
{"time": "2024-06-04T02:27:39.603898", "name": "__main__", "level": "INFO", "message": "Action: 2, Reward: tensor([-26.3073], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T02:27:41.602806", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 10 selected."}
{"time": "2024-06-04T02:27:46.478957", "name": "__main__", "level": "INFO", "message": "Action: 10, Reward: tensor([-26.4289], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T02:27:48.482374", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 0 selected."}
{"time": "2024-06-04T02:27:56.978713", "name": "__main__", "level": "INFO", "message": "Action: 0, Reward: tensor([-26.6657], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T02:27:58.883431", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 11 selected."}
{"time": "2024-06-04T02:28:03.818835", "name": "__main__", "level": "INFO", "message": "Action: 11, Reward: tensor([-26.4889], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T02:28:04.492599", "name": "__main__", "level": "INFO", "message": "Epoch 7, Iteration 10: Reward: tensor([-484.4567], grad_fn=<AddBackward0>), Policy Loss: None, Value Loss: None, Total Loss: None, Entropy: None"}
{"time": "2024-06-04T02:28:06.180298", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 1 selected."}
{"time": "2024-06-04T02:28:14.872878", "name": "__main__", "level": "INFO", "message": "Action: 1, Reward: tensor([-26.2861], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T02:28:16.844211", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 10 selected."}
{"time": "2024-06-04T02:28:20.975634", "name": "__main__", "level": "INFO", "message": "Episode timed out."}
{"time": "2024-06-04T02:28:21.553768", "name": "__main__", "level": "INFO", "message": "Action: 10, Reward: tensor([-26.9247], grad_fn=<AddBackward0>), Done: True"}
{"time": "2024-06-04T02:28:22.100782", "name": "__main__", "level": "INFO", "message": "Environment reset and takeoff completed."}
{"time": "2024-06-04T02:28:24.149096", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 3 selected."}
{"time": "2024-06-04T02:28:29.207404", "name": "__main__", "level": "INFO", "message": "Action: 3, Reward: tensor([-124.7613], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T02:28:29.969832", "name": "__main__", "level": "INFO", "message": "Epoch 8, Iteration 0: Reward: tensor([-124.7613], grad_fn=<AddBackward0>), Policy Loss: None, Value Loss: None, Total Loss: None, Entropy: None"}
{"time": "2024-06-04T02:28:31.709590", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 1 selected."}
{"time": "2024-06-04T02:28:40.753478", "name": "__main__", "level": "INFO", "message": "Action: 1, Reward: tensor([-25.0396], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T02:28:42.558574", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 13 selected."}
{"time": "2024-06-04T02:28:51.373507", "name": "__main__", "level": "INFO", "message": "Action: 13, Reward: tensor([-25.2997], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T02:28:53.277202", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 0 selected."}
{"time": "2024-06-04T02:29:02.138435", "name": "__main__", "level": "INFO", "message": "Action: 0, Reward: tensor([-25.3709], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T02:29:04.108651", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 3 selected."}
{"time": "2024-06-04T02:29:09.103755", "name": "__main__", "level": "INFO", "message": "Action: 3, Reward: tensor([-25.5562], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T02:29:10.898707", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 11 selected."}
{"time": "2024-06-04T02:29:15.651652", "name": "__main__", "level": "INFO", "message": "Action: 11, Reward: tensor([-25.6251], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T02:29:17.529995", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 0 selected."}
{"time": "2024-06-04T02:29:26.342126", "name": "__main__", "level": "INFO", "message": "Action: 0, Reward: tensor([-25.1316], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T02:29:28.334585", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 5 selected."}
{"time": "2024-06-04T02:29:36.900020", "name": "__main__", "level": "INFO", "message": "Action: 5, Reward: tensor([-24.8325], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T02:29:38.657667", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 13 selected."}
{"time": "2024-06-04T02:29:47.320886", "name": "__main__", "level": "INFO", "message": "Action: 13, Reward: tensor([-24.7477], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T02:29:49.181587", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 16 selected."}
{"time": "2024-06-04T02:29:57.969770", "name": "__main__", "level": "INFO", "message": "Action: 16, Reward: tensor([-24.7858], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T02:29:59.787358", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 7 selected."}
{"time": "2024-06-04T02:30:04.615489", "name": "__main__", "level": "INFO", "message": "Action: 7, Reward: tensor([-25.1095], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T02:30:05.352230", "name": "__main__", "level": "INFO", "message": "Epoch 8, Iteration 10: Reward: tensor([-376.2601], grad_fn=<AddBackward0>), Policy Loss: None, Value Loss: None, Total Loss: None, Entropy: None"}
{"time": "2024-06-04T02:30:07.046471", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 10 selected."}
{"time": "2024-06-04T02:30:12.197259", "name": "__main__", "level": "INFO", "message": "Action: 10, Reward: tensor([-25.7538], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T02:30:13.989751", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 3 selected."}
{"time": "2024-06-04T02:30:18.884302", "name": "__main__", "level": "INFO", "message": "Action: 3, Reward: tensor([-26.2105], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T02:30:20.875414", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 0 selected."}
{"time": "2024-06-04T02:30:29.082528", "name": "__main__", "level": "INFO", "message": "Episode timed out."}
{"time": "2024-06-04T02:30:29.630107", "name": "__main__", "level": "INFO", "message": "Action: 0, Reward: tensor([-26.8885], grad_fn=<AddBackward0>), Done: True"}
{"time": "2024-06-04T02:30:30.407450", "name": "__main__", "level": "INFO", "message": "Environment reset and takeoff completed."}
{"time": "2024-06-04T02:30:32.467143", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 1 selected."}
{"time": "2024-06-04T02:30:41.225317", "name": "__main__", "level": "INFO", "message": "Action: 1, Reward: tensor([-124.6648], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T02:30:42.037000", "name": "__main__", "level": "INFO", "message": "Epoch 9, Iteration 0: Reward: tensor([-124.6648], grad_fn=<AddBackward0>), Policy Loss: None, Value Loss: None, Total Loss: None, Entropy: None"}
{"time": "2024-06-04T02:30:43.710491", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 0 selected."}
{"time": "2024-06-04T02:30:52.245647", "name": "__main__", "level": "INFO", "message": "Action: 0, Reward: tensor([-24.7938], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T02:30:53.983625", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 14 selected."}
{"time": "2024-06-04T02:31:02.782299", "name": "__main__", "level": "INFO", "message": "Action: 14, Reward: tensor([-25.1477], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T02:31:04.799820", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 3 selected."}
{"time": "2024-06-04T02:31:09.677025", "name": "__main__", "level": "INFO", "message": "Action: 3, Reward: tensor([-25.2546], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T02:31:11.527966", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 1 selected."}
{"time": "2024-06-04T02:31:19.777111", "name": "__main__", "level": "INFO", "message": "Action: 1, Reward: tensor([-25.4562], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T02:31:21.558053", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 0 selected."}
{"time": "2024-06-04T02:31:30.323545", "name": "__main__", "level": "INFO", "message": "Action: 0, Reward: tensor([-25.4746], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T02:31:32.059459", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 3 selected."}
{"time": "2024-06-04T02:31:36.509194", "name": "__main__", "level": "INFO", "message": "Action: 3, Reward: tensor([-25.7007], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T02:31:38.280624", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 3 selected."}
{"time": "2024-06-04T02:31:43.032603", "name": "__main__", "level": "INFO", "message": "Action: 3, Reward: tensor([-25.9149], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T02:31:44.886109", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 0 selected."}
{"time": "2024-06-04T02:31:53.734134", "name": "__main__", "level": "INFO", "message": "Action: 0, Reward: tensor([-26.0710], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T02:31:55.704422", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 16 selected."}
{"time": "2024-06-04T02:32:04.768031", "name": "__main__", "level": "INFO", "message": "Action: 16, Reward: tensor([-26.4160], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T02:32:06.732279", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 0 selected."}
{"time": "2024-06-04T02:32:15.318259", "name": "__main__", "level": "INFO", "message": "Action: 0, Reward: tensor([-26.6571], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T02:32:16.082929", "name": "__main__", "level": "INFO", "message": "Epoch 9, Iteration 10: Reward: tensor([-381.5514], grad_fn=<AddBackward0>), Policy Loss: None, Value Loss: None, Total Loss: None, Entropy: None"}
{"time": "2024-06-04T02:32:17.713296", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 4 selected."}
{"time": "2024-06-04T02:32:26.556277", "name": "__main__", "level": "INFO", "message": "Action: 4, Reward: tensor([-26.8809], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T02:32:28.387654", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 0 selected."}
{"time": "2024-06-04T02:32:36.730969", "name": "__main__", "level": "INFO", "message": "Episode timed out."}
{"time": "2024-06-04T02:32:37.274900", "name": "__main__", "level": "INFO", "message": "Action: 0, Reward: tensor([-127.2464], grad_fn=<AddBackward0>), Done: True"}
{"time": "2024-06-04T02:33:00.236585", "name": "__main__", "level": "INFO", "message": "Dropped rows with NA values. Shape changed from (626, 2) to (626, 2)."}
{"time": "2024-06-04T03:01:43.073848", "name": "__main__", "level": "INFO", "message": "Time Series plot created successfully for steps vs values."}
{"time": "2024-06-04T03:02:14.060927", "name": "__main__", "level": "INFO", "message": "Histogram plotted successfully for column: values."}
{"time": "2024-06-04T03:02:30.931572", "name": "__main__", "level": "INFO", "message": "Correlation matrix heatmap generated successfully."}
{"time": "2024-06-04T03:02:51.732432", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Using device: cpu"}
{"time": "2024-06-04T03:02:56.583542", "name": "__main__", "level": "INFO", "message": "DataVisualizer initialized with Seaborn style set to 'whitegrid'."}
{"time": "2024-06-04T03:02:56.737693", "name": "__main__", "level": "INFO", "message": "Loading checkpoint from e:\\Project\\models/checkpoints\\ppo_agent_checkpoint.pt"}
{"time": "2024-06-04T03:03:00.833060", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Model loaded"}
{"time": "2024-06-04T03:03:02.084413", "name": "__main__", "level": "INFO", "message": "Resuming training from epoch 1"}
{"time": "2024-06-04T03:03:02.427237", "name": "__main__", "level": "INFO", "message": "Environment reset and takeoff completed."}
{"time": "2024-06-04T03:03:04.673205", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 1 selected."}
{"time": "2024-06-04T03:03:13.627053", "name": "__main__", "level": "INFO", "message": "Action: 1, Reward: tensor([-124.7726], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T03:03:14.442390", "name": "__main__", "level": "INFO", "message": "Epoch 1, Iteration 0: Reward: tensor([-124.7726], grad_fn=<AddBackward0>), Policy Loss: None, Value Loss: None, Total Loss: None, Entropy: None"}
{"time": "2024-06-04T03:03:15.975176", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 1 selected."}
{"time": "2024-06-04T03:03:24.574042", "name": "__main__", "level": "INFO", "message": "Action: 1, Reward: tensor([-24.7839], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T03:03:26.426126", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 0 selected."}
{"time": "2024-06-04T03:03:35.160445", "name": "__main__", "level": "INFO", "message": "Action: 0, Reward: tensor([-25.0020], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T03:03:37.218233", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 3 selected."}
{"time": "2024-06-04T03:03:41.617323", "name": "__main__", "level": "INFO", "message": "Action: 3, Reward: tensor([-25.4140], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T03:03:43.671513", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 2 selected."}
{"time": "2024-06-04T03:03:48.554879", "name": "__main__", "level": "INFO", "message": "Action: 2, Reward: tensor([-25.5312], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T03:03:50.464021", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 16 selected."}
{"time": "2024-06-04T03:03:59.315350", "name": "__main__", "level": "INFO", "message": "Action: 16, Reward: tensor([-125.8895], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T03:04:01.252085", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 12 selected."}
{"time": "2024-06-04T03:04:10.197356", "name": "__main__", "level": "INFO", "message": "Action: 12, Reward: tensor([-26.2409], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T03:04:12.015951", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 0 selected."}
{"time": "2024-06-04T03:04:20.830590", "name": "__main__", "level": "INFO", "message": "Action: 0, Reward: tensor([-26.4620], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T03:04:22.616125", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 15 selected."}
{"time": "2024-06-04T03:04:31.528282", "name": "__main__", "level": "INFO", "message": "Action: 15, Reward: tensor([-26.6351], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T03:04:33.577923", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 11 selected."}
{"time": "2024-06-04T03:04:38.369096", "name": "__main__", "level": "INFO", "message": "Action: 11, Reward: tensor([-26.3956], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T03:04:40.108590", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 8 selected."}
{"time": "2024-06-04T03:04:48.731784", "name": "__main__", "level": "INFO", "message": "Action: 8, Reward: tensor([-126.8963], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T03:04:49.611179", "name": "__main__", "level": "INFO", "message": "Epoch 1, Iteration 10: Reward: tensor([-584.0230], grad_fn=<AddBackward0>), Policy Loss: None, Value Loss: None, Total Loss: None, Entropy: None"}
{"time": "2024-06-04T03:04:51.270222", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 4 selected."}
{"time": "2024-06-04T03:04:59.913467", "name": "__main__", "level": "INFO", "message": "Action: 4, Reward: tensor([-27.1702], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T03:05:01.793737", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 7 selected."}
{"time": "2024-06-04T03:05:06.042425", "name": "__main__", "level": "INFO", "message": "Episode timed out."}
{"time": "2024-06-04T03:05:06.274461", "name": "__main__", "level": "INFO", "message": "Action: 7, Reward: tensor([-27.2210], grad_fn=<AddBackward0>), Done: True"}
{"time": "2024-06-04T03:05:06.883481", "name": "__main__", "level": "INFO", "message": "Environment reset and takeoff completed."}
{"time": "2024-06-04T03:05:09.056399", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 5 selected."}
{"time": "2024-06-04T03:05:17.887384", "name": "__main__", "level": "INFO", "message": "Action: 5, Reward: tensor([-124.8964], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T03:05:18.700817", "name": "__main__", "level": "INFO", "message": "Epoch 2, Iteration 0: Reward: tensor([-124.8964], grad_fn=<AddBackward0>), Policy Loss: None, Value Loss: None, Total Loss: None, Entropy: None"}
{"time": "2024-06-04T03:05:20.253438", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 0 selected."}
{"time": "2024-06-04T03:05:29.326623", "name": "__main__", "level": "INFO", "message": "Action: 0, Reward: tensor([-25.1372], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T03:05:31.225468", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 8 selected."}
{"time": "2024-06-04T03:05:40.115647", "name": "__main__", "level": "INFO", "message": "Action: 8, Reward: tensor([-125.4085], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T03:05:41.993466", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 8 selected."}
{"time": "2024-06-04T03:05:51.053776", "name": "__main__", "level": "INFO", "message": "Action: 8, Reward: tensor([-25.6646], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T03:05:52.949584", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 3 selected."}
{"time": "2024-06-04T03:05:57.705208", "name": "__main__", "level": "INFO", "message": "Action: 3, Reward: tensor([-25.7478], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T03:05:59.653937", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 6 selected."}
{"time": "2024-06-04T03:06:04.325173", "name": "__main__", "level": "INFO", "message": "Action: 6, Reward: tensor([-25.8855], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T03:06:06.238557", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 15 selected."}
{"time": "2024-06-04T03:06:15.039906", "name": "__main__", "level": "INFO", "message": "Action: 15, Reward: tensor([-26.1784], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T03:06:16.946062", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 3 selected."}
{"time": "2024-06-04T03:06:21.674690", "name": "__main__", "level": "INFO", "message": "Action: 3, Reward: tensor([-26.2977], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T03:06:23.455189", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 9 selected."}
{"time": "2024-06-04T03:06:32.223051", "name": "__main__", "level": "INFO", "message": "Action: 9, Reward: tensor([-25.1168], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T03:06:34.030210", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 0 selected."}
{"time": "2024-06-04T03:06:42.873972", "name": "__main__", "level": "INFO", "message": "Action: 0, Reward: tensor([-24.7312], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T03:06:44.755113", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 0 selected."}
{"time": "2024-06-04T03:06:53.702066", "name": "__main__", "level": "INFO", "message": "Action: 0, Reward: tensor([-24.4748], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T03:06:54.516279", "name": "__main__", "level": "INFO", "message": "Epoch 2, Iteration 10: Reward: tensor([-479.5388], grad_fn=<AddBackward0>), Policy Loss: None, Value Loss: None, Total Loss: None, Entropy: None"}
{"time": "2024-06-04T03:06:56.030984", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 14 selected."}
{"time": "2024-06-04T03:07:05.027404", "name": "__main__", "level": "INFO", "message": "Action: 14, Reward: tensor([-24.6660], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T03:07:06.901581", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 16 selected."}
{"time": "2024-06-04T03:07:15.380448", "name": "__main__", "level": "INFO", "message": "Episode timed out."}
{"time": "2024-06-04T03:07:15.974318", "name": "__main__", "level": "INFO", "message": "Action: 16, Reward: tensor([-25.0251], grad_fn=<AddBackward0>), Done: True"}
{"time": "2024-06-04T03:07:16.645857", "name": "__main__", "level": "INFO", "message": "Environment reset and takeoff completed."}
{"time": "2024-06-04T03:07:18.860330", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 8 selected."}
{"time": "2024-06-04T03:07:27.625379", "name": "__main__", "level": "INFO", "message": "Action: 8, Reward: tensor([-124.9285], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T03:07:28.507784", "name": "__main__", "level": "INFO", "message": "Epoch 3, Iteration 0: Reward: tensor([-124.9285], grad_fn=<AddBackward0>), Policy Loss: None, Value Loss: None, Total Loss: None, Entropy: None"}
{"time": "2024-06-04T03:07:30.187899", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 6 selected."}
{"time": "2024-06-04T03:07:35.120722", "name": "__main__", "level": "INFO", "message": "Action: 6, Reward: tensor([-25.0895], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T03:07:36.968498", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 2 selected."}
{"time": "2024-06-04T03:07:41.625224", "name": "__main__", "level": "INFO", "message": "Action: 2, Reward: tensor([-25.2279], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T03:07:43.415191", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 1 selected."}
{"time": "2024-06-04T03:07:52.311417", "name": "__main__", "level": "INFO", "message": "Action: 1, Reward: tensor([-25.3855], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T03:07:54.189790", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 2 selected."}
{"time": "2024-06-04T03:07:59.067245", "name": "__main__", "level": "INFO", "message": "Action: 2, Reward: tensor([-25.5349], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T03:08:00.931388", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 6 selected."}
{"time": "2024-06-04T03:08:05.786947", "name": "__main__", "level": "INFO", "message": "Action: 6, Reward: tensor([-25.7087], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T03:08:07.845478", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 4 selected."}
{"time": "2024-06-04T03:08:16.906881", "name": "__main__", "level": "INFO", "message": "Action: 4, Reward: tensor([-25.9675], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T03:08:18.959149", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 3 selected."}
{"time": "2024-06-04T03:08:23.878121", "name": "__main__", "level": "INFO", "message": "Action: 3, Reward: tensor([-26.0569], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T03:08:25.736970", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 1 selected."}
{"time": "2024-06-04T03:08:34.664980", "name": "__main__", "level": "INFO", "message": "Action: 1, Reward: tensor([-26.3180], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T03:08:36.613997", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 4 selected."}
{"time": "2024-06-04T03:08:45.423069", "name": "__main__", "level": "INFO", "message": "Action: 4, Reward: tensor([-26.4911], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T03:08:47.294986", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 15 selected."}
{"time": "2024-06-04T03:08:55.930315", "name": "__main__", "level": "INFO", "message": "Action: 15, Reward: tensor([-126.9078], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T03:08:56.662418", "name": "__main__", "level": "INFO", "message": "Epoch 3, Iteration 10: Reward: tensor([-483.6164], grad_fn=<AddBackward0>), Policy Loss: None, Value Loss: None, Total Loss: None, Entropy: None"}
{"time": "2024-06-04T03:08:58.330351", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 8 selected."}
{"time": "2024-06-04T03:09:07.209960", "name": "__main__", "level": "INFO", "message": "Action: 8, Reward: tensor([-127.0488], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T03:09:09.150908", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 1 selected."}
{"time": "2024-06-04T03:09:17.604086", "name": "__main__", "level": "INFO", "message": "Episode timed out."}
{"time": "2024-06-04T03:09:18.070718", "name": "__main__", "level": "INFO", "message": "Action: 1, Reward: tensor([-27.2697], grad_fn=<AddBackward0>), Done: True"}
{"time": "2024-06-04T03:09:18.661087", "name": "__main__", "level": "INFO", "message": "Environment reset and takeoff completed."}
{"time": "2024-06-04T03:09:20.820959", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 0 selected."}
{"time": "2024-06-04T03:09:29.497185", "name": "__main__", "level": "INFO", "message": "Action: 0, Reward: tensor([-124.9252], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T03:09:30.266153", "name": "__main__", "level": "INFO", "message": "Epoch 4, Iteration 0: Reward: tensor([-124.9252], grad_fn=<AddBackward0>), Policy Loss: None, Value Loss: None, Total Loss: None, Entropy: None"}
{"time": "2024-06-04T03:09:31.876065", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 5 selected."}
{"time": "2024-06-04T03:09:40.630086", "name": "__main__", "level": "INFO", "message": "Action: 5, Reward: tensor([-25.1549], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T03:09:42.472544", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 14 selected."}
{"time": "2024-06-04T03:09:51.375901", "name": "__main__", "level": "INFO", "message": "Action: 14, Reward: tensor([-125.4542], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T03:09:53.331380", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 9 selected."}
{"time": "2024-06-04T03:10:02.346532", "name": "__main__", "level": "INFO", "message": "Action: 9, Reward: tensor([-24.2403], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T03:10:04.238636", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 14 selected."}
{"time": "2024-06-04T03:10:13.062684", "name": "__main__", "level": "INFO", "message": "Action: 14, Reward: tensor([-23.8970], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T03:10:14.750000", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 9 selected."}
{"time": "2024-06-04T03:10:23.559655", "name": "__main__", "level": "INFO", "message": "Action: 9, Reward: tensor([-22.4644], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T03:10:25.531246", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 15 selected."}
{"time": "2024-06-04T03:10:34.318230", "name": "__main__", "level": "INFO", "message": "Action: 15, Reward: tensor([-21.4787], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T03:10:36.044372", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 10 selected."}
{"time": "2024-06-04T03:10:40.922500", "name": "__main__", "level": "INFO", "message": "Action: 10, Reward: tensor([-21.9236], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T03:10:42.923560", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 0 selected."}
{"time": "2024-06-04T03:10:51.676041", "name": "__main__", "level": "INFO", "message": "Action: 0, Reward: tensor([-22.5388], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T03:10:53.629312", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 9 selected."}
{"time": "2024-06-04T03:11:02.312732", "name": "__main__", "level": "INFO", "message": "Action: 9, Reward: tensor([-21.6449], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T03:11:04.271949", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 16 selected."}
{"time": "2024-06-04T03:11:12.963968", "name": "__main__", "level": "INFO", "message": "Action: 16, Reward: tensor([-21.1656], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T03:11:13.529797", "name": "__main__", "level": "INFO", "message": "Epoch 4, Iteration 10: Reward: tensor([-454.8874], grad_fn=<AddBackward0>), Policy Loss: None, Value Loss: None, Total Loss: None, Entropy: None"}
{"time": "2024-06-04T03:11:15.098618", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 5 selected."}
{"time": "2024-06-04T03:11:23.233076", "name": "__main__", "level": "INFO", "message": "Episode timed out."}
{"time": "2024-06-04T03:11:23.859551", "name": "__main__", "level": "INFO", "message": "Action: 5, Reward: tensor([-21.3429], grad_fn=<AddBackward0>), Done: True"}
{"time": "2024-06-04T03:11:24.626531", "name": "__main__", "level": "INFO", "message": "Environment reset and takeoff completed."}
{"time": "2024-06-04T03:11:26.600222", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 8 selected."}
{"time": "2024-06-04T03:11:35.357148", "name": "__main__", "level": "INFO", "message": "Action: 8, Reward: tensor([-124.9235], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T03:11:36.090936", "name": "__main__", "level": "INFO", "message": "Epoch 5, Iteration 0: Reward: tensor([-124.9235], grad_fn=<AddBackward0>), Policy Loss: None, Value Loss: None, Total Loss: None, Entropy: None"}
{"time": "2024-06-04T03:11:37.684194", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 16 selected."}
{"time": "2024-06-04T03:11:46.399656", "name": "__main__", "level": "INFO", "message": "Action: 16, Reward: tensor([-25.1027], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T03:11:48.091338", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 11 selected."}
{"time": "2024-06-04T03:11:53.094775", "name": "__main__", "level": "INFO", "message": "Action: 11, Reward: tensor([-25.2527], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T03:11:55.142624", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 11 selected."}
{"time": "2024-06-04T03:11:59.896527", "name": "__main__", "level": "INFO", "message": "Action: 11, Reward: tensor([-24.8341], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T03:12:01.740044", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 0 selected."}
{"time": "2024-06-04T03:12:10.429371", "name": "__main__", "level": "INFO", "message": "Action: 0, Reward: tensor([-24.1993], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T03:12:12.243776", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 7 selected."}
{"time": "2024-06-04T03:12:17.212254", "name": "__main__", "level": "INFO", "message": "Action: 7, Reward: tensor([-24.3273], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T03:12:19.038286", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 0 selected."}
{"time": "2024-06-04T03:12:27.948659", "name": "__main__", "level": "INFO", "message": "Action: 0, Reward: tensor([-24.8111], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T03:12:29.665287", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 9 selected."}
{"time": "2024-06-04T03:12:38.756352", "name": "__main__", "level": "INFO", "message": "Action: 9, Reward: tensor([-23.7807], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T03:12:40.214773", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 10 selected."}
{"time": "2024-06-04T03:12:45.175248", "name": "__main__", "level": "INFO", "message": "Action: 10, Reward: tensor([-24.2294], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T03:12:46.818417", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 5 selected."}
{"time": "2024-06-04T03:12:55.564975", "name": "__main__", "level": "INFO", "message": "Action: 5, Reward: tensor([-25.1165], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T03:12:57.361749", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 2 selected."}
{"time": "2024-06-04T03:13:02.206032", "name": "__main__", "level": "INFO", "message": "Action: 2, Reward: tensor([-25.3699], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T03:13:03.037030", "name": "__main__", "level": "INFO", "message": "Epoch 5, Iteration 10: Reward: tensor([-371.9472], grad_fn=<AddBackward0>), Policy Loss: None, Value Loss: None, Total Loss: None, Entropy: None"}
{"time": "2024-06-04T03:13:04.696171", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 4 selected."}
{"time": "2024-06-04T03:13:13.569673", "name": "__main__", "level": "INFO", "message": "Action: 4, Reward: tensor([-25.4303], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T03:13:15.412325", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 1 selected."}
{"time": "2024-06-04T03:13:23.804182", "name": "__main__", "level": "INFO", "message": "Action: 1, Reward: tensor([-25.5444], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T03:13:25.770268", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 5 selected."}
{"time": "2024-06-04T03:13:34.103738", "name": "__main__", "level": "INFO", "message": "Episode timed out."}
{"time": "2024-06-04T03:13:34.559996", "name": "__main__", "level": "INFO", "message": "Action: 5, Reward: tensor([-25.8346], grad_fn=<AddBackward0>), Done: True"}
{"time": "2024-06-04T03:13:35.183212", "name": "__main__", "level": "INFO", "message": "Environment reset and takeoff completed."}
{"time": "2024-06-04T03:13:37.503587", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 0 selected."}
{"time": "2024-06-04T03:13:46.311383", "name": "__main__", "level": "INFO", "message": "Action: 0, Reward: tensor([-124.9316], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T03:13:47.134398", "name": "__main__", "level": "INFO", "message": "Epoch 6, Iteration 0: Reward: tensor([-124.9316], grad_fn=<AddBackward0>), Policy Loss: None, Value Loss: None, Total Loss: None, Entropy: None"}
{"time": "2024-06-04T03:13:48.878919", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 4 selected."}
{"time": "2024-06-04T03:13:57.720945", "name": "__main__", "level": "INFO", "message": "Action: 4, Reward: tensor([-125.1676], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T03:13:59.649345", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 2 selected."}
{"time": "2024-06-04T03:14:04.420134", "name": "__main__", "level": "INFO", "message": "Action: 2, Reward: tensor([-25.3254], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T03:14:06.255259", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 7 selected."}
{"time": "2024-06-04T03:14:11.049727", "name": "__main__", "level": "INFO", "message": "Action: 7, Reward: tensor([-25.4273], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T03:14:13.109784", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 4 selected."}
{"time": "2024-06-04T03:14:21.752724", "name": "__main__", "level": "INFO", "message": "Action: 4, Reward: tensor([-25.5592], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T03:14:23.643664", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 2 selected."}
{"time": "2024-06-04T03:14:28.302534", "name": "__main__", "level": "INFO", "message": "Action: 2, Reward: tensor([-125.8025], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T03:14:30.175675", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 4 selected."}
{"time": "2024-06-04T03:14:39.080752", "name": "__main__", "level": "INFO", "message": "Action: 4, Reward: tensor([-126.0704], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T03:14:41.057807", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 0 selected."}
{"time": "2024-06-04T03:14:49.848551", "name": "__main__", "level": "INFO", "message": "Action: 0, Reward: tensor([-126.3391], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T03:14:51.718516", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 3 selected."}
{"time": "2024-06-04T03:14:56.515677", "name": "__main__", "level": "INFO", "message": "Action: 3, Reward: tensor([-126.3763], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T03:14:58.465158", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 11 selected."}
{"time": "2024-06-04T03:15:03.423179", "name": "__main__", "level": "INFO", "message": "Action: 11, Reward: tensor([-26.1955], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T03:15:05.373607", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 9 selected."}
{"time": "2024-06-04T03:15:14.194377", "name": "__main__", "level": "INFO", "message": "Action: 9, Reward: tensor([-24.4027], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T03:15:14.538275", "name": "__main__", "level": "INFO", "message": "Epoch 6, Iteration 10: Reward: tensor([-881.5978], grad_fn=<AddBackward0>), Policy Loss: None, Value Loss: None, Total Loss: None, Entropy: None"}
{"time": "2024-06-04T03:15:16.127726", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 2 selected."}
{"time": "2024-06-04T03:15:20.931852", "name": "__main__", "level": "INFO", "message": "Action: 2, Reward: tensor([-24.3208], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T03:15:22.840162", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 0 selected."}
{"time": "2024-06-04T03:15:31.559692", "name": "__main__", "level": "INFO", "message": "Action: 0, Reward: tensor([-24.2964], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T03:15:33.488416", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 0 selected."}
{"time": "2024-06-04T03:15:41.845275", "name": "__main__", "level": "INFO", "message": "Episode timed out."}
{"time": "2024-06-04T03:15:42.390800", "name": "__main__", "level": "INFO", "message": "Action: 0, Reward: tensor([-24.5583], grad_fn=<AddBackward0>), Done: True"}
{"time": "2024-06-04T03:15:43.063078", "name": "__main__", "level": "INFO", "message": "Environment reset and takeoff completed."}
{"time": "2024-06-04T03:15:45.236173", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 13 selected."}
{"time": "2024-06-04T03:15:54.243765", "name": "__main__", "level": "INFO", "message": "Action: 13, Reward: tensor([-124.9701], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T03:15:54.963730", "name": "__main__", "level": "INFO", "message": "Epoch 7, Iteration 0: Reward: tensor([-124.9701], grad_fn=<AddBackward0>), Policy Loss: None, Value Loss: None, Total Loss: None, Entropy: None"}
{"time": "2024-06-04T03:15:56.637434", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 3 selected."}
{"time": "2024-06-04T03:16:01.239491", "name": "__main__", "level": "INFO", "message": "Action: 3, Reward: tensor([-25.1321], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T03:16:03.214387", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 5 selected."}
{"time": "2024-06-04T03:16:11.677688", "name": "__main__", "level": "INFO", "message": "Action: 5, Reward: tensor([-125.3219], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T03:16:13.622862", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 0 selected."}
{"time": "2024-06-04T03:16:22.498683", "name": "__main__", "level": "INFO", "message": "Action: 0, Reward: tensor([-25.4794], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T03:16:23.766046", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 2 selected."}
{"time": "2024-06-04T03:16:28.715405", "name": "__main__", "level": "INFO", "message": "Action: 2, Reward: tensor([-25.6590], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T03:16:30.589381", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 10 selected."}
{"time": "2024-06-04T03:16:35.385789", "name": "__main__", "level": "INFO", "message": "Action: 10, Reward: tensor([-25.7803], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T03:16:37.277472", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 14 selected."}
{"time": "2024-06-04T03:16:46.118825", "name": "__main__", "level": "INFO", "message": "Action: 14, Reward: tensor([-26.0461], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T03:16:47.967493", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 2 selected."}
{"time": "2024-06-04T03:16:52.889691", "name": "__main__", "level": "INFO", "message": "Action: 2, Reward: tensor([-26.1713], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T03:16:54.791003", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 5 selected."}
{"time": "2024-06-04T03:17:03.570056", "name": "__main__", "level": "INFO", "message": "Action: 5, Reward: tensor([-26.3815], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T03:17:05.470147", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 0 selected."}
{"time": "2024-06-04T03:17:14.423437", "name": "__main__", "level": "INFO", "message": "Action: 0, Reward: tensor([-26.6057], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T03:17:16.332244", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 16 selected."}
{"time": "2024-06-04T03:17:25.240841", "name": "__main__", "level": "INFO", "message": "Action: 16, Reward: tensor([-26.7335], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T03:17:25.946313", "name": "__main__", "level": "INFO", "message": "Epoch 7, Iteration 10: Reward: tensor([-484.2811], grad_fn=<AddBackward0>), Policy Loss: None, Value Loss: None, Total Loss: None, Entropy: None"}
{"time": "2024-06-04T03:17:27.395496", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 0 selected."}
{"time": "2024-06-04T03:17:36.232350", "name": "__main__", "level": "INFO", "message": "Action: 0, Reward: tensor([-126.9926], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T03:17:38.157092", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 16 selected."}
{"time": "2024-06-04T03:17:46.641969", "name": "__main__", "level": "INFO", "message": "Episode timed out."}
{"time": "2024-06-04T03:17:47.280288", "name": "__main__", "level": "INFO", "message": "Action: 16, Reward: tensor([-27.1253], grad_fn=<AddBackward0>), Done: True"}
{"time": "2024-06-04T03:17:47.966815", "name": "__main__", "level": "INFO", "message": "Environment reset and takeoff completed."}
{"time": "2024-06-04T03:17:50.054314", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 11 selected."}
{"time": "2024-06-04T03:17:54.672178", "name": "__main__", "level": "INFO", "message": "Action: 11, Reward: tensor([-124.4319], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T03:17:55.358853", "name": "__main__", "level": "INFO", "message": "Epoch 8, Iteration 0: Reward: tensor([-124.4319], grad_fn=<AddBackward0>), Policy Loss: None, Value Loss: None, Total Loss: None, Entropy: None"}
{"time": "2024-06-04T03:17:57.062035", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 2 selected."}
{"time": "2024-06-04T03:18:01.740398", "name": "__main__", "level": "INFO", "message": "Action: 2, Reward: tensor([-24.4264], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T03:18:03.620382", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 2 selected."}
{"time": "2024-06-04T03:18:08.420344", "name": "__main__", "level": "INFO", "message": "Action: 2, Reward: tensor([-24.5944], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T03:18:10.313638", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 9 selected."}
{"time": "2024-06-04T03:18:19.161901", "name": "__main__", "level": "INFO", "message": "Action: 9, Reward: tensor([-23.3342], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T03:18:20.819797", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 0 selected."}
{"time": "2024-06-04T03:18:29.340218", "name": "__main__", "level": "INFO", "message": "Action: 0, Reward: tensor([-22.9494], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T03:18:31.301300", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 15 selected."}
{"time": "2024-06-04T03:18:40.176772", "name": "__main__", "level": "INFO", "message": "Action: 15, Reward: tensor([-22.7957], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T03:18:42.076811", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 1 selected."}
{"time": "2024-06-04T03:18:50.800942", "name": "__main__", "level": "INFO", "message": "Action: 1, Reward: tensor([-22.7977], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T03:18:52.702316", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 4 selected."}
{"time": "2024-06-04T03:19:01.422754", "name": "__main__", "level": "INFO", "message": "Action: 4, Reward: tensor([-23.0879], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T03:19:03.406563", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 7 selected."}
{"time": "2024-06-04T03:19:07.909590", "name": "__main__", "level": "INFO", "message": "Action: 7, Reward: tensor([-23.1693], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T03:19:09.556677", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 1 selected."}
{"time": "2024-06-04T03:19:18.318458", "name": "__main__", "level": "INFO", "message": "Action: 1, Reward: tensor([-23.1953], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T03:19:20.050758", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 14 selected."}
{"time": "2024-06-04T03:19:28.980708", "name": "__main__", "level": "INFO", "message": "Action: 14, Reward: tensor([-23.0656], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T03:19:29.796474", "name": "__main__", "level": "INFO", "message": "Epoch 8, Iteration 10: Reward: tensor([-357.8477], grad_fn=<AddBackward0>), Policy Loss: None, Value Loss: None, Total Loss: None, Entropy: None"}
{"time": "2024-06-04T03:19:31.375000", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 12 selected."}
{"time": "2024-06-04T03:19:40.182111", "name": "__main__", "level": "INFO", "message": "Action: 12, Reward: tensor([-23.1386], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T03:19:42.216576", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 5 selected."}
{"time": "2024-06-04T03:19:50.473089", "name": "__main__", "level": "INFO", "message": "Episode timed out."}
{"time": "2024-06-04T03:19:50.925055", "name": "__main__", "level": "INFO", "message": "Action: 5, Reward: tensor([-23.3401], grad_fn=<AddBackward0>), Done: True"}
{"time": "2024-06-04T03:19:51.562540", "name": "__main__", "level": "INFO", "message": "Environment reset and takeoff completed."}
{"time": "2024-06-04T03:19:53.684906", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 16 selected."}
{"time": "2024-06-04T03:20:02.372485", "name": "__main__", "level": "INFO", "message": "Action: 16, Reward: tensor([-124.8412], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T03:20:03.198371", "name": "__main__", "level": "INFO", "message": "Epoch 9, Iteration 0: Reward: tensor([-124.8412], grad_fn=<AddBackward0>), Policy Loss: None, Value Loss: None, Total Loss: None, Entropy: None"}
{"time": "2024-06-04T03:20:04.857671", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 1 selected."}
{"time": "2024-06-04T03:20:13.441953", "name": "__main__", "level": "INFO", "message": "Action: 1, Reward: tensor([-25.1536], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T03:20:15.231880", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 6 selected."}
{"time": "2024-06-04T03:20:20.024797", "name": "__main__", "level": "INFO", "message": "Action: 6, Reward: tensor([-125.2921], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T03:20:21.859043", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 1 selected."}
{"time": "2024-06-04T03:20:30.586123", "name": "__main__", "level": "INFO", "message": "Action: 1, Reward: tensor([-25.3909], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T03:20:32.383425", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 9 selected."}
{"time": "2024-06-04T03:20:40.974821", "name": "__main__", "level": "INFO", "message": "Action: 9, Reward: tensor([-24.1427], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T03:20:42.787752", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 4 selected."}
{"time": "2024-06-04T03:20:51.623339", "name": "__main__", "level": "INFO", "message": "Action: 4, Reward: tensor([-23.8153], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T03:20:53.634765", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 0 selected."}
{"time": "2024-06-04T03:21:02.174304", "name": "__main__", "level": "INFO", "message": "Action: 0, Reward: tensor([-23.3849], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T03:21:04.072328", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 9 selected."}
{"time": "2024-06-04T03:21:12.863661", "name": "__main__", "level": "INFO", "message": "Action: 9, Reward: tensor([-21.9169], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T03:21:14.922661", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 4 selected."}
{"time": "2024-06-04T03:21:23.939871", "name": "__main__", "level": "INFO", "message": "Action: 4, Reward: tensor([-21.7916], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T03:21:25.961673", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 10 selected."}
{"time": "2024-06-04T03:21:30.540020", "name": "__main__", "level": "INFO", "message": "Action: 10, Reward: tensor([-22.4334], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T03:21:32.417674", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 14 selected."}
{"time": "2024-06-04T03:21:41.332944", "name": "__main__", "level": "INFO", "message": "Action: 14, Reward: tensor([-23.0471], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T03:21:42.100545", "name": "__main__", "level": "INFO", "message": "Epoch 9, Iteration 10: Reward: tensor([-461.2096], grad_fn=<AddBackward0>), Policy Loss: None, Value Loss: None, Total Loss: None, Entropy: None"}
{"time": "2024-06-04T03:21:43.791113", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 10 selected."}
{"time": "2024-06-04T03:21:48.549769", "name": "__main__", "level": "INFO", "message": "Action: 10, Reward: tensor([-23.8211], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T03:21:50.514071", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 12 selected."}
{"time": "2024-06-04T03:21:58.936143", "name": "__main__", "level": "INFO", "message": "Episode timed out."}
{"time": "2024-06-04T03:21:59.326710", "name": "__main__", "level": "INFO", "message": "Action: 12, Reward: tensor([-25.2289], grad_fn=<AddBackward0>), Done: True"}
{"time": "2024-06-04T03:22:23.869771", "name": "__main__", "level": "INFO", "message": "Dropped rows with NA values. Shape changed from (744, 2) to (744, 2)."}
{"time": "2024-06-04T03:30:16.532883", "name": "__main__", "level": "INFO", "message": "Time Series plot created successfully for steps vs values."}
{"time": "2024-06-04T03:30:33.034078", "name": "__main__", "level": "INFO", "message": "Histogram plotted successfully for column: values."}
{"time": "2024-06-04T03:30:49.219939", "name": "__main__", "level": "INFO", "message": "Correlation matrix heatmap generated successfully."}
{"time": "2024-06-04T03:31:55.244437", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Using device: cpu"}
{"time": "2024-06-04T03:32:00.584954", "name": "__main__", "level": "INFO", "message": "DataVisualizer initialized with Seaborn style set to 'whitegrid'."}
{"time": "2024-06-04T03:32:00.770135", "name": "__main__", "level": "INFO", "message": "Loading checkpoint from e:\\Project\\models/checkpoints\\ppo_agent_checkpoint.pt"}
{"time": "2024-06-04T03:32:04.674729", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Model loaded"}
{"time": "2024-06-04T03:32:05.783709", "name": "__main__", "level": "INFO", "message": "Resuming training from epoch 1"}
{"time": "2024-06-04T03:32:06.130485", "name": "__main__", "level": "INFO", "message": "Environment reset and takeoff completed."}
{"time": "2024-06-04T03:32:08.209343", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 10 selected."}
{"time": "2024-06-04T03:32:12.819165", "name": "__main__", "level": "INFO", "message": "Action: 10, Reward: tensor([-124.7415], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T03:32:13.572541", "name": "__main__", "level": "INFO", "message": "Epoch 1, Iteration 0: Reward: tensor([-124.7415], grad_fn=<AddBackward0>), Policy Loss: None, Value Loss: None, Total Loss: None, Entropy: None"}
{"time": "2024-06-04T03:32:15.179821", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 7 selected."}
{"time": "2024-06-04T03:32:19.947225", "name": "__main__", "level": "INFO", "message": "Action: 7, Reward: tensor([-24.8849], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T03:32:21.576200", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 10 selected."}
{"time": "2024-06-04T03:32:26.590379", "name": "__main__", "level": "INFO", "message": "Action: 10, Reward: tensor([-25.0397], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T03:32:28.392202", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 0 selected."}
{"time": "2024-06-04T03:32:37.139365", "name": "__main__", "level": "INFO", "message": "Action: 0, Reward: tensor([-25.2380], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T03:32:39.067645", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 12 selected."}
{"time": "2024-06-04T03:32:47.909267", "name": "__main__", "level": "INFO", "message": "Action: 12, Reward: tensor([-25.5074], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T03:32:49.813857", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 7 selected."}
{"time": "2024-06-04T03:32:54.430701", "name": "__main__", "level": "INFO", "message": "Action: 7, Reward: tensor([-25.5467], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T03:32:56.371706", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 11 selected."}
{"time": "2024-06-04T03:33:00.886416", "name": "__main__", "level": "INFO", "message": "Action: 11, Reward: tensor([-25.6067], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T03:33:02.589315", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 9 selected."}
{"time": "2024-06-04T03:33:11.119370", "name": "__main__", "level": "INFO", "message": "Action: 9, Reward: tensor([-23.7648], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T03:33:12.908924", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 2 selected."}
{"time": "2024-06-04T03:33:17.588668", "name": "__main__", "level": "INFO", "message": "Action: 2, Reward: tensor([-23.5046], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T03:33:18.970650", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 1 selected."}
{"time": "2024-06-04T03:33:27.935427", "name": "__main__", "level": "INFO", "message": "Action: 1, Reward: tensor([-22.8873], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T03:33:29.873884", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 15 selected."}
{"time": "2024-06-04T03:33:38.457542", "name": "__main__", "level": "INFO", "message": "Action: 15, Reward: tensor([-22.9180], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T03:33:39.211131", "name": "__main__", "level": "INFO", "message": "Epoch 1, Iteration 10: Reward: tensor([-369.6396], grad_fn=<AddBackward0>), Policy Loss: None, Value Loss: None, Total Loss: None, Entropy: None"}
{"time": "2024-06-04T03:33:40.775674", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 9 selected."}
{"time": "2024-06-04T03:33:49.406133", "name": "__main__", "level": "INFO", "message": "Action: 9, Reward: tensor([-21.6332], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T03:33:51.156634", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 7 selected."}
{"time": "2024-06-04T03:33:56.043122", "name": "__main__", "level": "INFO", "message": "Action: 7, Reward: tensor([-21.5716], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T03:33:58.065042", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 12 selected."}
{"time": "2024-06-04T03:34:06.437396", "name": "__main__", "level": "INFO", "message": "Episode timed out."}
{"time": "2024-06-04T03:34:06.888852", "name": "__main__", "level": "INFO", "message": "Action: 12, Reward: tensor([-21.6569], grad_fn=<AddBackward0>), Done: True"}
{"time": "2024-06-04T03:34:07.450234", "name": "__main__", "level": "INFO", "message": "Environment reset and takeoff completed."}
{"time": "2024-06-04T03:34:09.779835", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 13 selected."}
{"time": "2024-06-04T03:34:18.667235", "name": "__main__", "level": "INFO", "message": "Action: 13, Reward: tensor([-124.8710], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T03:34:19.558779", "name": "__main__", "level": "INFO", "message": "Epoch 2, Iteration 0: Reward: tensor([-124.8710], grad_fn=<AddBackward0>), Policy Loss: None, Value Loss: None, Total Loss: None, Entropy: None"}
{"time": "2024-06-04T03:34:21.298911", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 15 selected."}
{"time": "2024-06-04T03:34:29.922135", "name": "__main__", "level": "INFO", "message": "Action: 15, Reward: tensor([-125.1174], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T03:34:31.609523", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 10 selected."}
{"time": "2024-06-04T03:34:36.428239", "name": "__main__", "level": "INFO", "message": "Action: 10, Reward: tensor([-125.2883], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T03:34:38.466200", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 1 selected."}
{"time": "2024-06-04T03:34:47.512780", "name": "__main__", "level": "INFO", "message": "Action: 1, Reward: tensor([-25.5265], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T03:34:49.295821", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 4 selected."}
{"time": "2024-06-04T03:34:58.225497", "name": "__main__", "level": "INFO", "message": "Action: 4, Reward: tensor([-25.7076], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T03:34:59.940387", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 0 selected."}
{"time": "2024-06-04T03:35:08.860693", "name": "__main__", "level": "INFO", "message": "Action: 0, Reward: tensor([-25.8894], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T03:35:10.896339", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 15 selected."}
{"time": "2024-06-04T03:35:19.751543", "name": "__main__", "level": "INFO", "message": "Action: 15, Reward: tensor([-26.1573], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T03:35:21.724288", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 11 selected."}
{"time": "2024-06-04T03:35:26.514497", "name": "__main__", "level": "INFO", "message": "Action: 11, Reward: tensor([-25.9076], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T03:35:28.316577", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 5 selected."}
{"time": "2024-06-04T03:35:37.278106", "name": "__main__", "level": "INFO", "message": "Action: 5, Reward: tensor([-25.2528], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T03:35:39.295529", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 1 selected."}
{"time": "2024-06-04T03:35:48.151854", "name": "__main__", "level": "INFO", "message": "Action: 1, Reward: tensor([-25.1895], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T03:35:49.957139", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 0 selected."}
{"time": "2024-06-04T03:35:58.978298", "name": "__main__", "level": "INFO", "message": "Action: 0, Reward: tensor([-25.1544], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T03:35:59.832875", "name": "__main__", "level": "INFO", "message": "Epoch 2, Iteration 10: Reward: tensor([-580.0618], grad_fn=<AddBackward0>), Policy Loss: None, Value Loss: None, Total Loss: None, Entropy: None"}
{"time": "2024-06-04T03:36:01.439000", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 7 selected."}
{"time": "2024-06-04T03:36:05.807139", "name": "__main__", "level": "INFO", "message": "Action: 7, Reward: tensor([-25.3248], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T03:36:07.651259", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 0 selected."}
{"time": "2024-06-04T03:36:15.741277", "name": "__main__", "level": "INFO", "message": "Episode timed out."}
{"time": "2024-06-04T03:36:16.238553", "name": "__main__", "level": "INFO", "message": "Action: 0, Reward: tensor([-25.0791], grad_fn=<AddBackward0>), Done: True"}
{"time": "2024-06-04T03:36:16.958657", "name": "__main__", "level": "INFO", "message": "Environment reset and takeoff completed."}
{"time": "2024-06-04T03:36:18.961831", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 7 selected."}
{"time": "2024-06-04T03:36:23.503469", "name": "__main__", "level": "INFO", "message": "Action: 7, Reward: tensor([-124.7340], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T03:36:24.301494", "name": "__main__", "level": "INFO", "message": "Epoch 3, Iteration 0: Reward: tensor([-124.7340], grad_fn=<AddBackward0>), Policy Loss: None, Value Loss: None, Total Loss: None, Entropy: None"}
{"time": "2024-06-04T03:36:25.910441", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 1 selected."}
{"time": "2024-06-04T03:36:34.879459", "name": "__main__", "level": "INFO", "message": "Action: 1, Reward: tensor([-24.9703], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T03:36:36.813691", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 0 selected."}
{"time": "2024-06-04T03:36:45.709027", "name": "__main__", "level": "INFO", "message": "Action: 0, Reward: tensor([-25.1345], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T03:36:47.634005", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 3 selected."}
{"time": "2024-06-04T03:36:52.182816", "name": "__main__", "level": "INFO", "message": "Action: 3, Reward: tensor([-25.2822], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T03:36:54.024337", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 10 selected."}
{"time": "2024-06-04T03:36:58.765678", "name": "__main__", "level": "INFO", "message": "Action: 10, Reward: tensor([-25.4360], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T03:37:00.668806", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 1 selected."}
{"time": "2024-06-04T03:37:09.452442", "name": "__main__", "level": "INFO", "message": "Action: 1, Reward: tensor([-25.6803], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T03:37:11.294673", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 13 selected."}
{"time": "2024-06-04T03:37:19.919498", "name": "__main__", "level": "INFO", "message": "Action: 13, Reward: tensor([-25.9415], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T03:37:21.670336", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 15 selected."}
{"time": "2024-06-04T03:37:30.281134", "name": "__main__", "level": "INFO", "message": "Action: 15, Reward: tensor([-26.1578], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T03:37:32.124193", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 3 selected."}
{"time": "2024-06-04T03:37:36.903044", "name": "__main__", "level": "INFO", "message": "Action: 3, Reward: tensor([-26.2894], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T03:37:38.753393", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 1 selected."}
{"time": "2024-06-04T03:37:47.520805", "name": "__main__", "level": "INFO", "message": "Action: 1, Reward: tensor([-26.5117], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T03:37:49.632477", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 7 selected."}
{"time": "2024-06-04T03:37:54.437772", "name": "__main__", "level": "INFO", "message": "Action: 7, Reward: tensor([-26.5772], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T03:37:55.157849", "name": "__main__", "level": "INFO", "message": "Epoch 3, Iteration 10: Reward: tensor([-382.7147], grad_fn=<AddBackward0>), Policy Loss: None, Value Loss: None, Total Loss: None, Entropy: None"}
{"time": "2024-06-04T03:37:56.762310", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 11 selected."}
{"time": "2024-06-04T03:38:01.638309", "name": "__main__", "level": "INFO", "message": "Action: 11, Reward: tensor([-126.2683], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T03:38:03.595312", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 1 selected."}
{"time": "2024-06-04T03:38:12.215244", "name": "__main__", "level": "INFO", "message": "Action: 1, Reward: tensor([-25.7693], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T03:38:14.121029", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 14 selected."}
{"time": "2024-06-04T03:38:22.632276", "name": "__main__", "level": "INFO", "message": "Episode timed out."}
{"time": "2024-06-04T03:38:23.192093", "name": "__main__", "level": "INFO", "message": "Action: 14, Reward: tensor([-25.6465], grad_fn=<AddBackward0>), Done: True"}
{"time": "2024-06-04T03:38:23.752824", "name": "__main__", "level": "INFO", "message": "Environment reset and takeoff completed."}
{"time": "2024-06-04T03:38:26.004626", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 14 selected."}
{"time": "2024-06-04T03:38:34.737861", "name": "__main__", "level": "INFO", "message": "Action: 14, Reward: tensor([-124.6853], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T03:38:35.470575", "name": "__main__", "level": "INFO", "message": "Epoch 4, Iteration 0: Reward: tensor([-124.6853], grad_fn=<AddBackward0>), Policy Loss: None, Value Loss: None, Total Loss: None, Entropy: None"}
{"time": "2024-06-04T03:38:37.258648", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 10 selected."}
{"time": "2024-06-04T03:38:41.713530", "name": "__main__", "level": "INFO", "message": "Action: 10, Reward: tensor([-124.9942], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T03:38:43.675665", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 1 selected."}
{"time": "2024-06-04T03:38:52.604136", "name": "__main__", "level": "INFO", "message": "Action: 1, Reward: tensor([-25.1799], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T03:38:54.417240", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 2 selected."}
{"time": "2024-06-04T03:38:59.118918", "name": "__main__", "level": "INFO", "message": "Action: 2, Reward: tensor([-25.2848], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T03:39:00.951734", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 3 selected."}
{"time": "2024-06-04T03:39:05.709004", "name": "__main__", "level": "INFO", "message": "Action: 3, Reward: tensor([-25.4197], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T03:39:07.657275", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 16 selected."}
{"time": "2024-06-04T03:39:16.696464", "name": "__main__", "level": "INFO", "message": "Action: 16, Reward: tensor([-25.5933], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T03:39:18.714163", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 0 selected."}
{"time": "2024-06-04T03:39:27.653478", "name": "__main__", "level": "INFO", "message": "Action: 0, Reward: tensor([-25.8778], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T03:39:29.410500", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 2 selected."}
{"time": "2024-06-04T03:39:34.330419", "name": "__main__", "level": "INFO", "message": "Action: 2, Reward: tensor([-26.0661], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T03:39:36.308633", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 3 selected."}
{"time": "2024-06-04T03:39:41.219490", "name": "__main__", "level": "INFO", "message": "Action: 3, Reward: tensor([-26.1037], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T03:39:43.053828", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 14 selected."}
{"time": "2024-06-04T03:39:51.679016", "name": "__main__", "level": "INFO", "message": "Action: 14, Reward: tensor([-26.3748], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T03:39:53.384610", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 12 selected."}
{"time": "2024-06-04T03:40:01.826284", "name": "__main__", "level": "INFO", "message": "Action: 12, Reward: tensor([-26.6292], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T03:40:02.558115", "name": "__main__", "level": "INFO", "message": "Epoch 4, Iteration 10: Reward: tensor([-482.2089], grad_fn=<AddBackward0>), Policy Loss: None, Value Loss: None, Total Loss: None, Entropy: None"}
{"time": "2024-06-04T03:40:04.315458", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 13 selected."}
{"time": "2024-06-04T03:40:13.259473", "name": "__main__", "level": "INFO", "message": "Action: 13, Reward: tensor([-26.7769], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T03:40:15.164976", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 10 selected."}
{"time": "2024-06-04T03:40:20.088205", "name": "__main__", "level": "INFO", "message": "Action: 10, Reward: tensor([-127.1543], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T03:40:22.042771", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 1 selected."}
{"time": "2024-06-04T03:40:30.404135", "name": "__main__", "level": "INFO", "message": "Episode timed out."}
{"time": "2024-06-04T03:40:30.886528", "name": "__main__", "level": "INFO", "message": "Action: 1, Reward: tensor([-27.3958], grad_fn=<AddBackward0>), Done: True"}
{"time": "2024-06-04T03:40:31.496511", "name": "__main__", "level": "INFO", "message": "Environment reset and takeoff completed."}
{"time": "2024-06-04T03:40:33.683322", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 0 selected."}
{"time": "2024-06-04T03:40:42.403473", "name": "__main__", "level": "INFO", "message": "Action: 0, Reward: tensor([-124.8052], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T03:40:43.199702", "name": "__main__", "level": "INFO", "message": "Epoch 5, Iteration 0: Reward: tensor([-124.8052], grad_fn=<AddBackward0>), Policy Loss: None, Value Loss: None, Total Loss: None, Entropy: None"}
{"time": "2024-06-04T03:40:44.887908", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 9 selected."}
{"time": "2024-06-04T03:40:53.681581", "name": "__main__", "level": "INFO", "message": "Action: 9, Reward: tensor([-23.6599], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T03:40:55.603082", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 3 selected."}
{"time": "2024-06-04T03:41:00.252328", "name": "__main__", "level": "INFO", "message": "Action: 3, Reward: tensor([-23.6893], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T03:41:02.067509", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 2 selected."}
{"time": "2024-06-04T03:41:07.027355", "name": "__main__", "level": "INFO", "message": "Action: 2, Reward: tensor([-23.7998], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T03:41:08.883537", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 11 selected."}
{"time": "2024-06-04T03:41:13.867494", "name": "__main__", "level": "INFO", "message": "Action: 11, Reward: tensor([-23.5111], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T03:41:15.836480", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 15 selected."}
{"time": "2024-06-04T03:41:24.508103", "name": "__main__", "level": "INFO", "message": "Action: 15, Reward: tensor([-23.0928], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T03:41:26.405361", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 2 selected."}
{"time": "2024-06-04T03:41:31.213539", "name": "__main__", "level": "INFO", "message": "Action: 2, Reward: tensor([-23.0979], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T03:41:33.102880", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 4 selected."}
{"time": "2024-06-04T03:41:41.882807", "name": "__main__", "level": "INFO", "message": "Action: 4, Reward: tensor([-23.4894], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T03:41:43.553510", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 2 selected."}
{"time": "2024-06-04T03:41:48.081592", "name": "__main__", "level": "INFO", "message": "Action: 2, Reward: tensor([-23.7372], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T03:41:49.988439", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 0 selected."}
{"time": "2024-06-04T03:41:58.723423", "name": "__main__", "level": "INFO", "message": "Action: 0, Reward: tensor([-24.1373], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T03:42:00.682986", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 0 selected."}
{"time": "2024-06-04T03:42:09.644158", "name": "__main__", "level": "INFO", "message": "Action: 0, Reward: tensor([-24.9593], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T03:42:10.505228", "name": "__main__", "level": "INFO", "message": "Epoch 5, Iteration 10: Reward: tensor([-361.9790], grad_fn=<AddBackward0>), Policy Loss: None, Value Loss: None, Total Loss: None, Entropy: None"}
{"time": "2024-06-04T03:42:11.878689", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 12 selected."}
{"time": "2024-06-04T03:42:20.629847", "name": "__main__", "level": "INFO", "message": "Action: 12, Reward: tensor([-25.9861], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T03:42:22.367629", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 4 selected."}
{"time": "2024-06-04T03:42:31.344451", "name": "__main__", "level": "INFO", "message": "Action: 4, Reward: tensor([-26.8723], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T03:42:33.252043", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 9 selected."}
{"time": "2024-06-04T03:42:41.488029", "name": "__main__", "level": "INFO", "message": "Episode timed out."}
{"time": "2024-06-04T03:42:42.049803", "name": "__main__", "level": "INFO", "message": "Action: 9, Reward: tensor([-26.1789], grad_fn=<AddBackward0>), Done: True"}
{"time": "2024-06-04T03:42:42.679446", "name": "__main__", "level": "INFO", "message": "Environment reset and takeoff completed."}
{"time": "2024-06-04T03:42:44.870280", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 0 selected."}
{"time": "2024-06-04T03:42:53.753799", "name": "__main__", "level": "INFO", "message": "Action: 0, Reward: tensor([-124.8253], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T03:42:54.491976", "name": "__main__", "level": "INFO", "message": "Epoch 6, Iteration 0: Reward: tensor([-124.8253], grad_fn=<AddBackward0>), Policy Loss: None, Value Loss: None, Total Loss: None, Entropy: None"}
{"time": "2024-06-04T03:42:55.887038", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 12 selected."}
{"time": "2024-06-04T03:43:04.910874", "name": "__main__", "level": "INFO", "message": "Action: 12, Reward: tensor([-125.1189], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T03:43:06.725599", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 4 selected."}
{"time": "2024-06-04T03:43:15.609328", "name": "__main__", "level": "INFO", "message": "Action: 4, Reward: tensor([-25.3284], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T03:43:17.422467", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 5 selected."}
{"time": "2024-06-04T03:43:26.141218", "name": "__main__", "level": "INFO", "message": "Action: 5, Reward: tensor([-25.4185], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T03:43:28.053147", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 0 selected."}
{"time": "2024-06-04T03:43:36.834964", "name": "__main__", "level": "INFO", "message": "Action: 0, Reward: tensor([-25.5781], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T03:43:38.732431", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 16 selected."}
{"time": "2024-06-04T03:43:47.586644", "name": "__main__", "level": "INFO", "message": "Action: 16, Reward: tensor([-25.6779], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T03:43:49.482310", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 15 selected."}
{"time": "2024-06-04T03:43:58.278872", "name": "__main__", "level": "INFO", "message": "Action: 15, Reward: tensor([-26.1144], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T03:44:00.153247", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 5 selected."}
{"time": "2024-06-04T03:44:08.891536", "name": "__main__", "level": "INFO", "message": "Action: 5, Reward: tensor([-126.2877], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T03:44:10.781027", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 9 selected."}
{"time": "2024-06-04T03:44:19.612869", "name": "__main__", "level": "INFO", "message": "Action: 9, Reward: tensor([-25.1436], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T03:44:21.615471", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 0 selected."}
{"time": "2024-06-04T03:44:30.424569", "name": "__main__", "level": "INFO", "message": "Action: 0, Reward: tensor([-24.7825], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T03:44:32.376023", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 15 selected."}
{"time": "2024-06-04T03:44:41.306370", "name": "__main__", "level": "INFO", "message": "Action: 15, Reward: tensor([-24.8744], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T03:44:42.091797", "name": "__main__", "level": "INFO", "message": "Epoch 6, Iteration 10: Reward: tensor([-579.1499], grad_fn=<AddBackward0>), Policy Loss: None, Value Loss: None, Total Loss: None, Entropy: None"}
{"time": "2024-06-04T03:44:43.670538", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 5 selected."}
{"time": "2024-06-04T03:44:51.988402", "name": "__main__", "level": "INFO", "message": "Episode timed out."}
{"time": "2024-06-04T03:44:52.253394", "name": "__main__", "level": "INFO", "message": "Action: 5, Reward: tensor([-24.8878], grad_fn=<AddBackward0>), Done: True"}
{"time": "2024-06-04T03:44:52.505214", "name": "__main__", "level": "INFO", "message": "Early stopping triggered after 7 epochs."}
{"time": "2024-06-04T03:45:18.068710", "name": "__main__", "level": "INFO", "message": "Dropped rows with NA values. Shape changed from (825, 2) to (825, 2)."}
{"time": "2024-06-04T04:46:24.567730", "name": "__main__", "level": "INFO", "message": "Time Series plot created successfully for steps vs values."}
{"time": "2024-06-04T04:46:47.813021", "name": "__main__", "level": "INFO", "message": "Histogram plotted successfully for column: values."}
{"time": "2024-06-04T04:47:00.031738", "name": "__main__", "level": "INFO", "message": "Correlation matrix heatmap generated successfully."}
{"time": "2024-06-04T04:47:14.429185", "name": "__main__", "level": "INFO", "message": "Scatter plot created successfully for steps vs values."}
{"time": "2024-06-04T04:51:00.806778", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Using device: cpu"}
{"time": "2024-06-04T04:51:06.099773", "name": "__main__", "level": "INFO", "message": "DataVisualizer initialized with Seaborn style set to 'whitegrid'."}
{"time": "2024-06-04T04:51:06.254924", "name": "__main__", "level": "INFO", "message": "Loading checkpoint from e:\\Project\\models/checkpoints\\ppo_agent_checkpoint.pt"}
{"time": "2024-06-04T04:51:09.971416", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Model loaded"}
{"time": "2024-06-04T04:51:11.110271", "name": "__main__", "level": "INFO", "message": "Resuming training from epoch 1"}
{"time": "2024-06-04T04:51:11.486405", "name": "__main__", "level": "INFO", "message": "Environment reset and takeoff completed."}
{"time": "2024-06-04T04:51:13.675763", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 2 selected."}
{"time": "2024-06-04T04:51:18.655419", "name": "__main__", "level": "INFO", "message": "Action: 2, Reward: tensor([-124.8188], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T04:51:19.572903", "name": "__main__", "level": "INFO", "message": "Epoch 1, Iteration 0: Reward: tensor([-124.8188], grad_fn=<AddBackward0>), Policy Loss: None, Value Loss: None, Total Loss: None, Entropy: None"}
{"time": "2024-06-04T04:51:21.279544", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 14 selected."}
{"time": "2024-06-04T04:51:30.214685", "name": "__main__", "level": "INFO", "message": "Action: 14, Reward: tensor([-25.0060], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T04:51:32.015017", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 0 selected."}
{"time": "2024-06-04T04:51:40.951418", "name": "__main__", "level": "INFO", "message": "Action: 0, Reward: tensor([-25.4946], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T04:51:42.732946", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 1 selected."}
{"time": "2024-06-04T04:51:51.625473", "name": "__main__", "level": "INFO", "message": "Action: 1, Reward: tensor([-25.6425], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T04:51:53.520903", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 8 selected."}
{"time": "2024-06-04T04:52:02.378644", "name": "__main__", "level": "INFO", "message": "Action: 8, Reward: tensor([-126.0157], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T04:52:04.351491", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 3 selected."}
{"time": "2024-06-04T04:52:08.959105", "name": "__main__", "level": "INFO", "message": "Action: 3, Reward: tensor([-26.1706], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T04:52:10.430563", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 4 selected."}
{"time": "2024-06-04T04:52:19.348727", "name": "__main__", "level": "INFO", "message": "Action: 4, Reward: tensor([-26.3751], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T04:52:21.286011", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 1 selected."}
{"time": "2024-06-04T04:52:30.159655", "name": "__main__", "level": "INFO", "message": "Action: 1, Reward: tensor([-26.6168], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T04:52:32.128734", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 0 selected."}
{"time": "2024-06-04T04:52:41.108267", "name": "__main__", "level": "INFO", "message": "Action: 0, Reward: tensor([-26.7511], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T04:52:42.936085", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 0 selected."}
{"time": "2024-06-04T04:52:51.882881", "name": "__main__", "level": "INFO", "message": "Action: 0, Reward: tensor([-27.0249], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T04:52:53.709265", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 16 selected."}
{"time": "2024-06-04T04:53:02.518343", "name": "__main__", "level": "INFO", "message": "Action: 16, Reward: tensor([-27.1731], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T04:53:03.282310", "name": "__main__", "level": "INFO", "message": "Epoch 1, Iteration 10: Reward: tensor([-487.0893], grad_fn=<AddBackward0>), Policy Loss: None, Value Loss: None, Total Loss: None, Entropy: None"}
{"time": "2024-06-04T04:53:04.906800", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 0 selected."}
{"time": "2024-06-04T04:53:13.007491", "name": "__main__", "level": "INFO", "message": "Episode timed out."}
{"time": "2024-06-04T04:53:13.539301", "name": "__main__", "level": "INFO", "message": "Action: 0, Reward: tensor([-27.4654], grad_fn=<AddBackward0>), Done: True"}
{"time": "2024-06-04T04:53:14.378390", "name": "__main__", "level": "INFO", "message": "Environment reset and takeoff completed."}
{"time": "2024-06-04T04:53:16.580609", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 5 selected."}
{"time": "2024-06-04T04:53:25.239141", "name": "__main__", "level": "INFO", "message": "Action: 5, Reward: tensor([-124.8914], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T04:53:26.046555", "name": "__main__", "level": "INFO", "message": "Epoch 2, Iteration 0: Reward: tensor([-124.8914], grad_fn=<AddBackward0>), Policy Loss: None, Value Loss: None, Total Loss: None, Entropy: None"}
{"time": "2024-06-04T04:53:27.750040", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 2 selected."}
{"time": "2024-06-04T04:53:32.514017", "name": "__main__", "level": "INFO", "message": "Action: 2, Reward: tensor([-25.0479], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T04:53:34.281723", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 0 selected."}
{"time": "2024-06-04T04:53:42.953578", "name": "__main__", "level": "INFO", "message": "Action: 0, Reward: tensor([-25.2254], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T04:53:44.796177", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 4 selected."}
{"time": "2024-06-04T04:53:53.769021", "name": "__main__", "level": "INFO", "message": "Action: 4, Reward: tensor([-25.4586], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T04:53:55.572714", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 6 selected."}
{"time": "2024-06-04T04:54:00.468981", "name": "__main__", "level": "INFO", "message": "Action: 6, Reward: tensor([-25.7124], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T04:54:01.986255", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 8 selected."}
{"time": "2024-06-04T04:54:10.972420", "name": "__main__", "level": "INFO", "message": "Action: 8, Reward: tensor([-125.9801], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T04:54:12.752163", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 3 selected."}
{"time": "2024-06-04T04:54:17.830801", "name": "__main__", "level": "INFO", "message": "Action: 3, Reward: tensor([-26.0892], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T04:54:19.645633", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 16 selected."}
{"time": "2024-06-04T04:54:28.243870", "name": "__main__", "level": "INFO", "message": "Action: 16, Reward: tensor([-26.2571], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T04:54:29.994724", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 4 selected."}
{"time": "2024-06-04T04:54:39.023921", "name": "__main__", "level": "INFO", "message": "Action: 4, Reward: tensor([-26.5204], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T04:54:40.953926", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 5 selected."}
{"time": "2024-06-04T04:54:49.671145", "name": "__main__", "level": "INFO", "message": "Action: 5, Reward: tensor([-26.6591], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T04:54:51.592987", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 10 selected."}
{"time": "2024-06-04T04:54:56.541445", "name": "__main__", "level": "INFO", "message": "Action: 10, Reward: tensor([-26.8637], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T04:54:57.338274", "name": "__main__", "level": "INFO", "message": "Epoch 2, Iteration 10: Reward: tensor([-484.7054], grad_fn=<AddBackward0>), Policy Loss: None, Value Loss: None, Total Loss: None, Entropy: None"}
{"time": "2024-06-04T04:54:59.091532", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 11 selected."}
{"time": "2024-06-04T04:55:03.875706", "name": "__main__", "level": "INFO", "message": "Action: 11, Reward: tensor([-26.8042], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T04:55:05.811172", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 15 selected."}
{"time": "2024-06-04T04:55:14.668028", "name": "__main__", "level": "INFO", "message": "Action: 15, Reward: tensor([-27.0465], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T04:55:16.621569", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 5 selected."}
{"time": "2024-06-04T04:55:24.825519", "name": "__main__", "level": "INFO", "message": "Episode timed out."}
{"time": "2024-06-04T04:55:25.374828", "name": "__main__", "level": "INFO", "message": "Action: 5, Reward: tensor([-27.2232], grad_fn=<AddBackward0>), Done: True"}
{"time": "2024-06-04T04:55:26.125789", "name": "__main__", "level": "INFO", "message": "Environment reset and takeoff completed."}
{"time": "2024-06-04T04:55:28.444817", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 11 selected."}
{"time": "2024-06-04T04:55:33.156990", "name": "__main__", "level": "INFO", "message": "Action: 11, Reward: tensor([-124.4017], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T04:55:33.514410", "name": "__main__", "level": "INFO", "message": "Epoch 3, Iteration 0: Reward: tensor([-124.4017], grad_fn=<AddBackward0>), Policy Loss: None, Value Loss: None, Total Loss: None, Entropy: None"}
{"time": "2024-06-04T04:55:35.236487", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 15 selected."}
{"time": "2024-06-04T04:55:44.118184", "name": "__main__", "level": "INFO", "message": "Action: 15, Reward: tensor([-24.3176], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T04:55:45.916249", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 7 selected."}
{"time": "2024-06-04T04:55:50.523627", "name": "__main__", "level": "INFO", "message": "Action: 7, Reward: tensor([-24.3623], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T04:55:52.224969", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 5 selected."}
{"time": "2024-06-04T04:56:00.806832", "name": "__main__", "level": "INFO", "message": "Action: 5, Reward: tensor([-24.9164], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T04:56:02.619493", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 16 selected."}
{"time": "2024-06-04T04:56:11.119307", "name": "__main__", "level": "INFO", "message": "Action: 16, Reward: tensor([-25.2901], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T04:56:12.880228", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 1 selected."}
{"time": "2024-06-04T04:56:21.607960", "name": "__main__", "level": "INFO", "message": "Action: 1, Reward: tensor([-25.8781], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T04:56:23.593089", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 11 selected."}
{"time": "2024-06-04T04:56:28.626632", "name": "__main__", "level": "INFO", "message": "Action: 11, Reward: tensor([-25.6740], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T04:56:30.630943", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 6 selected."}
{"time": "2024-06-04T04:56:35.379821", "name": "__main__", "level": "INFO", "message": "Action: 6, Reward: tensor([-25.5907], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T04:56:37.255045", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 16 selected."}
{"time": "2024-06-04T04:56:45.837675", "name": "__main__", "level": "INFO", "message": "Action: 16, Reward: tensor([-25.5433], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T04:56:47.778736", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 5 selected."}
{"time": "2024-06-04T04:56:56.609869", "name": "__main__", "level": "INFO", "message": "Action: 5, Reward: tensor([-25.7135], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T04:56:57.480033", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 13 selected."}
{"time": "2024-06-04T04:57:05.902123", "name": "__main__", "level": "INFO", "message": "Action: 13, Reward: tensor([-25.7741], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T04:57:06.543256", "name": "__main__", "level": "INFO", "message": "Epoch 3, Iteration 10: Reward: tensor([-377.4617], grad_fn=<AddBackward0>), Policy Loss: None, Value Loss: None, Total Loss: None, Entropy: None"}
{"time": "2024-06-04T04:57:08.040370", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 8 selected."}
{"time": "2024-06-04T04:57:17.043108", "name": "__main__", "level": "INFO", "message": "Action: 8, Reward: tensor([-127.3534], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T04:57:18.909288", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 1 selected."}
{"time": "2024-06-04T04:57:27.156954", "name": "__main__", "level": "INFO", "message": "Episode timed out."}
{"time": "2024-06-04T04:57:27.546273", "name": "__main__", "level": "INFO", "message": "Action: 1, Reward: tensor([-127.5957], grad_fn=<AddBackward0>), Done: True"}
{"time": "2024-06-04T04:57:28.382508", "name": "__main__", "level": "INFO", "message": "Environment reset and takeoff completed."}
{"time": "2024-06-04T04:57:30.757536", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 11 selected."}
{"time": "2024-06-04T04:57:35.730141", "name": "__main__", "level": "INFO", "message": "Action: 11, Reward: tensor([-124.4065], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T04:57:36.530925", "name": "__main__", "level": "INFO", "message": "Epoch 4, Iteration 0: Reward: tensor([-124.4065], grad_fn=<AddBackward0>), Policy Loss: None, Value Loss: None, Total Loss: None, Entropy: None"}
{"time": "2024-06-04T04:57:37.994284", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 8 selected."}
{"time": "2024-06-04T04:57:46.645799", "name": "__main__", "level": "INFO", "message": "Action: 8, Reward: tensor([-124.9980], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T04:57:48.508914", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 4 selected."}
{"time": "2024-06-04T04:57:57.182081", "name": "__main__", "level": "INFO", "message": "Action: 4, Reward: tensor([-25.2576], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T04:57:59.136041", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 0 selected."}
{"time": "2024-06-04T04:58:07.994884", "name": "__main__", "level": "INFO", "message": "Action: 0, Reward: tensor([-25.4825], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T04:58:09.738862", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 8 selected."}
{"time": "2024-06-04T04:58:18.704357", "name": "__main__", "level": "INFO", "message": "Action: 8, Reward: tensor([-25.6952], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T04:58:20.574346", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 16 selected."}
{"time": "2024-06-04T04:58:29.577806", "name": "__main__", "level": "INFO", "message": "Action: 16, Reward: tensor([-25.8510], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T04:58:31.577301", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 5 selected."}
{"time": "2024-06-04T04:58:40.017114", "name": "__main__", "level": "INFO", "message": "Action: 5, Reward: tensor([-26.1134], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T04:58:41.202815", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 5 selected."}
{"time": "2024-06-04T04:58:50.288613", "name": "__main__", "level": "INFO", "message": "Action: 5, Reward: tensor([-26.3639], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T04:58:52.224576", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 0 selected."}
{"time": "2024-06-04T04:59:00.364467", "name": "__main__", "level": "INFO", "message": "Action: 0, Reward: tensor([-26.5610], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T04:59:00.987790", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 1 selected."}
{"time": "2024-06-04T04:59:09.326111", "name": "__main__", "level": "INFO", "message": "Action: 1, Reward: tensor([-26.6582], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T04:59:11.014981", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 9 selected."}
{"time": "2024-06-04T04:59:19.816540", "name": "__main__", "level": "INFO", "message": "Action: 9, Reward: tensor([-25.5355], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T04:59:20.506244", "name": "__main__", "level": "INFO", "message": "Epoch 4, Iteration 10: Reward: tensor([-482.9229], grad_fn=<AddBackward0>), Policy Loss: None, Value Loss: None, Total Loss: None, Entropy: None"}
{"time": "2024-06-04T04:59:22.145237", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 0 selected."}
{"time": "2024-06-04T04:59:30.352785", "name": "__main__", "level": "INFO", "message": "Episode timed out."}
{"time": "2024-06-04T04:59:30.819945", "name": "__main__", "level": "INFO", "message": "Action: 0, Reward: tensor([-25.1440], grad_fn=<AddBackward0>), Done: True"}
{"time": "2024-06-04T04:59:31.553073", "name": "__main__", "level": "INFO", "message": "Environment reset and takeoff completed."}
{"time": "2024-06-04T04:59:33.659932", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 9 selected."}
{"time": "2024-06-04T04:59:42.058163", "name": "__main__", "level": "INFO", "message": "Action: 9, Reward: tensor([-123.5264], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T04:59:42.731318", "name": "__main__", "level": "INFO", "message": "Epoch 5, Iteration 0: Reward: tensor([-123.5264], grad_fn=<AddBackward0>), Policy Loss: None, Value Loss: None, Total Loss: None, Entropy: None"}
{"time": "2024-06-04T04:59:44.292938", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 1 selected."}
{"time": "2024-06-04T04:59:52.982445", "name": "__main__", "level": "INFO", "message": "Action: 1, Reward: tensor([-23.1318], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T04:59:54.728038", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 6 selected."}
{"time": "2024-06-04T04:59:59.629530", "name": "__main__", "level": "INFO", "message": "Action: 6, Reward: tensor([-23.1878], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T05:00:01.595999", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 3 selected."}
{"time": "2024-06-04T05:00:06.457153", "name": "__main__", "level": "INFO", "message": "Action: 3, Reward: tensor([-23.2988], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T05:00:08.332632", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 10 selected."}
{"time": "2024-06-04T05:00:12.951672", "name": "__main__", "level": "INFO", "message": "Action: 10, Reward: tensor([-23.9015], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T05:00:14.812947", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 15 selected."}
{"time": "2024-06-04T05:00:23.500836", "name": "__main__", "level": "INFO", "message": "Action: 15, Reward: tensor([-24.9879], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T05:00:25.084979", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 6 selected."}
{"time": "2024-06-04T05:00:29.886260", "name": "__main__", "level": "INFO", "message": "Action: 6, Reward: tensor([-25.3956], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T05:00:31.773688", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 11 selected."}
{"time": "2024-06-04T05:00:36.025234", "name": "__main__", "level": "INFO", "message": "Action: 11, Reward: tensor([-25.1314], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T05:00:37.935208", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 0 selected."}
{"time": "2024-06-04T05:00:46.760929", "name": "__main__", "level": "INFO", "message": "Action: 0, Reward: tensor([-24.6850], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T05:00:48.691321", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 3 selected."}
{"time": "2024-06-04T05:00:53.716798", "name": "__main__", "level": "INFO", "message": "Action: 3, Reward: tensor([-24.7853], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T05:00:55.391629", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 0 selected."}
{"time": "2024-06-04T05:01:03.896746", "name": "__main__", "level": "INFO", "message": "Action: 0, Reward: tensor([-24.9169], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T05:01:04.689937", "name": "__main__", "level": "INFO", "message": "Epoch 5, Iteration 10: Reward: tensor([-366.9485], grad_fn=<AddBackward0>), Policy Loss: None, Value Loss: None, Total Loss: None, Entropy: None"}
{"time": "2024-06-04T05:01:05.972505", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 0 selected."}
{"time": "2024-06-04T05:01:14.693710", "name": "__main__", "level": "INFO", "message": "Action: 0, Reward: tensor([-25.0035], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T05:01:16.500065", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 3 selected."}
{"time": "2024-06-04T05:01:21.004752", "name": "__main__", "level": "INFO", "message": "Action: 3, Reward: tensor([-25.0616], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T05:01:22.938008", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 6 selected."}
{"time": "2024-06-04T05:01:27.551095", "name": "__main__", "level": "INFO", "message": "Action: 6, Reward: tensor([-25.3797], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T05:01:29.013318", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 15 selected."}
{"time": "2024-06-04T05:01:37.021215", "name": "__main__", "level": "INFO", "message": "Episode timed out."}
{"time": "2024-06-04T05:01:37.580807", "name": "__main__", "level": "INFO", "message": "Action: 15, Reward: tensor([-25.9383], grad_fn=<AddBackward0>), Done: True"}
{"time": "2024-06-04T05:01:38.408885", "name": "__main__", "level": "INFO", "message": "Environment reset and takeoff completed."}
{"time": "2024-06-04T05:01:40.454642", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 9 selected."}
{"time": "2024-06-04T05:01:49.337885", "name": "__main__", "level": "INFO", "message": "Action: 9, Reward: tensor([-123.5322], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T05:01:49.963260", "name": "__main__", "level": "INFO", "message": "Epoch 6, Iteration 0: Reward: tensor([-123.5322], grad_fn=<AddBackward0>), Policy Loss: None, Value Loss: None, Total Loss: None, Entropy: None"}
{"time": "2024-06-04T05:01:51.520105", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 16 selected."}
{"time": "2024-06-04T05:02:00.484505", "name": "__main__", "level": "INFO", "message": "Action: 16, Reward: tensor([-23.1886], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T05:02:01.718156", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 13 selected."}
{"time": "2024-06-04T05:02:10.365357", "name": "__main__", "level": "INFO", "message": "Action: 13, Reward: tensor([-23.4014], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T05:02:12.290660", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 0 selected."}
{"time": "2024-06-04T05:02:21.150880", "name": "__main__", "level": "INFO", "message": "Action: 0, Reward: tensor([-23.5623], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T05:02:23.060900", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 3 selected."}
{"time": "2024-06-04T05:02:28.017386", "name": "__main__", "level": "INFO", "message": "Action: 3, Reward: tensor([-23.7401], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T05:02:29.686455", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 0 selected."}
{"time": "2024-06-04T05:02:37.607678", "name": "__main__", "level": "INFO", "message": "Action: 0, Reward: tensor([-23.9704], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T05:02:38.879994", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 16 selected."}
{"time": "2024-06-04T05:02:47.470053", "name": "__main__", "level": "INFO", "message": "Action: 16, Reward: tensor([-24.3627], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T05:02:49.480552", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 0 selected."}
{"time": "2024-06-04T05:02:58.243464", "name": "__main__", "level": "INFO", "message": "Action: 0, Reward: tensor([-25.0507], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T05:03:00.057405", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 4 selected."}
{"time": "2024-06-04T05:03:08.646777", "name": "__main__", "level": "INFO", "message": "Action: 4, Reward: tensor([-25.3271], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T05:03:10.337652", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 2 selected."}
{"time": "2024-06-04T05:03:14.697731", "name": "__main__", "level": "INFO", "message": "Action: 2, Reward: tensor([-25.5329], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T05:03:16.179555", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 10 selected."}
{"time": "2024-06-04T05:03:20.938018", "name": "__main__", "level": "INFO", "message": "Action: 10, Reward: tensor([-26.1656], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T05:03:21.641758", "name": "__main__", "level": "INFO", "message": "Epoch 6, Iteration 10: Reward: tensor([-367.8339], grad_fn=<AddBackward0>), Policy Loss: None, Value Loss: None, Total Loss: None, Entropy: None"}
{"time": "2024-06-04T05:03:22.961880", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 5 selected."}
{"time": "2024-06-04T05:03:31.979012", "name": "__main__", "level": "INFO", "message": "Action: 5, Reward: tensor([-127.1256], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T05:03:33.003013", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 0 selected."}
{"time": "2024-06-04T05:03:40.859451", "name": "__main__", "level": "INFO", "message": "Episode timed out."}
{"time": "2024-06-04T05:03:41.159547", "name": "__main__", "level": "INFO", "message": "Action: 0, Reward: tensor([-27.3431], grad_fn=<AddBackward0>), Done: True"}
{"time": "2024-06-04T05:03:41.809703", "name": "__main__", "level": "INFO", "message": "Environment reset and takeoff completed."}
{"time": "2024-06-04T05:03:43.966226", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 7 selected."}
{"time": "2024-06-04T05:03:48.788635", "name": "__main__", "level": "INFO", "message": "Action: 7, Reward: tensor([-124.8132], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T05:03:49.709376", "name": "__main__", "level": "INFO", "message": "Epoch 7, Iteration 0: Reward: tensor([-124.8132], grad_fn=<AddBackward0>), Policy Loss: None, Value Loss: None, Total Loss: None, Entropy: None"}
{"time": "2024-06-04T05:03:51.215709", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 0 selected."}
{"time": "2024-06-04T05:04:00.228679", "name": "__main__", "level": "INFO", "message": "Action: 0, Reward: tensor([-25.0567], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T05:04:02.158555", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 3 selected."}
{"time": "2024-06-04T05:04:06.967369", "name": "__main__", "level": "INFO", "message": "Action: 3, Reward: tensor([-25.1361], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T05:04:08.855758", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 8 selected."}
{"time": "2024-06-04T05:04:17.732332", "name": "__main__", "level": "INFO", "message": "Action: 8, Reward: tensor([-25.4061], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T05:04:19.481930", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 15 selected."}
{"time": "2024-06-04T05:04:27.851458", "name": "__main__", "level": "INFO", "message": "Action: 15, Reward: tensor([-25.6570], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T05:04:29.041473", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 0 selected."}
{"time": "2024-06-04T05:04:36.959849", "name": "__main__", "level": "INFO", "message": "Action: 0, Reward: tensor([-25.7725], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T05:04:38.756257", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 0 selected."}
{"time": "2024-06-04T05:04:48.045550", "name": "__main__", "level": "INFO", "message": "Action: 0, Reward: tensor([-26.0229], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T05:04:49.157138", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 7 selected."}
{"time": "2024-06-04T05:04:53.041583", "name": "__main__", "level": "INFO", "message": "Action: 7, Reward: tensor([-26.1312], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T05:04:54.857185", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 13 selected."}
{"time": "2024-06-04T05:05:03.764756", "name": "__main__", "level": "INFO", "message": "Action: 13, Reward: tensor([-26.3704], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T05:05:05.373467", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 6 selected."}
{"time": "2024-06-04T05:05:09.976898", "name": "__main__", "level": "INFO", "message": "Action: 6, Reward: tensor([-26.3811], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T05:05:11.963136", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 0 selected."}
{"time": "2024-06-04T05:05:20.584227", "name": "__main__", "level": "INFO", "message": "Action: 0, Reward: tensor([-26.6444], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T05:05:21.411288", "name": "__main__", "level": "INFO", "message": "Epoch 7, Iteration 10: Reward: tensor([-383.3917], grad_fn=<AddBackward0>), Policy Loss: None, Value Loss: None, Total Loss: None, Entropy: None"}
{"time": "2024-06-04T05:05:22.770368", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 0 selected."}
{"time": "2024-06-04T05:05:31.591303", "name": "__main__", "level": "INFO", "message": "Action: 0, Reward: tensor([-26.8626], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T05:05:33.514590", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 11 selected."}
{"time": "2024-06-04T05:05:38.624734", "name": "__main__", "level": "INFO", "message": "Action: 11, Reward: tensor([-26.5662], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T05:05:40.547654", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 15 selected."}
{"time": "2024-06-04T05:05:49.092302", "name": "__main__", "level": "INFO", "message": "Episode timed out."}
{"time": "2024-06-04T05:05:49.652853", "name": "__main__", "level": "INFO", "message": "Action: 15, Reward: tensor([-26.0751], grad_fn=<AddBackward0>), Done: True"}
{"time": "2024-06-04T05:05:50.372358", "name": "__main__", "level": "INFO", "message": "Environment reset and takeoff completed."}
{"time": "2024-06-04T05:05:52.557114", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 5 selected."}
{"time": "2024-06-04T05:06:01.517780", "name": "__main__", "level": "INFO", "message": "Action: 5, Reward: tensor([-124.8956], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T05:06:01.809888", "name": "__main__", "level": "INFO", "message": "Epoch 8, Iteration 0: Reward: tensor([-124.8956], grad_fn=<AddBackward0>), Policy Loss: None, Value Loss: None, Total Loss: None, Entropy: None"}
{"time": "2024-06-04T05:06:02.765017", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 2 selected."}
{"time": "2024-06-04T05:06:07.626486", "name": "__main__", "level": "INFO", "message": "Action: 2, Reward: tensor([-25.0332], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T05:06:09.571509", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 5 selected."}
{"time": "2024-06-04T05:06:18.772581", "name": "__main__", "level": "INFO", "message": "Action: 5, Reward: tensor([-125.2036], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T05:06:20.741874", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 0 selected."}
{"time": "2024-06-04T05:06:29.751252", "name": "__main__", "level": "INFO", "message": "Action: 0, Reward: tensor([-125.5371], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T05:06:31.545357", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 4 selected."}
{"time": "2024-06-04T05:06:40.631097", "name": "__main__", "level": "INFO", "message": "Action: 4, Reward: tensor([-125.7091], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T05:06:42.465151", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 2 selected."}
{"time": "2024-06-04T05:06:46.906585", "name": "__main__", "level": "INFO", "message": "Action: 2, Reward: tensor([-125.9245], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T05:06:48.697888", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 11 selected."}
{"time": "2024-06-04T05:06:53.227484", "name": "__main__", "level": "INFO", "message": "Action: 11, Reward: tensor([-25.6616], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T05:06:55.144123", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 9 selected."}
{"time": "2024-06-04T05:07:04.032902", "name": "__main__", "level": "INFO", "message": "Action: 9, Reward: tensor([-23.8762], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T05:07:05.718364", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 7 selected."}
{"time": "2024-06-04T05:07:10.676204", "name": "__main__", "level": "INFO", "message": "Action: 7, Reward: tensor([-23.6739], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T05:07:12.438029", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 9 selected."}
{"time": "2024-06-04T05:07:20.846171", "name": "__main__", "level": "INFO", "message": "Action: 9, Reward: tensor([-21.9662], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T05:07:22.780876", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 4 selected."}
{"time": "2024-06-04T05:07:31.762549", "name": "__main__", "level": "INFO", "message": "Action: 4, Reward: tensor([-21.1734], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T05:07:32.701745", "name": "__main__", "level": "INFO", "message": "Epoch 8, Iteration 10: Reward: tensor([-768.6545], grad_fn=<AddBackward0>), Policy Loss: None, Value Loss: None, Total Loss: None, Entropy: None"}
{"time": "2024-06-04T05:07:34.207377", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 13 selected."}
{"time": "2024-06-04T05:07:42.368044", "name": "__main__", "level": "INFO", "message": "Action: 13, Reward: tensor([-20.7968], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T05:07:43.969509", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 15 selected."}
{"time": "2024-06-04T05:07:52.503978", "name": "__main__", "level": "INFO", "message": "Episode timed out."}
{"time": "2024-06-04T05:07:52.974197", "name": "__main__", "level": "INFO", "message": "Action: 15, Reward: tensor([-20.8198], grad_fn=<AddBackward0>), Done: True"}
{"time": "2024-06-04T05:07:53.642054", "name": "__main__", "level": "INFO", "message": "Environment reset and takeoff completed."}
{"time": "2024-06-04T05:07:55.440889", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 10 selected."}
{"time": "2024-06-04T05:08:00.130538", "name": "__main__", "level": "INFO", "message": "Action: 10, Reward: tensor([-124.7957], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T05:08:00.973279", "name": "__main__", "level": "INFO", "message": "Epoch 9, Iteration 0: Reward: tensor([-124.7957], grad_fn=<AddBackward0>), Policy Loss: None, Value Loss: None, Total Loss: None, Entropy: None"}
{"time": "2024-06-04T05:08:02.742699", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 16 selected."}
{"time": "2024-06-04T05:08:11.871768", "name": "__main__", "level": "INFO", "message": "Action: 16, Reward: tensor([-25.0093], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T05:08:13.117265", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 7 selected."}
{"time": "2024-06-04T05:08:17.807299", "name": "__main__", "level": "INFO", "message": "Action: 7, Reward: tensor([-25.1510], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T05:08:19.671474", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 11 selected."}
{"time": "2024-06-04T05:08:24.029555", "name": "__main__", "level": "INFO", "message": "Action: 11, Reward: tensor([-24.9538], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T05:08:25.002973", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 0 selected."}
{"time": "2024-06-04T05:08:32.995261", "name": "__main__", "level": "INFO", "message": "Action: 0, Reward: tensor([-24.7641], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T05:08:34.677600", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 10 selected."}
{"time": "2024-06-04T05:08:39.208951", "name": "__main__", "level": "INFO", "message": "Action: 10, Reward: tensor([-25.3829], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T05:08:41.097618", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 4 selected."}
{"time": "2024-06-04T05:08:49.854007", "name": "__main__", "level": "INFO", "message": "Action: 4, Reward: tensor([-125.8392], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T05:08:51.625103", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 5 selected."}
{"time": "2024-06-04T05:09:00.614574", "name": "__main__", "level": "INFO", "message": "Action: 5, Reward: tensor([-26.0104], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T05:09:01.513167", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 0 selected."}
{"time": "2024-06-04T05:09:10.402361", "name": "__main__", "level": "INFO", "message": "Action: 0, Reward: tensor([-26.2560], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T05:09:12.341849", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 0 selected."}
{"time": "2024-06-04T05:09:20.775661", "name": "__main__", "level": "INFO", "message": "Action: 0, Reward: tensor([-26.5176], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T05:09:22.772851", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 0 selected."}
{"time": "2024-06-04T05:09:31.840626", "name": "__main__", "level": "INFO", "message": "Action: 0, Reward: tensor([-26.7487], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T05:09:32.637119", "name": "__main__", "level": "INFO", "message": "Epoch 9, Iteration 10: Reward: tensor([-481.4288], grad_fn=<AddBackward0>), Policy Loss: None, Value Loss: None, Total Loss: None, Entropy: None"}
{"time": "2024-06-04T05:09:34.350527", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 0 selected."}
{"time": "2024-06-04T05:09:43.070295", "name": "__main__", "level": "INFO", "message": "Action: 0, Reward: tensor([-26.9916], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T05:09:44.832191", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 14 selected."}
{"time": "2024-06-04T05:09:53.770512", "name": "__main__", "level": "INFO", "message": "Action: 14, Reward: tensor([-27.2356], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T05:09:55.768422", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 16 selected."}
{"time": "2024-06-04T05:10:04.133904", "name": "__main__", "level": "INFO", "message": "Episode timed out."}
{"time": "2024-06-04T05:10:04.433024", "name": "__main__", "level": "INFO", "message": "Action: 16, Reward: tensor([-27.3492], grad_fn=<AddBackward0>), Done: True"}
{"time": "2024-06-04T05:10:32.396756", "name": "__main__", "level": "INFO", "message": "Dropped rows with NA values. Shape changed from (945, 2) to (945, 2)."}
{"time": "2024-06-04T05:11:55.488157", "name": "__main__", "level": "INFO", "message": "Time Series plot created successfully for steps vs values."}
{"time": "2024-06-04T05:12:32.569621", "name": "__main__", "level": "INFO", "message": "Histogram plotted successfully for column: values."}
{"time": "2024-06-04T05:12:54.688785", "name": "__main__", "level": "INFO", "message": "Correlation matrix heatmap generated successfully."}
{"time": "2024-06-04T05:32:58.403131", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Using device: cpu"}
{"time": "2024-06-04T08:40:09.843256", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Using device: cpu"}
{"time": "2024-06-04T08:40:17.302158", "name": "__main__", "level": "INFO", "message": "DataVisualizer initialized with Seaborn style set to 'whitegrid'."}
{"time": "2024-06-04T08:40:17.443091", "name": "__main__", "level": "INFO", "message": "Environment reset and takeoff completed."}
{"time": "2024-06-04T08:40:18.990217", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 9 selected."}
{"time": "2024-06-04T08:40:27.750504", "name": "__main__", "level": "INFO", "message": "Action: 9, Reward: tensor([-123.2824], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T08:45:52.873111", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Using device: cpu"}
{"time": "2024-06-04T08:50:28.636070", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Using device: cpu"}
{"time": "2024-06-04T08:53:49.356403", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Using device: cpu"}
{"time": "2024-06-04T08:53:57.405955", "name": "__main__", "level": "INFO", "message": "DataVisualizer initialized with Seaborn style set to 'whitegrid'."}
{"time": "2024-06-04T08:53:57.937808", "name": "__main__", "level": "INFO", "message": "Environment reset and takeoff completed."}
{"time": "2024-06-04T08:53:59.778086", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 0 selected."}
{"time": "2024-06-04T08:54:08.427451", "name": "__main__", "level": "INFO", "message": "Action: 0, Reward: tensor([-124.7604], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T12:37:35.995029", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Using device: cpu"}
{"time": "2024-06-04T12:37:43.449852", "name": "__main__", "level": "INFO", "message": "DataVisualizer initialized with Seaborn style set to 'whitegrid'."}
{"time": "2024-06-04T12:37:43.790105", "name": "__main__", "level": "INFO", "message": "Environment reset and takeoff completed."}
{"time": "2024-06-04T12:37:45.654575", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 12 selected."}
{"time": "2024-06-04T12:37:54.530352", "name": "__main__", "level": "INFO", "message": "Action: 12, Reward: tensor([-124.7073], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T12:37:55.307184", "name": "__main__", "level": "INFO", "message": "Epoch 0, Iteration 0: Reward: tensor([-124.7073], grad_fn=<AddBackward0>), Policy Loss: None, Value Loss: None, Total Loss: None, Entropy: None"}
{"time": "2024-06-04T12:37:56.603424", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 6 selected."}
{"time": "2024-06-04T12:38:01.362651", "name": "__main__", "level": "INFO", "message": "Action: 6, Reward: tensor([-24.9723], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T12:38:02.921895", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 13 selected."}
{"time": "2024-06-04T12:38:11.226687", "name": "__main__", "level": "INFO", "message": "Action: 13, Reward: tensor([-125.1077], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T12:38:12.849644", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 13 selected."}
{"time": "2024-06-04T12:38:21.556515", "name": "__main__", "level": "INFO", "message": "Action: 13, Reward: tensor([-25.4075], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T12:38:23.080879", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 1 selected."}
{"time": "2024-06-04T12:38:30.955719", "name": "__main__", "level": "INFO", "message": "Action: 1, Reward: tensor([-25.6059], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T12:38:32.168165", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 2 selected."}
{"time": "2024-06-04T12:38:36.750383", "name": "__main__", "level": "INFO", "message": "Action: 2, Reward: tensor([-25.5505], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T12:38:37.867293", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 13 selected."}
{"time": "2024-06-04T12:38:45.450615", "name": "__main__", "level": "INFO", "message": "Action: 13, Reward: tensor([-25.8587], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T12:38:46.174623", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 8 selected."}
{"time": "2024-06-04T12:38:54.713284", "name": "__main__", "level": "INFO", "message": "Action: 8, Reward: tensor([-26.0122], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T12:38:55.836411", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 8 selected."}
{"time": "2024-06-04T12:39:04.158452", "name": "__main__", "level": "INFO", "message": "Action: 8, Reward: tensor([-26.2379], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T12:39:05.727143", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 4 selected."}
{"time": "2024-06-04T12:39:13.771034", "name": "__main__", "level": "INFO", "message": "Action: 4, Reward: tensor([-26.4053], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T12:39:14.331263", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 1 selected."}
{"time": "2024-06-04T12:39:22.640661", "name": "__main__", "level": "INFO", "message": "Action: 1, Reward: tensor([-26.5824], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T12:39:23.310379", "name": "__main__", "level": "INFO", "message": "Epoch 0, Iteration 10: Reward: tensor([-482.4476], grad_fn=<AddBackward0>), Policy Loss: None, Value Loss: None, Total Loss: None, Entropy: None"}
{"time": "2024-06-04T12:39:24.120806", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 14 selected."}
{"time": "2024-06-04T12:39:32.217278", "name": "__main__", "level": "INFO", "message": "Action: 14, Reward: tensor([-26.7355], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T12:39:33.549295", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 4 selected."}
{"time": "2024-06-04T12:39:41.935467", "name": "__main__", "level": "INFO", "message": "Action: 4, Reward: tensor([-26.9058], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T12:39:42.712434", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 7 selected."}
{"time": "2024-06-04T12:39:47.059818", "name": "__main__", "level": "INFO", "message": "Action: 7, Reward: tensor([-27.0098], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T12:39:48.435209", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 2 selected."}
{"time": "2024-06-04T12:39:52.863014", "name": "__main__", "level": "INFO", "message": "Action: 2, Reward: tensor([-27.1685], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T12:39:53.862324", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 1 selected."}
{"time": "2024-06-04T12:40:01.685100", "name": "__main__", "level": "INFO", "message": "Action: 1, Reward: tensor([-27.1195], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T12:40:02.710944", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 7 selected."}
{"time": "2024-06-04T12:40:07.185486", "name": "__main__", "level": "INFO", "message": "Action: 7, Reward: tensor([-27.2852], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T12:40:08.653906", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 0 selected."}
{"time": "2024-06-04T12:40:16.536411", "name": "__main__", "level": "INFO", "message": "Action: 0, Reward: tensor([-27.4662], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T12:40:17.626805", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 6 selected."}
{"time": "2024-06-04T12:40:21.814028", "name": "__main__", "level": "INFO", "message": "Action: 6, Reward: tensor([-27.6572], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T12:40:22.573109", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 16 selected."}
{"time": "2024-06-04T12:40:30.780910", "name": "__main__", "level": "INFO", "message": "Action: 16, Reward: tensor([-27.8626], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T12:40:31.994427", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 9 selected."}
{"time": "2024-06-04T12:40:39.760226", "name": "__main__", "level": "INFO", "message": "Action: 9, Reward: tensor([-26.7809], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T12:40:40.364886", "name": "__main__", "level": "INFO", "message": "Epoch 0, Iteration 20: Reward: tensor([-754.4388], grad_fn=<AddBackward0>), Policy Loss: None, Value Loss: None, Total Loss: None, Entropy: None"}
{"time": "2024-06-04T12:40:40.676084", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 14 selected."}
{"time": "2024-06-04T12:40:48.159772", "name": "__main__", "level": "INFO", "message": "Action: 14, Reward: tensor([-26.4016], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T12:40:48.873819", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 15 selected."}
{"time": "2024-06-04T12:40:56.207077", "name": "__main__", "level": "INFO", "message": "Action: 15, Reward: tensor([-25.8747], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T12:40:56.872379", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 4 selected."}
{"time": "2024-06-04T12:41:04.890837", "name": "__main__", "level": "INFO", "message": "Action: 4, Reward: tensor([-25.7439], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T12:41:05.588078", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 6 selected."}
{"time": "2024-06-04T12:41:09.167564", "name": "__main__", "level": "INFO", "message": "Action: 6, Reward: tensor([-25.9603], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T12:41:09.744515", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 10 selected."}
{"time": "2024-06-04T12:41:13.093623", "name": "__main__", "level": "INFO", "message": "Action: 10, Reward: tensor([-26.5257], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T12:41:13.967495", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 13 selected."}
{"time": "2024-06-04T12:41:21.305356", "name": "__main__", "level": "INFO", "message": "Action: 13, Reward: tensor([-27.2891], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T12:41:21.939088", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 0 selected."}
{"time": "2024-06-04T12:41:29.455362", "name": "__main__", "level": "INFO", "message": "Action: 0, Reward: tensor([-27.8095], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T12:41:30.091235", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 3 selected."}
{"time": "2024-06-04T12:41:33.502011", "name": "__main__", "level": "INFO", "message": "Action: 3, Reward: tensor([-27.9721], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T12:41:34.121298", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 8 selected."}
{"time": "2024-06-04T12:41:42.017663", "name": "__main__", "level": "INFO", "message": "Action: 8, Reward: tensor([-129.4059], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T12:41:42.812160", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 8 selected."}
{"time": "2024-06-04T12:41:50.588243", "name": "__main__", "level": "INFO", "message": "Action: 8, Reward: tensor([-29.6310], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T12:41:50.821932", "name": "__main__", "level": "INFO", "message": "Epoch 0, Iteration 30: Reward: tensor([-1127.0525], grad_fn=<AddBackward0>), Policy Loss: None, Value Loss: None, Total Loss: None, Entropy: None"}
{"time": "2024-06-04T12:41:51.099811", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 12 selected."}
{"time": "2024-06-04T12:41:58.432452", "name": "__main__", "level": "INFO", "message": "Action: 12, Reward: tensor([-29.7879], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T12:41:58.868941", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 15 selected."}
{"time": "2024-06-04T12:42:06.042104", "name": "__main__", "level": "INFO", "message": "Action: 15, Reward: tensor([-29.9539], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T12:42:06.614591", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 4 selected."}
{"time": "2024-06-04T12:42:13.534778", "name": "__main__", "level": "INFO", "message": "Action: 4, Reward: tensor([-30.1211], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T12:42:14.093843", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 11 selected."}
{"time": "2024-06-04T12:42:17.282324", "name": "__main__", "level": "INFO", "message": "Action: 11, Reward: tensor([-29.7845], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T12:42:18.087765", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 4 selected."}
{"time": "2024-06-04T12:42:25.276803", "name": "__main__", "level": "INFO", "message": "Action: 4, Reward: tensor([-29.5044], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T12:42:25.913193", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 7 selected."}
{"time": "2024-06-04T12:42:29.538140", "name": "__main__", "level": "INFO", "message": "Action: 7, Reward: tensor([-29.5906], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T12:42:30.436546", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 8 selected."}
{"time": "2024-06-04T12:42:37.331284", "name": "__main__", "level": "INFO", "message": "Action: 8, Reward: tensor([-130.6261], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T12:42:37.670833", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 0 selected."}
{"time": "2024-06-04T12:42:44.826983", "name": "__main__", "level": "INFO", "message": "Action: 0, Reward: tensor([-30.7951], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T12:42:45.259421", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 11 selected."}
{"time": "2024-06-04T12:42:48.387451", "name": "__main__", "level": "INFO", "message": "Action: 11, Reward: tensor([-30.6109], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T12:42:49.026881", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 6 selected."}
{"time": "2024-06-04T12:42:52.306495", "name": "__main__", "level": "INFO", "message": "Action: 6, Reward: tensor([-30.6481], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T12:42:52.712321", "name": "__main__", "level": "INFO", "message": "Epoch 0, Iteration 40: Reward: tensor([-1528.4753], grad_fn=<AddBackward0>), Policy Loss: None, Value Loss: None, Total Loss: None, Entropy: None"}
{"time": "2024-06-04T12:42:53.009604", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 16 selected."}
{"time": "2024-06-04T12:43:00.433919", "name": "__main__", "level": "INFO", "message": "Action: 16, Reward: tensor([-30.7394], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T12:43:00.993246", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 2 selected."}
{"time": "2024-06-04T12:43:04.264136", "name": "__main__", "level": "INFO", "message": "Action: 2, Reward: tensor([-30.9092], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T12:43:04.830166", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 3 selected."}
{"time": "2024-06-04T12:43:07.971577", "name": "__main__", "level": "INFO", "message": "Action: 3, Reward: tensor([-30.9363], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T12:43:08.606177", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 11 selected."}
{"time": "2024-06-04T12:43:12.271501", "name": "__main__", "level": "INFO", "message": "Action: 11, Reward: tensor([-30.6545], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T12:43:12.970377", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 15 selected."}
{"time": "2024-06-04T12:43:20.072661", "name": "__main__", "level": "INFO", "message": "Action: 15, Reward: tensor([-30.1745], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T12:43:20.679621", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 15 selected."}
{"time": "2024-06-04T12:43:27.823534", "name": "__main__", "level": "INFO", "message": "Action: 15, Reward: tensor([-30.3310], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T12:43:28.472113", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 16 selected."}
{"time": "2024-06-04T12:43:35.920144", "name": "__main__", "level": "INFO", "message": "Action: 16, Reward: tensor([-30.4803], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T12:43:36.820526", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 7 selected."}
{"time": "2024-06-04T12:43:40.804885", "name": "__main__", "level": "INFO", "message": "Action: 7, Reward: tensor([-30.5946], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T12:43:41.814315", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 10 selected."}
{"time": "2024-06-04T12:43:45.371088", "name": "__main__", "level": "INFO", "message": "Action: 10, Reward: tensor([-31.2410], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T12:43:46.314399", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 14 selected."}
{"time": "2024-06-04T12:43:53.935208", "name": "__main__", "level": "INFO", "message": "Action: 14, Reward: tensor([-31.8477], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T12:43:54.587505", "name": "__main__", "level": "INFO", "message": "Epoch 0, Iteration 50: Reward: tensor([-1836.3838], grad_fn=<AddBackward0>), Policy Loss: None, Value Loss: None, Total Loss: None, Entropy: None"}
{"time": "2024-06-04T12:43:55.443615", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 0 selected."}
{"time": "2024-06-04T12:44:02.876562", "name": "__main__", "level": "INFO", "message": "Action: 0, Reward: tensor([-31.9627], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T12:44:03.500073", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 9 selected."}
{"time": "2024-06-04T12:44:10.961640", "name": "__main__", "level": "INFO", "message": "Action: 9, Reward: tensor([-30.7549], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T12:44:11.535818", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 5 selected."}
{"time": "2024-06-04T12:44:18.871882", "name": "__main__", "level": "INFO", "message": "Action: 5, Reward: tensor([-29.9219], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T12:44:20.148757", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 11 selected."}
{"time": "2024-06-04T12:44:23.833173", "name": "__main__", "level": "INFO", "message": "Action: 11, Reward: tensor([-29.4261], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T12:44:24.887074", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 0 selected."}
{"time": "2024-06-04T12:44:32.401314", "name": "__main__", "level": "INFO", "message": "Action: 0, Reward: tensor([-28.7715], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T12:44:33.176131", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 15 selected."}
{"time": "2024-06-04T12:44:40.530690", "name": "__main__", "level": "INFO", "message": "Action: 15, Reward: tensor([-28.5258], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T12:44:40.947442", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 9 selected."}
{"time": "2024-06-04T12:44:47.828576", "name": "__main__", "level": "INFO", "message": "Action: 9, Reward: tensor([-27.1675], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T12:44:48.462724", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 2 selected."}
{"time": "2024-06-04T12:44:51.728839", "name": "__main__", "level": "INFO", "message": "Action: 2, Reward: tensor([-27.0586], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T12:44:52.316617", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 16 selected."}
{"time": "2024-06-04T12:45:00.004640", "name": "__main__", "level": "INFO", "message": "Action: 16, Reward: tensor([-26.6445], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T12:45:00.808306", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 9 selected."}
{"time": "2024-06-04T12:45:07.769760", "name": "__main__", "level": "INFO", "message": "Action: 9, Reward: tensor([-25.2714], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T12:45:07.997661", "name": "__main__", "level": "INFO", "message": "Epoch 0, Iteration 60: Reward: tensor([-2121.8887], grad_fn=<AddBackward0>), Policy Loss: None, Value Loss: None, Total Loss: None, Entropy: None"}
{"time": "2024-06-04T12:45:08.320469", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 4 selected."}
{"time": "2024-06-04T12:45:16.498054", "name": "__main__", "level": "INFO", "message": "Action: 4, Reward: tensor([-24.8661], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T12:45:17.245562", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 10 selected."}
{"time": "2024-06-04T12:45:20.966946", "name": "__main__", "level": "INFO", "message": "Action: 10, Reward: tensor([-25.4389], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T12:45:22.002853", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 2 selected."}
{"time": "2024-06-04T12:45:25.822547", "name": "__main__", "level": "INFO", "message": "Action: 2, Reward: tensor([-25.7962], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T12:45:26.878134", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 8 selected."}
{"time": "2024-06-04T12:45:34.483751", "name": "__main__", "level": "INFO", "message": "Action: 8, Reward: tensor([-27.7089], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T12:45:34.872627", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 13 selected."}
{"time": "2024-06-04T12:45:43.232880", "name": "__main__", "level": "INFO", "message": "Action: 13, Reward: tensor([-28.3464], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T12:45:44.348105", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 1 selected."}
{"time": "2024-06-04T12:45:52.404325", "name": "__main__", "level": "INFO", "message": "Action: 1, Reward: tensor([-28.6805], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T12:45:53.153083", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 5 selected."}
{"time": "2024-06-04T12:46:01.911106", "name": "__main__", "level": "INFO", "message": "Action: 5, Reward: tensor([-28.6740], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T12:46:03.339468", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 5 selected."}
{"time": "2024-06-04T12:46:11.452913", "name": "__main__", "level": "INFO", "message": "Action: 5, Reward: tensor([-28.8288], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T12:46:12.910625", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 0 selected."}
{"time": "2024-06-04T12:46:20.844048", "name": "__main__", "level": "INFO", "message": "Action: 0, Reward: tensor([-29.1719], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T12:46:21.850640", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 1 selected."}
{"time": "2024-06-04T12:46:30.607577", "name": "__main__", "level": "INFO", "message": "Action: 1, Reward: tensor([-29.5338], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T12:46:31.198172", "name": "__main__", "level": "INFO", "message": "Epoch 0, Iteration 70: Reward: tensor([-2398.9343], grad_fn=<AddBackward0>), Policy Loss: None, Value Loss: None, Total Loss: None, Entropy: None"}
{"time": "2024-06-04T12:46:32.297857", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 14 selected."}
{"time": "2024-06-04T12:46:40.330836", "name": "__main__", "level": "INFO", "message": "Action: 14, Reward: tensor([-29.9624], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T12:46:41.267063", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 11 selected."}
{"time": "2024-06-04T12:46:45.290734", "name": "__main__", "level": "INFO", "message": "Action: 11, Reward: tensor([-29.6637], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T12:46:46.195687", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 15 selected."}
{"time": "2024-06-04T12:46:53.814556", "name": "__main__", "level": "INFO", "message": "Action: 15, Reward: tensor([-29.1012], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T12:46:54.869014", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 6 selected."}
{"time": "2024-06-04T12:46:58.781721", "name": "__main__", "level": "INFO", "message": "Action: 6, Reward: tensor([-29.2162], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T12:46:59.499277", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 14 selected."}
{"time": "2024-06-04T12:47:07.259244", "name": "__main__", "level": "INFO", "message": "Action: 14, Reward: tensor([-29.5441], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T12:47:08.023013", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 7 selected."}
{"time": "2024-06-04T12:47:12.174804", "name": "__main__", "level": "INFO", "message": "Action: 7, Reward: tensor([-29.8548], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T12:47:13.136723", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 2 selected."}
{"time": "2024-06-04T12:47:17.145448", "name": "__main__", "level": "INFO", "message": "Action: 2, Reward: tensor([-30.1551], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T12:47:18.531327", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 1 selected."}
{"time": "2024-06-04T12:47:25.929287", "name": "__main__", "level": "INFO", "message": "Action: 1, Reward: tensor([-30.2600], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T12:47:26.594426", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 2 selected."}
{"time": "2024-06-04T12:47:29.957750", "name": "__main__", "level": "INFO", "message": "Action: 2, Reward: tensor([-30.4675], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T12:47:30.528939", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 2 selected."}
{"time": "2024-06-04T12:47:34.465038", "name": "__main__", "level": "INFO", "message": "Action: 2, Reward: tensor([-30.6903], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T12:47:34.526751", "name": "__main__", "level": "INFO", "message": "Epoch 0, Iteration 80: Reward: tensor([-2697.8499], grad_fn=<AddBackward0>), Policy Loss: None, Value Loss: None, Total Loss: None, Entropy: None"}
{"time": "2024-06-04T12:47:34.828227", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 1 selected."}
{"time": "2024-06-04T12:47:42.702086", "name": "__main__", "level": "INFO", "message": "Action: 1, Reward: tensor([-31.0019], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T12:47:43.693858", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 15 selected."}
{"time": "2024-06-04T12:47:52.038031", "name": "__main__", "level": "INFO", "message": "Action: 15, Reward: tensor([-31.1251], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T12:47:53.242027", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 2 selected."}
{"time": "2024-06-04T12:47:57.393912", "name": "__main__", "level": "INFO", "message": "Action: 2, Reward: tensor([-31.1954], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T12:47:58.533020", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 8 selected."}
{"time": "2024-06-04T12:48:06.003608", "name": "__main__", "level": "INFO", "message": "Action: 8, Reward: tensor([-32.9407], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T12:48:07.090855", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 15 selected."}
{"time": "2024-06-04T12:48:15.140893", "name": "__main__", "level": "INFO", "message": "Action: 15, Reward: tensor([-33.9088], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T12:48:16.337978", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 14 selected."}
{"time": "2024-06-04T12:48:23.722203", "name": "__main__", "level": "INFO", "message": "Action: 14, Reward: tensor([-34.4533], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T12:48:24.190989", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 7 selected."}
{"time": "2024-06-04T12:48:28.494099", "name": "__main__", "level": "INFO", "message": "Action: 7, Reward: tensor([-34.7802], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T12:48:30.042063", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 12 selected."}
{"time": "2024-06-04T12:48:38.249088", "name": "__main__", "level": "INFO", "message": "Action: 12, Reward: tensor([-35.0514], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T12:48:39.752815", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 0 selected."}
{"time": "2024-06-04T12:48:48.604275", "name": "__main__", "level": "INFO", "message": "Action: 0, Reward: tensor([-35.6482], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T12:48:49.735205", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 0 selected."}
{"time": "2024-06-04T12:48:58.690989", "name": "__main__", "level": "INFO", "message": "Action: 0, Reward: tensor([-36.3071], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T12:48:59.536017", "name": "__main__", "level": "INFO", "message": "Epoch 0, Iteration 90: Reward: tensor([-3034.2622], grad_fn=<AddBackward0>), Policy Loss: None, Value Loss: None, Total Loss: None, Entropy: None"}
{"time": "2024-06-04T12:49:00.704690", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 0 selected."}
{"time": "2024-06-04T12:49:09.044336", "name": "__main__", "level": "INFO", "message": "Action: 0, Reward: tensor([-37.3258], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T12:49:10.500306", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 4 selected."}
{"time": "2024-06-04T12:49:18.937843", "name": "__main__", "level": "INFO", "message": "Action: 4, Reward: tensor([-37.8156], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T12:49:20.365380", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 7 selected."}
{"time": "2024-06-04T12:49:24.436986", "name": "__main__", "level": "INFO", "message": "Action: 7, Reward: tensor([-38.0586], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T12:49:25.929053", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 0 selected."}
{"time": "2024-06-04T12:49:34.888692", "name": "__main__", "level": "INFO", "message": "Action: 0, Reward: tensor([-39.0500], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T12:49:36.335704", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 16 selected."}
{"time": "2024-06-04T12:49:44.578478", "name": "__main__", "level": "INFO", "message": "Action: 16, Reward: tensor([-39.6343], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T12:49:45.878097", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 2 selected."}
{"time": "2024-06-04T12:49:50.907721", "name": "__main__", "level": "INFO", "message": "Action: 2, Reward: tensor([-40.0855], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T12:49:52.522753", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 2 selected."}
{"time": "2024-06-04T12:49:57.655942", "name": "__main__", "level": "INFO", "message": "Action: 2, Reward: tensor([-40.5093], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T12:49:59.179981", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 10 selected."}
{"time": "2024-06-04T12:50:04.030642", "name": "__main__", "level": "INFO", "message": "Action: 10, Reward: tensor([-41.1383], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T12:50:05.664087", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 14 selected."}
{"time": "2024-06-04T12:50:14.479210", "name": "__main__", "level": "INFO", "message": "Action: 14, Reward: tensor([-142.3421], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T12:50:15.364279", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 0 selected."}
{"time": "2024-06-04T12:50:23.954926", "name": "__main__", "level": "INFO", "message": "Action: 0, Reward: tensor([-42.5317], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T12:50:24.870678", "name": "__main__", "level": "INFO", "message": "Epoch 0, Iteration 100: Reward: tensor([-3532.7532], grad_fn=<AddBackward0>), Policy Loss: None, Value Loss: None, Total Loss: None, Entropy: None"}
{"time": "2024-06-04T12:50:26.114572", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 1 selected."}
{"time": "2024-06-04T12:50:34.837840", "name": "__main__", "level": "INFO", "message": "Action: 1, Reward: tensor([-42.5943], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T12:50:36.545256", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 11 selected."}
{"time": "2024-06-04T12:50:41.338207", "name": "__main__", "level": "INFO", "message": "Action: 11, Reward: tensor([-42.4510], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T12:50:42.981702", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 3 selected."}
{"time": "2024-06-04T12:50:48.027844", "name": "__main__", "level": "INFO", "message": "Action: 3, Reward: tensor([-42.3248], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T12:50:49.734563", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 1 selected."}
{"time": "2024-06-04T12:50:58.507294", "name": "__main__", "level": "INFO", "message": "Action: 1, Reward: tensor([-41.7030], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T12:50:59.826436", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 11 selected."}
{"time": "2024-06-04T12:51:04.541248", "name": "__main__", "level": "INFO", "message": "Action: 11, Reward: tensor([-41.2091], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T12:51:05.562870", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 2 selected."}
{"time": "2024-06-04T12:51:10.060377", "name": "__main__", "level": "INFO", "message": "Action: 2, Reward: tensor([-41.2218], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T12:51:11.477119", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 3 selected."}
{"time": "2024-06-04T12:51:16.428406", "name": "__main__", "level": "INFO", "message": "Action: 3, Reward: tensor([-41.0562], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T12:51:17.844470", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 0 selected."}
{"time": "2024-06-04T12:51:26.141839", "name": "__main__", "level": "INFO", "message": "Action: 0, Reward: tensor([-41.6600], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T12:51:27.577473", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 2 selected."}
{"time": "2024-06-04T12:51:32.317319", "name": "__main__", "level": "INFO", "message": "Action: 2, Reward: tensor([-42.1099], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T12:51:33.940410", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 13 selected."}
{"time": "2024-06-04T12:51:42.739281", "name": "__main__", "level": "INFO", "message": "Action: 13, Reward: tensor([-42.1483], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T12:51:43.502055", "name": "__main__", "level": "INFO", "message": "Epoch 0, Iteration 110: Reward: tensor([-3951.2312], grad_fn=<AddBackward0>), Policy Loss: None, Value Loss: None, Total Loss: None, Entropy: None"}
{"time": "2024-06-04T12:51:44.818096", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 0 selected."}
{"time": "2024-06-04T12:51:53.261541", "name": "__main__", "level": "INFO", "message": "Action: 0, Reward: tensor([-42.7145], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T12:51:54.614935", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 14 selected."}
{"time": "2024-06-04T12:52:03.321901", "name": "__main__", "level": "INFO", "message": "Action: 14, Reward: tensor([-43.7600], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T12:52:04.725550", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 3 selected."}
{"time": "2024-06-04T12:52:09.843048", "name": "__main__", "level": "INFO", "message": "Action: 3, Reward: tensor([-43.8498], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T12:52:11.498659", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 6 selected."}
{"time": "2024-06-04T12:52:16.386639", "name": "__main__", "level": "INFO", "message": "Action: 6, Reward: tensor([-43.9645], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T12:52:17.986526", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 2 selected."}
{"time": "2024-06-04T12:52:22.656828", "name": "__main__", "level": "INFO", "message": "Action: 2, Reward: tensor([-44.2905], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T12:52:24.404252", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 2 selected."}
{"time": "2024-06-04T12:52:29.209102", "name": "__main__", "level": "INFO", "message": "Action: 2, Reward: tensor([-44.6609], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T12:52:30.811028", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 6 selected."}
{"time": "2024-06-04T12:52:35.805692", "name": "__main__", "level": "INFO", "message": "Action: 6, Reward: tensor([-44.7752], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T12:52:37.301500", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 3 selected."}
{"time": "2024-06-04T12:52:42.027307", "name": "__main__", "level": "INFO", "message": "Action: 3, Reward: tensor([-44.6943], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T12:52:43.412311", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 1 selected."}
{"time": "2024-06-04T12:52:52.622846", "name": "__main__", "level": "INFO", "message": "Action: 1, Reward: tensor([-44.2991], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T12:52:54.272731", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 2 selected."}
{"time": "2024-06-04T12:52:59.155845", "name": "__main__", "level": "INFO", "message": "Action: 2, Reward: tensor([-44.4466], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T12:53:00.029866", "name": "__main__", "level": "INFO", "message": "Epoch 0, Iteration 120: Reward: tensor([-4392.6865], grad_fn=<AddBackward0>), Policy Loss: None, Value Loss: None, Total Loss: None, Entropy: None"}
{"time": "2024-06-04T12:53:01.277699", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 2 selected."}
{"time": "2024-06-04T12:53:06.200101", "name": "__main__", "level": "INFO", "message": "Action: 2, Reward: tensor([-44.8662], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T12:53:07.581867", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 0 selected."}
{"time": "2024-06-04T12:53:16.690005", "name": "__main__", "level": "INFO", "message": "Action: 0, Reward: tensor([-46.0379], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T12:53:18.332716", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 1 selected."}
{"time": "2024-06-04T12:53:27.337105", "name": "__main__", "level": "INFO", "message": "Action: 1, Reward: tensor([-46.1244], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T12:53:28.970727", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 4 selected."}
{"time": "2024-06-04T12:53:37.625981", "name": "__main__", "level": "INFO", "message": "Action: 4, Reward: tensor([-46.2451], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T12:53:39.198331", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 0 selected."}
{"time": "2024-06-04T12:53:48.198486", "name": "__main__", "level": "INFO", "message": "Action: 0, Reward: tensor([-47.0115], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T12:53:49.876899", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 1 selected."}
{"time": "2024-06-04T12:53:58.602473", "name": "__main__", "level": "INFO", "message": "Action: 1, Reward: tensor([-47.0206], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T12:53:59.917956", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 12 selected."}
{"time": "2024-06-04T12:54:08.793006", "name": "__main__", "level": "INFO", "message": "Action: 12, Reward: tensor([-47.6410], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T12:54:10.330557", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 9 selected."}
{"time": "2024-06-04T12:54:19.016613", "name": "__main__", "level": "INFO", "message": "Action: 9, Reward: tensor([-46.8375], grad_fn=<AddBackward0>), Done: False"}
{"time": "2024-06-04T12:54:20.604258", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 4 selected."}
{"time": "2024-06-04T12:54:28.897467", "name": "__main__", "level": "INFO", "message": "Episode timed out."}
{"time": "2024-06-04T12:54:29.395472", "name": "__main__", "level": "INFO", "message": "Action: 4, Reward: tensor([-46.5437], grad_fn=<AddBackward0>), Done: True"}
{"time": "2024-06-05T12:11:43.829875", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Using device: cpu"}
{"time": "2024-06-05T12:16:10.189682", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Using device: cpu"}
{"time": "2024-06-05T12:20:08.414738", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Using device: cpu"}
{"time": "2024-06-05T12:23:22.104379", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Using device: cpu"}
{"time": "2024-06-05T12:23:32.513771", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 0 selected."}
{"time": "2024-06-05T12:27:33.952500", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Using device: cpu"}
{"time": "2024-06-05T12:27:45.098377", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 2 selected."}
{"time": "2024-06-05T12:27:50.093878", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 1 selected."}
{"time": "2024-06-05T12:27:53.637765", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 1 selected."}
{"time": "2024-06-05T12:27:57.167823", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 1 selected."}
{"time": "2024-06-05T12:28:01.252418", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 2 selected."}
{"time": "2024-06-05T12:28:05.696309", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 3 selected."}
{"time": "2024-06-05T12:28:10.080402", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 3 selected."}
{"time": "2024-06-05T12:28:14.254509", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 3 selected."}
{"time": "2024-06-05T12:28:18.657737", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 2 selected."}
{"time": "2024-06-05T12:28:23.013023", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 1 selected."}
{"time": "2024-06-05T12:28:27.201777", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 2 selected."}
{"time": "2024-06-05T12:28:32.038761", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 1 selected."}
{"time": "2024-06-05T12:28:34.941213", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 1 selected."}
{"time": "2024-06-05T12:28:38.866285", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 3 selected."}
{"time": "2024-06-05T12:28:42.902529", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 3 selected."}
{"time": "2024-06-05T12:28:46.944835", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 3 selected."}
{"time": "2024-06-05T12:28:51.207966", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 0 selected."}
{"time": "2024-06-05T12:28:55.209611", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 1 selected."}
{"time": "2024-06-05T12:28:58.986125", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 0 selected."}
{"time": "2024-06-05T12:29:02.254857", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 0 selected."}
{"time": "2024-06-05T12:29:06.597712", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 1 selected."}
{"time": "2024-06-05T12:29:11.018237", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 0 selected."}
{"time": "2024-06-05T12:29:14.605319", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 0 selected."}
{"time": "2024-06-05T12:29:18.668035", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 0 selected."}
{"time": "2024-06-05T12:29:22.971265", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 0 selected."}
{"time": "2024-06-05T12:29:27.207731", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 0 selected."}
{"time": "2024-06-05T12:29:31.327679", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 0 selected."}
{"time": "2024-06-05T12:29:34.900364", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 3 selected."}
{"time": "2024-06-05T12:29:38.998757", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 1 selected."}
{"time": "2024-06-05T12:29:43.300541", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 0 selected."}
{"time": "2024-06-05T12:29:47.185020", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 0 selected."}
{"time": "2024-06-05T12:29:51.751843", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 3 selected."}
{"time": "2024-06-05T12:29:55.698162", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 1 selected."}
{"time": "2024-06-05T12:29:59.884395", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 2 selected."}
{"time": "2024-06-05T12:30:03.877504", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 1 selected."}
{"time": "2024-06-05T12:30:07.984142", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 2 selected."}
{"time": "2024-06-05T12:30:12.223798", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 0 selected."}
{"time": "2024-06-05T12:30:16.548184", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 2 selected."}
{"time": "2024-06-05T12:30:20.713416", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 0 selected."}
{"time": "2024-06-05T12:30:24.930174", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 2 selected."}
{"time": "2024-06-05T12:30:28.993327", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 3 selected."}
{"time": "2024-06-05T12:30:33.580974", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 3 selected."}
{"time": "2024-06-05T12:30:37.779387", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 2 selected."}
{"time": "2024-06-05T12:30:42.089862", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 2 selected."}
{"time": "2024-06-05T12:30:46.048675", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 0 selected."}
{"time": "2024-06-05T12:30:50.382037", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 2 selected."}
{"time": "2024-06-05T12:30:54.602617", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 3 selected."}
{"time": "2024-06-05T12:30:58.603842", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 0 selected."}
{"time": "2024-06-05T12:31:02.807362", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 3 selected."}
{"time": "2024-06-05T12:31:07.061347", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 2 selected."}
{"time": "2024-06-05T12:31:10.742982", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 3 selected."}
{"time": "2024-06-05T12:31:15.466197", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 1 selected."}
{"time": "2024-06-05T12:31:19.669393", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 0 selected."}
{"time": "2024-06-05T12:31:23.742238", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 3 selected."}
{"time": "2024-06-05T12:31:28.092143", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 0 selected."}
{"time": "2024-06-05T12:31:31.794889", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 2 selected."}
{"time": "2024-06-05T12:31:35.990175", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 2 selected."}
{"time": "2024-06-05T12:31:40.104589", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 2 selected."}
{"time": "2024-06-05T12:31:43.938106", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 0 selected."}
{"time": "2024-06-05T12:31:48.047654", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 0 selected."}
{"time": "2024-06-05T12:31:52.274967", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 0 selected."}
{"time": "2024-06-05T12:31:56.822943", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 0 selected."}
{"time": "2024-06-05T12:32:00.857527", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 0 selected."}
{"time": "2024-06-05T12:32:05.176778", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 3 selected."}
{"time": "2024-06-05T12:32:08.884528", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 3 selected."}
{"time": "2024-06-05T12:32:13.254896", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 3 selected."}
{"time": "2024-06-05T12:32:17.526241", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 0 selected."}
{"time": "2024-06-05T12:32:21.965804", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 0 selected."}
{"time": "2024-06-05T12:32:26.172303", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 0 selected."}
{"time": "2024-06-05T12:32:30.421256", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 2 selected."}
{"time": "2024-06-05T12:32:34.584796", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 3 selected."}
{"time": "2024-06-05T12:32:38.538387", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 3 selected."}
{"time": "2024-06-05T12:32:42.839756", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 2 selected."}
{"time": "2024-06-05T12:32:47.122440", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 0 selected."}
{"time": "2024-06-05T12:32:51.302719", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 2 selected."}
{"time": "2024-06-05T12:32:55.415596", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 0 selected."}
{"time": "2024-06-05T12:32:59.911212", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 0 selected."}
{"time": "2024-06-05T12:33:04.153076", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 3 selected."}
{"time": "2024-06-05T12:33:08.411033", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 0 selected."}
{"time": "2024-06-05T12:33:12.717078", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 2 selected."}
{"time": "2024-06-05T12:33:16.937486", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 3 selected."}
{"time": "2024-06-05T12:33:21.734150", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 2 selected."}
{"time": "2024-06-05T12:33:25.950708", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 2 selected."}
{"time": "2024-06-05T12:33:30.202932", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 0 selected."}
{"time": "2024-06-05T12:33:34.411035", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 2 selected."}
{"time": "2024-06-05T12:33:38.441136", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 3 selected."}
{"time": "2024-06-05T12:33:42.731586", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 1 selected."}
{"time": "2024-06-05T12:33:46.996514", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 0 selected."}
{"time": "2024-06-05T12:33:51.075525", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 0 selected."}
{"time": "2024-06-05T12:33:55.382469", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 0 selected."}
{"time": "2024-06-05T12:33:59.745663", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 0 selected."}
{"time": "2024-06-05T12:34:04.709402", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 0 selected."}
{"time": "2024-06-05T12:34:08.536569", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 2 selected."}
{"time": "2024-06-05T12:34:12.703067", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 3 selected."}
{"time": "2024-06-05T12:34:16.797051", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 0 selected."}
{"time": "2024-06-05T12:34:20.745207", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 0 selected."}
{"time": "2024-06-05T12:34:24.972218", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 3 selected."}
{"time": "2024-06-05T12:34:29.281824", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 2 selected."}
{"time": "2024-06-05T12:34:33.631366", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 3 selected."}
{"time": "2024-06-05T12:34:38.173049", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 1 selected."}
{"time": "2024-06-05T12:34:42.138726", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 0 selected."}
{"time": "2024-06-05T12:34:46.996762", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 1 selected."}
{"time": "2024-06-05T12:34:51.168333", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 2 selected."}
{"time": "2024-06-05T12:34:55.524349", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 2 selected."}
{"time": "2024-06-05T12:34:59.950361", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 1 selected."}
{"time": "2024-06-05T12:35:03.908132", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 0 selected."}
{"time": "2024-06-05T12:35:08.166800", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 1 selected."}
{"time": "2024-06-05T12:35:12.484988", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 1 selected."}
{"time": "2024-06-05T12:35:16.986466", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 1 selected."}
{"time": "2024-06-05T12:35:21.503782", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 0 selected."}
{"time": "2024-06-05T12:35:25.602193", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 0 selected."}
{"time": "2024-06-05T12:35:30.382529", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 3 selected."}
{"time": "2024-06-05T12:35:34.583402", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 3 selected."}
{"time": "2024-06-05T12:35:38.423015", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 3 selected."}
{"time": "2024-06-05T12:35:42.631467", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 0 selected."}
{"time": "2024-06-05T12:35:47.017171", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 0 selected."}
{"time": "2024-06-05T12:35:51.320521", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 1 selected."}
{"time": "2024-06-05T12:35:55.615905", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 1 selected."}
{"time": "2024-06-05T12:35:59.773311", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 3 selected."}
{"time": "2024-06-05T12:36:03.846352", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 1 selected."}
{"time": "2024-06-05T12:36:07.965146", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 3 selected."}
{"time": "2024-06-05T12:36:12.603081", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 1 selected."}
{"time": "2024-06-05T12:36:17.023762", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 3 selected."}
{"time": "2024-06-05T12:36:21.156186", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 3 selected."}
{"time": "2024-06-05T12:36:25.737418", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 0 selected."}
{"time": "2024-06-05T12:36:30.034635", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 3 selected."}
{"time": "2024-06-05T12:36:34.149119", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 0 selected."}
{"time": "2024-06-05T12:36:38.341668", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 0 selected."}
{"time": "2024-06-05T12:36:42.608622", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 0 selected."}
{"time": "2024-06-05T12:36:46.815643", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 3 selected."}
{"time": "2024-06-05T12:36:51.146041", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 2 selected."}
{"time": "2024-06-05T12:36:56.214444", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 0 selected."}
{"time": "2024-06-05T12:37:00.312003", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 0 selected."}
{"time": "2024-06-05T12:37:04.525852", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 3 selected."}
{"time": "2024-06-05T12:37:08.711452", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 0 selected."}
{"time": "2024-06-05T12:37:12.510471", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 0 selected."}
{"time": "2024-06-05T12:37:16.359944", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 2 selected."}
{"time": "2024-06-05T12:37:20.658612", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 0 selected."}
{"time": "2024-06-05T12:37:24.775707", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 3 selected."}
{"time": "2024-06-05T12:37:29.040802", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 1 selected."}
{"time": "2024-06-05T12:37:33.137822", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 3 selected."}
{"time": "2024-06-05T12:37:38.110459", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 0 selected."}
{"time": "2024-06-05T12:37:42.353784", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 3 selected."}
{"time": "2024-06-05T12:37:46.396058", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 0 selected."}
{"time": "2024-06-05T12:37:50.526287", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 1 selected."}
{"time": "2024-06-05T12:37:54.572140", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 1 selected."}
{"time": "2024-06-05T12:37:58.855408", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 0 selected."}
{"time": "2024-06-05T12:38:02.779690", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 1 selected."}
{"time": "2024-06-05T12:38:06.989105", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 1 selected."}
{"time": "2024-06-05T12:38:11.129891", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 2 selected."}
{"time": "2024-06-05T12:38:15.286376", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 1 selected."}
{"time": "2024-06-05T12:38:20.404399", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 2 selected."}
{"time": "2024-06-05T12:38:24.613591", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 0 selected."}
{"time": "2024-06-05T12:38:28.619834", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 2 selected."}
{"time": "2024-06-05T12:38:32.784828", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 3 selected."}
{"time": "2024-06-05T12:38:36.376181", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 1 selected."}
{"time": "2024-06-05T12:38:40.262628", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 1 selected."}
{"time": "2024-06-05T12:38:44.504287", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 3 selected."}
{"time": "2024-06-05T12:38:48.560082", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 0 selected."}
{"time": "2024-06-05T12:38:52.795868", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 1 selected."}
{"time": "2024-06-05T12:38:57.123436", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 0 selected."}
{"time": "2024-06-05T12:39:02.136204", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 0 selected."}
{"time": "2024-06-05T12:39:06.367760", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 3 selected."}
{"time": "2024-06-05T12:39:10.592367", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 3 selected."}
{"time": "2024-06-05T12:39:14.532946", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 0 selected."}
{"time": "2024-06-05T12:39:18.567589", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 0 selected."}
{"time": "2024-06-05T12:39:23.019462", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 0 selected."}
{"time": "2024-06-05T12:39:27.179435", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 0 selected."}
{"time": "2024-06-05T12:39:31.250198", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 0 selected."}
{"time": "2024-06-05T12:39:35.721276", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 2 selected."}
{"time": "2024-06-05T12:39:40.054298", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 3 selected."}
{"time": "2024-06-05T12:39:45.001411", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 0 selected."}
{"time": "2024-06-05T12:39:49.179250", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 2 selected."}
{"time": "2024-06-05T12:39:53.510401", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 3 selected."}
{"time": "2024-06-05T12:39:57.766572", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 0 selected."}
{"time": "2024-06-05T12:40:01.976993", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 1 selected."}
{"time": "2024-06-05T12:40:05.888052", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 0 selected."}
{"time": "2024-06-05T12:40:10.327089", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 1 selected."}
{"time": "2024-06-05T12:40:14.567827", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 2 selected."}
{"time": "2024-06-05T12:40:18.677594", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 0 selected."}
{"time": "2024-06-05T12:40:22.861417", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 1 selected."}
{"time": "2024-06-05T12:40:27.772369", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 0 selected."}
{"time": "2024-06-05T12:40:31.719836", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 3 selected."}
{"time": "2024-06-05T12:40:35.913164", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 0 selected."}
{"time": "2024-06-05T12:40:40.240405", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 0 selected."}
{"time": "2024-06-05T12:40:44.599860", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 3 selected."}
{"time": "2024-06-05T12:40:48.937063", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 3 selected."}
{"time": "2024-06-05T12:40:53.139767", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 3 selected."}
{"time": "2024-06-05T12:40:57.443842", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 1 selected."}
{"time": "2024-06-05T12:41:01.557043", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 0 selected."}
{"time": "2024-06-05T12:41:05.620977", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 2 selected."}
{"time": "2024-06-05T12:41:10.282112", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 0 selected."}
{"time": "2024-06-05T12:41:14.278246", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 3 selected."}
{"time": "2024-06-05T12:41:18.687198", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 3 selected."}
{"time": "2024-06-05T12:41:23.014963", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 2 selected."}
{"time": "2024-06-05T12:41:27.299862", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 2 selected."}
{"time": "2024-06-05T12:41:31.702464", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 0 selected."}
{"time": "2024-06-05T12:41:35.981003", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 0 selected."}
{"time": "2024-06-05T12:41:40.234668", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 3 selected."}
{"time": "2024-06-05T12:41:44.336202", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 0 selected."}
{"time": "2024-06-05T12:41:48.290845", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 0 selected."}
{"time": "2024-06-05T12:41:53.014147", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 0 selected."}
{"time": "2024-06-05T12:41:57.247945", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 0 selected."}
{"time": "2024-06-05T12:42:01.447133", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 0 selected."}
{"time": "2024-06-05T12:42:05.477531", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 2 selected."}
{"time": "2024-06-05T12:42:09.630773", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 0 selected."}
{"time": "2024-06-05T12:42:13.977284", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 1 selected."}
{"time": "2024-06-05T12:42:18.197154", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 0 selected."}
{"time": "2024-06-05T12:42:22.410378", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 2 selected."}
{"time": "2024-06-05T12:42:26.566991", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 1 selected."}
{"time": "2024-06-05T12:42:30.830939", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 0 selected."}
{"time": "2024-06-05T12:42:35.546514", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 1 selected."}
{"time": "2024-06-05T12:42:38.882748", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 0 selected."}
{"time": "2024-06-05T12:42:43.212688", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 0 selected."}
{"time": "2024-06-05T12:42:47.568039", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 3 selected."}
{"time": "2024-06-05T12:42:51.985732", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 1 selected."}
{"time": "2024-06-05T12:42:56.271482", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 0 selected."}
{"time": "2024-06-05T12:43:00.296610", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 3 selected."}
{"time": "2024-06-05T12:43:04.561923", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 3 selected."}
{"time": "2024-06-05T12:43:08.349229", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 0 selected."}
{"time": "2024-06-05T12:43:12.429626", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 0 selected."}
{"time": "2024-06-05T12:43:17.272635", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 1 selected."}
{"time": "2024-06-05T12:43:21.335974", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 2 selected."}
{"time": "2024-06-05T12:43:25.650208", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 1 selected."}
{"time": "2024-06-05T12:43:29.606040", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 0 selected."}
{"time": "2024-06-05T12:43:33.839930", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 0 selected."}
{"time": "2024-06-05T12:43:38.057916", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 1 selected."}
{"time": "2024-06-05T12:43:42.293552", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 0 selected."}
{"time": "2024-06-05T12:43:46.472521", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 0 selected."}
{"time": "2024-06-05T12:43:50.858444", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 0 selected."}
{"time": "2024-06-05T12:43:55.292144", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 0 selected."}
{"time": "2024-06-05T12:43:59.970086", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 1 selected."}
{"time": "2024-06-05T12:44:04.048379", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 3 selected."}
{"time": "2024-06-05T12:44:08.247461", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 3 selected."}
{"time": "2024-06-05T12:44:12.417295", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 2 selected."}
{"time": "2024-06-05T12:44:16.608781", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 3 selected."}
{"time": "2024-06-05T12:44:20.848338", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 0 selected."}
{"time": "2024-06-05T12:44:25.117744", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 0 selected."}
{"time": "2024-06-08T19:52:29.739846", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Using device: cpu"}
{"time": "2024-06-08T19:52:39.687813", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 0 selected."}
{"time": "2024-06-08T19:52:43.452615", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 0 selected."}
{"time": "2024-06-08T19:52:46.240102", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 1 selected."}
{"time": "2024-06-08T19:52:49.041806", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 2 selected."}
{"time": "2024-06-08T19:52:51.937736", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 0 selected."}
{"time": "2024-06-08T19:52:55.483653", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 2 selected."}
{"time": "2024-06-08T19:52:59.084588", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 3 selected."}
{"time": "2024-06-08T19:53:02.419908", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 3 selected."}
{"time": "2024-06-08T19:53:06.133325", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 3 selected."}
{"time": "2024-06-08T19:53:09.712158", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 1 selected."}
{"time": "2024-06-08T19:53:13.030650", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 0 selected."}
{"time": "2024-06-08T19:53:16.440883", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 3 selected."}
{"time": "2024-06-08T19:53:20.021278", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 2 selected."}
{"time": "2024-06-08T19:53:23.232723", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 0 selected."}
{"time": "2024-06-08T19:53:26.257812", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 1 selected."}
{"time": "2024-06-08T19:53:29.376153", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 2 selected."}
{"time": "2024-06-08T19:53:32.921836", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 2 selected."}
{"time": "2024-06-08T19:53:36.261032", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 2 selected."}
{"time": "2024-06-08T19:53:40.181195", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 1 selected."}
{"time": "2024-06-08T19:53:43.994693", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 3 selected."}
{"time": "2024-06-08T19:53:47.124092", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 0 selected."}
{"time": "2024-06-08T19:53:50.649259", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 1 selected."}
{"time": "2024-06-08T19:53:52.808408", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 2 selected."}
{"time": "2024-06-08T19:53:55.191819", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 3 selected."}
{"time": "2024-06-08T19:53:57.650150", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 3 selected."}
{"time": "2024-06-08T19:53:59.748298", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 2 selected."}
{"time": "2024-06-08T19:54:03.198268", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 1 selected."}
{"time": "2024-06-08T19:54:05.261479", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 1 selected."}
{"time": "2024-06-08T19:54:07.513393", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 3 selected."}
{"time": "2024-06-08T19:54:10.201918", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 2 selected."}
{"time": "2024-06-08T19:54:13.053368", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 0 selected."}
{"time": "2024-06-08T19:54:15.856365", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 1 selected."}
{"time": "2024-06-08T19:54:17.897190", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 1 selected."}
{"time": "2024-06-08T19:54:20.779775", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 3 selected."}
{"time": "2024-06-08T19:54:23.871942", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 1 selected."}
{"time": "2024-06-08T19:54:26.676125", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 0 selected."}
{"time": "2024-06-08T19:54:29.790177", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 0 selected."}
{"time": "2024-06-08T19:54:33.671537", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 3 selected."}
{"time": "2024-06-08T19:54:37.007037", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 2 selected."}
{"time": "2024-06-08T19:54:40.953295", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 1 selected."}
{"time": "2024-06-08T19:54:44.757822", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 1 selected."}
{"time": "2024-06-08T19:54:48.717706", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 0 selected."}
{"time": "2024-06-08T19:54:52.536178", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 1 selected."}
{"time": "2024-06-08T19:54:56.088760", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 2 selected."}
{"time": "2024-06-08T19:54:59.244210", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 1 selected."}
{"time": "2024-06-08T19:55:02.487495", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 1 selected."}
{"time": "2024-06-08T19:55:05.760653", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 2 selected."}
{"time": "2024-06-08T19:55:09.385783", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 0 selected."}
{"time": "2024-06-08T19:55:12.336993", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 0 selected."}
{"time": "2024-06-08T19:55:15.316730", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 2 selected."}
{"time": "2024-06-08T19:55:18.872880", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 3 selected."}
{"time": "2024-06-08T19:55:22.476120", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 2 selected."}
{"time": "2024-06-08T19:55:26.231652", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 3 selected."}
{"time": "2024-06-08T19:55:29.816476", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 1 selected."}
{"time": "2024-06-08T19:55:33.436117", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 3 selected."}
{"time": "2024-06-08T19:55:36.983959", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 0 selected."}
{"time": "2024-06-08T19:55:40.691147", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 2 selected."}
{"time": "2024-06-08T19:55:44.140208", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 1 selected."}
{"time": "2024-06-08T19:55:47.080463", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 1 selected."}
{"time": "2024-06-08T19:55:50.515951", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 3 selected."}
{"time": "2024-06-08T19:55:53.766588", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 2 selected."}
{"time": "2024-06-08T19:55:57.456981", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 1 selected."}
{"time": "2024-06-08T19:56:00.637424", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 0 selected."}
{"time": "2024-06-08T19:56:04.122190", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 0 selected."}
{"time": "2024-06-08T19:56:07.474011", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 0 selected."}
{"time": "2024-06-08T19:56:10.292411", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 1 selected."}
{"time": "2024-06-08T19:56:13.060820", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 0 selected."}
{"time": "2024-06-08T19:56:17.115178", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 3 selected."}
{"time": "2024-06-08T19:56:20.037218", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 2 selected."}
{"time": "2024-06-08T19:56:22.633808", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 1 selected."}
{"time": "2024-06-08T19:56:25.974031", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 1 selected."}
{"time": "2024-06-08T19:56:29.809292", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 2 selected."}
{"time": "2024-06-08T19:56:32.994691", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 0 selected."}
{"time": "2024-06-08T19:56:36.305787", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 1 selected."}
{"time": "2024-06-08T19:56:39.689945", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 2 selected."}
{"time": "2024-06-08T19:56:42.790905", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 1 selected."}
{"time": "2024-06-08T19:56:46.262281", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 1 selected."}
{"time": "2024-06-08T19:56:49.005955", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 1 selected."}
{"time": "2024-06-08T19:56:51.386802", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploitation: Action 0 selected."}
{"time": "2024-06-08T19:56:54.385347", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 3 selected."}
{"time": "2024-06-08T20:03:15.133169", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Using device: cpu"}
{"time": "2024-06-08T20:03:25.307756", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 14 selected."}
{"time": "2024-06-08T20:10:49.985349", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Using device: cpu"}
{"time": "2024-06-08T20:10:59.444460", "name": "Drone.source.models.ppo.ppo_agent", "level": "INFO", "message": "Exploration: Random action 13 selected."}
{"time": "2024-07-20T10:38:16.248375", "name": "AirSimEnvLogger", "level": "INFO", "message": "Initializing AirSimEnv"}
{"time": "2024-07-20T10:38:16.251602", "name": "AirSimEnvLogger", "level": "INFO", "message": "Configuration: {\n  \"learning_rate\": 0.0001,\n  \"gamma\": 0.99,\n  \"tau\": 0.95,\n  \"batch_size\": 64,\n  \"num_timesteps\": 2000000,\n  \"ppo\": {\n    \"learning_rate\": 0.0003,\n    \"n_steps\": 2048,\n    \"batch_size\": 64,\n    \"n_epochs\": 2000,\n    \"gamma\": 0.99,\n    \"gae_lambda\": 0.95,\n    \"clip_range\": 0.2,\n    \"ent_coef\": 0.01,\n    \"vf_coef\": 0.5,\n    \"max_grad_norm\": 0.5,\n    \"use_sde\": true,\n    \"sde_sample_freq\": 4,\n    \"tensorboard_log\": \"logs/tensorboard_logs/ppo_airsim_tensorboard/\",\n    \"verbose\": 1,\n    \"seed\": null,\n    \"device\": \"auto\",\n    \"continuous\": true,\n    \"save_freq\": 10000\n  },\n  \"policy_network\": {\n    \"input_size\": 16,\n    \"hidden_layers\": [\n      256,\n      256\n    ],\n    \"output_size\": 4,\n    \"use_batch_norm\": true,\n    \"use_dropout\": true,\n    \"dropout_rate\": 0.2,\n    \"use_attention\": true,\n    \"num_action_heads\": 1\n  },\n  \"critic_network\": {\n    \"input_size\": 15,\n    \"hidden_layers\": [\n      256,\n      256\n    ],\n    \"output_size\": 1,\n    \"use_batch_norm\": true,\n    \"use_dropout\": true,\n    \"dropout_rate\": 0.2,\n    \"use_attention\": true\n  },\n  \"environment\": {\n    \"env_name\": \"Africa_001\",\n    \"reward_threshold\": 250,\n    \"max_env_steps\": 1000,\n    \"state_dim\": 15,\n    \"action_dim\": 4,\n    \"reward_scale\": 20,\n    \"proximity_threshold\": 5.0,\n    \"collision_penalty\": 25,\n    \"height_target\": -10,\n    \"height_tolerance\": 1.0,\n    \"height_penalty\": 1,\n    \"movement_penalty\": 0.5,\n    \"smoothness_penalty\": 0.5,\n    \"duration\": 0.1,\n    \"exploration_area\": {\n      \"x_min\": -1000,\n      \"x_max\": 1000,\n      \"y_min\": -1000,\n      \"y_max\": 1000,\n      \"z_min\": -100,\n      \"z_max\": 100\n    }\n  },\n  \"exploration\": {\n    \"strategy\": \"epsilon_decay\",\n    \"initial_epsilon\": 1.0,\n    \"min_epsilon\": 0.05,\n    \"epsilon_decay_rate\": 0.995\n  },\n  \"model_checkpointing\": {\n    \"checkpoint_interval\": 10,\n    \"save_best_only\": true,\n    \"checkpoint_dir\": \"models/checkpoints\"\n  },\n  \"logging\": {\n    \"log_interval\": 10,\n    \"log_dir\": \"logs/\",\n    \"tensorboard\": true,\n    \"tensorboard_log_dir\": \"logs/tensorboard_logs\",\n    \"model_save_path\": \"models/saved_models\"\n  },\n  \"advanced_training_techniques\": {\n    \"gradient_clipping\": 0.5,\n    \"use_gae\": true,\n    \"gae_lambda\": 0.95,\n    \"normalize_advantages\": true\n  },\n  \"early_stopping\": {\n    \"patience\": 5\n  },\n  \"reward_adjustments\": {\n    \"collision_penalty\": 50,\n    \"reward_threshold\": 250\n  },\n  \"shared_components\": {\n    \"residual_block\": {\n      \"input_dim\": 128,\n      \"hidden_dim\": 128,\n      \"dropout_rate\": 0.2\n    },\n    \"attention_layer\": {\n      \"input_dim\": 128,\n      \"hidden_dim\": 128\n    }\n  },\n  \"icm\": {\n    \"state_dim\": 16,\n    \"action_dim\": 3,\n    \"image_channels\": 3,\n    \"image_height\": 144,\n    \"image_width\": 256,\n    \"cnn\": {\n      \"conv1\": {\n        \"out_channels\": 32,\n        \"kernel_size\": 8,\n        \"stride\": 4\n      },\n      \"conv2\": {\n        \"out_channels\": 64,\n        \"kernel_size\": 4,\n        \"stride\": 2\n      },\n      \"conv3\": {\n        \"out_channels\": 64,\n        \"kernel_size\": 3,\n        \"stride\": 1\n      }\n    },\n    \"state_encoder\": {\n      \"hidden_dim\": 128\n    },\n    \"forward_model\": {\n      \"hidden_dim\": 256\n    },\n    \"inverse_model\": {\n      \"hidden_dim\": 256\n    }\n  },\n  \"predictive_model\": {\n    \"learning_rate\": 0.0001,\n    \"hidden_layers\": [\n      256,\n      256\n    ]\n  },\n  \"hrl\": {\n    \"use_hierarchical\": true,\n    \"high_level_policy\": {\n      \"input_size\": 15,\n      \"hidden_layers\": [\n        256,\n        256\n      ],\n      \"output_size\": 4\n    },\n    \"sub_goal_dim\": 3,\n    \"low_level_policy\": {\n      \"input_size\": 18,\n      \"hidden_layers\": [\n        256,\n        256\n      ],\n      \"output_size\": 4\n    }\n  },\n  \"curriculum_learning\": {\n    \"use_curriculum\": true,\n    \"initial_difficulty\": 1,\n    \"difficulty_increment\": 1,\n    \"difficulty_threshold\": 200\n  },\n  \"multi_agent\": {\n    \"use_multi_agent\": true,\n    \"num_agents\": 2,\n    \"hidden_layers\": [\n      256,\n      256\n    ]\n  }\n}"}
{"time": "2024-07-21T01:31:15.687352", "name": "AirSimEnvLogger", "level": "INFO", "message": "Initialized with state_dim: 16, action_dim: 4"}
{"time": "2024-07-21T01:31:15.706056", "name": "AirSimEnvLogger", "level": "INFO", "message": "Initializing AirSimEnv"}
{"time": "2024-07-21T01:31:15.706056", "name": "AirSimEnvLogger", "level": "INFO", "message": "Configuration: {\n  \"learning_rate\": 0.0001,\n  \"gamma\": 0.99,\n  \"tau\": 0.95,\n  \"batch_size\": 64,\n  \"num_timesteps\": 2000000,\n  \"ppo\": {\n    \"learning_rate\": 0.0003,\n    \"n_steps\": 2048,\n    \"batch_size\": 64,\n    \"n_epochs\": 2000,\n    \"gamma\": 0.99,\n    \"gae_lambda\": 0.95,\n    \"clip_range\": 0.2,\n    \"ent_coef\": 0.01,\n    \"vf_coef\": 0.5,\n    \"max_grad_norm\": 0.5,\n    \"use_sde\": true,\n    \"sde_sample_freq\": 4,\n    \"tensorboard_log\": \"logs/tensorboard_logs/ppo_airsim_tensorboard/\",\n    \"verbose\": 1,\n    \"seed\": null,\n    \"device\": \"auto\",\n    \"continuous\": true,\n    \"save_freq\": 10000\n  },\n  \"environment\": {\n    \"env_name\": \"Africa_001\",\n    \"reward_threshold\": 250,\n    \"max_episode_steps\": 1000,\n    \"state_dim\": 16,\n    \"action_dim\": 4,\n    \"reward_scale\": 20,\n    \"proximity_threshold\": 5.0,\n    \"collision_penalty\": 25,\n    \"height_target\": -10,\n    \"height_tolerance\": 1.0,\n    \"height_penalty\": 1,\n    \"movement_penalty\": 0.1,\n    \"smoothness_penalty\": 0.1,\n    \"duration\": 0.1,\n    \"exploration_area\": {\n      \"x_min\": -1000,\n      \"x_max\": 1000,\n      \"y_min\": -1000,\n      \"y_max\": 1000,\n      \"z_min\": -100,\n      \"z_max\": 100\n    }\n  },\n  \"policy_network\": {\n    \"input_size\": 16,\n    \"hidden_layers\": [\n      256,\n      256\n    ],\n    \"output_size\": 4,\n    \"use_batch_norm\": true,\n    \"use_dropout\": true,\n    \"dropout_rate\": 0.2,\n    \"use_attention\": true,\n    \"num_action_heads\": 1\n  },\n  \"critic_network\": {\n    \"input_size\": 16,\n    \"hidden_layers\": [\n      256,\n      256\n    ],\n    \"output_size\": 1,\n    \"use_batch_norm\": true,\n    \"use_dropout\": true,\n    \"dropout_rate\": 0.2,\n    \"use_attention\": true\n  },\n  \"exploration\": {\n    \"strategy\": \"epsilon_decay\",\n    \"initial_epsilon\": 1.0,\n    \"min_epsilon\": 0.05,\n    \"epsilon_decay_rate\": 0.9995\n  },\n  \"model_checkpointing\": {\n    \"checkpoint_interval\": 10,\n    \"save_best_only\": true,\n    \"checkpoint_dir\": \"models/checkpoints\"\n  },\n  \"logging\": {\n    \"log_interval\": 10,\n    \"log_dir\": \"logs/\",\n    \"tensorboard\": true,\n    \"tensorboard_log_dir\": \"logs/tensorboard_logs\",\n    \"model_save_path\": \"models/saved_models\"\n  },\n  \"advanced_training_techniques\": {\n    \"gradient_clipping\": 0.5,\n    \"use_gae\": true,\n    \"gae_lambda\": 0.95,\n    \"normalize_advantages\": true\n  },\n  \"early_stopping\": {\n    \"patience\": 10\n  },\n  \"reward_adjustments\": {\n    \"collision_penalty\": 50,\n    \"reward_threshold\": 250\n  },\n  \"shared_components\": {\n    \"residual_block\": {\n      \"input_dim\": 128,\n      \"hidden_dim\": 128,\n      \"dropout_rate\": 0.2\n    },\n    \"attention_layer\": {\n      \"input_dim\": 128,\n      \"hidden_dim\": 128\n    }\n  },\n  \"icm\": {\n    \"state_dim\": 16,\n    \"action_dim\": 4,\n    \"image_channels\": 3,\n    \"image_height\": 144,\n    \"image_width\": 256,\n    \"cnn\": {\n      \"conv1\": {\n        \"out_channels\": 32,\n        \"kernel_size\": 8,\n        \"stride\": 4\n      },\n      \"conv2\": {\n        \"out_channels\": 64,\n        \"kernel_size\": 4,\n        \"stride\": 2\n      },\n      \"conv3\": {\n        \"out_channels\": 64,\n        \"kernel_size\": 3,\n        \"stride\": 1\n      }\n    },\n    \"state_encoder\": {\n      \"hidden_dim\": 128\n    },\n    \"forward_model\": {\n      \"hidden_dim\": 256\n    },\n    \"inverse_model\": {\n      \"hidden_dim\": 256\n    }\n  },\n  \"predictive_model\": {\n    \"learning_rate\": 0.0001,\n    \"hidden_layers\": [\n      256,\n      256\n    ]\n  },\n  \"hrl\": {\n    \"use_hierarchical\": true,\n    \"high_level_policy\": {\n      \"input_size\": 16,\n      \"hidden_layers\": [\n        256,\n        256\n      ],\n      \"output_size\": 4\n    },\n    \"sub_goal_dim\": 3,\n    \"low_level_policy\": {\n      \"input_size\": 19,\n      \"hidden_layers\": [\n        256,\n        256\n      ],\n      \"output_size\": 4\n    }\n  },\n  \"curriculum_learning\": {\n    \"use_curriculum\": true,\n    \"initial_difficulty\": 1,\n    \"difficulty_increment\": 1,\n    \"difficulty_threshold\": 200\n  },\n  \"multi_agent\": {\n    \"use_multi_agent\": true,\n    \"num_agents\": 2,\n    \"hidden_layers\": [\n      256,\n      256\n    ]\n  }\n}"}
{"time": "2024-07-21T01:31:16.742829", "name": "AirSimEnvLogger", "level": "INFO", "message": "DataVisualizer initialized with Seaborn style set to 'whitegrid'."}
{"time": "2024-07-21T01:31:16.742829", "name": "AirSimEnvLogger", "level": "INFO", "message": "Using device: cpu"}
{"time": "2024-07-21T01:31:22.242113", "name": "AirSimEnvLogger", "level": "INFO", "message": "PPOAgent initialized successfully."}
{"time": "2024-07-21T01:31:22.304065", "name": "AirSimEnvLogger", "level": "INFO", "message": "Loading checkpoint from e:\\Project\\Drone\\models/checkpoints\\ppo_agent_checkpoint.pt"}
{"time": "2024-07-21T01:31:23.540528", "name": "AirSimEnvLogger", "level": "ERROR", "message": "Error loading checkpoint: 'policy_state_dict'"}
{"time": "2024-07-21T01:31:25.316649", "name": "AirSimEnvLogger", "level": "INFO", "message": "Resuming training from epoch 1"}
{"time": "2024-07-21T01:31:29.083743", "name": "AirSimEnvLogger", "level": "INFO", "message": "Environment reset and takeoff completed."}
{"time": "2024-07-21T01:31:29.675861", "name": "AirSimEnvLogger", "level": "ERROR", "message": "An error occurred: float() argument must be a string or a number, not 'dict'"}
{"time": "2024-07-21T01:31:35.887734", "name": "AirSimEnvLogger", "level": "INFO", "message": "Environment closed."}
{"time": "2024-07-21T01:31:35.919268", "name": "AirSimEnvLogger", "level": "INFO", "message": "Training completed and models saved."}
{"time": "2024-07-21T01:34:42.958518", "name": "AirSimEnvLogger", "level": "INFO", "message": "Initialized with state_dim: 16, action_dim: 4"}
{"time": "2024-07-21T01:34:42.975022", "name": "AirSimEnvLogger", "level": "INFO", "message": "Initializing AirSimEnv"}
{"time": "2024-07-21T01:34:42.975022", "name": "AirSimEnvLogger", "level": "INFO", "message": "Configuration: {\n  \"learning_rate\": 0.0001,\n  \"gamma\": 0.99,\n  \"tau\": 0.95,\n  \"batch_size\": 64,\n  \"num_timesteps\": 2000000,\n  \"ppo\": {\n    \"learning_rate\": 0.0003,\n    \"n_steps\": 2048,\n    \"batch_size\": 64,\n    \"n_epochs\": 2000,\n    \"gamma\": 0.99,\n    \"gae_lambda\": 0.95,\n    \"clip_range\": 0.2,\n    \"ent_coef\": 0.01,\n    \"vf_coef\": 0.5,\n    \"max_grad_norm\": 0.5,\n    \"use_sde\": true,\n    \"sde_sample_freq\": 4,\n    \"tensorboard_log\": \"logs/tensorboard_logs/ppo_airsim_tensorboard/\",\n    \"verbose\": 1,\n    \"seed\": null,\n    \"device\": \"auto\",\n    \"continuous\": true,\n    \"save_freq\": 10000\n  },\n  \"environment\": {\n    \"env_name\": \"Africa_001\",\n    \"reward_threshold\": 250,\n    \"max_episode_steps\": 1000,\n    \"state_dim\": 16,\n    \"action_dim\": 4,\n    \"reward_scale\": 20,\n    \"proximity_threshold\": 5.0,\n    \"collision_penalty\": 25,\n    \"height_target\": -10,\n    \"height_tolerance\": 1.0,\n    \"height_penalty\": 1,\n    \"movement_penalty\": 0.1,\n    \"smoothness_penalty\": 0.1,\n    \"duration\": 0.1,\n    \"exploration_area\": {\n      \"x_min\": -1000,\n      \"x_max\": 1000,\n      \"y_min\": -1000,\n      \"y_max\": 1000,\n      \"z_min\": -100,\n      \"z_max\": 100\n    }\n  },\n  \"policy_network\": {\n    \"input_size\": 16,\n    \"hidden_layers\": [\n      256,\n      256\n    ],\n    \"output_size\": 4,\n    \"use_batch_norm\": true,\n    \"use_dropout\": true,\n    \"dropout_rate\": 0.2,\n    \"use_attention\": true,\n    \"num_action_heads\": 1\n  },\n  \"critic_network\": {\n    \"input_size\": 16,\n    \"hidden_layers\": [\n      256,\n      256\n    ],\n    \"output_size\": 1,\n    \"use_batch_norm\": true,\n    \"use_dropout\": true,\n    \"dropout_rate\": 0.2,\n    \"use_attention\": true\n  },\n  \"exploration\": {\n    \"strategy\": \"epsilon_decay\",\n    \"initial_epsilon\": 1.0,\n    \"min_epsilon\": 0.05,\n    \"epsilon_decay_rate\": 0.9995\n  },\n  \"model_checkpointing\": {\n    \"checkpoint_interval\": 10,\n    \"save_best_only\": true,\n    \"checkpoint_dir\": \"models/checkpoints\"\n  },\n  \"logging\": {\n    \"log_interval\": 10,\n    \"log_dir\": \"logs/\",\n    \"tensorboard\": true,\n    \"tensorboard_log_dir\": \"logs/tensorboard_logs\",\n    \"model_save_path\": \"models/saved_models\"\n  },\n  \"advanced_training_techniques\": {\n    \"gradient_clipping\": 0.5,\n    \"use_gae\": true,\n    \"gae_lambda\": 0.95,\n    \"normalize_advantages\": true\n  },\n  \"early_stopping\": {\n    \"patience\": 10\n  },\n  \"reward_adjustments\": {\n    \"collision_penalty\": 50,\n    \"reward_threshold\": 250\n  },\n  \"shared_components\": {\n    \"residual_block\": {\n      \"input_dim\": 128,\n      \"hidden_dim\": 128,\n      \"dropout_rate\": 0.2\n    },\n    \"attention_layer\": {\n      \"input_dim\": 128,\n      \"hidden_dim\": 128\n    }\n  },\n  \"icm\": {\n    \"state_dim\": 16,\n    \"action_dim\": 4,\n    \"image_channels\": 3,\n    \"image_height\": 144,\n    \"image_width\": 256,\n    \"cnn\": {\n      \"conv1\": {\n        \"out_channels\": 32,\n        \"kernel_size\": 8,\n        \"stride\": 4\n      },\n      \"conv2\": {\n        \"out_channels\": 64,\n        \"kernel_size\": 4,\n        \"stride\": 2\n      },\n      \"conv3\": {\n        \"out_channels\": 64,\n        \"kernel_size\": 3,\n        \"stride\": 1\n      }\n    },\n    \"state_encoder\": {\n      \"hidden_dim\": 128\n    },\n    \"forward_model\": {\n      \"hidden_dim\": 256\n    },\n    \"inverse_model\": {\n      \"hidden_dim\": 256\n    }\n  },\n  \"predictive_model\": {\n    \"learning_rate\": 0.0001,\n    \"hidden_layers\": [\n      256,\n      256\n    ]\n  },\n  \"hrl\": {\n    \"use_hierarchical\": true,\n    \"high_level_policy\": {\n      \"input_size\": 16,\n      \"hidden_layers\": [\n        256,\n        256\n      ],\n      \"output_size\": 4\n    },\n    \"sub_goal_dim\": 3,\n    \"low_level_policy\": {\n      \"input_size\": 19,\n      \"hidden_layers\": [\n        256,\n        256\n      ],\n      \"output_size\": 4\n    }\n  },\n  \"curriculum_learning\": {\n    \"use_curriculum\": true,\n    \"initial_difficulty\": 1,\n    \"difficulty_increment\": 1,\n    \"difficulty_threshold\": 200\n  },\n  \"multi_agent\": {\n    \"use_multi_agent\": true,\n    \"num_agents\": 2,\n    \"hidden_layers\": [\n      256,\n      256\n    ]\n  }\n}"}
{"time": "2024-07-21T01:34:43.966584", "name": "AirSimEnvLogger", "level": "INFO", "message": "DataVisualizer initialized with Seaborn style set to 'whitegrid'."}
{"time": "2024-07-21T01:34:43.967088", "name": "AirSimEnvLogger", "level": "INFO", "message": "Using device: cpu"}
{"time": "2024-07-21T01:34:49.846582", "name": "AirSimEnvLogger", "level": "INFO", "message": "PPOAgent initialized successfully."}
{"time": "2024-07-21T01:34:49.907852", "name": "AirSimEnvLogger", "level": "INFO", "message": "Loading checkpoint from e:\\Project\\Drone\\models/checkpoints\\ppo_agent_checkpoint.pt"}
{"time": "2024-07-21T01:34:51.162160", "name": "AirSimEnvLogger", "level": "ERROR", "message": "Error loading checkpoint: 'policy_state_dict'"}
{"time": "2024-07-21T01:34:52.487085", "name": "AirSimEnvLogger", "level": "INFO", "message": "Resuming training from epoch 1"}
{"time": "2024-07-21T01:34:56.834640", "name": "AirSimEnvLogger", "level": "INFO", "message": "Environment reset and takeoff completed."}
{"time": "2024-07-21T01:34:57.481646", "name": "AirSimEnvLogger", "level": "ERROR", "message": "An error occurred: float() argument must be a string or a number, not 'dict'"}
{"time": "2024-07-21T01:35:03.906633", "name": "AirSimEnvLogger", "level": "INFO", "message": "Environment closed."}
{"time": "2024-07-21T01:35:04.000994", "name": "AirSimEnvLogger", "level": "INFO", "message": "Training completed and models saved."}
{"time": "2024-07-21T01:50:56.343784", "name": "AirSimEnvLogger", "level": "INFO", "message": "Initialized with state_dim: 16, action_dim: 4"}
{"time": "2024-07-21T01:50:56.363258", "name": "AirSimEnvLogger", "level": "INFO", "message": "Initializing AirSimEnv"}
{"time": "2024-07-21T01:50:56.363258", "name": "AirSimEnvLogger", "level": "INFO", "message": "Configuration: {\n  \"learning_rate\": 0.0001,\n  \"gamma\": 0.99,\n  \"tau\": 0.95,\n  \"batch_size\": 64,\n  \"num_timesteps\": 2000000,\n  \"ppo\": {\n    \"learning_rate\": 0.0003,\n    \"n_steps\": 2048,\n    \"batch_size\": 64,\n    \"n_epochs\": 2000,\n    \"gamma\": 0.99,\n    \"gae_lambda\": 0.95,\n    \"clip_range\": 0.2,\n    \"ent_coef\": 0.01,\n    \"vf_coef\": 0.5,\n    \"max_grad_norm\": 0.5,\n    \"use_sde\": true,\n    \"sde_sample_freq\": 4,\n    \"tensorboard_log\": \"logs/tensorboard_logs/ppo_airsim_tensorboard/\",\n    \"verbose\": 1,\n    \"seed\": null,\n    \"device\": \"auto\",\n    \"continuous\": true,\n    \"save_freq\": 10000\n  },\n  \"environment\": {\n    \"env_name\": \"Africa_001\",\n    \"reward_threshold\": 250,\n    \"max_episode_steps\": 1000,\n    \"state_dim\": 16,\n    \"action_dim\": 4,\n    \"reward_scale\": 20,\n    \"proximity_threshold\": 5.0,\n    \"collision_penalty\": 25,\n    \"height_target\": -10,\n    \"height_tolerance\": 1.0,\n    \"height_penalty\": 1,\n    \"movement_penalty\": 0.1,\n    \"smoothness_penalty\": 0.1,\n    \"duration\": 0.1,\n    \"exploration_area\": {\n      \"x_min\": -1000,\n      \"x_max\": 1000,\n      \"y_min\": -1000,\n      \"y_max\": 1000,\n      \"z_min\": -100,\n      \"z_max\": 100\n    }\n  },\n  \"policy_network\": {\n    \"input_size\": 16,\n    \"hidden_layers\": [\n      256,\n      256\n    ],\n    \"output_size\": 4,\n    \"use_batch_norm\": true,\n    \"use_dropout\": true,\n    \"dropout_rate\": 0.2,\n    \"use_attention\": true,\n    \"num_action_heads\": 1\n  },\n  \"critic_network\": {\n    \"input_size\": 16,\n    \"hidden_layers\": [\n      256,\n      256\n    ],\n    \"output_size\": 1,\n    \"use_batch_norm\": true,\n    \"use_dropout\": true,\n    \"dropout_rate\": 0.2,\n    \"use_attention\": true\n  },\n  \"exploration\": {\n    \"strategy\": \"epsilon_decay\",\n    \"initial_epsilon\": 1.0,\n    \"min_epsilon\": 0.05,\n    \"epsilon_decay_rate\": 0.9995\n  },\n  \"model_checkpointing\": {\n    \"checkpoint_interval\": 10,\n    \"save_best_only\": true,\n    \"checkpoint_dir\": \"models/checkpoints\"\n  },\n  \"logging\": {\n    \"log_interval\": 10,\n    \"log_dir\": \"logs/\",\n    \"tensorboard\": true,\n    \"tensorboard_log_dir\": \"logs/tensorboard_logs\",\n    \"model_save_path\": \"models/saved_models\"\n  },\n  \"advanced_training_techniques\": {\n    \"gradient_clipping\": 0.5,\n    \"use_gae\": true,\n    \"gae_lambda\": 0.95,\n    \"normalize_advantages\": true\n  },\n  \"early_stopping\": {\n    \"patience\": 10\n  },\n  \"reward_adjustments\": {\n    \"collision_penalty\": 50,\n    \"reward_threshold\": 250\n  },\n  \"shared_components\": {\n    \"residual_block\": {\n      \"input_dim\": 128,\n      \"hidden_dim\": 128,\n      \"dropout_rate\": 0.2\n    },\n    \"attention_layer\": {\n      \"input_dim\": 128,\n      \"hidden_dim\": 128\n    }\n  },\n  \"icm\": {\n    \"state_dim\": 16,\n    \"action_dim\": 4,\n    \"image_channels\": 3,\n    \"image_height\": 144,\n    \"image_width\": 256,\n    \"cnn\": {\n      \"conv1\": {\n        \"out_channels\": 32,\n        \"kernel_size\": 8,\n        \"stride\": 4\n      },\n      \"conv2\": {\n        \"out_channels\": 64,\n        \"kernel_size\": 4,\n        \"stride\": 2\n      },\n      \"conv3\": {\n        \"out_channels\": 64,\n        \"kernel_size\": 3,\n        \"stride\": 1\n      }\n    },\n    \"state_encoder\": {\n      \"hidden_dim\": 128\n    },\n    \"forward_model\": {\n      \"hidden_dim\": 256\n    },\n    \"inverse_model\": {\n      \"hidden_dim\": 256\n    }\n  },\n  \"predictive_model\": {\n    \"learning_rate\": 0.0001,\n    \"hidden_layers\": [\n      256,\n      256\n    ]\n  },\n  \"hrl\": {\n    \"use_hierarchical\": true,\n    \"high_level_policy\": {\n      \"input_size\": 16,\n      \"hidden_layers\": [\n        256,\n        256\n      ],\n      \"output_size\": 4\n    },\n    \"sub_goal_dim\": 3,\n    \"low_level_policy\": {\n      \"input_size\": 19,\n      \"hidden_layers\": [\n        256,\n        256\n      ],\n      \"output_size\": 4\n    }\n  },\n  \"curriculum_learning\": {\n    \"use_curriculum\": true,\n    \"initial_difficulty\": 1,\n    \"difficulty_increment\": 1,\n    \"difficulty_threshold\": 200\n  },\n  \"multi_agent\": {\n    \"use_multi_agent\": true,\n    \"num_agents\": 2,\n    \"hidden_layers\": [\n      256,\n      256\n    ]\n  }\n}"}
{"time": "2024-07-21T01:50:57.559305", "name": "AirSimEnvLogger", "level": "INFO", "message": "DataVisualizer initialized with Seaborn style set to 'whitegrid'."}
{"time": "2024-07-21T01:50:57.560301", "name": "AirSimEnvLogger", "level": "INFO", "message": "Using device: cpu"}
{"time": "2024-07-21T01:51:03.922463", "name": "AirSimEnvLogger", "level": "INFO", "message": "PPOAgent initialized successfully."}
{"time": "2024-07-21T01:51:03.951030", "name": "AirSimEnvLogger", "level": "INFO", "message": "Loading checkpoint from e:\\Project\\Drone\\models/checkpoints\\ppo_agent_checkpoint.pt"}
{"time": "2024-07-21T01:51:05.319736", "name": "AirSimEnvLogger", "level": "INFO", "message": "Model loaded successfully"}
{"time": "2024-07-21T01:51:07.430295", "name": "AirSimEnvLogger", "level": "INFO", "message": "Resuming training from epoch 1"}
{"time": "2024-07-21T01:51:11.742181", "name": "AirSimEnvLogger", "level": "INFO", "message": "Environment reset and takeoff completed."}
{"time": "2024-07-21T01:51:12.275131", "name": "AirSimEnvLogger", "level": "ERROR", "message": "An error occurred: float() argument must be a string or a number, not 'dict'"}
{"time": "2024-07-21T01:51:19.043303", "name": "AirSimEnvLogger", "level": "INFO", "message": "Environment closed."}
{"time": "2024-07-21T01:51:19.105703", "name": "AirSimEnvLogger", "level": "INFO", "message": "Training completed and models saved."}
{"time": "2024-07-21T01:54:37.293706", "name": "AirSimEnvLogger", "level": "INFO", "message": "Initialized with state_dim: 16, action_dim: 4"}
{"time": "2024-07-21T01:54:37.320320", "name": "AirSimEnvLogger", "level": "INFO", "message": "Initializing AirSimEnv"}
{"time": "2024-07-21T01:54:37.320320", "name": "AirSimEnvLogger", "level": "INFO", "message": "Configuration: {\n  \"learning_rate\": 0.0001,\n  \"gamma\": 0.99,\n  \"tau\": 0.95,\n  \"batch_size\": 64,\n  \"num_timesteps\": 2000000,\n  \"ppo\": {\n    \"learning_rate\": 0.0003,\n    \"n_steps\": 2048,\n    \"batch_size\": 64,\n    \"n_epochs\": 2000,\n    \"gamma\": 0.99,\n    \"gae_lambda\": 0.95,\n    \"clip_range\": 0.2,\n    \"ent_coef\": 0.01,\n    \"vf_coef\": 0.5,\n    \"max_grad_norm\": 0.5,\n    \"use_sde\": true,\n    \"sde_sample_freq\": 4,\n    \"tensorboard_log\": \"logs/tensorboard_logs/ppo_airsim_tensorboard/\",\n    \"verbose\": 1,\n    \"seed\": null,\n    \"device\": \"auto\",\n    \"continuous\": true,\n    \"save_freq\": 10000\n  },\n  \"environment\": {\n    \"env_name\": \"Africa_001\",\n    \"reward_threshold\": 250,\n    \"max_episode_steps\": 1000,\n    \"state_dim\": 16,\n    \"action_dim\": 4,\n    \"reward_scale\": 20,\n    \"proximity_threshold\": 5.0,\n    \"collision_penalty\": 25,\n    \"height_target\": -10,\n    \"height_tolerance\": 1.0,\n    \"height_penalty\": 1,\n    \"movement_penalty\": 0.1,\n    \"smoothness_penalty\": 0.1,\n    \"duration\": 0.1,\n    \"exploration_area\": {\n      \"x_min\": -1000,\n      \"x_max\": 1000,\n      \"y_min\": -1000,\n      \"y_max\": 1000,\n      \"z_min\": -100,\n      \"z_max\": 100\n    }\n  },\n  \"policy_network\": {\n    \"input_size\": 16,\n    \"hidden_layers\": [\n      256,\n      256\n    ],\n    \"output_size\": 4,\n    \"use_batch_norm\": true,\n    \"use_dropout\": true,\n    \"dropout_rate\": 0.2,\n    \"use_attention\": true,\n    \"num_action_heads\": 1\n  },\n  \"critic_network\": {\n    \"input_size\": 16,\n    \"hidden_layers\": [\n      256,\n      256\n    ],\n    \"output_size\": 1,\n    \"use_batch_norm\": true,\n    \"use_dropout\": true,\n    \"dropout_rate\": 0.2,\n    \"use_attention\": true\n  },\n  \"exploration\": {\n    \"strategy\": \"epsilon_decay\",\n    \"initial_epsilon\": 1.0,\n    \"min_epsilon\": 0.05,\n    \"epsilon_decay_rate\": 0.9995\n  },\n  \"model_checkpointing\": {\n    \"checkpoint_interval\": 10,\n    \"save_best_only\": true,\n    \"checkpoint_dir\": \"models/checkpoints\"\n  },\n  \"logging\": {\n    \"log_interval\": 10,\n    \"log_dir\": \"logs/\",\n    \"tensorboard\": true,\n    \"tensorboard_log_dir\": \"logs/tensorboard_logs\",\n    \"model_save_path\": \"models/saved_models\"\n  },\n  \"advanced_training_techniques\": {\n    \"gradient_clipping\": 0.5,\n    \"use_gae\": true,\n    \"gae_lambda\": 0.95,\n    \"normalize_advantages\": true\n  },\n  \"early_stopping\": {\n    \"patience\": 10\n  },\n  \"reward_adjustments\": {\n    \"collision_penalty\": 50,\n    \"reward_threshold\": 250\n  },\n  \"shared_components\": {\n    \"residual_block\": {\n      \"input_dim\": 128,\n      \"hidden_dim\": 128,\n      \"dropout_rate\": 0.2\n    },\n    \"attention_layer\": {\n      \"input_dim\": 128,\n      \"hidden_dim\": 128\n    }\n  },\n  \"icm\": {\n    \"state_dim\": 16,\n    \"action_dim\": 4,\n    \"image_channels\": 3,\n    \"image_height\": 144,\n    \"image_width\": 256,\n    \"cnn\": {\n      \"conv1\": {\n        \"out_channels\": 32,\n        \"kernel_size\": 8,\n        \"stride\": 4\n      },\n      \"conv2\": {\n        \"out_channels\": 64,\n        \"kernel_size\": 4,\n        \"stride\": 2\n      },\n      \"conv3\": {\n        \"out_channels\": 64,\n        \"kernel_size\": 3,\n        \"stride\": 1\n      }\n    },\n    \"state_encoder\": {\n      \"hidden_dim\": 128\n    },\n    \"forward_model\": {\n      \"hidden_dim\": 256\n    },\n    \"inverse_model\": {\n      \"hidden_dim\": 256\n    }\n  },\n  \"predictive_model\": {\n    \"learning_rate\": 0.0001,\n    \"hidden_layers\": [\n      256,\n      256\n    ]\n  },\n  \"hrl\": {\n    \"use_hierarchical\": true,\n    \"high_level_policy\": {\n      \"input_size\": 16,\n      \"hidden_layers\": [\n        256,\n        256\n      ],\n      \"output_size\": 4\n    },\n    \"sub_goal_dim\": 3,\n    \"low_level_policy\": {\n      \"input_size\": 19,\n      \"hidden_layers\": [\n        256,\n        256\n      ],\n      \"output_size\": 4\n    }\n  },\n  \"curriculum_learning\": {\n    \"use_curriculum\": true,\n    \"initial_difficulty\": 1,\n    \"difficulty_increment\": 1,\n    \"difficulty_threshold\": 200\n  },\n  \"multi_agent\": {\n    \"use_multi_agent\": true,\n    \"num_agents\": 2,\n    \"hidden_layers\": [\n      256,\n      256\n    ]\n  }\n}"}
{"time": "2024-07-21T01:54:38.757648", "name": "AirSimEnvLogger", "level": "INFO", "message": "DataVisualizer initialized with Seaborn style set to 'whitegrid'."}
{"time": "2024-07-21T01:54:38.758658", "name": "AirSimEnvLogger", "level": "INFO", "message": "Using device: cpu"}
{"time": "2024-07-21T01:55:04.232304", "name": "AirSimEnvLogger", "level": "INFO", "message": "PPOAgent initialized successfully."}
{"time": "2024-07-21T01:55:04.322922", "name": "AirSimEnvLogger", "level": "INFO", "message": "Loading checkpoint from e:\\Project\\Drone\\models/checkpoints\\ppo_agent_checkpoint.pt"}
{"time": "2024-07-21T01:55:05.745630", "name": "AirSimEnvLogger", "level": "INFO", "message": "Model loaded successfully"}
{"time": "2024-07-21T01:55:07.496567", "name": "AirSimEnvLogger", "level": "INFO", "message": "Resuming training from epoch 1"}
{"time": "2024-07-21T01:55:12.282907", "name": "AirSimEnvLogger", "level": "INFO", "message": "Environment reset and takeoff completed."}
{"time": "2024-07-21T01:55:12.860201", "name": "AirSimEnvLogger", "level": "ERROR", "message": "An error occurred: float() argument must be a string or a number, not 'dict'"}
{"time": "2024-07-21T01:55:19.110231", "name": "AirSimEnvLogger", "level": "INFO", "message": "Environment closed."}
{"time": "2024-07-21T01:55:19.172880", "name": "AirSimEnvLogger", "level": "INFO", "message": "Training completed and models saved."}
{"time": "2024-07-21T02:03:23.586040", "name": "AirSimEnvLogger", "level": "INFO", "message": "Initialized with state_dim: 16, action_dim: 4"}
{"time": "2024-07-21T02:03:23.607174", "name": "AirSimEnvLogger", "level": "INFO", "message": "Initializing AirSimEnv"}
{"time": "2024-07-21T02:03:23.608181", "name": "AirSimEnvLogger", "level": "INFO", "message": "Configuration: {\n  \"learning_rate\": 0.0001,\n  \"gamma\": 0.99,\n  \"tau\": 0.95,\n  \"batch_size\": 64,\n  \"num_timesteps\": 2000000,\n  \"ppo\": {\n    \"learning_rate\": 0.0003,\n    \"n_steps\": 2048,\n    \"batch_size\": 64,\n    \"n_epochs\": 2000,\n    \"gamma\": 0.99,\n    \"gae_lambda\": 0.95,\n    \"clip_range\": 0.2,\n    \"ent_coef\": 0.01,\n    \"vf_coef\": 0.5,\n    \"max_grad_norm\": 0.5,\n    \"use_sde\": true,\n    \"sde_sample_freq\": 4,\n    \"tensorboard_log\": \"logs/tensorboard_logs/ppo_airsim_tensorboard/\",\n    \"verbose\": 1,\n    \"seed\": null,\n    \"device\": \"auto\",\n    \"continuous\": true,\n    \"save_freq\": 10000\n  },\n  \"environment\": {\n    \"env_name\": \"Africa_001\",\n    \"reward_threshold\": 250,\n    \"max_episode_steps\": 1000,\n    \"state_dim\": 16,\n    \"action_dim\": 4,\n    \"reward_scale\": 20,\n    \"proximity_threshold\": 5.0,\n    \"collision_penalty\": 25,\n    \"height_target\": -10,\n    \"height_tolerance\": 1.0,\n    \"height_penalty\": 1,\n    \"movement_penalty\": 0.1,\n    \"smoothness_penalty\": 0.1,\n    \"duration\": 0.1,\n    \"exploration_area\": {\n      \"x_min\": -1000,\n      \"x_max\": 1000,\n      \"y_min\": -1000,\n      \"y_max\": 1000,\n      \"z_min\": -100,\n      \"z_max\": 100\n    }\n  },\n  \"policy_network\": {\n    \"input_size\": 16,\n    \"hidden_layers\": [\n      256,\n      256\n    ],\n    \"output_size\": 4,\n    \"use_batch_norm\": true,\n    \"use_dropout\": true,\n    \"dropout_rate\": 0.2,\n    \"use_attention\": true,\n    \"num_action_heads\": 1\n  },\n  \"critic_network\": {\n    \"input_size\": 16,\n    \"hidden_layers\": [\n      256,\n      256\n    ],\n    \"output_size\": 1,\n    \"use_batch_norm\": true,\n    \"use_dropout\": true,\n    \"dropout_rate\": 0.2,\n    \"use_attention\": true\n  },\n  \"exploration\": {\n    \"strategy\": \"epsilon_decay\",\n    \"initial_epsilon\": 1.0,\n    \"min_epsilon\": 0.05,\n    \"epsilon_decay_rate\": 0.9995\n  },\n  \"model_checkpointing\": {\n    \"checkpoint_interval\": 10,\n    \"save_best_only\": true,\n    \"checkpoint_dir\": \"models/checkpoints\"\n  },\n  \"logging\": {\n    \"log_interval\": 10,\n    \"log_dir\": \"logs/\",\n    \"tensorboard\": true,\n    \"tensorboard_log_dir\": \"logs/tensorboard_logs\",\n    \"model_save_path\": \"models/saved_models\"\n  },\n  \"advanced_training_techniques\": {\n    \"gradient_clipping\": 0.5,\n    \"use_gae\": true,\n    \"gae_lambda\": 0.95,\n    \"normalize_advantages\": true\n  },\n  \"early_stopping\": {\n    \"patience\": 10\n  },\n  \"reward_adjustments\": {\n    \"collision_penalty\": 50,\n    \"reward_threshold\": 250\n  },\n  \"shared_components\": {\n    \"residual_block\": {\n      \"input_dim\": 128,\n      \"hidden_dim\": 128,\n      \"dropout_rate\": 0.2\n    },\n    \"attention_layer\": {\n      \"input_dim\": 128,\n      \"hidden_dim\": 128\n    }\n  },\n  \"icm\": {\n    \"state_dim\": 16,\n    \"action_dim\": 4,\n    \"image_channels\": 3,\n    \"image_height\": 144,\n    \"image_width\": 256,\n    \"cnn\": {\n      \"conv1\": {\n        \"out_channels\": 32,\n        \"kernel_size\": 8,\n        \"stride\": 4\n      },\n      \"conv2\": {\n        \"out_channels\": 64,\n        \"kernel_size\": 4,\n        \"stride\": 2\n      },\n      \"conv3\": {\n        \"out_channels\": 64,\n        \"kernel_size\": 3,\n        \"stride\": 1\n      }\n    },\n    \"state_encoder\": {\n      \"hidden_dim\": 128\n    },\n    \"forward_model\": {\n      \"hidden_dim\": 256\n    },\n    \"inverse_model\": {\n      \"hidden_dim\": 256\n    }\n  },\n  \"predictive_model\": {\n    \"learning_rate\": 0.0001,\n    \"hidden_layers\": [\n      256,\n      256\n    ]\n  },\n  \"hrl\": {\n    \"use_hierarchical\": true,\n    \"high_level_policy\": {\n      \"input_size\": 16,\n      \"hidden_layers\": [\n        256,\n        256\n      ],\n      \"output_size\": 4\n    },\n    \"sub_goal_dim\": 3,\n    \"low_level_policy\": {\n      \"input_size\": 19,\n      \"hidden_layers\": [\n        256,\n        256\n      ],\n      \"output_size\": 4\n    }\n  },\n  \"curriculum_learning\": {\n    \"use_curriculum\": true,\n    \"initial_difficulty\": 1,\n    \"difficulty_increment\": 1,\n    \"difficulty_threshold\": 200\n  },\n  \"multi_agent\": {\n    \"use_multi_agent\": true,\n    \"num_agents\": 2,\n    \"hidden_layers\": [\n      256,\n      256\n    ]\n  }\n}"}
{"time": "2024-07-21T02:03:24.774003", "name": "AirSimEnvLogger", "level": "INFO", "message": "DataVisualizer initialized with Seaborn style set to 'whitegrid'."}
{"time": "2024-07-21T02:03:24.774003", "name": "AirSimEnvLogger", "level": "INFO", "message": "Using device: cpu"}
{"time": "2024-07-21T02:03:31.289266", "name": "AirSimEnvLogger", "level": "INFO", "message": "PPOAgent initialized successfully."}
{"time": "2024-07-21T02:03:31.352810", "name": "AirSimEnvLogger", "level": "INFO", "message": "Loading checkpoint from e:\\Project\\Drone\\models/checkpoints\\ppo_agent_checkpoint.pt"}
{"time": "2024-07-21T02:03:33.041427", "name": "AirSimEnvLogger", "level": "INFO", "message": "Model loaded successfully"}
{"time": "2024-07-21T02:03:35.281264", "name": "AirSimEnvLogger", "level": "INFO", "message": "Resuming training from epoch 1"}
{"time": "2024-07-21T02:03:40.609371", "name": "AirSimEnvLogger", "level": "INFO", "message": "Environment reset and takeoff completed."}
{"time": "2024-07-21T02:03:41.217940", "name": "AirSimEnvLogger", "level": "ERROR", "message": "Error in training loop: float() argument must be a string or a number, not 'dict'"}
{"time": "2024-07-21T02:03:41.217940", "name": "AirSimEnvLogger", "level": "ERROR", "message": "An error occurred: local variable 'observation' referenced before assignment"}
{"time": "2024-07-21T02:03:47.683875", "name": "AirSimEnvLogger", "level": "INFO", "message": "Environment closed."}
{"time": "2024-07-21T02:03:47.778740", "name": "AirSimEnvLogger", "level": "INFO", "message": "Training completed and models saved."}
{"time": "2024-07-21T02:07:50.211610", "name": "AirSimEnvLogger", "level": "INFO", "message": "Initialized with state_dim: 16, action_dim: 4"}
{"time": "2024-07-21T02:07:50.232970", "name": "AirSimEnvLogger", "level": "INFO", "message": "Initializing AirSimEnv"}
{"time": "2024-07-21T02:07:50.233968", "name": "AirSimEnvLogger", "level": "INFO", "message": "Configuration: {\n  \"learning_rate\": 0.0001,\n  \"gamma\": 0.99,\n  \"tau\": 0.95,\n  \"batch_size\": 64,\n  \"num_timesteps\": 2000000,\n  \"ppo\": {\n    \"learning_rate\": 0.0003,\n    \"n_steps\": 2048,\n    \"batch_size\": 64,\n    \"n_epochs\": 2000,\n    \"gamma\": 0.99,\n    \"gae_lambda\": 0.95,\n    \"clip_range\": 0.2,\n    \"ent_coef\": 0.01,\n    \"vf_coef\": 0.5,\n    \"max_grad_norm\": 0.5,\n    \"use_sde\": true,\n    \"sde_sample_freq\": 4,\n    \"tensorboard_log\": \"logs/tensorboard_logs/ppo_airsim_tensorboard/\",\n    \"verbose\": 1,\n    \"seed\": null,\n    \"device\": \"auto\",\n    \"continuous\": true,\n    \"save_freq\": 10000\n  },\n  \"environment\": {\n    \"env_name\": \"Africa_001\",\n    \"reward_threshold\": 250,\n    \"max_episode_steps\": 1000,\n    \"state_dim\": 16,\n    \"action_dim\": 4,\n    \"reward_scale\": 20,\n    \"proximity_threshold\": 5.0,\n    \"collision_penalty\": 25,\n    \"height_target\": -10,\n    \"height_tolerance\": 1.0,\n    \"height_penalty\": 1,\n    \"movement_penalty\": 0.1,\n    \"smoothness_penalty\": 0.1,\n    \"duration\": 0.1,\n    \"exploration_area\": {\n      \"x_min\": -1000,\n      \"x_max\": 1000,\n      \"y_min\": -1000,\n      \"y_max\": 1000,\n      \"z_min\": -100,\n      \"z_max\": 100\n    }\n  },\n  \"policy_network\": {\n    \"input_size\": 16,\n    \"hidden_layers\": [\n      256,\n      256\n    ],\n    \"output_size\": 4,\n    \"use_batch_norm\": true,\n    \"use_dropout\": true,\n    \"dropout_rate\": 0.2,\n    \"use_attention\": true,\n    \"num_action_heads\": 1\n  },\n  \"critic_network\": {\n    \"input_size\": 16,\n    \"hidden_layers\": [\n      256,\n      256\n    ],\n    \"output_size\": 1,\n    \"use_batch_norm\": true,\n    \"use_dropout\": true,\n    \"dropout_rate\": 0.2,\n    \"use_attention\": true\n  },\n  \"exploration\": {\n    \"strategy\": \"epsilon_decay\",\n    \"initial_epsilon\": 1.0,\n    \"min_epsilon\": 0.05,\n    \"epsilon_decay_rate\": 0.9995\n  },\n  \"model_checkpointing\": {\n    \"checkpoint_interval\": 10,\n    \"save_best_only\": true,\n    \"checkpoint_dir\": \"models/checkpoints\"\n  },\n  \"logging\": {\n    \"log_interval\": 10,\n    \"log_dir\": \"logs/\",\n    \"tensorboard\": true,\n    \"tensorboard_log_dir\": \"logs/tensorboard_logs\",\n    \"model_save_path\": \"models/saved_models\"\n  },\n  \"advanced_training_techniques\": {\n    \"gradient_clipping\": 0.5,\n    \"use_gae\": true,\n    \"gae_lambda\": 0.95,\n    \"normalize_advantages\": true\n  },\n  \"early_stopping\": {\n    \"patience\": 10\n  },\n  \"reward_adjustments\": {\n    \"collision_penalty\": 50,\n    \"reward_threshold\": 250\n  },\n  \"shared_components\": {\n    \"residual_block\": {\n      \"input_dim\": 128,\n      \"hidden_dim\": 128,\n      \"dropout_rate\": 0.2\n    },\n    \"attention_layer\": {\n      \"input_dim\": 128,\n      \"hidden_dim\": 128\n    }\n  },\n  \"icm\": {\n    \"state_dim\": 16,\n    \"action_dim\": 4,\n    \"image_channels\": 3,\n    \"image_height\": 144,\n    \"image_width\": 256,\n    \"cnn\": {\n      \"conv1\": {\n        \"out_channels\": 32,\n        \"kernel_size\": 8,\n        \"stride\": 4\n      },\n      \"conv2\": {\n        \"out_channels\": 64,\n        \"kernel_size\": 4,\n        \"stride\": 2\n      },\n      \"conv3\": {\n        \"out_channels\": 64,\n        \"kernel_size\": 3,\n        \"stride\": 1\n      }\n    },\n    \"state_encoder\": {\n      \"hidden_dim\": 128\n    },\n    \"forward_model\": {\n      \"hidden_dim\": 256\n    },\n    \"inverse_model\": {\n      \"hidden_dim\": 256\n    }\n  },\n  \"predictive_model\": {\n    \"learning_rate\": 0.0001,\n    \"hidden_layers\": [\n      256,\n      256\n    ]\n  },\n  \"hrl\": {\n    \"use_hierarchical\": true,\n    \"high_level_policy\": {\n      \"input_size\": 16,\n      \"hidden_layers\": [\n        256,\n        256\n      ],\n      \"output_size\": 4\n    },\n    \"sub_goal_dim\": 3,\n    \"low_level_policy\": {\n      \"input_size\": 19,\n      \"hidden_layers\": [\n        256,\n        256\n      ],\n      \"output_size\": 4\n    }\n  },\n  \"curriculum_learning\": {\n    \"use_curriculum\": true,\n    \"initial_difficulty\": 1,\n    \"difficulty_increment\": 1,\n    \"difficulty_threshold\": 200\n  },\n  \"multi_agent\": {\n    \"use_multi_agent\": true,\n    \"num_agents\": 2,\n    \"hidden_layers\": [\n      256,\n      256\n    ]\n  }\n}"}
{"time": "2024-07-21T02:07:51.402897", "name": "AirSimEnvLogger", "level": "INFO", "message": "DataVisualizer initialized with Seaborn style set to 'whitegrid'."}
{"time": "2024-07-21T02:07:51.403898", "name": "AirSimEnvLogger", "level": "INFO", "message": "Using device: cpu"}
{"time": "2024-07-21T02:07:58.207424", "name": "AirSimEnvLogger", "level": "INFO", "message": "PPOAgent initialized successfully."}
{"time": "2024-07-21T02:07:58.302025", "name": "AirSimEnvLogger", "level": "INFO", "message": "Loading checkpoint from e:\\Project\\Drone\\models/checkpoints\\ppo_agent_checkpoint.pt"}
{"time": "2024-07-21T02:07:59.831817", "name": "AirSimEnvLogger", "level": "INFO", "message": "Model loaded successfully"}
{"time": "2024-07-21T02:08:01.840808", "name": "AirSimEnvLogger", "level": "INFO", "message": "Resuming training from epoch 1"}
{"time": "2024-07-21T02:08:06.771037", "name": "AirSimEnvLogger", "level": "INFO", "message": "Environment reset and takeoff completed."}
{"time": "2024-07-21T02:08:07.352388", "name": "AirSimEnvLogger", "level": "INFO", "message": "Reset completed. Observation keys: dict_keys(['state', 'visual'])"}
{"time": "2024-07-21T02:08:07.352388", "name": "AirSimEnvLogger", "level": "INFO", "message": "State shape: (16,), Visual shape: (144, 256, 3)"}
{"time": "2024-07-21T02:08:07.352388", "name": "AirSimEnvLogger", "level": "ERROR", "message": "Error in training loop: float() argument must be a string or a number, not 'dict'"}
{"time": "2024-07-21T02:08:07.352388", "name": "AirSimEnvLogger", "level": "ERROR", "message": "Current epoch: 1"}
{"time": "2024-07-21T02:08:07.353388", "name": "AirSimEnvLogger", "level": "ERROR", "message": "An error occurred: local variable 'episode_steps' referenced before assignment"}
{"time": "2024-07-21T02:08:14.106564", "name": "AirSimEnvLogger", "level": "INFO", "message": "Environment closed."}
{"time": "2024-07-21T02:08:14.169461", "name": "AirSimEnvLogger", "level": "INFO", "message": "Training completed and models saved."}
{"time": "2024-07-21T02:10:27.692568", "name": "AirSimEnvLogger", "level": "INFO", "message": "Initialized with state_dim: 16, action_dim: 4"}
{"time": "2024-07-21T02:10:27.710611", "name": "AirSimEnvLogger", "level": "INFO", "message": "Initializing AirSimEnv"}
{"time": "2024-07-21T02:10:27.711611", "name": "AirSimEnvLogger", "level": "INFO", "message": "Configuration: {\n  \"learning_rate\": 0.0001,\n  \"gamma\": 0.99,\n  \"tau\": 0.95,\n  \"batch_size\": 64,\n  \"num_timesteps\": 2000000,\n  \"ppo\": {\n    \"learning_rate\": 0.0003,\n    \"n_steps\": 2048,\n    \"batch_size\": 64,\n    \"n_epochs\": 2000,\n    \"gamma\": 0.99,\n    \"gae_lambda\": 0.95,\n    \"clip_range\": 0.2,\n    \"ent_coef\": 0.01,\n    \"vf_coef\": 0.5,\n    \"max_grad_norm\": 0.5,\n    \"use_sde\": true,\n    \"sde_sample_freq\": 4,\n    \"tensorboard_log\": \"logs/tensorboard_logs/ppo_airsim_tensorboard/\",\n    \"verbose\": 1,\n    \"seed\": null,\n    \"device\": \"auto\",\n    \"continuous\": true,\n    \"save_freq\": 10000\n  },\n  \"environment\": {\n    \"env_name\": \"Africa_001\",\n    \"reward_threshold\": 250,\n    \"max_episode_steps\": 1000,\n    \"state_dim\": 16,\n    \"action_dim\": 4,\n    \"reward_scale\": 20,\n    \"proximity_threshold\": 5.0,\n    \"collision_penalty\": 25,\n    \"height_target\": -10,\n    \"height_tolerance\": 1.0,\n    \"height_penalty\": 1,\n    \"movement_penalty\": 0.1,\n    \"smoothness_penalty\": 0.1,\n    \"duration\": 0.1,\n    \"exploration_area\": {\n      \"x_min\": -1000,\n      \"x_max\": 1000,\n      \"y_min\": -1000,\n      \"y_max\": 1000,\n      \"z_min\": -100,\n      \"z_max\": 100\n    }\n  },\n  \"policy_network\": {\n    \"input_size\": 16,\n    \"hidden_layers\": [\n      256,\n      256\n    ],\n    \"output_size\": 4,\n    \"use_batch_norm\": true,\n    \"use_dropout\": true,\n    \"dropout_rate\": 0.2,\n    \"use_attention\": true,\n    \"num_action_heads\": 1\n  },\n  \"critic_network\": {\n    \"input_size\": 16,\n    \"hidden_layers\": [\n      256,\n      256\n    ],\n    \"output_size\": 1,\n    \"use_batch_norm\": true,\n    \"use_dropout\": true,\n    \"dropout_rate\": 0.2,\n    \"use_attention\": true\n  },\n  \"exploration\": {\n    \"strategy\": \"epsilon_decay\",\n    \"initial_epsilon\": 1.0,\n    \"min_epsilon\": 0.05,\n    \"epsilon_decay_rate\": 0.9995\n  },\n  \"model_checkpointing\": {\n    \"checkpoint_interval\": 10,\n    \"save_best_only\": true,\n    \"checkpoint_dir\": \"models/checkpoints\"\n  },\n  \"logging\": {\n    \"log_interval\": 10,\n    \"log_dir\": \"logs/\",\n    \"tensorboard\": true,\n    \"tensorboard_log_dir\": \"logs/tensorboard_logs\",\n    \"model_save_path\": \"models/saved_models\"\n  },\n  \"advanced_training_techniques\": {\n    \"gradient_clipping\": 0.5,\n    \"use_gae\": true,\n    \"gae_lambda\": 0.95,\n    \"normalize_advantages\": true\n  },\n  \"early_stopping\": {\n    \"patience\": 10\n  },\n  \"reward_adjustments\": {\n    \"collision_penalty\": 50,\n    \"reward_threshold\": 250\n  },\n  \"shared_components\": {\n    \"residual_block\": {\n      \"input_dim\": 128,\n      \"hidden_dim\": 128,\n      \"dropout_rate\": 0.2\n    },\n    \"attention_layer\": {\n      \"input_dim\": 128,\n      \"hidden_dim\": 128\n    }\n  },\n  \"icm\": {\n    \"state_dim\": 16,\n    \"action_dim\": 4,\n    \"image_channels\": 3,\n    \"image_height\": 144,\n    \"image_width\": 256,\n    \"cnn\": {\n      \"conv1\": {\n        \"out_channels\": 32,\n        \"kernel_size\": 8,\n        \"stride\": 4\n      },\n      \"conv2\": {\n        \"out_channels\": 64,\n        \"kernel_size\": 4,\n        \"stride\": 2\n      },\n      \"conv3\": {\n        \"out_channels\": 64,\n        \"kernel_size\": 3,\n        \"stride\": 1\n      }\n    },\n    \"state_encoder\": {\n      \"hidden_dim\": 128\n    },\n    \"forward_model\": {\n      \"hidden_dim\": 256\n    },\n    \"inverse_model\": {\n      \"hidden_dim\": 256\n    }\n  },\n  \"predictive_model\": {\n    \"learning_rate\": 0.0001,\n    \"hidden_layers\": [\n      256,\n      256\n    ]\n  },\n  \"hrl\": {\n    \"use_hierarchical\": true,\n    \"high_level_policy\": {\n      \"input_size\": 16,\n      \"hidden_layers\": [\n        256,\n        256\n      ],\n      \"output_size\": 4\n    },\n    \"sub_goal_dim\": 3,\n    \"low_level_policy\": {\n      \"input_size\": 19,\n      \"hidden_layers\": [\n        256,\n        256\n      ],\n      \"output_size\": 4\n    }\n  },\n  \"curriculum_learning\": {\n    \"use_curriculum\": true,\n    \"initial_difficulty\": 1,\n    \"difficulty_increment\": 1,\n    \"difficulty_threshold\": 200\n  },\n  \"multi_agent\": {\n    \"use_multi_agent\": true,\n    \"num_agents\": 2,\n    \"hidden_layers\": [\n      256,\n      256\n    ]\n  }\n}"}
{"time": "2024-07-21T02:10:28.741654", "name": "AirSimEnvLogger", "level": "INFO", "message": "DataVisualizer initialized with Seaborn style set to 'whitegrid'."}
{"time": "2024-07-21T02:10:28.742655", "name": "AirSimEnvLogger", "level": "INFO", "message": "Using device: cpu"}
{"time": "2024-07-21T02:10:35.298251", "name": "AirSimEnvLogger", "level": "INFO", "message": "PPOAgent initialized successfully."}
{"time": "2024-07-21T02:10:35.392492", "name": "AirSimEnvLogger", "level": "INFO", "message": "Loading checkpoint from e:\\Project\\Drone\\models/checkpoints\\ppo_agent_checkpoint.pt"}
{"time": "2024-07-21T02:10:36.948339", "name": "AirSimEnvLogger", "level": "INFO", "message": "Model loaded successfully"}
{"time": "2024-07-21T02:10:39.363339", "name": "AirSimEnvLogger", "level": "INFO", "message": "Resuming training from epoch 1"}
{"time": "2024-07-21T02:10:44.614523", "name": "AirSimEnvLogger", "level": "INFO", "message": "Environment reset and takeoff completed."}
{"time": "2024-07-21T02:10:45.255862", "name": "AirSimEnvLogger", "level": "INFO", "message": "Reset completed. Observation keys: dict_keys(['state', 'visual'])"}
{"time": "2024-07-21T02:10:45.255862", "name": "AirSimEnvLogger", "level": "INFO", "message": "State shape: (16,), Visual shape: (144, 256, 3)"}
{"time": "2024-07-21T02:10:45.255862", "name": "AirSimEnvLogger", "level": "ERROR", "message": "An error occurred: float() argument must be a string or a number, not 'dict'"}
{"time": "2024-07-21T02:10:51.454717", "name": "AirSimEnvLogger", "level": "INFO", "message": "Environment closed."}
{"time": "2024-07-21T02:10:51.517578", "name": "AirSimEnvLogger", "level": "INFO", "message": "Training completed and models saved."}
{"time": "2024-07-21T02:21:12.654632", "name": "AirSimEnvLogger", "level": "INFO", "message": "Initialized with state_dim: 16, action_dim: 4"}
{"time": "2024-07-21T02:21:12.689201", "name": "AirSimEnvLogger", "level": "INFO", "message": "Initializing AirSimEnv"}
{"time": "2024-07-21T02:21:12.689201", "name": "AirSimEnvLogger", "level": "INFO", "message": "Configuration: {\n  \"learning_rate\": 0.0001,\n  \"gamma\": 0.99,\n  \"tau\": 0.95,\n  \"batch_size\": 64,\n  \"num_timesteps\": 2000000,\n  \"ppo\": {\n    \"learning_rate\": 0.0003,\n    \"n_steps\": 2048,\n    \"batch_size\": 64,\n    \"n_epochs\": 2000,\n    \"gamma\": 0.99,\n    \"gae_lambda\": 0.95,\n    \"clip_range\": 0.2,\n    \"ent_coef\": 0.01,\n    \"vf_coef\": 0.5,\n    \"max_grad_norm\": 0.5,\n    \"use_sde\": true,\n    \"sde_sample_freq\": 4,\n    \"tensorboard_log\": \"logs/tensorboard_logs/ppo_airsim_tensorboard/\",\n    \"verbose\": 1,\n    \"seed\": null,\n    \"device\": \"auto\",\n    \"continuous\": true,\n    \"save_freq\": 10000\n  },\n  \"environment\": {\n    \"env_name\": \"Africa_001\",\n    \"reward_threshold\": 250,\n    \"max_episode_steps\": 1000,\n    \"state_dim\": 16,\n    \"action_dim\": 4,\n    \"reward_scale\": 20,\n    \"proximity_threshold\": 5.0,\n    \"collision_penalty\": 25,\n    \"height_target\": -10,\n    \"height_tolerance\": 1.0,\n    \"height_penalty\": 1,\n    \"movement_penalty\": 0.1,\n    \"smoothness_penalty\": 0.1,\n    \"duration\": 0.1,\n    \"exploration_area\": {\n      \"x_min\": -1000,\n      \"x_max\": 1000,\n      \"y_min\": -1000,\n      \"y_max\": 1000,\n      \"z_min\": -100,\n      \"z_max\": 100\n    }\n  },\n  \"policy_network\": {\n    \"input_size\": 16,\n    \"hidden_layers\": [\n      256,\n      256\n    ],\n    \"output_size\": 4,\n    \"use_batch_norm\": true,\n    \"use_dropout\": true,\n    \"dropout_rate\": 0.2,\n    \"use_attention\": true,\n    \"num_action_heads\": 1\n  },\n  \"critic_network\": {\n    \"input_size\": 16,\n    \"hidden_layers\": [\n      256,\n      256\n    ],\n    \"output_size\": 1,\n    \"use_batch_norm\": true,\n    \"use_dropout\": true,\n    \"dropout_rate\": 0.2,\n    \"use_attention\": true\n  },\n  \"exploration\": {\n    \"strategy\": \"epsilon_decay\",\n    \"initial_epsilon\": 1.0,\n    \"min_epsilon\": 0.05,\n    \"epsilon_decay_rate\": 0.9995\n  },\n  \"model_checkpointing\": {\n    \"checkpoint_interval\": 10,\n    \"save_best_only\": true,\n    \"checkpoint_dir\": \"models/checkpoints\"\n  },\n  \"logging\": {\n    \"log_interval\": 10,\n    \"log_dir\": \"logs/\",\n    \"tensorboard\": true,\n    \"tensorboard_log_dir\": \"logs/tensorboard_logs\",\n    \"model_save_path\": \"models/saved_models\"\n  },\n  \"advanced_training_techniques\": {\n    \"gradient_clipping\": 0.5,\n    \"use_gae\": true,\n    \"gae_lambda\": 0.95,\n    \"normalize_advantages\": true\n  },\n  \"early_stopping\": {\n    \"patience\": 10\n  },\n  \"reward_adjustments\": {\n    \"collision_penalty\": 50,\n    \"reward_threshold\": 250\n  },\n  \"shared_components\": {\n    \"residual_block\": {\n      \"input_dim\": 128,\n      \"hidden_dim\": 128,\n      \"dropout_rate\": 0.2\n    },\n    \"attention_layer\": {\n      \"input_dim\": 128,\n      \"hidden_dim\": 128\n    }\n  },\n  \"icm\": {\n    \"state_dim\": 16,\n    \"action_dim\": 4,\n    \"image_channels\": 3,\n    \"image_height\": 144,\n    \"image_width\": 256,\n    \"cnn\": {\n      \"conv1\": {\n        \"out_channels\": 32,\n        \"kernel_size\": 8,\n        \"stride\": 4\n      },\n      \"conv2\": {\n        \"out_channels\": 64,\n        \"kernel_size\": 4,\n        \"stride\": 2\n      },\n      \"conv3\": {\n        \"out_channels\": 64,\n        \"kernel_size\": 3,\n        \"stride\": 1\n      }\n    },\n    \"state_encoder\": {\n      \"hidden_dim\": 128\n    },\n    \"forward_model\": {\n      \"hidden_dim\": 256\n    },\n    \"inverse_model\": {\n      \"hidden_dim\": 256\n    }\n  },\n  \"predictive_model\": {\n    \"learning_rate\": 0.0001,\n    \"hidden_layers\": [\n      256,\n      256\n    ]\n  },\n  \"hrl\": {\n    \"use_hierarchical\": true,\n    \"high_level_policy\": {\n      \"input_size\": 16,\n      \"hidden_layers\": [\n        256,\n        256\n      ],\n      \"output_size\": 4\n    },\n    \"sub_goal_dim\": 3,\n    \"low_level_policy\": {\n      \"input_size\": 19,\n      \"hidden_layers\": [\n        256,\n        256\n      ],\n      \"output_size\": 4\n    }\n  },\n  \"curriculum_learning\": {\n    \"use_curriculum\": true,\n    \"initial_difficulty\": 1,\n    \"difficulty_increment\": 1,\n    \"difficulty_threshold\": 200\n  },\n  \"multi_agent\": {\n    \"use_multi_agent\": true,\n    \"num_agents\": 2,\n    \"hidden_layers\": [\n      256,\n      256\n    ]\n  }\n}"}
{"time": "2024-07-21T02:21:13.790786", "name": "AirSimEnvLogger", "level": "INFO", "message": "DataVisualizer initialized with Seaborn style set to 'whitegrid'."}
{"time": "2024-07-21T02:21:13.790786", "name": "AirSimEnvLogger", "level": "INFO", "message": "Using device: cpu"}
{"time": "2024-07-21T02:21:19.878276", "name": "AirSimEnvLogger", "level": "INFO", "message": "PPOAgent initialized successfully."}
{"time": "2024-07-21T02:21:19.957175", "name": "AirSimEnvLogger", "level": "INFO", "message": "Loading checkpoint from e:\\Project\\Drone\\models/checkpoints\\ppo_agent_checkpoint.pt"}
{"time": "2024-07-21T02:21:21.435880", "name": "AirSimEnvLogger", "level": "INFO", "message": "Model loaded successfully"}
{"time": "2024-07-21T02:21:23.888821", "name": "AirSimEnvLogger", "level": "INFO", "message": "Resuming training from epoch 1"}
{"time": "2024-07-21T02:21:28.274125", "name": "AirSimEnvLogger", "level": "INFO", "message": "Environment reset and takeoff completed."}
{"time": "2024-07-21T02:21:28.918222", "name": "AirSimEnvLogger", "level": "INFO", "message": "Reset completed. Observation keys: dict_keys(['state', 'visual'])"}
{"time": "2024-07-21T02:21:28.918222", "name": "AirSimEnvLogger", "level": "INFO", "message": "State shape: (16,), Visual shape: (144, 256, 3)"}
{"time": "2024-07-21T02:21:28.918222", "name": "AirSimEnvLogger", "level": "ERROR", "message": "An error occurred: float() argument must be a string or a number, not 'dict'"}
{"time": "2024-07-21T02:21:35.195924", "name": "AirSimEnvLogger", "level": "INFO", "message": "Environment closed."}
{"time": "2024-07-21T02:21:35.259102", "name": "AirSimEnvLogger", "level": "INFO", "message": "Training completed and models saved."}
{"time": "2024-07-21T02:28:09.103552", "name": "AirSimEnvLogger", "level": "INFO", "message": "Initialized with state_dim: 16, action_dim: 4"}
{"time": "2024-07-21T02:28:09.121597", "name": "AirSimEnvLogger", "level": "INFO", "message": "Initializing AirSimEnv"}
{"time": "2024-07-21T02:28:09.122605", "name": "AirSimEnvLogger", "level": "INFO", "message": "Configuration: {\n  \"learning_rate\": 0.0001,\n  \"gamma\": 0.99,\n  \"tau\": 0.95,\n  \"batch_size\": 64,\n  \"num_timesteps\": 2000000,\n  \"ppo\": {\n    \"learning_rate\": 0.0003,\n    \"n_steps\": 2048,\n    \"batch_size\": 64,\n    \"n_epochs\": 2000,\n    \"gamma\": 0.99,\n    \"gae_lambda\": 0.95,\n    \"clip_range\": 0.2,\n    \"ent_coef\": 0.01,\n    \"vf_coef\": 0.5,\n    \"max_grad_norm\": 0.5,\n    \"use_sde\": true,\n    \"sde_sample_freq\": 4,\n    \"tensorboard_log\": \"logs/tensorboard_logs/ppo_airsim_tensorboard/\",\n    \"verbose\": 1,\n    \"seed\": null,\n    \"device\": \"auto\",\n    \"continuous\": true,\n    \"save_freq\": 10000\n  },\n  \"environment\": {\n    \"env_name\": \"Africa_001\",\n    \"reward_threshold\": 250,\n    \"max_episode_steps\": 1000,\n    \"state_dim\": 16,\n    \"action_dim\": 4,\n    \"reward_scale\": 20,\n    \"proximity_threshold\": 5.0,\n    \"collision_penalty\": 25,\n    \"height_target\": -10,\n    \"height_tolerance\": 1.0,\n    \"height_penalty\": 1,\n    \"movement_penalty\": 0.1,\n    \"smoothness_penalty\": 0.1,\n    \"duration\": 0.1,\n    \"exploration_area\": {\n      \"x_min\": -1000,\n      \"x_max\": 1000,\n      \"y_min\": -1000,\n      \"y_max\": 1000,\n      \"z_min\": -100,\n      \"z_max\": 100\n    }\n  },\n  \"policy_network\": {\n    \"input_size\": 16,\n    \"hidden_layers\": [\n      256,\n      256\n    ],\n    \"output_size\": 4,\n    \"use_batch_norm\": true,\n    \"use_dropout\": true,\n    \"dropout_rate\": 0.2,\n    \"use_attention\": true,\n    \"num_action_heads\": 1\n  },\n  \"critic_network\": {\n    \"input_size\": 16,\n    \"hidden_layers\": [\n      256,\n      256\n    ],\n    \"output_size\": 1,\n    \"use_batch_norm\": true,\n    \"use_dropout\": true,\n    \"dropout_rate\": 0.2,\n    \"use_attention\": true\n  },\n  \"exploration\": {\n    \"strategy\": \"epsilon_decay\",\n    \"initial_epsilon\": 1.0,\n    \"min_epsilon\": 0.05,\n    \"epsilon_decay_rate\": 0.9995\n  },\n  \"model_checkpointing\": {\n    \"checkpoint_interval\": 10,\n    \"save_best_only\": true,\n    \"checkpoint_dir\": \"models/checkpoints\"\n  },\n  \"logging\": {\n    \"log_interval\": 10,\n    \"log_dir\": \"logs/\",\n    \"tensorboard\": true,\n    \"tensorboard_log_dir\": \"logs/tensorboard_logs\",\n    \"model_save_path\": \"models/saved_models\"\n  },\n  \"advanced_training_techniques\": {\n    \"gradient_clipping\": 0.5,\n    \"use_gae\": true,\n    \"gae_lambda\": 0.95,\n    \"normalize_advantages\": true\n  },\n  \"early_stopping\": {\n    \"patience\": 10\n  },\n  \"reward_adjustments\": {\n    \"collision_penalty\": 50,\n    \"reward_threshold\": 250\n  },\n  \"shared_components\": {\n    \"residual_block\": {\n      \"input_dim\": 128,\n      \"hidden_dim\": 128,\n      \"dropout_rate\": 0.2\n    },\n    \"attention_layer\": {\n      \"input_dim\": 128,\n      \"hidden_dim\": 128\n    }\n  },\n  \"icm\": {\n    \"state_dim\": 16,\n    \"action_dim\": 4,\n    \"image_channels\": 3,\n    \"image_height\": 144,\n    \"image_width\": 256,\n    \"cnn\": {\n      \"conv1\": {\n        \"out_channels\": 32,\n        \"kernel_size\": 8,\n        \"stride\": 4\n      },\n      \"conv2\": {\n        \"out_channels\": 64,\n        \"kernel_size\": 4,\n        \"stride\": 2\n      },\n      \"conv3\": {\n        \"out_channels\": 64,\n        \"kernel_size\": 3,\n        \"stride\": 1\n      }\n    },\n    \"state_encoder\": {\n      \"hidden_dim\": 128\n    },\n    \"forward_model\": {\n      \"hidden_dim\": 256\n    },\n    \"inverse_model\": {\n      \"hidden_dim\": 256\n    }\n  },\n  \"predictive_model\": {\n    \"learning_rate\": 0.0001,\n    \"hidden_layers\": [\n      256,\n      256\n    ]\n  },\n  \"hrl\": {\n    \"use_hierarchical\": true,\n    \"high_level_policy\": {\n      \"input_size\": 16,\n      \"hidden_layers\": [\n        256,\n        256\n      ],\n      \"output_size\": 4\n    },\n    \"sub_goal_dim\": 3,\n    \"low_level_policy\": {\n      \"input_size\": 19,\n      \"hidden_layers\": [\n        256,\n        256\n      ],\n      \"output_size\": 4\n    }\n  },\n  \"curriculum_learning\": {\n    \"use_curriculum\": true,\n    \"initial_difficulty\": 1,\n    \"difficulty_increment\": 1,\n    \"difficulty_threshold\": 200\n  },\n  \"multi_agent\": {\n    \"use_multi_agent\": true,\n    \"num_agents\": 2,\n    \"hidden_layers\": [\n      256,\n      256\n    ]\n  }\n}"}
{"time": "2024-07-21T02:28:10.422410", "name": "AirSimEnvLogger", "level": "INFO", "message": "DataVisualizer initialized with Seaborn style set to 'whitegrid'."}
{"time": "2024-07-21T02:28:10.423417", "name": "AirSimEnvLogger", "level": "INFO", "message": "Using device: cpu"}
{"time": "2024-07-21T02:28:17.156760", "name": "AirSimEnvLogger", "level": "INFO", "message": "PPOAgent initialized successfully."}
{"time": "2024-07-21T02:28:17.259095", "name": "AirSimEnvLogger", "level": "INFO", "message": "Loading checkpoint from e:\\Project\\Drone\\models/checkpoints\\ppo_agent_checkpoint.pt"}
{"time": "2024-07-21T02:28:18.947497", "name": "AirSimEnvLogger", "level": "INFO", "message": "Model loaded successfully"}
{"time": "2024-07-21T02:28:21.436281", "name": "AirSimEnvLogger", "level": "INFO", "message": "Resuming training from epoch 1"}
{"time": "2024-07-21T02:28:25.943510", "name": "AirSimEnvLogger", "level": "INFO", "message": "Environment reset and takeoff completed."}
{"time": "2024-07-21T02:28:26.474034", "name": "AirSimEnvLogger", "level": "INFO", "message": "Reset completed. Observation keys: dict_keys(['state', 'visual'])"}
{"time": "2024-07-21T02:28:26.474034", "name": "AirSimEnvLogger", "level": "INFO", "message": "State shape: (16,), Visual shape: (144, 256, 3)"}
{"time": "2024-07-21T02:28:26.475034", "name": "AirSimEnvLogger", "level": "ERROR", "message": "An error occurred: float() argument must be a string or a number, not 'dict'"}
{"time": "2024-07-21T02:28:32.895657", "name": "AirSimEnvLogger", "level": "INFO", "message": "Environment closed."}
{"time": "2024-07-21T02:28:33.022146", "name": "AirSimEnvLogger", "level": "INFO", "message": "Training completed and models saved."}
{"time": "2024-07-21T02:32:03.725747", "name": "AirSimEnvLogger", "level": "INFO", "message": "Initialized with state_dim: 16, action_dim: 4"}
{"time": "2024-07-21T02:32:03.743798", "name": "AirSimEnvLogger", "level": "INFO", "message": "Initializing AirSimEnv"}
{"time": "2024-07-21T02:32:03.744798", "name": "AirSimEnvLogger", "level": "INFO", "message": "Configuration: {\n  \"learning_rate\": 0.0001,\n  \"gamma\": 0.99,\n  \"tau\": 0.95,\n  \"batch_size\": 64,\n  \"num_timesteps\": 2000000,\n  \"ppo\": {\n    \"learning_rate\": 0.0003,\n    \"n_steps\": 2048,\n    \"batch_size\": 64,\n    \"n_epochs\": 2000,\n    \"gamma\": 0.99,\n    \"gae_lambda\": 0.95,\n    \"clip_range\": 0.2,\n    \"ent_coef\": 0.01,\n    \"vf_coef\": 0.5,\n    \"max_grad_norm\": 0.5,\n    \"use_sde\": true,\n    \"sde_sample_freq\": 4,\n    \"tensorboard_log\": \"logs/tensorboard_logs/ppo_airsim_tensorboard/\",\n    \"verbose\": 1,\n    \"seed\": null,\n    \"device\": \"auto\",\n    \"continuous\": true,\n    \"save_freq\": 10000\n  },\n  \"environment\": {\n    \"env_name\": \"Africa_001\",\n    \"reward_threshold\": 250,\n    \"max_episode_steps\": 1000,\n    \"state_dim\": 16,\n    \"action_dim\": 4,\n    \"reward_scale\": 20,\n    \"proximity_threshold\": 5.0,\n    \"collision_penalty\": 25,\n    \"height_target\": -10,\n    \"height_tolerance\": 1.0,\n    \"height_penalty\": 1,\n    \"movement_penalty\": 0.1,\n    \"smoothness_penalty\": 0.1,\n    \"duration\": 0.1,\n    \"exploration_area\": {\n      \"x_min\": -1000,\n      \"x_max\": 1000,\n      \"y_min\": -1000,\n      \"y_max\": 1000,\n      \"z_min\": -100,\n      \"z_max\": 100\n    }\n  },\n  \"policy_network\": {\n    \"input_size\": 16,\n    \"hidden_layers\": [\n      256,\n      256\n    ],\n    \"output_size\": 4,\n    \"use_batch_norm\": true,\n    \"use_dropout\": true,\n    \"dropout_rate\": 0.2,\n    \"use_attention\": true,\n    \"num_action_heads\": 1\n  },\n  \"critic_network\": {\n    \"input_size\": 16,\n    \"hidden_layers\": [\n      256,\n      256\n    ],\n    \"output_size\": 1,\n    \"use_batch_norm\": true,\n    \"use_dropout\": true,\n    \"dropout_rate\": 0.2,\n    \"use_attention\": true\n  },\n  \"exploration\": {\n    \"strategy\": \"epsilon_decay\",\n    \"initial_epsilon\": 1.0,\n    \"min_epsilon\": 0.05,\n    \"epsilon_decay_rate\": 0.9995\n  },\n  \"model_checkpointing\": {\n    \"checkpoint_interval\": 10,\n    \"save_best_only\": true,\n    \"checkpoint_dir\": \"models/checkpoints\"\n  },\n  \"logging\": {\n    \"log_interval\": 10,\n    \"log_dir\": \"logs/\",\n    \"tensorboard\": true,\n    \"tensorboard_log_dir\": \"logs/tensorboard_logs\",\n    \"model_save_path\": \"models/saved_models\"\n  },\n  \"advanced_training_techniques\": {\n    \"gradient_clipping\": 0.5,\n    \"use_gae\": true,\n    \"gae_lambda\": 0.95,\n    \"normalize_advantages\": true\n  },\n  \"early_stopping\": {\n    \"patience\": 10\n  },\n  \"reward_adjustments\": {\n    \"collision_penalty\": 50,\n    \"reward_threshold\": 250\n  },\n  \"shared_components\": {\n    \"residual_block\": {\n      \"input_dim\": 128,\n      \"hidden_dim\": 128,\n      \"dropout_rate\": 0.2\n    },\n    \"attention_layer\": {\n      \"input_dim\": 128,\n      \"hidden_dim\": 128\n    }\n  },\n  \"icm\": {\n    \"state_dim\": 16,\n    \"action_dim\": 4,\n    \"image_channels\": 3,\n    \"image_height\": 144,\n    \"image_width\": 256,\n    \"cnn\": {\n      \"conv1\": {\n        \"out_channels\": 32,\n        \"kernel_size\": 8,\n        \"stride\": 4\n      },\n      \"conv2\": {\n        \"out_channels\": 64,\n        \"kernel_size\": 4,\n        \"stride\": 2\n      },\n      \"conv3\": {\n        \"out_channels\": 64,\n        \"kernel_size\": 3,\n        \"stride\": 1\n      }\n    },\n    \"state_encoder\": {\n      \"hidden_dim\": 128\n    },\n    \"forward_model\": {\n      \"hidden_dim\": 256\n    },\n    \"inverse_model\": {\n      \"hidden_dim\": 256\n    }\n  },\n  \"predictive_model\": {\n    \"learning_rate\": 0.0001,\n    \"hidden_layers\": [\n      256,\n      256\n    ]\n  },\n  \"hrl\": {\n    \"use_hierarchical\": true,\n    \"high_level_policy\": {\n      \"input_size\": 16,\n      \"hidden_layers\": [\n        256,\n        256\n      ],\n      \"output_size\": 4\n    },\n    \"sub_goal_dim\": 3,\n    \"low_level_policy\": {\n      \"input_size\": 19,\n      \"hidden_layers\": [\n        256,\n        256\n      ],\n      \"output_size\": 4\n    }\n  },\n  \"curriculum_learning\": {\n    \"use_curriculum\": true,\n    \"initial_difficulty\": 1,\n    \"difficulty_increment\": 1,\n    \"difficulty_threshold\": 200\n  },\n  \"multi_agent\": {\n    \"use_multi_agent\": true,\n    \"num_agents\": 2,\n    \"hidden_layers\": [\n      256,\n      256\n    ]\n  }\n}"}
{"time": "2024-07-21T02:32:04.843273", "name": "AirSimEnvLogger", "level": "INFO", "message": "DataVisualizer initialized with Seaborn style set to 'whitegrid'."}
{"time": "2024-07-21T02:32:04.844718", "name": "AirSimEnvLogger", "level": "INFO", "message": "Using device: cpu"}
{"time": "2024-07-21T02:32:11.243714", "name": "AirSimEnvLogger", "level": "INFO", "message": "PPOAgent initialized successfully."}
{"time": "2024-07-21T02:32:11.244714", "name": "AirSimEnvLogger", "level": "ERROR", "message": "An error occurred: train_agents() takes 4 positional arguments but 5 were given"}
{"time": "2024-07-21T02:32:12.043521", "name": "AirSimEnvLogger", "level": "INFO", "message": "Environment closed."}
{"time": "2024-07-21T02:32:12.152319", "name": "AirSimEnvLogger", "level": "INFO", "message": "Training completed and models saved."}
{"time": "2024-07-21T02:37:34.633922", "name": "AirSimEnvLogger", "level": "INFO", "message": "Initialized with state_dim: 16, action_dim: 4"}
{"time": "2024-07-21T02:37:34.650973", "name": "AirSimEnvLogger", "level": "INFO", "message": "Initializing AirSimEnv"}
{"time": "2024-07-21T02:37:34.650973", "name": "AirSimEnvLogger", "level": "INFO", "message": "Configuration: {\n  \"learning_rate\": 0.0001,\n  \"gamma\": 0.99,\n  \"tau\": 0.95,\n  \"batch_size\": 64,\n  \"num_timesteps\": 2000000,\n  \"ppo\": {\n    \"learning_rate\": 0.0003,\n    \"n_steps\": 2048,\n    \"batch_size\": 64,\n    \"n_epochs\": 2000,\n    \"gamma\": 0.99,\n    \"gae_lambda\": 0.95,\n    \"clip_range\": 0.2,\n    \"ent_coef\": 0.01,\n    \"vf_coef\": 0.5,\n    \"max_grad_norm\": 0.5,\n    \"use_sde\": true,\n    \"sde_sample_freq\": 4,\n    \"tensorboard_log\": \"logs/tensorboard_logs/ppo_airsim_tensorboard/\",\n    \"verbose\": 1,\n    \"seed\": null,\n    \"device\": \"auto\",\n    \"continuous\": true,\n    \"save_freq\": 10000\n  },\n  \"environment\": {\n    \"env_name\": \"Africa_001\",\n    \"reward_threshold\": 250,\n    \"max_episode_steps\": 1000,\n    \"state_dim\": 16,\n    \"action_dim\": 4,\n    \"reward_scale\": 20,\n    \"proximity_threshold\": 5.0,\n    \"collision_penalty\": 25,\n    \"height_target\": -10,\n    \"height_tolerance\": 1.0,\n    \"height_penalty\": 1,\n    \"movement_penalty\": 0.1,\n    \"smoothness_penalty\": 0.1,\n    \"duration\": 0.1,\n    \"exploration_area\": {\n      \"x_min\": -1000,\n      \"x_max\": 1000,\n      \"y_min\": -1000,\n      \"y_max\": 1000,\n      \"z_min\": -100,\n      \"z_max\": 100\n    }\n  },\n  \"policy_network\": {\n    \"input_size\": 16,\n    \"hidden_layers\": [\n      256,\n      256\n    ],\n    \"output_size\": 4,\n    \"use_batch_norm\": true,\n    \"use_dropout\": true,\n    \"dropout_rate\": 0.2,\n    \"use_attention\": true,\n    \"num_action_heads\": 1\n  },\n  \"critic_network\": {\n    \"input_size\": 16,\n    \"hidden_layers\": [\n      256,\n      256\n    ],\n    \"output_size\": 1,\n    \"use_batch_norm\": true,\n    \"use_dropout\": true,\n    \"dropout_rate\": 0.2,\n    \"use_attention\": true\n  },\n  \"exploration\": {\n    \"strategy\": \"epsilon_decay\",\n    \"initial_epsilon\": 1.0,\n    \"min_epsilon\": 0.05,\n    \"epsilon_decay_rate\": 0.9995\n  },\n  \"model_checkpointing\": {\n    \"checkpoint_interval\": 10,\n    \"save_best_only\": true,\n    \"checkpoint_dir\": \"models/checkpoints\"\n  },\n  \"logging\": {\n    \"log_interval\": 10,\n    \"log_dir\": \"logs/\",\n    \"tensorboard\": true,\n    \"tensorboard_log_dir\": \"logs/tensorboard_logs\",\n    \"model_save_path\": \"models/saved_models\"\n  },\n  \"advanced_training_techniques\": {\n    \"gradient_clipping\": 0.5,\n    \"use_gae\": true,\n    \"gae_lambda\": 0.95,\n    \"normalize_advantages\": true\n  },\n  \"early_stopping\": {\n    \"patience\": 10\n  },\n  \"reward_adjustments\": {\n    \"collision_penalty\": 50,\n    \"reward_threshold\": 250\n  },\n  \"shared_components\": {\n    \"residual_block\": {\n      \"input_dim\": 128,\n      \"hidden_dim\": 128,\n      \"dropout_rate\": 0.2\n    },\n    \"attention_layer\": {\n      \"input_dim\": 128,\n      \"hidden_dim\": 128\n    }\n  },\n  \"icm\": {\n    \"state_dim\": 16,\n    \"action_dim\": 4,\n    \"image_channels\": 3,\n    \"image_height\": 144,\n    \"image_width\": 256,\n    \"cnn\": {\n      \"conv1\": {\n        \"out_channels\": 32,\n        \"kernel_size\": 8,\n        \"stride\": 4\n      },\n      \"conv2\": {\n        \"out_channels\": 64,\n        \"kernel_size\": 4,\n        \"stride\": 2\n      },\n      \"conv3\": {\n        \"out_channels\": 64,\n        \"kernel_size\": 3,\n        \"stride\": 1\n      }\n    },\n    \"state_encoder\": {\n      \"hidden_dim\": 128\n    },\n    \"forward_model\": {\n      \"hidden_dim\": 256\n    },\n    \"inverse_model\": {\n      \"hidden_dim\": 256\n    }\n  },\n  \"predictive_model\": {\n    \"learning_rate\": 0.0001,\n    \"hidden_layers\": [\n      256,\n      256\n    ]\n  },\n  \"hrl\": {\n    \"use_hierarchical\": true,\n    \"high_level_policy\": {\n      \"input_size\": 16,\n      \"hidden_layers\": [\n        256,\n        256\n      ],\n      \"output_size\": 4\n    },\n    \"sub_goal_dim\": 3,\n    \"low_level_policy\": {\n      \"input_size\": 19,\n      \"hidden_layers\": [\n        256,\n        256\n      ],\n      \"output_size\": 4\n    }\n  },\n  \"curriculum_learning\": {\n    \"use_curriculum\": true,\n    \"initial_difficulty\": 1,\n    \"difficulty_increment\": 1,\n    \"difficulty_threshold\": 200\n  },\n  \"multi_agent\": {\n    \"use_multi_agent\": true,\n    \"num_agents\": 2,\n    \"hidden_layers\": [\n      256,\n      256\n    ]\n  }\n}"}
{"time": "2024-07-21T02:37:35.830627", "name": "AirSimEnvLogger", "level": "INFO", "message": "DataVisualizer initialized with Seaborn style set to 'whitegrid'."}
{"time": "2024-07-21T02:37:35.832629", "name": "AirSimEnvLogger", "level": "INFO", "message": "Using device: cpu"}
{"time": "2024-07-21T02:37:42.131899", "name": "AirSimEnvLogger", "level": "INFO", "message": "PPOAgent initialized successfully."}
{"time": "2024-07-21T02:37:47.319782", "name": "AirSimEnvLogger", "level": "INFO", "message": "Environment reset and takeoff completed."}
{"time": "2024-07-21T02:37:47.902124", "name": "AirSimEnvLogger", "level": "INFO", "message": "Reset completed. Observation keys: dict_keys(['state', 'visual'])"}
{"time": "2024-07-21T02:37:47.902124", "name": "AirSimEnvLogger", "level": "INFO", "message": "State shape: (16,), Visual shape: (144, 256, 3)"}
{"time": "2024-07-21T02:37:47.903122", "name": "AirSimEnvLogger", "level": "ERROR", "message": "An error occurred: float() argument must be a string or a number, not 'dict'"}
{"time": "2024-07-21T02:37:53.603036", "name": "AirSimEnvLogger", "level": "INFO", "message": "Environment closed."}
{"time": "2024-07-21T02:37:53.667393", "name": "AirSimEnvLogger", "level": "INFO", "message": "Training completed and models saved."}
{"time": "2024-07-21T02:40:37.945827", "name": "AirSimEnvLogger", "level": "INFO", "message": "Initialized with state_dim: 16, action_dim: 4"}
{"time": "2024-07-21T02:40:37.967368", "name": "AirSimEnvLogger", "level": "INFO", "message": "Initializing AirSimEnv"}
{"time": "2024-07-21T02:40:37.967368", "name": "AirSimEnvLogger", "level": "INFO", "message": "Configuration: {\n  \"learning_rate\": 0.0001,\n  \"gamma\": 0.99,\n  \"tau\": 0.95,\n  \"batch_size\": 64,\n  \"num_timesteps\": 2000000,\n  \"ppo\": {\n    \"learning_rate\": 0.0003,\n    \"n_steps\": 2048,\n    \"batch_size\": 64,\n    \"n_epochs\": 2000,\n    \"gamma\": 0.99,\n    \"gae_lambda\": 0.95,\n    \"clip_range\": 0.2,\n    \"ent_coef\": 0.01,\n    \"vf_coef\": 0.5,\n    \"max_grad_norm\": 0.5,\n    \"use_sde\": true,\n    \"sde_sample_freq\": 4,\n    \"tensorboard_log\": \"logs/tensorboard_logs/ppo_airsim_tensorboard/\",\n    \"verbose\": 1,\n    \"seed\": null,\n    \"device\": \"auto\",\n    \"continuous\": true,\n    \"save_freq\": 10000\n  },\n  \"environment\": {\n    \"env_name\": \"Africa_001\",\n    \"reward_threshold\": 250,\n    \"max_episode_steps\": 1000,\n    \"state_dim\": 16,\n    \"action_dim\": 4,\n    \"reward_scale\": 20,\n    \"proximity_threshold\": 5.0,\n    \"collision_penalty\": 25,\n    \"height_target\": -10,\n    \"height_tolerance\": 1.0,\n    \"height_penalty\": 1,\n    \"movement_penalty\": 0.1,\n    \"smoothness_penalty\": 0.1,\n    \"duration\": 0.1,\n    \"exploration_area\": {\n      \"x_min\": -1000,\n      \"x_max\": 1000,\n      \"y_min\": -1000,\n      \"y_max\": 1000,\n      \"z_min\": -100,\n      \"z_max\": 100\n    }\n  },\n  \"policy_network\": {\n    \"input_size\": 16,\n    \"hidden_layers\": [\n      256,\n      256\n    ],\n    \"output_size\": 4,\n    \"use_batch_norm\": true,\n    \"use_dropout\": true,\n    \"dropout_rate\": 0.2,\n    \"use_attention\": true,\n    \"num_action_heads\": 1\n  },\n  \"critic_network\": {\n    \"input_size\": 16,\n    \"hidden_layers\": [\n      256,\n      256\n    ],\n    \"output_size\": 1,\n    \"use_batch_norm\": true,\n    \"use_dropout\": true,\n    \"dropout_rate\": 0.2,\n    \"use_attention\": true\n  },\n  \"exploration\": {\n    \"strategy\": \"epsilon_decay\",\n    \"initial_epsilon\": 1.0,\n    \"min_epsilon\": 0.05,\n    \"epsilon_decay_rate\": 0.9995\n  },\n  \"model_checkpointing\": {\n    \"checkpoint_interval\": 10,\n    \"save_best_only\": true,\n    \"checkpoint_dir\": \"models/checkpoints\"\n  },\n  \"logging\": {\n    \"log_interval\": 10,\n    \"log_dir\": \"logs/\",\n    \"tensorboard\": true,\n    \"tensorboard_log_dir\": \"logs/tensorboard_logs\",\n    \"model_save_path\": \"models/saved_models\"\n  },\n  \"advanced_training_techniques\": {\n    \"gradient_clipping\": 0.5,\n    \"use_gae\": true,\n    \"gae_lambda\": 0.95,\n    \"normalize_advantages\": true\n  },\n  \"early_stopping\": {\n    \"patience\": 10\n  },\n  \"reward_adjustments\": {\n    \"collision_penalty\": 50,\n    \"reward_threshold\": 250\n  },\n  \"shared_components\": {\n    \"residual_block\": {\n      \"input_dim\": 128,\n      \"hidden_dim\": 128,\n      \"dropout_rate\": 0.2\n    },\n    \"attention_layer\": {\n      \"input_dim\": 128,\n      \"hidden_dim\": 128\n    }\n  },\n  \"icm\": {\n    \"state_dim\": 16,\n    \"action_dim\": 4,\n    \"image_channels\": 3,\n    \"image_height\": 144,\n    \"image_width\": 256,\n    \"cnn\": {\n      \"conv1\": {\n        \"out_channels\": 32,\n        \"kernel_size\": 8,\n        \"stride\": 4\n      },\n      \"conv2\": {\n        \"out_channels\": 64,\n        \"kernel_size\": 4,\n        \"stride\": 2\n      },\n      \"conv3\": {\n        \"out_channels\": 64,\n        \"kernel_size\": 3,\n        \"stride\": 1\n      }\n    },\n    \"state_encoder\": {\n      \"hidden_dim\": 128\n    },\n    \"forward_model\": {\n      \"hidden_dim\": 256\n    },\n    \"inverse_model\": {\n      \"hidden_dim\": 256\n    }\n  },\n  \"predictive_model\": {\n    \"learning_rate\": 0.0001,\n    \"hidden_layers\": [\n      256,\n      256\n    ]\n  },\n  \"hrl\": {\n    \"use_hierarchical\": true,\n    \"high_level_policy\": {\n      \"input_size\": 16,\n      \"hidden_layers\": [\n        256,\n        256\n      ],\n      \"output_size\": 4\n    },\n    \"sub_goal_dim\": 3,\n    \"low_level_policy\": {\n      \"input_size\": 19,\n      \"hidden_layers\": [\n        256,\n        256\n      ],\n      \"output_size\": 4\n    }\n  },\n  \"curriculum_learning\": {\n    \"use_curriculum\": true,\n    \"initial_difficulty\": 1,\n    \"difficulty_increment\": 1,\n    \"difficulty_threshold\": 200\n  },\n  \"multi_agent\": {\n    \"use_multi_agent\": true,\n    \"num_agents\": 2,\n    \"hidden_layers\": [\n      256,\n      256\n    ]\n  }\n}"}
{"time": "2024-07-21T02:40:39.150479", "name": "AirSimEnvLogger", "level": "INFO", "message": "DataVisualizer initialized with Seaborn style set to 'whitegrid'."}
{"time": "2024-07-21T02:40:39.152478", "name": "AirSimEnvLogger", "level": "INFO", "message": "Using device: cpu"}
{"time": "2024-07-21T02:40:45.517854", "name": "AirSimEnvLogger", "level": "INFO", "message": "PPOAgent initialized successfully."}
{"time": "2024-07-21T02:40:50.175198", "name": "AirSimEnvLogger", "level": "INFO", "message": "Environment reset and takeoff completed."}
{"time": "2024-07-21T02:40:50.740849", "name": "AirSimEnvLogger", "level": "INFO", "message": "Reset completed. Observation keys: dict_keys(['state', 'visual'])"}
{"time": "2024-07-21T02:40:50.740849", "name": "AirSimEnvLogger", "level": "INFO", "message": "State shape: (16,), Visual shape: (144, 256, 3)"}
{"time": "2024-07-21T02:40:50.741848", "name": "AirSimEnvLogger", "level": "ERROR", "message": "An error occurred: float() argument must be a string or a number, not 'dict'"}
{"time": "2024-07-21T02:40:56.388727", "name": "AirSimEnvLogger", "level": "INFO", "message": "Environment closed."}
{"time": "2024-07-21T02:40:56.482964", "name": "AirSimEnvLogger", "level": "INFO", "message": "Training completed and models saved."}
{"time": "2024-07-21T02:45:41.291521", "name": "AirSimEnvLogger", "level": "INFO", "message": "Initialized with state_dim: 16, action_dim: 4"}
{"time": "2024-07-21T02:45:41.310569", "name": "AirSimEnvLogger", "level": "INFO", "message": "Initializing AirSimEnv"}
{"time": "2024-07-21T02:45:41.311566", "name": "AirSimEnvLogger", "level": "INFO", "message": "Configuration: {\n  \"learning_rate\": 0.0001,\n  \"gamma\": 0.99,\n  \"tau\": 0.95,\n  \"batch_size\": 64,\n  \"num_timesteps\": 2000000,\n  \"ppo\": {\n    \"learning_rate\": 0.0003,\n    \"n_steps\": 2048,\n    \"batch_size\": 64,\n    \"n_epochs\": 2000,\n    \"gamma\": 0.99,\n    \"gae_lambda\": 0.95,\n    \"clip_range\": 0.2,\n    \"ent_coef\": 0.01,\n    \"vf_coef\": 0.5,\n    \"max_grad_norm\": 0.5,\n    \"use_sde\": true,\n    \"sde_sample_freq\": 4,\n    \"tensorboard_log\": \"logs/tensorboard_logs/ppo_airsim_tensorboard/\",\n    \"verbose\": 1,\n    \"seed\": null,\n    \"device\": \"auto\",\n    \"continuous\": true,\n    \"save_freq\": 10000\n  },\n  \"environment\": {\n    \"env_name\": \"Africa_001\",\n    \"reward_threshold\": 250,\n    \"max_episode_steps\": 1000,\n    \"state_dim\": 16,\n    \"action_dim\": 4,\n    \"reward_scale\": 20,\n    \"proximity_threshold\": 5.0,\n    \"collision_penalty\": 25,\n    \"height_target\": -10,\n    \"height_tolerance\": 1.0,\n    \"height_penalty\": 1,\n    \"movement_penalty\": 0.1,\n    \"smoothness_penalty\": 0.1,\n    \"duration\": 0.1,\n    \"exploration_area\": {\n      \"x_min\": -1000,\n      \"x_max\": 1000,\n      \"y_min\": -1000,\n      \"y_max\": 1000,\n      \"z_min\": -100,\n      \"z_max\": 100\n    }\n  },\n  \"policy_network\": {\n    \"input_size\": 16,\n    \"hidden_layers\": [\n      256,\n      256\n    ],\n    \"output_size\": 4,\n    \"use_batch_norm\": true,\n    \"use_dropout\": true,\n    \"dropout_rate\": 0.2,\n    \"use_attention\": true,\n    \"num_action_heads\": 1\n  },\n  \"critic_network\": {\n    \"input_size\": 16,\n    \"hidden_layers\": [\n      256,\n      256\n    ],\n    \"output_size\": 1,\n    \"use_batch_norm\": true,\n    \"use_dropout\": true,\n    \"dropout_rate\": 0.2,\n    \"use_attention\": true\n  },\n  \"exploration\": {\n    \"strategy\": \"epsilon_decay\",\n    \"initial_epsilon\": 1.0,\n    \"min_epsilon\": 0.05,\n    \"epsilon_decay_rate\": 0.9995\n  },\n  \"model_checkpointing\": {\n    \"checkpoint_interval\": 10,\n    \"save_best_only\": true,\n    \"checkpoint_dir\": \"models/checkpoints\"\n  },\n  \"logging\": {\n    \"log_interval\": 10,\n    \"log_dir\": \"logs/\",\n    \"tensorboard\": true,\n    \"tensorboard_log_dir\": \"logs/tensorboard_logs\",\n    \"model_save_path\": \"models/saved_models\"\n  },\n  \"advanced_training_techniques\": {\n    \"gradient_clipping\": 0.5,\n    \"use_gae\": true,\n    \"gae_lambda\": 0.95,\n    \"normalize_advantages\": true\n  },\n  \"early_stopping\": {\n    \"patience\": 10\n  },\n  \"reward_adjustments\": {\n    \"collision_penalty\": 50,\n    \"reward_threshold\": 250\n  },\n  \"shared_components\": {\n    \"residual_block\": {\n      \"input_dim\": 128,\n      \"hidden_dim\": 128,\n      \"dropout_rate\": 0.2\n    },\n    \"attention_layer\": {\n      \"input_dim\": 128,\n      \"hidden_dim\": 128\n    }\n  },\n  \"icm\": {\n    \"state_dim\": 16,\n    \"action_dim\": 4,\n    \"image_channels\": 3,\n    \"image_height\": 144,\n    \"image_width\": 256,\n    \"cnn\": {\n      \"conv1\": {\n        \"out_channels\": 32,\n        \"kernel_size\": 8,\n        \"stride\": 4\n      },\n      \"conv2\": {\n        \"out_channels\": 64,\n        \"kernel_size\": 4,\n        \"stride\": 2\n      },\n      \"conv3\": {\n        \"out_channels\": 64,\n        \"kernel_size\": 3,\n        \"stride\": 1\n      }\n    },\n    \"state_encoder\": {\n      \"hidden_dim\": 128\n    },\n    \"forward_model\": {\n      \"hidden_dim\": 256\n    },\n    \"inverse_model\": {\n      \"hidden_dim\": 256\n    }\n  },\n  \"predictive_model\": {\n    \"learning_rate\": 0.0001,\n    \"hidden_layers\": [\n      256,\n      256\n    ]\n  },\n  \"hrl\": {\n    \"use_hierarchical\": true,\n    \"high_level_policy\": {\n      \"input_size\": 16,\n      \"hidden_layers\": [\n        256,\n        256\n      ],\n      \"output_size\": 4\n    },\n    \"sub_goal_dim\": 3,\n    \"low_level_policy\": {\n      \"input_size\": 19,\n      \"hidden_layers\": [\n        256,\n        256\n      ],\n      \"output_size\": 4\n    }\n  },\n  \"curriculum_learning\": {\n    \"use_curriculum\": true,\n    \"initial_difficulty\": 1,\n    \"difficulty_increment\": 1,\n    \"difficulty_threshold\": 200\n  },\n  \"multi_agent\": {\n    \"use_multi_agent\": true,\n    \"num_agents\": 2,\n    \"hidden_layers\": [\n      256,\n      256\n    ]\n  }\n}"}
{"time": "2024-07-21T02:45:42.522291", "name": "AirSimEnvLogger", "level": "INFO", "message": "DataVisualizer initialized with Seaborn style set to 'whitegrid'."}
{"time": "2024-07-21T02:45:42.524293", "name": "AirSimEnvLogger", "level": "INFO", "message": "Using device: cpu"}
{"time": "2024-07-21T02:45:49.137089", "name": "AirSimEnvLogger", "level": "INFO", "message": "PPOAgent initialized successfully."}
{"time": "2024-07-21T02:45:54.620389", "name": "AirSimEnvLogger", "level": "INFO", "message": "Environment reset and takeoff completed."}
{"time": "2024-07-21T02:45:55.234218", "name": "AirSimEnvLogger", "level": "INFO", "message": "Reset completed. Observation keys: dict_keys(['state', 'visual'])"}
{"time": "2024-07-21T02:45:55.234218", "name": "AirSimEnvLogger", "level": "INFO", "message": "State shape: (16,), Visual shape: (144, 256, 3)"}
{"time": "2024-07-21T02:45:55.234218", "name": "AirSimEnvLogger", "level": "ERROR", "message": "An error occurred: float() argument must be a string or a number, not 'dict'"}
{"time": "2024-07-21T02:46:00.896397", "name": "AirSimEnvLogger", "level": "INFO", "message": "Environment closed."}
{"time": "2024-07-21T02:46:00.958185", "name": "AirSimEnvLogger", "level": "INFO", "message": "Training completed and models saved."}
{"time": "2024-07-21T02:49:26.101099", "name": "AirSimEnvLogger", "level": "INFO", "message": "Initialized with state_dim: 16, action_dim: 4"}
{"time": "2024-07-21T02:49:26.122068", "name": "AirSimEnvLogger", "level": "INFO", "message": "Initializing AirSimEnv"}
{"time": "2024-07-21T02:49:26.123066", "name": "AirSimEnvLogger", "level": "INFO", "message": "Configuration: {\n  \"learning_rate\": 0.0001,\n  \"gamma\": 0.99,\n  \"tau\": 0.95,\n  \"batch_size\": 64,\n  \"num_timesteps\": 2000000,\n  \"ppo\": {\n    \"learning_rate\": 0.0003,\n    \"n_steps\": 2048,\n    \"batch_size\": 64,\n    \"n_epochs\": 2000,\n    \"gamma\": 0.99,\n    \"gae_lambda\": 0.95,\n    \"clip_range\": 0.2,\n    \"ent_coef\": 0.01,\n    \"vf_coef\": 0.5,\n    \"max_grad_norm\": 0.5,\n    \"use_sde\": true,\n    \"sde_sample_freq\": 4,\n    \"tensorboard_log\": \"logs/tensorboard_logs/ppo_airsim_tensorboard/\",\n    \"verbose\": 1,\n    \"seed\": null,\n    \"device\": \"auto\",\n    \"continuous\": true,\n    \"save_freq\": 10000\n  },\n  \"environment\": {\n    \"env_name\": \"Africa_001\",\n    \"reward_threshold\": 250,\n    \"max_episode_steps\": 1000,\n    \"state_dim\": 16,\n    \"action_dim\": 4,\n    \"reward_scale\": 20,\n    \"proximity_threshold\": 5.0,\n    \"collision_penalty\": 25,\n    \"height_target\": -10,\n    \"height_tolerance\": 1.0,\n    \"height_penalty\": 1,\n    \"movement_penalty\": 0.1,\n    \"smoothness_penalty\": 0.1,\n    \"duration\": 0.1,\n    \"exploration_area\": {\n      \"x_min\": -1000,\n      \"x_max\": 1000,\n      \"y_min\": -1000,\n      \"y_max\": 1000,\n      \"z_min\": -100,\n      \"z_max\": 100\n    }\n  },\n  \"policy_network\": {\n    \"input_size\": 16,\n    \"hidden_layers\": [\n      256,\n      256\n    ],\n    \"output_size\": 4,\n    \"use_batch_norm\": true,\n    \"use_dropout\": true,\n    \"dropout_rate\": 0.2,\n    \"use_attention\": true,\n    \"num_action_heads\": 1\n  },\n  \"critic_network\": {\n    \"input_size\": 16,\n    \"hidden_layers\": [\n      256,\n      256\n    ],\n    \"output_size\": 1,\n    \"use_batch_norm\": true,\n    \"use_dropout\": true,\n    \"dropout_rate\": 0.2,\n    \"use_attention\": true\n  },\n  \"exploration\": {\n    \"strategy\": \"epsilon_decay\",\n    \"initial_epsilon\": 1.0,\n    \"min_epsilon\": 0.05,\n    \"epsilon_decay_rate\": 0.9995\n  },\n  \"model_checkpointing\": {\n    \"checkpoint_interval\": 10,\n    \"save_best_only\": true,\n    \"checkpoint_dir\": \"models/checkpoints\"\n  },\n  \"logging\": {\n    \"log_interval\": 10,\n    \"log_dir\": \"logs/\",\n    \"tensorboard\": true,\n    \"tensorboard_log_dir\": \"logs/tensorboard_logs\",\n    \"model_save_path\": \"models/saved_models\"\n  },\n  \"advanced_training_techniques\": {\n    \"gradient_clipping\": 0.5,\n    \"use_gae\": true,\n    \"gae_lambda\": 0.95,\n    \"normalize_advantages\": true\n  },\n  \"early_stopping\": {\n    \"patience\": 10\n  },\n  \"reward_adjustments\": {\n    \"collision_penalty\": 50,\n    \"reward_threshold\": 250\n  },\n  \"shared_components\": {\n    \"residual_block\": {\n      \"input_dim\": 128,\n      \"hidden_dim\": 128,\n      \"dropout_rate\": 0.2\n    },\n    \"attention_layer\": {\n      \"input_dim\": 128,\n      \"hidden_dim\": 128\n    }\n  },\n  \"icm\": {\n    \"state_dim\": 16,\n    \"action_dim\": 4,\n    \"image_channels\": 3,\n    \"image_height\": 144,\n    \"image_width\": 256,\n    \"cnn\": {\n      \"conv1\": {\n        \"out_channels\": 32,\n        \"kernel_size\": 8,\n        \"stride\": 4\n      },\n      \"conv2\": {\n        \"out_channels\": 64,\n        \"kernel_size\": 4,\n        \"stride\": 2\n      },\n      \"conv3\": {\n        \"out_channels\": 64,\n        \"kernel_size\": 3,\n        \"stride\": 1\n      }\n    },\n    \"state_encoder\": {\n      \"hidden_dim\": 128\n    },\n    \"forward_model\": {\n      \"hidden_dim\": 256\n    },\n    \"inverse_model\": {\n      \"hidden_dim\": 256\n    }\n  },\n  \"predictive_model\": {\n    \"learning_rate\": 0.0001,\n    \"hidden_layers\": [\n      256,\n      256\n    ]\n  },\n  \"hrl\": {\n    \"use_hierarchical\": true,\n    \"high_level_policy\": {\n      \"input_size\": 16,\n      \"hidden_layers\": [\n        256,\n        256\n      ],\n      \"output_size\": 4\n    },\n    \"sub_goal_dim\": 3,\n    \"low_level_policy\": {\n      \"input_size\": 19,\n      \"hidden_layers\": [\n        256,\n        256\n      ],\n      \"output_size\": 4\n    }\n  },\n  \"curriculum_learning\": {\n    \"use_curriculum\": true,\n    \"initial_difficulty\": 1,\n    \"difficulty_increment\": 1,\n    \"difficulty_threshold\": 200\n  },\n  \"multi_agent\": {\n    \"use_multi_agent\": true,\n    \"num_agents\": 2,\n    \"hidden_layers\": [\n      256,\n      256\n    ]\n  }\n}"}
{"time": "2024-07-21T02:49:27.149659", "name": "AirSimEnvLogger", "level": "INFO", "message": "DataVisualizer initialized with Seaborn style set to 'whitegrid'."}
{"time": "2024-07-21T02:49:27.151659", "name": "AirSimEnvLogger", "level": "INFO", "message": "Using device: cpu"}
{"time": "2024-07-21T02:49:34.092463", "name": "AirSimEnvLogger", "level": "INFO", "message": "PPOAgent initialized successfully."}
{"time": "2024-07-21T02:49:34.092463", "name": "AirSimEnvLogger", "level": "ERROR", "message": "Error in reset function: 'AirSimEnv' object has no attribute '_reset_env'"}
{"time": "2024-07-21T02:49:34.092463", "name": "AirSimEnvLogger", "level": "ERROR", "message": "An error occurred: 'AirSimEnv' object has no attribute '_reset_env'"}
{"time": "2024-07-21T02:49:34.921067", "name": "AirSimEnvLogger", "level": "INFO", "message": "Environment closed."}
{"time": "2024-07-21T02:49:34.983264", "name": "AirSimEnvLogger", "level": "INFO", "message": "Training completed and models saved."}
{"time": "2024-07-21T07:08:47.964938", "name": "AirSimEnvLogger", "level": "INFO", "message": "Initialized with state_dim: 16, action_dim: 4"}
{"time": "2024-07-21T07:08:47.981989", "name": "AirSimEnvLogger", "level": "INFO", "message": "Initializing AirSimEnv"}
{"time": "2024-07-21T07:08:47.982989", "name": "AirSimEnvLogger", "level": "INFO", "message": "Configuration: {\n  \"learning_rate\": 0.0001,\n  \"gamma\": 0.99,\n  \"tau\": 0.95,\n  \"batch_size\": 64,\n  \"num_timesteps\": 2000000,\n  \"ppo\": {\n    \"learning_rate\": 0.0003,\n    \"n_steps\": 2048,\n    \"batch_size\": 64,\n    \"n_epochs\": 2000,\n    \"gamma\": 0.99,\n    \"gae_lambda\": 0.95,\n    \"clip_range\": 0.2,\n    \"ent_coef\": 0.01,\n    \"vf_coef\": 0.5,\n    \"max_grad_norm\": 0.5,\n    \"use_sde\": true,\n    \"sde_sample_freq\": 4,\n    \"tensorboard_log\": \"logs/tensorboard_logs/ppo_airsim_tensorboard/\",\n    \"verbose\": 1,\n    \"seed\": null,\n    \"device\": \"auto\",\n    \"continuous\": true,\n    \"save_freq\": 10000\n  },\n  \"environment\": {\n    \"env_name\": \"Africa_001\",\n    \"reward_threshold\": 250,\n    \"max_episode_steps\": 1000,\n    \"state_dim\": 16,\n    \"action_dim\": 4,\n    \"reward_scale\": 20,\n    \"proximity_threshold\": 5.0,\n    \"collision_penalty\": 25,\n    \"height_target\": -10,\n    \"height_tolerance\": 1.0,\n    \"height_penalty\": 1,\n    \"movement_penalty\": 0.1,\n    \"smoothness_penalty\": 0.1,\n    \"duration\": 0.1,\n    \"exploration_area\": {\n      \"x_min\": -1000,\n      \"x_max\": 1000,\n      \"y_min\": -1000,\n      \"y_max\": 1000,\n      \"z_min\": -100,\n      \"z_max\": 100\n    }\n  },\n  \"policy_network\": {\n    \"input_size\": 16,\n    \"hidden_layers\": [\n      256,\n      256\n    ],\n    \"output_size\": 4,\n    \"use_batch_norm\": true,\n    \"use_dropout\": true,\n    \"dropout_rate\": 0.2,\n    \"use_attention\": true,\n    \"num_action_heads\": 1\n  },\n  \"critic_network\": {\n    \"input_size\": 16,\n    \"hidden_layers\": [\n      256,\n      256\n    ],\n    \"output_size\": 1,\n    \"use_batch_norm\": true,\n    \"use_dropout\": true,\n    \"dropout_rate\": 0.2,\n    \"use_attention\": true\n  },\n  \"exploration\": {\n    \"strategy\": \"epsilon_decay\",\n    \"initial_epsilon\": 1.0,\n    \"min_epsilon\": 0.05,\n    \"epsilon_decay_rate\": 0.9995\n  },\n  \"model_checkpointing\": {\n    \"checkpoint_interval\": 10,\n    \"save_best_only\": true,\n    \"checkpoint_dir\": \"models/checkpoints\"\n  },\n  \"logging\": {\n    \"log_interval\": 10,\n    \"log_dir\": \"logs/\",\n    \"tensorboard\": true,\n    \"tensorboard_log_dir\": \"logs/tensorboard_logs\",\n    \"model_save_path\": \"models/saved_models\"\n  },\n  \"advanced_training_techniques\": {\n    \"gradient_clipping\": 0.5,\n    \"use_gae\": true,\n    \"gae_lambda\": 0.95,\n    \"normalize_advantages\": true\n  },\n  \"early_stopping\": {\n    \"patience\": 10\n  },\n  \"reward_adjustments\": {\n    \"collision_penalty\": 50,\n    \"reward_threshold\": 250\n  },\n  \"shared_components\": {\n    \"residual_block\": {\n      \"input_dim\": 128,\n      \"hidden_dim\": 128,\n      \"dropout_rate\": 0.2\n    },\n    \"attention_layer\": {\n      \"input_dim\": 128,\n      \"hidden_dim\": 128\n    }\n  },\n  \"icm\": {\n    \"state_dim\": 16,\n    \"action_dim\": 4,\n    \"image_channels\": 3,\n    \"image_height\": 144,\n    \"image_width\": 256,\n    \"cnn\": {\n      \"conv1\": {\n        \"out_channels\": 32,\n        \"kernel_size\": 8,\n        \"stride\": 4\n      },\n      \"conv2\": {\n        \"out_channels\": 64,\n        \"kernel_size\": 4,\n        \"stride\": 2\n      },\n      \"conv3\": {\n        \"out_channels\": 64,\n        \"kernel_size\": 3,\n        \"stride\": 1\n      }\n    },\n    \"state_encoder\": {\n      \"hidden_dim\": 128\n    },\n    \"forward_model\": {\n      \"hidden_dim\": 256\n    },\n    \"inverse_model\": {\n      \"hidden_dim\": 256\n    }\n  },\n  \"predictive_model\": {\n    \"learning_rate\": 0.0001,\n    \"hidden_layers\": [\n      256,\n      256\n    ]\n  },\n  \"hrl\": {\n    \"use_hierarchical\": true,\n    \"high_level_policy\": {\n      \"input_size\": 16,\n      \"hidden_layers\": [\n        256,\n        256\n      ],\n      \"output_size\": 4\n    },\n    \"sub_goal_dim\": 3,\n    \"low_level_policy\": {\n      \"input_size\": 19,\n      \"hidden_layers\": [\n        256,\n        256\n      ],\n      \"output_size\": 4\n    }\n  },\n  \"curriculum_learning\": {\n    \"use_curriculum\": true,\n    \"initial_difficulty\": 1,\n    \"difficulty_increment\": 1,\n    \"difficulty_threshold\": 200\n  },\n  \"multi_agent\": {\n    \"use_multi_agent\": true,\n    \"num_agents\": 2,\n    \"hidden_layers\": [\n      256,\n      256\n    ]\n  }\n}"}
{"time": "2024-07-21T07:08:49.466551", "name": "AirSimEnvLogger", "level": "INFO", "message": "DataVisualizer initialized with Seaborn style set to 'whitegrid'."}
{"time": "2024-07-21T07:08:49.467827", "name": "AirSimEnvLogger", "level": "INFO", "message": "Using device: cpu"}
{"time": "2024-07-21T07:08:54.925627", "name": "AirSimEnvLogger", "level": "INFO", "message": "PPOAgent initialized successfully."}
{"time": "2024-07-21T07:09:00.593843", "name": "AirSimEnvLogger", "level": "INFO", "message": "Environment reset and takeoff completed."}
{"time": "2024-07-21T07:09:01.033409", "name": "AirSimEnvLogger", "level": "INFO", "message": "Reset completed. Observation keys: dict_keys(['state', 'visual'])"}
{"time": "2024-07-21T07:09:01.033409", "name": "AirSimEnvLogger", "level": "INFO", "message": "State shape: (16,), Visual shape: (144, 256, 3)"}
{"time": "2024-07-21T07:09:01.096536", "name": "AirSimEnvLogger", "level": "ERROR", "message": "Error during training: 'training'"}
{"time": "2024-07-21T07:09:01.096536", "name": "AirSimEnvLogger", "level": "ERROR", "message": "An error occurred in main: 'training'"}
{"time": "2024-07-21T07:09:06.772244", "name": "AirSimEnvLogger", "level": "INFO", "message": "Environment closed."}
{"time": "2024-07-21T07:09:06.868288", "name": "AirSimEnvLogger", "level": "INFO", "message": "Training completed and models saved."}
{"time": "2024-07-21T14:18:38.383334", "name": "AirSimEnvLogger", "level": "INFO", "message": "Initialized with state_dim: 16, action_dim: 4"}
{"time": "2024-07-21T14:18:38.399489", "name": "AirSimEnvLogger", "level": "INFO", "message": "Initializing AirSimEnv"}
{"time": "2024-07-21T14:18:38.400482", "name": "AirSimEnvLogger", "level": "INFO", "message": "Configuration: {\n  \"learning_rate\": 0.0001,\n  \"gamma\": 0.99,\n  \"tau\": 0.95,\n  \"batch_size\": 64,\n  \"num_timesteps\": 2000000,\n  \"ppo\": {\n    \"learning_rate\": 0.0003,\n    \"n_steps\": 2048,\n    \"batch_size\": 64,\n    \"n_epochs\": 2000,\n    \"gamma\": 0.99,\n    \"gae_lambda\": 0.95,\n    \"clip_range\": 0.2,\n    \"ent_coef\": 0.01,\n    \"vf_coef\": 0.5,\n    \"max_grad_norm\": 0.5,\n    \"use_sde\": true,\n    \"sde_sample_freq\": 4,\n    \"tensorboard_log\": \"logs/tensorboard_logs/ppo_airsim_tensorboard/\",\n    \"verbose\": 1,\n    \"seed\": null,\n    \"device\": \"auto\",\n    \"continuous\": true,\n    \"save_freq\": 10000\n  },\n  \"environment\": {\n    \"env_name\": \"Africa_001\",\n    \"reward_threshold\": 250,\n    \"max_episode_steps\": 1000,\n    \"state_dim\": 16,\n    \"action_dim\": 4,\n    \"reward_scale\": 20,\n    \"proximity_threshold\": 5.0,\n    \"collision_penalty\": 25,\n    \"height_target\": -10,\n    \"height_tolerance\": 1.0,\n    \"height_penalty\": 1,\n    \"movement_penalty\": 0.1,\n    \"smoothness_penalty\": 0.1,\n    \"duration\": 0.1,\n    \"exploration_area\": {\n      \"x_min\": -1000,\n      \"x_max\": 1000,\n      \"y_min\": -1000,\n      \"y_max\": 1000,\n      \"z_min\": -100,\n      \"z_max\": 100\n    }\n  },\n  \"policy_network\": {\n    \"input_size\": 16,\n    \"hidden_layers\": [\n      256,\n      256\n    ],\n    \"output_size\": 4,\n    \"use_batch_norm\": true,\n    \"use_dropout\": true,\n    \"dropout_rate\": 0.2,\n    \"use_attention\": true,\n    \"num_action_heads\": 1\n  },\n  \"critic_network\": {\n    \"input_size\": 16,\n    \"hidden_layers\": [\n      256,\n      256\n    ],\n    \"output_size\": 1,\n    \"use_batch_norm\": true,\n    \"use_dropout\": true,\n    \"dropout_rate\": 0.2,\n    \"use_attention\": true\n  },\n  \"exploration\": {\n    \"strategy\": \"epsilon_decay\",\n    \"initial_epsilon\": 1.0,\n    \"min_epsilon\": 0.05,\n    \"epsilon_decay_rate\": 0.9995\n  },\n  \"model_checkpointing\": {\n    \"checkpoint_interval\": 10,\n    \"save_best_only\": true,\n    \"checkpoint_dir\": \"models/checkpoints\"\n  },\n  \"logging\": {\n    \"log_interval\": 10,\n    \"log_dir\": \"logs/\",\n    \"tensorboard\": true,\n    \"tensorboard_log_dir\": \"logs/tensorboard_logs\",\n    \"model_save_path\": \"models/saved_models\"\n  },\n  \"advanced_training_techniques\": {\n    \"gradient_clipping\": 0.5,\n    \"use_gae\": true,\n    \"gae_lambda\": 0.95,\n    \"normalize_advantages\": true\n  },\n  \"early_stopping\": {\n    \"patience\": 10\n  },\n  \"reward_adjustments\": {\n    \"collision_penalty\": 50,\n    \"reward_threshold\": 250\n  },\n  \"shared_components\": {\n    \"residual_block\": {\n      \"input_dim\": 128,\n      \"hidden_dim\": 128,\n      \"dropout_rate\": 0.2\n    },\n    \"attention_layer\": {\n      \"input_dim\": 128,\n      \"hidden_dim\": 128\n    }\n  },\n  \"icm\": {\n    \"state_dim\": 16,\n    \"action_dim\": 4,\n    \"image_channels\": 3,\n    \"image_height\": 144,\n    \"image_width\": 256,\n    \"cnn\": {\n      \"conv1\": {\n        \"out_channels\": 32,\n        \"kernel_size\": 8,\n        \"stride\": 4\n      },\n      \"conv2\": {\n        \"out_channels\": 64,\n        \"kernel_size\": 4,\n        \"stride\": 2\n      },\n      \"conv3\": {\n        \"out_channels\": 64,\n        \"kernel_size\": 3,\n        \"stride\": 1\n      }\n    },\n    \"state_encoder\": {\n      \"hidden_dim\": 128\n    },\n    \"forward_model\": {\n      \"hidden_dim\": 256\n    },\n    \"inverse_model\": {\n      \"hidden_dim\": 256\n    }\n  },\n  \"predictive_model\": {\n    \"learning_rate\": 0.0001,\n    \"hidden_layers\": [\n      256,\n      256\n    ]\n  },\n  \"hrl\": {\n    \"use_hierarchical\": true,\n    \"high_level_policy\": {\n      \"input_size\": 16,\n      \"hidden_layers\": [\n        256,\n        256\n      ],\n      \"output_size\": 4\n    },\n    \"sub_goal_dim\": 3,\n    \"low_level_policy\": {\n      \"input_size\": 19,\n      \"hidden_layers\": [\n        256,\n        256\n      ],\n      \"output_size\": 4\n    }\n  },\n  \"curriculum_learning\": {\n    \"use_curriculum\": true,\n    \"initial_difficulty\": 1,\n    \"difficulty_increment\": 1,\n    \"difficulty_threshold\": 200\n  },\n  \"multi_agent\": {\n    \"use_multi_agent\": true,\n    \"num_agents\": 2,\n    \"hidden_layers\": [\n      256,\n      256\n    ]\n  }\n}"}
{"time": "2024-07-21T14:18:39.887521", "name": "AirSimEnvLogger", "level": "INFO", "message": "DataVisualizer initialized with Seaborn style set to 'whitegrid'."}
{"time": "2024-07-21T14:18:39.888524", "name": "AirSimEnvLogger", "level": "INFO", "message": "Using device: cpu"}
{"time": "2024-07-21T14:18:46.083143", "name": "AirSimEnvLogger", "level": "INFO", "message": "PPOAgent initialized successfully."}
{"time": "2024-07-21T14:18:50.956211", "name": "AirSimEnvLogger", "level": "INFO", "message": "Environment reset and takeoff completed."}
{"time": "2024-07-21T14:18:51.522469", "name": "AirSimEnvLogger", "level": "INFO", "message": "Reset completed. Observation keys: dict_keys(['state', 'visual'])"}
{"time": "2024-07-21T14:18:51.522469", "name": "AirSimEnvLogger", "level": "INFO", "message": "State shape: (16,), Visual shape: (144, 256, 3)"}
{"time": "2024-07-21T14:18:53.156379", "name": "AirSimEnvLogger", "level": "ERROR", "message": "Error during training: permute(sparse_coo): number of dimensions in the tensor input does not match the length of the desired ordering of dimensions i.e. input.dim() = 5 is not equal to len(dims) = 4"}
{"time": "2024-07-21T14:18:53.156379", "name": "AirSimEnvLogger", "level": "ERROR", "message": "An error occurred in main: permute(sparse_coo): number of dimensions in the tensor input does not match the length of the desired ordering of dimensions i.e. input.dim() = 5 is not equal to len(dims) = 4"}
{"time": "2024-07-21T14:18:58.848676", "name": "AirSimEnvLogger", "level": "INFO", "message": "Environment closed."}
{"time": "2024-07-21T14:18:58.879953", "name": "AirSimEnvLogger", "level": "INFO", "message": "Training completed and models saved."}
{"time": "2024-07-21T14:30:14.959256", "name": "AirSimEnvLogger", "level": "INFO", "message": "Initialized with state_dim: 16, action_dim: 4"}
{"time": "2024-07-21T14:30:14.977301", "name": "AirSimEnvLogger", "level": "INFO", "message": "Initializing AirSimEnv"}
{"time": "2024-07-21T14:30:14.977301", "name": "AirSimEnvLogger", "level": "INFO", "message": "Configuration: {\n  \"learning_rate\": 0.0001,\n  \"gamma\": 0.99,\n  \"tau\": 0.95,\n  \"batch_size\": 64,\n  \"num_timesteps\": 2000000,\n  \"ppo\": {\n    \"learning_rate\": 0.0003,\n    \"n_steps\": 2048,\n    \"batch_size\": 64,\n    \"n_epochs\": 2000,\n    \"gamma\": 0.99,\n    \"gae_lambda\": 0.95,\n    \"clip_range\": 0.2,\n    \"ent_coef\": 0.01,\n    \"vf_coef\": 0.5,\n    \"max_grad_norm\": 0.5,\n    \"use_sde\": true,\n    \"sde_sample_freq\": 4,\n    \"tensorboard_log\": \"logs/tensorboard_logs/ppo_airsim_tensorboard/\",\n    \"verbose\": 1,\n    \"seed\": null,\n    \"device\": \"auto\",\n    \"continuous\": true,\n    \"save_freq\": 10000\n  },\n  \"environment\": {\n    \"env_name\": \"Africa_001\",\n    \"reward_threshold\": 250,\n    \"max_episode_steps\": 1000,\n    \"state_dim\": 16,\n    \"action_dim\": 4,\n    \"reward_scale\": 20,\n    \"proximity_threshold\": 5.0,\n    \"collision_penalty\": 25,\n    \"height_target\": -10,\n    \"height_tolerance\": 1.0,\n    \"height_penalty\": 1,\n    \"movement_penalty\": 0.1,\n    \"smoothness_penalty\": 0.1,\n    \"duration\": 0.1,\n    \"exploration_area\": {\n      \"x_min\": -1000,\n      \"x_max\": 1000,\n      \"y_min\": -1000,\n      \"y_max\": 1000,\n      \"z_min\": -100,\n      \"z_max\": 100\n    }\n  },\n  \"policy_network\": {\n    \"input_size\": 16,\n    \"hidden_layers\": [\n      256,\n      256\n    ],\n    \"output_size\": 4,\n    \"use_batch_norm\": true,\n    \"use_dropout\": true,\n    \"dropout_rate\": 0.2,\n    \"use_attention\": true,\n    \"num_action_heads\": 1\n  },\n  \"critic_network\": {\n    \"input_size\": 16,\n    \"hidden_layers\": [\n      256,\n      256\n    ],\n    \"output_size\": 1,\n    \"use_batch_norm\": true,\n    \"use_dropout\": true,\n    \"dropout_rate\": 0.2,\n    \"use_attention\": true\n  },\n  \"exploration\": {\n    \"strategy\": \"epsilon_decay\",\n    \"initial_epsilon\": 1.0,\n    \"min_epsilon\": 0.05,\n    \"epsilon_decay_rate\": 0.9995\n  },\n  \"model_checkpointing\": {\n    \"checkpoint_interval\": 10,\n    \"save_best_only\": true,\n    \"checkpoint_dir\": \"models/checkpoints\"\n  },\n  \"logging\": {\n    \"log_interval\": 10,\n    \"log_dir\": \"logs/\",\n    \"tensorboard\": true,\n    \"tensorboard_log_dir\": \"logs/tensorboard_logs\",\n    \"model_save_path\": \"models/saved_models\"\n  },\n  \"advanced_training_techniques\": {\n    \"gradient_clipping\": 0.5,\n    \"use_gae\": true,\n    \"gae_lambda\": 0.95,\n    \"normalize_advantages\": true\n  },\n  \"early_stopping\": {\n    \"patience\": 10\n  },\n  \"reward_adjustments\": {\n    \"collision_penalty\": 50,\n    \"reward_threshold\": 250\n  },\n  \"shared_components\": {\n    \"residual_block\": {\n      \"input_dim\": 128,\n      \"hidden_dim\": 128,\n      \"dropout_rate\": 0.2\n    },\n    \"attention_layer\": {\n      \"input_dim\": 128,\n      \"hidden_dim\": 128\n    }\n  },\n  \"icm\": {\n    \"state_dim\": 16,\n    \"action_dim\": 4,\n    \"image_channels\": 3,\n    \"image_height\": 144,\n    \"image_width\": 256,\n    \"cnn\": {\n      \"conv1\": {\n        \"out_channels\": 32,\n        \"kernel_size\": 8,\n        \"stride\": 4\n      },\n      \"conv2\": {\n        \"out_channels\": 64,\n        \"kernel_size\": 4,\n        \"stride\": 2\n      },\n      \"conv3\": {\n        \"out_channels\": 64,\n        \"kernel_size\": 3,\n        \"stride\": 1\n      }\n    },\n    \"state_encoder\": {\n      \"hidden_dim\": 128\n    },\n    \"forward_model\": {\n      \"hidden_dim\": 256\n    },\n    \"inverse_model\": {\n      \"hidden_dim\": 256\n    }\n  },\n  \"predictive_model\": {\n    \"learning_rate\": 0.0001,\n    \"hidden_layers\": [\n      256,\n      256\n    ]\n  },\n  \"hrl\": {\n    \"use_hierarchical\": true,\n    \"high_level_policy\": {\n      \"input_size\": 16,\n      \"hidden_layers\": [\n        256,\n        256\n      ],\n      \"output_size\": 4\n    },\n    \"sub_goal_dim\": 3,\n    \"low_level_policy\": {\n      \"input_size\": 19,\n      \"hidden_layers\": [\n        256,\n        256\n      ],\n      \"output_size\": 4\n    }\n  },\n  \"curriculum_learning\": {\n    \"use_curriculum\": true,\n    \"initial_difficulty\": 1,\n    \"difficulty_increment\": 1,\n    \"difficulty_threshold\": 200\n  },\n  \"multi_agent\": {\n    \"use_multi_agent\": true,\n    \"num_agents\": 2,\n    \"hidden_layers\": [\n      256,\n      256\n    ]\n  }\n}"}
{"time": "2024-07-21T14:30:16.447443", "name": "AirSimEnvLogger", "level": "INFO", "message": "DataVisualizer initialized with Seaborn style set to 'whitegrid'."}
{"time": "2024-07-21T14:30:16.447443", "name": "AirSimEnvLogger", "level": "INFO", "message": "Using device: cpu"}
{"time": "2024-07-21T14:30:23.189347", "name": "AirSimEnvLogger", "level": "INFO", "message": "PPOAgent initialized successfully."}
{"time": "2024-07-21T14:30:28.312088", "name": "AirSimEnvLogger", "level": "INFO", "message": "Environment reset and takeoff completed."}
{"time": "2024-07-21T14:30:28.938865", "name": "AirSimEnvLogger", "level": "INFO", "message": "Reset completed. Observation keys: dict_keys(['state', 'visual'])"}
{"time": "2024-07-21T14:30:28.938865", "name": "AirSimEnvLogger", "level": "INFO", "message": "State shape: (16,), Visual shape: (144, 256, 3)"}
{"time": "2024-07-21T14:30:30.145032", "name": "AirSimEnvLogger", "level": "ERROR", "message": "Error during training: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 256, 3, 144] to have 3 channels, but got 256 channels instead"}
{"time": "2024-07-21T14:30:30.145032", "name": "AirSimEnvLogger", "level": "ERROR", "message": "An error occurred in main: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 256, 3, 144] to have 3 channels, but got 256 channels instead"}
{"time": "2024-07-21T14:30:36.000370", "name": "AirSimEnvLogger", "level": "INFO", "message": "Environment closed."}
{"time": "2024-07-21T14:30:36.095599", "name": "AirSimEnvLogger", "level": "INFO", "message": "Training script execution finished."}
{"time": "2024-07-21T14:33:49.411422", "name": "AirSimEnvLogger", "level": "INFO", "message": "Initialized with state_dim: 16, action_dim: 4"}
{"time": "2024-07-21T14:33:49.427464", "name": "AirSimEnvLogger", "level": "INFO", "message": "Initializing AirSimEnv"}
{"time": "2024-07-21T14:33:49.428476", "name": "AirSimEnvLogger", "level": "INFO", "message": "Configuration: {\n  \"learning_rate\": 0.0001,\n  \"gamma\": 0.99,\n  \"tau\": 0.95,\n  \"batch_size\": 64,\n  \"num_timesteps\": 2000000,\n  \"ppo\": {\n    \"learning_rate\": 0.0003,\n    \"n_steps\": 2048,\n    \"batch_size\": 64,\n    \"n_epochs\": 2000,\n    \"gamma\": 0.99,\n    \"gae_lambda\": 0.95,\n    \"clip_range\": 0.2,\n    \"ent_coef\": 0.01,\n    \"vf_coef\": 0.5,\n    \"max_grad_norm\": 0.5,\n    \"use_sde\": true,\n    \"sde_sample_freq\": 4,\n    \"tensorboard_log\": \"logs/tensorboard_logs/ppo_airsim_tensorboard/\",\n    \"verbose\": 1,\n    \"seed\": null,\n    \"device\": \"auto\",\n    \"continuous\": true,\n    \"save_freq\": 10000\n  },\n  \"environment\": {\n    \"env_name\": \"Africa_001\",\n    \"reward_threshold\": 250,\n    \"max_episode_steps\": 1000,\n    \"state_dim\": 16,\n    \"action_dim\": 4,\n    \"reward_scale\": 20,\n    \"proximity_threshold\": 5.0,\n    \"collision_penalty\": 25,\n    \"height_target\": -10,\n    \"height_tolerance\": 1.0,\n    \"height_penalty\": 1,\n    \"movement_penalty\": 0.1,\n    \"smoothness_penalty\": 0.1,\n    \"duration\": 0.1,\n    \"exploration_area\": {\n      \"x_min\": -1000,\n      \"x_max\": 1000,\n      \"y_min\": -1000,\n      \"y_max\": 1000,\n      \"z_min\": -100,\n      \"z_max\": 100\n    }\n  },\n  \"policy_network\": {\n    \"input_size\": 16,\n    \"hidden_layers\": [\n      256,\n      256\n    ],\n    \"output_size\": 4,\n    \"use_batch_norm\": true,\n    \"use_dropout\": true,\n    \"dropout_rate\": 0.2,\n    \"use_attention\": true,\n    \"num_action_heads\": 1\n  },\n  \"critic_network\": {\n    \"input_size\": 16,\n    \"hidden_layers\": [\n      256,\n      256\n    ],\n    \"output_size\": 1,\n    \"use_batch_norm\": true,\n    \"use_dropout\": true,\n    \"dropout_rate\": 0.2,\n    \"use_attention\": true\n  },\n  \"exploration\": {\n    \"strategy\": \"epsilon_decay\",\n    \"initial_epsilon\": 1.0,\n    \"min_epsilon\": 0.05,\n    \"epsilon_decay_rate\": 0.9995\n  },\n  \"model_checkpointing\": {\n    \"checkpoint_interval\": 10,\n    \"save_best_only\": true,\n    \"checkpoint_dir\": \"models/checkpoints\"\n  },\n  \"logging\": {\n    \"log_interval\": 10,\n    \"log_dir\": \"logs/\",\n    \"tensorboard\": true,\n    \"tensorboard_log_dir\": \"logs/tensorboard_logs\",\n    \"model_save_path\": \"models/saved_models\"\n  },\n  \"advanced_training_techniques\": {\n    \"gradient_clipping\": 0.5,\n    \"use_gae\": true,\n    \"gae_lambda\": 0.95,\n    \"normalize_advantages\": true\n  },\n  \"early_stopping\": {\n    \"patience\": 10\n  },\n  \"reward_adjustments\": {\n    \"collision_penalty\": 50,\n    \"reward_threshold\": 250\n  },\n  \"shared_components\": {\n    \"residual_block\": {\n      \"input_dim\": 128,\n      \"hidden_dim\": 128,\n      \"dropout_rate\": 0.2\n    },\n    \"attention_layer\": {\n      \"input_dim\": 128,\n      \"hidden_dim\": 128\n    }\n  },\n  \"icm\": {\n    \"state_dim\": 16,\n    \"action_dim\": 4,\n    \"image_channels\": 3,\n    \"image_height\": 144,\n    \"image_width\": 256,\n    \"cnn\": {\n      \"conv1\": {\n        \"out_channels\": 32,\n        \"kernel_size\": 8,\n        \"stride\": 4\n      },\n      \"conv2\": {\n        \"out_channels\": 64,\n        \"kernel_size\": 4,\n        \"stride\": 2\n      },\n      \"conv3\": {\n        \"out_channels\": 64,\n        \"kernel_size\": 3,\n        \"stride\": 1\n      }\n    },\n    \"state_encoder\": {\n      \"hidden_dim\": 128\n    },\n    \"forward_model\": {\n      \"hidden_dim\": 256\n    },\n    \"inverse_model\": {\n      \"hidden_dim\": 256\n    }\n  },\n  \"predictive_model\": {\n    \"learning_rate\": 0.0001,\n    \"hidden_layers\": [\n      256,\n      256\n    ]\n  },\n  \"hrl\": {\n    \"use_hierarchical\": true,\n    \"high_level_policy\": {\n      \"input_size\": 16,\n      \"hidden_layers\": [\n        256,\n        256\n      ],\n      \"output_size\": 4\n    },\n    \"sub_goal_dim\": 3,\n    \"low_level_policy\": {\n      \"input_size\": 19,\n      \"hidden_layers\": [\n        256,\n        256\n      ],\n      \"output_size\": 4\n    }\n  },\n  \"curriculum_learning\": {\n    \"use_curriculum\": true,\n    \"initial_difficulty\": 1,\n    \"difficulty_increment\": 1,\n    \"difficulty_threshold\": 200\n  },\n  \"multi_agent\": {\n    \"use_multi_agent\": true,\n    \"num_agents\": 2,\n    \"hidden_layers\": [\n      256,\n      256\n    ]\n  }\n}"}
{"time": "2024-07-21T14:33:50.950424", "name": "AirSimEnvLogger", "level": "INFO", "message": "DataVisualizer initialized with Seaborn style set to 'whitegrid'."}
{"time": "2024-07-21T14:33:50.952424", "name": "AirSimEnvLogger", "level": "INFO", "message": "Using device: cpu"}
{"time": "2024-07-21T14:33:57.254196", "name": "AirSimEnvLogger", "level": "INFO", "message": "PPOAgent initialized successfully."}
{"time": "2024-07-21T14:34:02.107209", "name": "AirSimEnvLogger", "level": "INFO", "message": "Environment reset and takeoff completed."}
{"time": "2024-07-21T14:34:02.704256", "name": "AirSimEnvLogger", "level": "INFO", "message": "Reset completed. Observation keys: dict_keys(['state', 'visual'])"}
{"time": "2024-07-21T14:34:02.704256", "name": "AirSimEnvLogger", "level": "INFO", "message": "State shape: (16,), Visual shape: (144, 256, 3)"}
{"time": "2024-07-21T14:34:02.847198", "name": "AirSimEnvLogger", "level": "INFO", "message": "Visual tensor shape after permute: torch.Size([1, 256, 3, 144])"}
{"time": "2024-07-21T14:34:04.027766", "name": "AirSimEnvLogger", "level": "ERROR", "message": "Error during training: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 144, 256, 3] to have 3 channels, but got 144 channels instead"}
{"time": "2024-07-21T14:34:04.027766", "name": "AirSimEnvLogger", "level": "ERROR", "message": "An error occurred in main: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 144, 256, 3] to have 3 channels, but got 144 channels instead"}
{"time": "2024-07-21T14:34:09.549724", "name": "AirSimEnvLogger", "level": "INFO", "message": "Environment closed."}
{"time": "2024-07-21T14:34:09.675260", "name": "AirSimEnvLogger", "level": "INFO", "message": "Training script execution finished."}
{"time": "2024-07-21T14:36:28.801469", "name": "AirSimEnvLogger", "level": "INFO", "message": "Initialized with state_dim: 16, action_dim: 4"}
{"time": "2024-07-21T14:36:28.817774", "name": "AirSimEnvLogger", "level": "INFO", "message": "Initializing AirSimEnv"}
{"time": "2024-07-21T14:36:28.818784", "name": "AirSimEnvLogger", "level": "INFO", "message": "Configuration: {\n  \"learning_rate\": 0.0001,\n  \"gamma\": 0.99,\n  \"tau\": 0.95,\n  \"batch_size\": 64,\n  \"num_timesteps\": 2000000,\n  \"ppo\": {\n    \"learning_rate\": 0.0003,\n    \"n_steps\": 2048,\n    \"batch_size\": 64,\n    \"n_epochs\": 2000,\n    \"gamma\": 0.99,\n    \"gae_lambda\": 0.95,\n    \"clip_range\": 0.2,\n    \"ent_coef\": 0.01,\n    \"vf_coef\": 0.5,\n    \"max_grad_norm\": 0.5,\n    \"use_sde\": true,\n    \"sde_sample_freq\": 4,\n    \"tensorboard_log\": \"logs/tensorboard_logs/ppo_airsim_tensorboard/\",\n    \"verbose\": 1,\n    \"seed\": null,\n    \"device\": \"auto\",\n    \"continuous\": true,\n    \"save_freq\": 10000\n  },\n  \"environment\": {\n    \"env_name\": \"Africa_001\",\n    \"reward_threshold\": 250,\n    \"max_episode_steps\": 1000,\n    \"state_dim\": 16,\n    \"action_dim\": 4,\n    \"reward_scale\": 20,\n    \"proximity_threshold\": 5.0,\n    \"collision_penalty\": 25,\n    \"height_target\": -10,\n    \"height_tolerance\": 1.0,\n    \"height_penalty\": 1,\n    \"movement_penalty\": 0.1,\n    \"smoothness_penalty\": 0.1,\n    \"duration\": 0.1,\n    \"exploration_area\": {\n      \"x_min\": -1000,\n      \"x_max\": 1000,\n      \"y_min\": -1000,\n      \"y_max\": 1000,\n      \"z_min\": -100,\n      \"z_max\": 100\n    }\n  },\n  \"policy_network\": {\n    \"input_size\": 16,\n    \"hidden_layers\": [\n      256,\n      256\n    ],\n    \"output_size\": 4,\n    \"use_batch_norm\": true,\n    \"use_dropout\": true,\n    \"dropout_rate\": 0.2,\n    \"use_attention\": true,\n    \"num_action_heads\": 1\n  },\n  \"critic_network\": {\n    \"input_size\": 16,\n    \"hidden_layers\": [\n      256,\n      256\n    ],\n    \"output_size\": 1,\n    \"use_batch_norm\": true,\n    \"use_dropout\": true,\n    \"dropout_rate\": 0.2,\n    \"use_attention\": true\n  },\n  \"exploration\": {\n    \"strategy\": \"epsilon_decay\",\n    \"initial_epsilon\": 1.0,\n    \"min_epsilon\": 0.05,\n    \"epsilon_decay_rate\": 0.9995\n  },\n  \"model_checkpointing\": {\n    \"checkpoint_interval\": 10,\n    \"save_best_only\": true,\n    \"checkpoint_dir\": \"models/checkpoints\"\n  },\n  \"logging\": {\n    \"log_interval\": 10,\n    \"log_dir\": \"logs/\",\n    \"tensorboard\": true,\n    \"tensorboard_log_dir\": \"logs/tensorboard_logs\",\n    \"model_save_path\": \"models/saved_models\"\n  },\n  \"advanced_training_techniques\": {\n    \"gradient_clipping\": 0.5,\n    \"use_gae\": true,\n    \"gae_lambda\": 0.95,\n    \"normalize_advantages\": true\n  },\n  \"early_stopping\": {\n    \"patience\": 10\n  },\n  \"reward_adjustments\": {\n    \"collision_penalty\": 50,\n    \"reward_threshold\": 250\n  },\n  \"shared_components\": {\n    \"residual_block\": {\n      \"input_dim\": 128,\n      \"hidden_dim\": 128,\n      \"dropout_rate\": 0.2\n    },\n    \"attention_layer\": {\n      \"input_dim\": 128,\n      \"hidden_dim\": 128\n    }\n  },\n  \"icm\": {\n    \"state_dim\": 16,\n    \"action_dim\": 4,\n    \"image_channels\": 3,\n    \"image_height\": 144,\n    \"image_width\": 256,\n    \"cnn\": {\n      \"conv1\": {\n        \"out_channels\": 32,\n        \"kernel_size\": 8,\n        \"stride\": 4\n      },\n      \"conv2\": {\n        \"out_channels\": 64,\n        \"kernel_size\": 4,\n        \"stride\": 2\n      },\n      \"conv3\": {\n        \"out_channels\": 64,\n        \"kernel_size\": 3,\n        \"stride\": 1\n      }\n    },\n    \"state_encoder\": {\n      \"hidden_dim\": 128\n    },\n    \"forward_model\": {\n      \"hidden_dim\": 256\n    },\n    \"inverse_model\": {\n      \"hidden_dim\": 256\n    }\n  },\n  \"predictive_model\": {\n    \"learning_rate\": 0.0001,\n    \"hidden_layers\": [\n      256,\n      256\n    ]\n  },\n  \"hrl\": {\n    \"use_hierarchical\": true,\n    \"high_level_policy\": {\n      \"input_size\": 16,\n      \"hidden_layers\": [\n        256,\n        256\n      ],\n      \"output_size\": 4\n    },\n    \"sub_goal_dim\": 3,\n    \"low_level_policy\": {\n      \"input_size\": 19,\n      \"hidden_layers\": [\n        256,\n        256\n      ],\n      \"output_size\": 4\n    }\n  },\n  \"curriculum_learning\": {\n    \"use_curriculum\": true,\n    \"initial_difficulty\": 1,\n    \"difficulty_increment\": 1,\n    \"difficulty_threshold\": 200\n  },\n  \"multi_agent\": {\n    \"use_multi_agent\": true,\n    \"num_agents\": 2,\n    \"hidden_layers\": [\n      256,\n      256\n    ]\n  }\n}"}
{"time": "2024-07-21T14:36:30.189349", "name": "AirSimEnvLogger", "level": "ERROR", "message": "Error initializing policy network: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 144, 256, 3] to have 3 channels, but got 144 channels instead"}
{"time": "2024-07-21T14:36:30.190372", "name": "AirSimEnvLogger", "level": "ERROR", "message": "An error occurred in main: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 144, 256, 3] to have 3 channels, but got 144 channels instead"}
{"time": "2024-07-21T14:36:30.200434", "name": "AirSimEnvLogger", "level": "INFO", "message": "Training script execution finished."}
{"time": "2024-07-21T14:41:49.192108", "name": "AirSimEnvLogger", "level": "INFO", "message": "Initialized with state_dim: 16, action_dim: 4"}
{"time": "2024-07-21T14:41:49.207621", "name": "AirSimEnvLogger", "level": "INFO", "message": "Initializing AirSimEnv"}
{"time": "2024-07-21T14:41:49.207621", "name": "AirSimEnvLogger", "level": "INFO", "message": "Configuration: {\n  \"learning_rate\": 0.0001,\n  \"gamma\": 0.99,\n  \"tau\": 0.95,\n  \"batch_size\": 64,\n  \"num_timesteps\": 2000000,\n  \"ppo\": {\n    \"learning_rate\": 0.0003,\n    \"n_steps\": 2048,\n    \"batch_size\": 64,\n    \"n_epochs\": 2000,\n    \"gamma\": 0.99,\n    \"gae_lambda\": 0.95,\n    \"clip_range\": 0.2,\n    \"ent_coef\": 0.01,\n    \"vf_coef\": 0.5,\n    \"max_grad_norm\": 0.5,\n    \"use_sde\": true,\n    \"sde_sample_freq\": 4,\n    \"tensorboard_log\": \"logs/tensorboard_logs/ppo_airsim_tensorboard/\",\n    \"verbose\": 1,\n    \"seed\": null,\n    \"device\": \"auto\",\n    \"continuous\": true,\n    \"save_freq\": 10000\n  },\n  \"environment\": {\n    \"env_name\": \"Africa_001\",\n    \"reward_threshold\": 250,\n    \"max_episode_steps\": 1000,\n    \"state_dim\": 16,\n    \"action_dim\": 4,\n    \"reward_scale\": 20,\n    \"proximity_threshold\": 5.0,\n    \"collision_penalty\": 25,\n    \"height_target\": -10,\n    \"height_tolerance\": 1.0,\n    \"height_penalty\": 1,\n    \"movement_penalty\": 0.1,\n    \"smoothness_penalty\": 0.1,\n    \"duration\": 0.1,\n    \"exploration_area\": {\n      \"x_min\": -1000,\n      \"x_max\": 1000,\n      \"y_min\": -1000,\n      \"y_max\": 1000,\n      \"z_min\": -100,\n      \"z_max\": 100\n    }\n  },\n  \"policy_network\": {\n    \"input_size\": 16,\n    \"hidden_layers\": [\n      256,\n      256\n    ],\n    \"output_size\": 4,\n    \"use_batch_norm\": true,\n    \"use_dropout\": true,\n    \"dropout_rate\": 0.2,\n    \"use_attention\": true,\n    \"num_action_heads\": 1\n  },\n  \"critic_network\": {\n    \"input_size\": 16,\n    \"hidden_layers\": [\n      256,\n      256\n    ],\n    \"output_size\": 1,\n    \"use_batch_norm\": true,\n    \"use_dropout\": true,\n    \"dropout_rate\": 0.2,\n    \"use_attention\": true\n  },\n  \"exploration\": {\n    \"strategy\": \"epsilon_decay\",\n    \"initial_epsilon\": 1.0,\n    \"min_epsilon\": 0.05,\n    \"epsilon_decay_rate\": 0.9995\n  },\n  \"model_checkpointing\": {\n    \"checkpoint_interval\": 10,\n    \"save_best_only\": true,\n    \"checkpoint_dir\": \"models/checkpoints\"\n  },\n  \"logging\": {\n    \"log_interval\": 10,\n    \"log_dir\": \"logs/\",\n    \"tensorboard\": true,\n    \"tensorboard_log_dir\": \"logs/tensorboard_logs\",\n    \"model_save_path\": \"models/saved_models\"\n  },\n  \"advanced_training_techniques\": {\n    \"gradient_clipping\": 0.5,\n    \"use_gae\": true,\n    \"gae_lambda\": 0.95,\n    \"normalize_advantages\": true\n  },\n  \"early_stopping\": {\n    \"patience\": 10\n  },\n  \"reward_adjustments\": {\n    \"collision_penalty\": 50,\n    \"reward_threshold\": 250\n  },\n  \"shared_components\": {\n    \"residual_block\": {\n      \"input_dim\": 128,\n      \"hidden_dim\": 128,\n      \"dropout_rate\": 0.2\n    },\n    \"attention_layer\": {\n      \"input_dim\": 128,\n      \"hidden_dim\": 128\n    }\n  },\n  \"icm\": {\n    \"state_dim\": 16,\n    \"action_dim\": 4,\n    \"image_channels\": 3,\n    \"image_height\": 144,\n    \"image_width\": 256,\n    \"cnn\": {\n      \"conv1\": {\n        \"out_channels\": 32,\n        \"kernel_size\": 8,\n        \"stride\": 4\n      },\n      \"conv2\": {\n        \"out_channels\": 64,\n        \"kernel_size\": 4,\n        \"stride\": 2\n      },\n      \"conv3\": {\n        \"out_channels\": 64,\n        \"kernel_size\": 3,\n        \"stride\": 1\n      }\n    },\n    \"state_encoder\": {\n      \"hidden_dim\": 128\n    },\n    \"forward_model\": {\n      \"hidden_dim\": 256\n    },\n    \"inverse_model\": {\n      \"hidden_dim\": 256\n    }\n  },\n  \"predictive_model\": {\n    \"learning_rate\": 0.0001,\n    \"hidden_layers\": [\n      256,\n      256\n    ]\n  },\n  \"hrl\": {\n    \"use_hierarchical\": true,\n    \"high_level_policy\": {\n      \"input_size\": 16,\n      \"hidden_layers\": [\n        256,\n        256\n      ],\n      \"output_size\": 4\n    },\n    \"sub_goal_dim\": 3,\n    \"low_level_policy\": {\n      \"input_size\": 19,\n      \"hidden_layers\": [\n        256,\n        256\n      ],\n      \"output_size\": 4\n    }\n  },\n  \"curriculum_learning\": {\n    \"use_curriculum\": true,\n    \"initial_difficulty\": 1,\n    \"difficulty_increment\": 1,\n    \"difficulty_threshold\": 200\n  },\n  \"multi_agent\": {\n    \"use_multi_agent\": true,\n    \"num_agents\": 2,\n    \"hidden_layers\": [\n      256,\n      256\n    ]\n  }\n}"}
{"time": "2024-07-21T14:41:50.797230", "name": "AirSimEnvLogger", "level": "INFO", "message": "DataVisualizer initialized with Seaborn style set to 'whitegrid'."}
{"time": "2024-07-21T14:41:50.799231", "name": "AirSimEnvLogger", "level": "INFO", "message": "Using device: cpu"}
{"time": "2024-07-21T14:41:56.361289", "name": "AirSimEnvLogger", "level": "INFO", "message": "PPOAgent initialized successfully."}
{"time": "2024-07-21T14:42:00.928961", "name": "AirSimEnvLogger", "level": "INFO", "message": "Environment reset and takeoff completed."}
{"time": "2024-07-21T14:42:01.553962", "name": "AirSimEnvLogger", "level": "INFO", "message": "Reset completed. Observation keys: dict_keys(['state', 'visual'])"}
{"time": "2024-07-21T14:42:01.553962", "name": "AirSimEnvLogger", "level": "INFO", "message": "State shape: (16,), Visual shape: (144, 256, 3)"}
{"time": "2024-07-21T14:42:01.649018", "name": "AirSimEnvLogger", "level": "INFO", "message": "Visual tensor shape after permute: torch.Size([1, 3, 144, 256])"}
{"time": "2024-07-21T14:42:03.034337", "name": "AirSimEnvLogger", "level": "ERROR", "message": "Error during training: Tensors must have same number of dimensions: got 3 and 2"}
{"time": "2024-07-21T14:42:03.034337", "name": "AirSimEnvLogger", "level": "ERROR", "message": "An error occurred in main: Tensors must have same number of dimensions: got 3 and 2"}
{"time": "2024-07-21T14:42:08.614028", "name": "AirSimEnvLogger", "level": "INFO", "message": "Environment closed."}
{"time": "2024-07-21T14:42:08.645883", "name": "AirSimEnvLogger", "level": "INFO", "message": "Training script execution finished."}
{"time": "2024-07-21T14:44:53.807186", "name": "AirSimEnvLogger", "level": "INFO", "message": "Initialized with state_dim: 16, action_dim: 4"}
{"time": "2024-07-21T14:44:53.822817", "name": "AirSimEnvLogger", "level": "INFO", "message": "Initializing AirSimEnv"}
{"time": "2024-07-21T14:44:53.823818", "name": "AirSimEnvLogger", "level": "INFO", "message": "Configuration: {\n  \"learning_rate\": 0.0001,\n  \"gamma\": 0.99,\n  \"tau\": 0.95,\n  \"batch_size\": 64,\n  \"num_timesteps\": 2000000,\n  \"ppo\": {\n    \"learning_rate\": 0.0003,\n    \"n_steps\": 2048,\n    \"batch_size\": 64,\n    \"n_epochs\": 2000,\n    \"gamma\": 0.99,\n    \"gae_lambda\": 0.95,\n    \"clip_range\": 0.2,\n    \"ent_coef\": 0.01,\n    \"vf_coef\": 0.5,\n    \"max_grad_norm\": 0.5,\n    \"use_sde\": true,\n    \"sde_sample_freq\": 4,\n    \"tensorboard_log\": \"logs/tensorboard_logs/ppo_airsim_tensorboard/\",\n    \"verbose\": 1,\n    \"seed\": null,\n    \"device\": \"auto\",\n    \"continuous\": true,\n    \"save_freq\": 10000\n  },\n  \"environment\": {\n    \"env_name\": \"Africa_001\",\n    \"reward_threshold\": 250,\n    \"max_episode_steps\": 1000,\n    \"state_dim\": 16,\n    \"action_dim\": 4,\n    \"reward_scale\": 20,\n    \"proximity_threshold\": 5.0,\n    \"collision_penalty\": 25,\n    \"height_target\": -10,\n    \"height_tolerance\": 1.0,\n    \"height_penalty\": 1,\n    \"movement_penalty\": 0.1,\n    \"smoothness_penalty\": 0.1,\n    \"duration\": 0.1,\n    \"exploration_area\": {\n      \"x_min\": -1000,\n      \"x_max\": 1000,\n      \"y_min\": -1000,\n      \"y_max\": 1000,\n      \"z_min\": -100,\n      \"z_max\": 100\n    }\n  },\n  \"policy_network\": {\n    \"input_size\": 16,\n    \"hidden_layers\": [\n      256,\n      256\n    ],\n    \"output_size\": 4,\n    \"use_batch_norm\": true,\n    \"use_dropout\": true,\n    \"dropout_rate\": 0.2,\n    \"use_attention\": true,\n    \"num_action_heads\": 1\n  },\n  \"critic_network\": {\n    \"input_size\": 16,\n    \"hidden_layers\": [\n      256,\n      256\n    ],\n    \"output_size\": 1,\n    \"use_batch_norm\": true,\n    \"use_dropout\": true,\n    \"dropout_rate\": 0.2,\n    \"use_attention\": true\n  },\n  \"exploration\": {\n    \"strategy\": \"epsilon_decay\",\n    \"initial_epsilon\": 1.0,\n    \"min_epsilon\": 0.05,\n    \"epsilon_decay_rate\": 0.9995\n  },\n  \"model_checkpointing\": {\n    \"checkpoint_interval\": 10,\n    \"save_best_only\": true,\n    \"checkpoint_dir\": \"models/checkpoints\"\n  },\n  \"logging\": {\n    \"log_interval\": 10,\n    \"log_dir\": \"logs/\",\n    \"tensorboard\": true,\n    \"tensorboard_log_dir\": \"logs/tensorboard_logs\",\n    \"model_save_path\": \"models/saved_models\"\n  },\n  \"advanced_training_techniques\": {\n    \"gradient_clipping\": 0.5,\n    \"use_gae\": true,\n    \"gae_lambda\": 0.95,\n    \"normalize_advantages\": true\n  },\n  \"early_stopping\": {\n    \"patience\": 10\n  },\n  \"reward_adjustments\": {\n    \"collision_penalty\": 50,\n    \"reward_threshold\": 250\n  },\n  \"shared_components\": {\n    \"residual_block\": {\n      \"input_dim\": 128,\n      \"hidden_dim\": 128,\n      \"dropout_rate\": 0.2\n    },\n    \"attention_layer\": {\n      \"input_dim\": 128,\n      \"hidden_dim\": 128\n    }\n  },\n  \"icm\": {\n    \"state_dim\": 16,\n    \"action_dim\": 4,\n    \"image_channels\": 3,\n    \"image_height\": 144,\n    \"image_width\": 256,\n    \"cnn\": {\n      \"conv1\": {\n        \"out_channels\": 32,\n        \"kernel_size\": 8,\n        \"stride\": 4\n      },\n      \"conv2\": {\n        \"out_channels\": 64,\n        \"kernel_size\": 4,\n        \"stride\": 2\n      },\n      \"conv3\": {\n        \"out_channels\": 64,\n        \"kernel_size\": 3,\n        \"stride\": 1\n      }\n    },\n    \"state_encoder\": {\n      \"hidden_dim\": 128\n    },\n    \"forward_model\": {\n      \"hidden_dim\": 256\n    },\n    \"inverse_model\": {\n      \"hidden_dim\": 256\n    }\n  },\n  \"predictive_model\": {\n    \"learning_rate\": 0.0001,\n    \"hidden_layers\": [\n      256,\n      256\n    ]\n  },\n  \"hrl\": {\n    \"use_hierarchical\": true,\n    \"high_level_policy\": {\n      \"input_size\": 16,\n      \"hidden_layers\": [\n        256,\n        256\n      ],\n      \"output_size\": 4\n    },\n    \"sub_goal_dim\": 3,\n    \"low_level_policy\": {\n      \"input_size\": 19,\n      \"hidden_layers\": [\n        256,\n        256\n      ],\n      \"output_size\": 4\n    }\n  },\n  \"curriculum_learning\": {\n    \"use_curriculum\": true,\n    \"initial_difficulty\": 1,\n    \"difficulty_increment\": 1,\n    \"difficulty_threshold\": 200\n  },\n  \"multi_agent\": {\n    \"use_multi_agent\": true,\n    \"num_agents\": 2,\n    \"hidden_layers\": [\n      256,\n      256\n    ]\n  }\n}"}
{"time": "2024-07-21T14:44:55.443249", "name": "AirSimEnvLogger", "level": "INFO", "message": "DataVisualizer initialized with Seaborn style set to 'whitegrid'."}
{"time": "2024-07-21T14:44:55.445249", "name": "AirSimEnvLogger", "level": "INFO", "message": "Using device: cpu"}
{"time": "2024-07-21T14:45:01.317990", "name": "AirSimEnvLogger", "level": "INFO", "message": "PPOAgent initialized successfully."}
{"time": "2024-07-21T14:45:06.042402", "name": "AirSimEnvLogger", "level": "INFO", "message": "Environment reset and takeoff completed."}
{"time": "2024-07-21T14:45:06.576546", "name": "AirSimEnvLogger", "level": "INFO", "message": "Reset completed. Observation keys: dict_keys(['state', 'visual'])"}
{"time": "2024-07-21T14:45:06.576546", "name": "AirSimEnvLogger", "level": "INFO", "message": "State shape: (16,), Visual shape: (144, 256, 3)"}
{"time": "2024-07-21T14:45:06.686949", "name": "AirSimEnvLogger", "level": "INFO", "message": "Visual tensor shape after permute: torch.Size([1, 3, 144, 256])"}
{"time": "2024-07-21T14:45:08.095885", "name": "AirSimEnvLogger", "level": "ERROR", "message": "Error during training: Tensors must have same number of dimensions: got 3 and 2"}
{"time": "2024-07-21T14:45:08.095885", "name": "AirSimEnvLogger", "level": "ERROR", "message": "An error occurred in main: Tensors must have same number of dimensions: got 3 and 2"}
{"time": "2024-07-21T14:45:13.809290", "name": "AirSimEnvLogger", "level": "INFO", "message": "Environment closed."}
{"time": "2024-07-21T14:45:13.934551", "name": "AirSimEnvLogger", "level": "INFO", "message": "Training script execution finished."}
{"time": "2024-07-21T14:56:07.460407", "name": "AirSimEnvLogger", "level": "INFO", "message": "Initialized with state_dim: 16, action_dim: 4"}
{"time": "2024-07-21T14:56:07.476425", "name": "AirSimEnvLogger", "level": "INFO", "message": "Initializing AirSimEnv"}
{"time": "2024-07-21T14:56:07.477432", "name": "AirSimEnvLogger", "level": "INFO", "message": "Configuration: {\n  \"learning_rate\": 0.0001,\n  \"gamma\": 0.99,\n  \"tau\": 0.95,\n  \"batch_size\": 64,\n  \"num_timesteps\": 2000000,\n  \"ppo\": {\n    \"learning_rate\": 0.0003,\n    \"n_steps\": 2048,\n    \"batch_size\": 64,\n    \"n_epochs\": 2000,\n    \"gamma\": 0.99,\n    \"gae_lambda\": 0.95,\n    \"clip_range\": 0.2,\n    \"ent_coef\": 0.01,\n    \"vf_coef\": 0.5,\n    \"max_grad_norm\": 0.5,\n    \"use_sde\": true,\n    \"sde_sample_freq\": 4,\n    \"tensorboard_log\": \"logs/tensorboard_logs/ppo_airsim_tensorboard/\",\n    \"verbose\": 1,\n    \"seed\": null,\n    \"device\": \"auto\",\n    \"continuous\": true,\n    \"save_freq\": 10000\n  },\n  \"environment\": {\n    \"env_name\": \"Africa_001\",\n    \"reward_threshold\": 250,\n    \"max_episode_steps\": 1000,\n    \"state_dim\": 16,\n    \"action_dim\": 4,\n    \"reward_scale\": 20,\n    \"proximity_threshold\": 5.0,\n    \"collision_penalty\": 25,\n    \"height_target\": -10,\n    \"height_tolerance\": 1.0,\n    \"height_penalty\": 1,\n    \"movement_penalty\": 0.1,\n    \"smoothness_penalty\": 0.1,\n    \"duration\": 0.1,\n    \"exploration_area\": {\n      \"x_min\": -1000,\n      \"x_max\": 1000,\n      \"y_min\": -1000,\n      \"y_max\": 1000,\n      \"z_min\": -100,\n      \"z_max\": 100\n    }\n  },\n  \"policy_network\": {\n    \"input_size\": 16,\n    \"hidden_layers\": [\n      256,\n      256\n    ],\n    \"output_size\": 4,\n    \"use_batch_norm\": true,\n    \"use_dropout\": true,\n    \"dropout_rate\": 0.2,\n    \"use_attention\": true,\n    \"num_action_heads\": 1\n  },\n  \"critic_network\": {\n    \"input_size\": 16,\n    \"hidden_layers\": [\n      256,\n      256\n    ],\n    \"output_size\": 1,\n    \"use_batch_norm\": true,\n    \"use_dropout\": true,\n    \"dropout_rate\": 0.2,\n    \"use_attention\": true\n  },\n  \"exploration\": {\n    \"strategy\": \"epsilon_decay\",\n    \"initial_epsilon\": 1.0,\n    \"min_epsilon\": 0.05,\n    \"epsilon_decay_rate\": 0.9995\n  },\n  \"model_checkpointing\": {\n    \"checkpoint_interval\": 10,\n    \"save_best_only\": true,\n    \"checkpoint_dir\": \"models/checkpoints\"\n  },\n  \"logging\": {\n    \"log_interval\": 10,\n    \"log_dir\": \"logs/\",\n    \"tensorboard\": true,\n    \"tensorboard_log_dir\": \"logs/tensorboard_logs\",\n    \"model_save_path\": \"models/saved_models\"\n  },\n  \"advanced_training_techniques\": {\n    \"gradient_clipping\": 0.5,\n    \"use_gae\": true,\n    \"gae_lambda\": 0.95,\n    \"normalize_advantages\": true\n  },\n  \"early_stopping\": {\n    \"patience\": 10\n  },\n  \"reward_adjustments\": {\n    \"collision_penalty\": 50,\n    \"reward_threshold\": 250\n  },\n  \"shared_components\": {\n    \"residual_block\": {\n      \"input_dim\": 128,\n      \"hidden_dim\": 128,\n      \"dropout_rate\": 0.2\n    },\n    \"attention_layer\": {\n      \"input_dim\": 128,\n      \"hidden_dim\": 128\n    }\n  },\n  \"icm\": {\n    \"state_dim\": 16,\n    \"action_dim\": 4,\n    \"image_channels\": 3,\n    \"image_height\": 144,\n    \"image_width\": 256,\n    \"cnn\": {\n      \"input_channels\": 3,\n      \"conv1\": {\n        \"out_channels\": 32,\n        \"kernel_size\": 8,\n        \"stride\": 4,\n        \"padding\": 0\n      },\n      \"conv2\": {\n        \"out_channels\": 64,\n        \"kernel_size\": 4,\n        \"stride\": 2,\n        \"padding\": 0\n      },\n      \"conv3\": {\n        \"out_channels\": 64,\n        \"kernel_size\": 3,\n        \"stride\": 1,\n        \"padding\": 0\n      }\n    },\n    \"state_encoder\": {\n      \"hidden_dim\": 128\n    },\n    \"forward_model\": {\n      \"hidden_dim\": 256\n    },\n    \"inverse_model\": {\n      \"hidden_dim\": 256\n    }\n  },\n  \"predictive_model\": {\n    \"learning_rate\": 0.0001,\n    \"hidden_layers\": [\n      256,\n      256\n    ],\n    \"cnn_config\": {\n      \"input_channels\": 3,\n      \"image_height\": 144,\n      \"image_width\": 256,\n      \"conv1\": {\n        \"out_channels\": 32,\n        \"kernel_size\": 8,\n        \"stride\": 4,\n        \"padding\": 0\n      },\n      \"conv2\": {\n        \"out_channels\": 64,\n        \"kernel_size\": 4,\n        \"stride\": 2,\n        \"padding\": 0\n      },\n      \"conv3\": {\n        \"out_channels\": 64,\n        \"kernel_size\": 3,\n        \"stride\": 1,\n        \"padding\": 0\n      }\n    }\n  },\n  \"hrl\": {\n    \"use_hierarchical\": true,\n    \"high_level_policy\": {\n      \"input_size\": 16,\n      \"hidden_layers\": [\n        256,\n        256\n      ],\n      \"output_size\": 4\n    },\n    \"sub_goal_dim\": 3,\n    \"low_level_policy\": {\n      \"input_size\": 19,\n      \"hidden_layers\": [\n        256,\n        256\n      ],\n      \"output_size\": 4\n    }\n  },\n  \"curriculum_learning\": {\n    \"use_curriculum\": true,\n    \"initial_difficulty\": 1,\n    \"difficulty_increment\": 1,\n    \"difficulty_threshold\": 200\n  },\n  \"multi_agent\": {\n    \"use_multi_agent\": true,\n    \"num_agents\": 2,\n    \"hidden_layers\": [\n      256,\n      256\n    ]\n  }\n}"}
{"time": "2024-07-21T14:56:09.053920", "name": "AirSimEnvLogger", "level": "INFO", "message": "DataVisualizer initialized with Seaborn style set to 'whitegrid'."}
{"time": "2024-07-21T14:56:09.053920", "name": "AirSimEnvLogger", "level": "INFO", "message": "Using device: cpu"}
{"time": "2024-07-21T14:56:15.398582", "name": "AirSimEnvLogger", "level": "INFO", "message": "PPOAgent initialized successfully."}
{"time": "2024-07-21T14:56:20.265117", "name": "AirSimEnvLogger", "level": "INFO", "message": "Environment reset and takeoff completed."}
{"time": "2024-07-21T14:56:20.894888", "name": "AirSimEnvLogger", "level": "INFO", "message": "Reset completed. Observation keys: dict_keys(['state', 'visual'])"}
{"time": "2024-07-21T14:56:20.894888", "name": "AirSimEnvLogger", "level": "INFO", "message": "State shape: (16,), Visual shape: (144, 256, 3)"}
{"time": "2024-07-21T14:56:22.494507", "name": "AirSimEnvLogger", "level": "ERROR", "message": "Error during training: mat1 and mat2 shapes cannot be multiplied (1x4096 and 256x256)"}
{"time": "2024-07-21T14:56:22.494507", "name": "AirSimEnvLogger", "level": "ERROR", "message": "An error occurred in main: mat1 and mat2 shapes cannot be multiplied (1x4096 and 256x256)"}
{"time": "2024-07-21T14:56:28.190308", "name": "AirSimEnvLogger", "level": "INFO", "message": "Environment closed."}
{"time": "2024-07-21T14:56:28.253812", "name": "AirSimEnvLogger", "level": "INFO", "message": "Training script execution finished."}
{"time": "2024-07-21T14:57:58.227743", "name": "AirSimEnvLogger", "level": "INFO", "message": "Initialized with state_dim: 16, action_dim: 4"}
{"time": "2024-07-21T14:57:58.248792", "name": "AirSimEnvLogger", "level": "INFO", "message": "Initializing AirSimEnv"}
{"time": "2024-07-21T14:57:58.248792", "name": "AirSimEnvLogger", "level": "INFO", "message": "Configuration: {\n  \"learning_rate\": 0.0001,\n  \"gamma\": 0.99,\n  \"tau\": 0.95,\n  \"batch_size\": 64,\n  \"num_timesteps\": 2000000,\n  \"ppo\": {\n    \"learning_rate\": 0.0003,\n    \"n_steps\": 2048,\n    \"batch_size\": 64,\n    \"n_epochs\": 2000,\n    \"gamma\": 0.99,\n    \"gae_lambda\": 0.95,\n    \"clip_range\": 0.2,\n    \"ent_coef\": 0.01,\n    \"vf_coef\": 0.5,\n    \"max_grad_norm\": 0.5,\n    \"use_sde\": true,\n    \"sde_sample_freq\": 4,\n    \"tensorboard_log\": \"logs/tensorboard_logs/ppo_airsim_tensorboard/\",\n    \"verbose\": 1,\n    \"seed\": null,\n    \"device\": \"auto\",\n    \"continuous\": true,\n    \"save_freq\": 10000\n  },\n  \"environment\": {\n    \"env_name\": \"Africa_001\",\n    \"reward_threshold\": 250,\n    \"max_episode_steps\": 1000,\n    \"state_dim\": 16,\n    \"action_dim\": 4,\n    \"reward_scale\": 20,\n    \"proximity_threshold\": 5.0,\n    \"collision_penalty\": 25,\n    \"height_target\": -10,\n    \"height_tolerance\": 1.0,\n    \"height_penalty\": 1,\n    \"movement_penalty\": 0.1,\n    \"smoothness_penalty\": 0.1,\n    \"duration\": 0.1,\n    \"exploration_area\": {\n      \"x_min\": -1000,\n      \"x_max\": 1000,\n      \"y_min\": -1000,\n      \"y_max\": 1000,\n      \"z_min\": -100,\n      \"z_max\": 100\n    }\n  },\n  \"policy_network\": {\n    \"input_size\": 16,\n    \"hidden_layers\": [\n      256,\n      256\n    ],\n    \"output_size\": 4,\n    \"use_batch_norm\": true,\n    \"use_dropout\": true,\n    \"dropout_rate\": 0.2,\n    \"use_attention\": true,\n    \"num_action_heads\": 1\n  },\n  \"critic_network\": {\n    \"input_size\": 16,\n    \"hidden_layers\": [\n      256,\n      256\n    ],\n    \"output_size\": 1,\n    \"use_batch_norm\": true,\n    \"use_dropout\": true,\n    \"dropout_rate\": 0.2,\n    \"use_attention\": true\n  },\n  \"exploration\": {\n    \"strategy\": \"epsilon_decay\",\n    \"initial_epsilon\": 1.0,\n    \"min_epsilon\": 0.05,\n    \"epsilon_decay_rate\": 0.9995\n  },\n  \"model_checkpointing\": {\n    \"checkpoint_interval\": 10,\n    \"save_best_only\": true,\n    \"checkpoint_dir\": \"models/checkpoints\"\n  },\n  \"logging\": {\n    \"log_interval\": 10,\n    \"log_dir\": \"logs/\",\n    \"tensorboard\": true,\n    \"tensorboard_log_dir\": \"logs/tensorboard_logs\",\n    \"model_save_path\": \"models/saved_models\"\n  },\n  \"advanced_training_techniques\": {\n    \"gradient_clipping\": 0.5,\n    \"use_gae\": true,\n    \"gae_lambda\": 0.95,\n    \"normalize_advantages\": true\n  },\n  \"early_stopping\": {\n    \"patience\": 10\n  },\n  \"reward_adjustments\": {\n    \"collision_penalty\": 50,\n    \"reward_threshold\": 250\n  },\n  \"shared_components\": {\n    \"residual_block\": {\n      \"input_dim\": 128,\n      \"hidden_dim\": 128,\n      \"dropout_rate\": 0.2\n    },\n    \"attention_layer\": {\n      \"input_dim\": 128,\n      \"hidden_dim\": 128\n    }\n  },\n  \"icm\": {\n    \"state_dim\": 16,\n    \"action_dim\": 4,\n    \"image_channels\": 3,\n    \"image_height\": 144,\n    \"image_width\": 256,\n    \"cnn\": {\n      \"input_channels\": 3,\n      \"conv1\": {\n        \"out_channels\": 32,\n        \"kernel_size\": 8,\n        \"stride\": 4,\n        \"padding\": 0\n      },\n      \"conv2\": {\n        \"out_channels\": 64,\n        \"kernel_size\": 4,\n        \"stride\": 2,\n        \"padding\": 0\n      },\n      \"conv3\": {\n        \"out_channels\": 64,\n        \"kernel_size\": 3,\n        \"stride\": 1,\n        \"padding\": 0\n      }\n    },\n    \"state_encoder\": {\n      \"hidden_dim\": 128\n    },\n    \"forward_model\": {\n      \"hidden_dim\": 256\n    },\n    \"inverse_model\": {\n      \"hidden_dim\": 256\n    }\n  },\n  \"predictive_model\": {\n    \"learning_rate\": 0.0001,\n    \"hidden_layers\": [\n      256,\n      256\n    ],\n    \"cnn_config\": {\n      \"input_channels\": 3,\n      \"image_height\": 144,\n      \"image_width\": 256,\n      \"conv1\": {\n        \"out_channels\": 32,\n        \"kernel_size\": 8,\n        \"stride\": 4,\n        \"padding\": 0\n      },\n      \"conv2\": {\n        \"out_channels\": 64,\n        \"kernel_size\": 4,\n        \"stride\": 2,\n        \"padding\": 0\n      },\n      \"conv3\": {\n        \"out_channels\": 64,\n        \"kernel_size\": 3,\n        \"stride\": 1,\n        \"padding\": 0\n      }\n    }\n  },\n  \"hrl\": {\n    \"use_hierarchical\": true,\n    \"high_level_policy\": {\n      \"input_size\": 16,\n      \"hidden_layers\": [\n        256,\n        256\n      ],\n      \"output_size\": 4\n    },\n    \"sub_goal_dim\": 3,\n    \"low_level_policy\": {\n      \"input_size\": 19,\n      \"hidden_layers\": [\n        256,\n        256\n      ],\n      \"output_size\": 4\n    }\n  },\n  \"curriculum_learning\": {\n    \"use_curriculum\": true,\n    \"initial_difficulty\": 1,\n    \"difficulty_increment\": 1,\n    \"difficulty_threshold\": 200\n  },\n  \"multi_agent\": {\n    \"use_multi_agent\": true,\n    \"num_agents\": 2,\n    \"hidden_layers\": [\n      256,\n      256\n    ]\n  }\n}"}
{"time": "2024-07-21T14:57:59.875919", "name": "AirSimEnvLogger", "level": "INFO", "message": "DataVisualizer initialized with Seaborn style set to 'whitegrid'."}
{"time": "2024-07-21T14:57:59.876929", "name": "AirSimEnvLogger", "level": "INFO", "message": "Using device: cpu"}
{"time": "2024-07-21T14:58:06.430679", "name": "AirSimEnvLogger", "level": "INFO", "message": "PPOAgent initialized successfully."}
{"time": "2024-07-21T14:58:11.889231", "name": "AirSimEnvLogger", "level": "INFO", "message": "Environment reset and takeoff completed."}
{"time": "2024-07-21T14:58:12.487901", "name": "AirSimEnvLogger", "level": "INFO", "message": "Reset completed. Observation keys: dict_keys(['state', 'visual'])"}
{"time": "2024-07-21T14:58:12.487901", "name": "AirSimEnvLogger", "level": "INFO", "message": "State shape: (16,), Visual shape: (144, 256, 3)"}
{"time": "2024-07-21T14:58:14.479529", "name": "AirSimEnvLogger", "level": "ERROR", "message": "Error during training: mat1 and mat2 shapes cannot be multiplied (1x4096 and 256x256)"}
{"time": "2024-07-21T14:58:14.479529", "name": "AirSimEnvLogger", "level": "ERROR", "message": "An error occurred in main: mat1 and mat2 shapes cannot be multiplied (1x4096 and 256x256)"}
{"time": "2024-07-21T14:58:20.514282", "name": "AirSimEnvLogger", "level": "INFO", "message": "Environment closed."}
{"time": "2024-07-21T14:58:20.561697", "name": "AirSimEnvLogger", "level": "INFO", "message": "Training script execution finished."}
{"time": "2024-07-21T15:00:07.506173", "name": "AirSimEnvLogger", "level": "INFO", "message": "Initialized with state_dim: 16, action_dim: 4"}
{"time": "2024-07-21T15:00:07.523707", "name": "AirSimEnvLogger", "level": "INFO", "message": "Initializing AirSimEnv"}
{"time": "2024-07-21T15:00:07.523707", "name": "AirSimEnvLogger", "level": "INFO", "message": "Configuration: {\n  \"learning_rate\": 0.0001,\n  \"gamma\": 0.99,\n  \"tau\": 0.95,\n  \"batch_size\": 64,\n  \"num_timesteps\": 2000000,\n  \"ppo\": {\n    \"learning_rate\": 0.0003,\n    \"n_steps\": 2048,\n    \"batch_size\": 64,\n    \"n_epochs\": 2000,\n    \"gamma\": 0.99,\n    \"gae_lambda\": 0.95,\n    \"clip_range\": 0.2,\n    \"ent_coef\": 0.01,\n    \"vf_coef\": 0.5,\n    \"max_grad_norm\": 0.5,\n    \"use_sde\": true,\n    \"sde_sample_freq\": 4,\n    \"tensorboard_log\": \"logs/tensorboard_logs/ppo_airsim_tensorboard/\",\n    \"verbose\": 1,\n    \"seed\": null,\n    \"device\": \"auto\",\n    \"continuous\": true,\n    \"save_freq\": 10000\n  },\n  \"environment\": {\n    \"env_name\": \"Africa_001\",\n    \"reward_threshold\": 250,\n    \"max_episode_steps\": 1000,\n    \"state_dim\": 16,\n    \"action_dim\": 4,\n    \"reward_scale\": 20,\n    \"proximity_threshold\": 5.0,\n    \"collision_penalty\": 25,\n    \"height_target\": -10,\n    \"height_tolerance\": 1.0,\n    \"height_penalty\": 1,\n    \"movement_penalty\": 0.1,\n    \"smoothness_penalty\": 0.1,\n    \"duration\": 0.1,\n    \"exploration_area\": {\n      \"x_min\": -1000,\n      \"x_max\": 1000,\n      \"y_min\": -1000,\n      \"y_max\": 1000,\n      \"z_min\": -100,\n      \"z_max\": 100\n    }\n  },\n  \"policy_network\": {\n    \"input_size\": 16,\n    \"hidden_layers\": [\n      256,\n      256\n    ],\n    \"output_size\": 4,\n    \"use_batch_norm\": true,\n    \"use_dropout\": true,\n    \"dropout_rate\": 0.2,\n    \"use_attention\": true,\n    \"num_action_heads\": 1\n  },\n  \"critic_network\": {\n    \"input_size\": 16,\n    \"hidden_layers\": [\n      256,\n      256\n    ],\n    \"output_size\": 1,\n    \"use_batch_norm\": true,\n    \"use_dropout\": true,\n    \"dropout_rate\": 0.2,\n    \"use_attention\": true\n  },\n  \"exploration\": {\n    \"strategy\": \"epsilon_decay\",\n    \"initial_epsilon\": 1.0,\n    \"min_epsilon\": 0.05,\n    \"epsilon_decay_rate\": 0.9995\n  },\n  \"model_checkpointing\": {\n    \"checkpoint_interval\": 10,\n    \"save_best_only\": true,\n    \"checkpoint_dir\": \"models/checkpoints\"\n  },\n  \"logging\": {\n    \"log_interval\": 10,\n    \"log_dir\": \"logs/\",\n    \"tensorboard\": true,\n    \"tensorboard_log_dir\": \"logs/tensorboard_logs\",\n    \"model_save_path\": \"models/saved_models\"\n  },\n  \"advanced_training_techniques\": {\n    \"gradient_clipping\": 0.5,\n    \"use_gae\": true,\n    \"gae_lambda\": 0.95,\n    \"normalize_advantages\": true\n  },\n  \"early_stopping\": {\n    \"patience\": 10\n  },\n  \"reward_adjustments\": {\n    \"collision_penalty\": 50,\n    \"reward_threshold\": 250\n  },\n  \"shared_components\": {\n    \"residual_block\": {\n      \"input_dim\": 128,\n      \"hidden_dim\": 128,\n      \"dropout_rate\": 0.2\n    },\n    \"attention_layer\": {\n      \"input_dim\": 128,\n      \"hidden_dim\": 128\n    }\n  },\n  \"icm\": {\n    \"state_dim\": 16,\n    \"action_dim\": 4,\n    \"image_channels\": 3,\n    \"image_height\": 144,\n    \"image_width\": 256,\n    \"cnn\": {\n      \"input_channels\": 3,\n      \"conv1\": {\n        \"out_channels\": 32,\n        \"kernel_size\": 8,\n        \"stride\": 4,\n        \"padding\": 0\n      },\n      \"conv2\": {\n        \"out_channels\": 64,\n        \"kernel_size\": 4,\n        \"stride\": 2,\n        \"padding\": 0\n      },\n      \"conv3\": {\n        \"out_channels\": 64,\n        \"kernel_size\": 3,\n        \"stride\": 1,\n        \"padding\": 0\n      }\n    },\n    \"state_encoder\": {\n      \"hidden_dim\": 128\n    },\n    \"forward_model\": {\n      \"hidden_dim\": 256\n    },\n    \"inverse_model\": {\n      \"hidden_dim\": 256\n    }\n  },\n  \"predictive_model\": {\n    \"learning_rate\": 0.0001,\n    \"hidden_layers\": [\n      256,\n      256\n    ],\n    \"cnn_config\": {\n      \"input_channels\": 3,\n      \"image_height\": 144,\n      \"image_width\": 256,\n      \"conv1\": {\n        \"out_channels\": 32,\n        \"kernel_size\": 8,\n        \"stride\": 4,\n        \"padding\": 0\n      },\n      \"conv2\": {\n        \"out_channels\": 64,\n        \"kernel_size\": 4,\n        \"stride\": 2,\n        \"padding\": 0\n      },\n      \"conv3\": {\n        \"out_channels\": 64,\n        \"kernel_size\": 3,\n        \"stride\": 1,\n        \"padding\": 0\n      }\n    }\n  },\n  \"hrl\": {\n    \"use_hierarchical\": true,\n    \"high_level_policy\": {\n      \"input_size\": 16,\n      \"hidden_layers\": [\n        256,\n        256\n      ],\n      \"output_size\": 4\n    },\n    \"sub_goal_dim\": 3,\n    \"low_level_policy\": {\n      \"input_size\": 19,\n      \"hidden_layers\": [\n        256,\n        256\n      ],\n      \"output_size\": 4\n    }\n  },\n  \"curriculum_learning\": {\n    \"use_curriculum\": true,\n    \"initial_difficulty\": 1,\n    \"difficulty_increment\": 1,\n    \"difficulty_threshold\": 200\n  },\n  \"multi_agent\": {\n    \"use_multi_agent\": true,\n    \"num_agents\": 2,\n    \"hidden_layers\": [\n      256,\n      256\n    ]\n  }\n}"}
{"time": "2024-07-21T15:00:09.128139", "name": "AirSimEnvLogger", "level": "INFO", "message": "DataVisualizer initialized with Seaborn style set to 'whitegrid'."}
{"time": "2024-07-21T15:00:09.128139", "name": "AirSimEnvLogger", "level": "INFO", "message": "Using device: cpu"}
{"time": "2024-07-21T15:00:15.127189", "name": "AirSimEnvLogger", "level": "INFO", "message": "PPOAgent initialized successfully."}
{"time": "2024-07-21T15:00:20.471796", "name": "AirSimEnvLogger", "level": "INFO", "message": "Environment reset and takeoff completed."}
{"time": "2024-07-21T15:00:21.110583", "name": "AirSimEnvLogger", "level": "INFO", "message": "Reset completed. Observation keys: dict_keys(['state', 'visual'])"}
{"time": "2024-07-21T15:00:21.110583", "name": "AirSimEnvLogger", "level": "INFO", "message": "State shape: (16,), Visual shape: (144, 256, 3)"}
{"time": "2024-07-21T15:00:22.995544", "name": "AirSimEnvLogger", "level": "ERROR", "message": "Error during training: mat1 and mat2 shapes cannot be multiplied (1x4096 and 256x256)"}
{"time": "2024-07-21T15:00:22.995544", "name": "AirSimEnvLogger", "level": "ERROR", "message": "An error occurred in main: mat1 and mat2 shapes cannot be multiplied (1x4096 and 256x256)"}
{"time": "2024-07-21T15:00:28.668963", "name": "AirSimEnvLogger", "level": "INFO", "message": "Environment closed."}
{"time": "2024-07-21T15:00:28.716299", "name": "AirSimEnvLogger", "level": "INFO", "message": "Training script execution finished."}
{"time": "2024-07-21T15:01:58.690408", "name": "AirSimEnvLogger", "level": "INFO", "message": "Initialized with state_dim: 16, action_dim: 4"}
{"time": "2024-07-21T15:01:58.706213", "name": "AirSimEnvLogger", "level": "INFO", "message": "Initializing AirSimEnv"}
{"time": "2024-07-21T15:01:58.707212", "name": "AirSimEnvLogger", "level": "INFO", "message": "Configuration: {\n  \"learning_rate\": 0.0001,\n  \"gamma\": 0.99,\n  \"tau\": 0.95,\n  \"batch_size\": 64,\n  \"num_timesteps\": 2000000,\n  \"ppo\": {\n    \"learning_rate\": 0.0003,\n    \"n_steps\": 2048,\n    \"batch_size\": 64,\n    \"n_epochs\": 2000,\n    \"gamma\": 0.99,\n    \"gae_lambda\": 0.95,\n    \"clip_range\": 0.2,\n    \"ent_coef\": 0.01,\n    \"vf_coef\": 0.5,\n    \"max_grad_norm\": 0.5,\n    \"use_sde\": true,\n    \"sde_sample_freq\": 4,\n    \"tensorboard_log\": \"logs/tensorboard_logs/ppo_airsim_tensorboard/\",\n    \"verbose\": 1,\n    \"seed\": null,\n    \"device\": \"auto\",\n    \"continuous\": true,\n    \"save_freq\": 10000\n  },\n  \"environment\": {\n    \"env_name\": \"Africa_001\",\n    \"reward_threshold\": 250,\n    \"max_episode_steps\": 1000,\n    \"state_dim\": 16,\n    \"action_dim\": 4,\n    \"reward_scale\": 20,\n    \"proximity_threshold\": 5.0,\n    \"collision_penalty\": 25,\n    \"height_target\": -10,\n    \"height_tolerance\": 1.0,\n    \"height_penalty\": 1,\n    \"movement_penalty\": 0.1,\n    \"smoothness_penalty\": 0.1,\n    \"duration\": 0.1,\n    \"exploration_area\": {\n      \"x_min\": -1000,\n      \"x_max\": 1000,\n      \"y_min\": -1000,\n      \"y_max\": 1000,\n      \"z_min\": -100,\n      \"z_max\": 100\n    }\n  },\n  \"policy_network\": {\n    \"input_size\": 16,\n    \"hidden_layers\": [\n      256,\n      256\n    ],\n    \"output_size\": 4,\n    \"use_batch_norm\": true,\n    \"use_dropout\": true,\n    \"dropout_rate\": 0.2,\n    \"use_attention\": true,\n    \"num_action_heads\": 1\n  },\n  \"critic_network\": {\n    \"input_size\": 16,\n    \"hidden_layers\": [\n      256,\n      256\n    ],\n    \"output_size\": 1,\n    \"use_batch_norm\": true,\n    \"use_dropout\": true,\n    \"dropout_rate\": 0.2,\n    \"use_attention\": true\n  },\n  \"exploration\": {\n    \"strategy\": \"epsilon_decay\",\n    \"initial_epsilon\": 1.0,\n    \"min_epsilon\": 0.05,\n    \"epsilon_decay_rate\": 0.9995\n  },\n  \"model_checkpointing\": {\n    \"checkpoint_interval\": 10,\n    \"save_best_only\": true,\n    \"checkpoint_dir\": \"models/checkpoints\"\n  },\n  \"logging\": {\n    \"log_interval\": 10,\n    \"log_dir\": \"logs/\",\n    \"tensorboard\": true,\n    \"tensorboard_log_dir\": \"logs/tensorboard_logs\",\n    \"model_save_path\": \"models/saved_models\"\n  },\n  \"advanced_training_techniques\": {\n    \"gradient_clipping\": 0.5,\n    \"use_gae\": true,\n    \"gae_lambda\": 0.95,\n    \"normalize_advantages\": true\n  },\n  \"early_stopping\": {\n    \"patience\": 10\n  },\n  \"reward_adjustments\": {\n    \"collision_penalty\": 50,\n    \"reward_threshold\": 250\n  },\n  \"shared_components\": {\n    \"residual_block\": {\n      \"input_dim\": 128,\n      \"hidden_dim\": 128,\n      \"dropout_rate\": 0.2\n    },\n    \"attention_layer\": {\n      \"input_dim\": 128,\n      \"hidden_dim\": 128\n    }\n  },\n  \"icm\": {\n    \"state_dim\": 16,\n    \"action_dim\": 4,\n    \"image_channels\": 3,\n    \"image_height\": 144,\n    \"image_width\": 256,\n    \"cnn\": {\n      \"input_channels\": 3,\n      \"conv1\": {\n        \"out_channels\": 32,\n        \"kernel_size\": 8,\n        \"stride\": 4,\n        \"padding\": 0\n      },\n      \"conv2\": {\n        \"out_channels\": 64,\n        \"kernel_size\": 4,\n        \"stride\": 2,\n        \"padding\": 0\n      },\n      \"conv3\": {\n        \"out_channels\": 64,\n        \"kernel_size\": 3,\n        \"stride\": 1,\n        \"padding\": 0\n      }\n    },\n    \"state_encoder\": {\n      \"hidden_dim\": 128\n    },\n    \"forward_model\": {\n      \"hidden_dim\": 256\n    },\n    \"inverse_model\": {\n      \"hidden_dim\": 256\n    }\n  },\n  \"predictive_model\": {\n    \"learning_rate\": 0.0001,\n    \"hidden_layers\": [\n      256,\n      256\n    ],\n    \"cnn_config\": {\n      \"input_channels\": 3,\n      \"image_height\": 144,\n      \"image_width\": 256,\n      \"conv1\": {\n        \"out_channels\": 32,\n        \"kernel_size\": 8,\n        \"stride\": 4,\n        \"padding\": 0\n      },\n      \"conv2\": {\n        \"out_channels\": 64,\n        \"kernel_size\": 4,\n        \"stride\": 2,\n        \"padding\": 0\n      },\n      \"conv3\": {\n        \"out_channels\": 64,\n        \"kernel_size\": 3,\n        \"stride\": 1,\n        \"padding\": 0\n      }\n    }\n  },\n  \"hrl\": {\n    \"use_hierarchical\": true,\n    \"high_level_policy\": {\n      \"input_size\": 16,\n      \"hidden_layers\": [\n        256,\n        256\n      ],\n      \"output_size\": 4\n    },\n    \"sub_goal_dim\": 3,\n    \"low_level_policy\": {\n      \"input_size\": 19,\n      \"hidden_layers\": [\n        256,\n        256\n      ],\n      \"output_size\": 4\n    }\n  },\n  \"curriculum_learning\": {\n    \"use_curriculum\": true,\n    \"initial_difficulty\": 1,\n    \"difficulty_increment\": 1,\n    \"difficulty_threshold\": 200\n  },\n  \"multi_agent\": {\n    \"use_multi_agent\": true,\n    \"num_agents\": 2,\n    \"hidden_layers\": [\n      256,\n      256\n    ]\n  }\n}"}
{"time": "2024-07-21T15:02:00.352309", "name": "AirSimEnvLogger", "level": "INFO", "message": "DataVisualizer initialized with Seaborn style set to 'whitegrid'."}
{"time": "2024-07-21T15:02:00.353613", "name": "AirSimEnvLogger", "level": "INFO", "message": "Using device: cpu"}
{"time": "2024-07-21T15:02:07.365908", "name": "AirSimEnvLogger", "level": "INFO", "message": "PPOAgent initialized successfully."}
{"time": "2024-07-21T15:02:12.764911", "name": "AirSimEnvLogger", "level": "INFO", "message": "Environment reset and takeoff completed."}
{"time": "2024-07-21T15:02:13.362606", "name": "AirSimEnvLogger", "level": "INFO", "message": "Reset completed. Observation keys: dict_keys(['state', 'visual'])"}
{"time": "2024-07-21T15:02:13.362606", "name": "AirSimEnvLogger", "level": "INFO", "message": "State shape: (16,), Visual shape: (144, 256, 3)"}
{"time": "2024-07-21T15:02:15.272206", "name": "AirSimEnvLogger", "level": "ERROR", "message": "Error during training: mat1 and mat2 shapes cannot be multiplied (1x4096 and 256x256)"}
{"time": "2024-07-21T15:02:15.272206", "name": "AirSimEnvLogger", "level": "ERROR", "message": "An error occurred in main: mat1 and mat2 shapes cannot be multiplied (1x4096 and 256x256)"}
{"time": "2024-07-21T15:02:20.873635", "name": "AirSimEnvLogger", "level": "INFO", "message": "Environment closed."}
{"time": "2024-07-21T15:02:20.951991", "name": "AirSimEnvLogger", "level": "INFO", "message": "Training script execution finished."}
{"time": "2024-07-21T15:06:04.162303", "name": "AirSimEnvLogger", "level": "INFO", "message": "Initialized with state_dim: 16, action_dim: 4"}
{"time": "2024-07-21T15:06:04.178358", "name": "AirSimEnvLogger", "level": "INFO", "message": "Initializing AirSimEnv"}
{"time": "2024-07-21T15:06:04.178358", "name": "AirSimEnvLogger", "level": "INFO", "message": "Configuration: {\n  \"learning_rate\": 0.0001,\n  \"gamma\": 0.99,\n  \"tau\": 0.95,\n  \"batch_size\": 64,\n  \"num_timesteps\": 2000000,\n  \"ppo\": {\n    \"learning_rate\": 0.0003,\n    \"n_steps\": 2048,\n    \"batch_size\": 64,\n    \"n_epochs\": 2000,\n    \"gamma\": 0.99,\n    \"gae_lambda\": 0.95,\n    \"clip_range\": 0.2,\n    \"ent_coef\": 0.01,\n    \"vf_coef\": 0.5,\n    \"max_grad_norm\": 0.5,\n    \"use_sde\": true,\n    \"sde_sample_freq\": 4,\n    \"tensorboard_log\": \"logs/tensorboard_logs/ppo_airsim_tensorboard/\",\n    \"verbose\": 1,\n    \"seed\": null,\n    \"device\": \"auto\",\n    \"continuous\": true,\n    \"save_freq\": 10000\n  },\n  \"environment\": {\n    \"env_name\": \"Africa_001\",\n    \"reward_threshold\": 250,\n    \"max_episode_steps\": 1000,\n    \"state_dim\": 16,\n    \"action_dim\": 4,\n    \"reward_scale\": 20,\n    \"proximity_threshold\": 5.0,\n    \"collision_penalty\": 25,\n    \"height_target\": -10,\n    \"height_tolerance\": 1.0,\n    \"height_penalty\": 1,\n    \"movement_penalty\": 0.1,\n    \"smoothness_penalty\": 0.1,\n    \"duration\": 0.1,\n    \"exploration_area\": {\n      \"x_min\": -1000,\n      \"x_max\": 1000,\n      \"y_min\": -1000,\n      \"y_max\": 1000,\n      \"z_min\": -100,\n      \"z_max\": 100\n    }\n  },\n  \"policy_network\": {\n    \"input_size\": 16,\n    \"hidden_layers\": [\n      256,\n      256,\n      256\n    ],\n    \"output_size\": 4,\n    \"use_batch_norm\": true,\n    \"use_dropout\": true,\n    \"dropout_rate\": 0.2,\n    \"use_attention\": false,\n    \"num_action_heads\": 1\n  },\n  \"critic_network\": {\n    \"input_size\": 16,\n    \"hidden_layers\": [\n      256,\n      256\n    ],\n    \"output_size\": 1,\n    \"use_batch_norm\": true,\n    \"use_dropout\": true,\n    \"dropout_rate\": 0.2,\n    \"use_attention\": true\n  },\n  \"exploration\": {\n    \"strategy\": \"epsilon_decay\",\n    \"initial_epsilon\": 1.0,\n    \"min_epsilon\": 0.05,\n    \"epsilon_decay_rate\": 0.9995\n  },\n  \"model_checkpointing\": {\n    \"checkpoint_interval\": 10,\n    \"save_best_only\": true,\n    \"checkpoint_dir\": \"models/checkpoints\"\n  },\n  \"logging\": {\n    \"log_interval\": 10,\n    \"log_dir\": \"logs/\",\n    \"tensorboard\": true,\n    \"tensorboard_log_dir\": \"logs/tensorboard_logs\",\n    \"model_save_path\": \"models/saved_models\"\n  },\n  \"advanced_training_techniques\": {\n    \"gradient_clipping\": 0.5,\n    \"use_gae\": true,\n    \"gae_lambda\": 0.95,\n    \"normalize_advantages\": true\n  },\n  \"early_stopping\": {\n    \"patience\": 10\n  },\n  \"reward_adjustments\": {\n    \"collision_penalty\": 50,\n    \"reward_threshold\": 250\n  },\n  \"shared_components\": {\n    \"residual_block\": {\n      \"input_dim\": 128,\n      \"hidden_dim\": 128,\n      \"dropout_rate\": 0.2\n    },\n    \"attention_layer\": {\n      \"input_dim\": 128,\n      \"hidden_dim\": 128\n    }\n  },\n  \"icm\": {\n    \"state_dim\": 16,\n    \"action_dim\": 4,\n    \"image_channels\": 3,\n    \"image_height\": 144,\n    \"image_width\": 256,\n    \"cnn\": {\n      \"input_channels\": 3,\n      \"conv1\": {\n        \"out_channels\": 32,\n        \"kernel_size\": 8,\n        \"stride\": 4,\n        \"padding\": 0\n      },\n      \"conv2\": {\n        \"out_channels\": 64,\n        \"kernel_size\": 4,\n        \"stride\": 2,\n        \"padding\": 0\n      },\n      \"conv3\": {\n        \"out_channels\": 64,\n        \"kernel_size\": 3,\n        \"stride\": 1,\n        \"padding\": 0\n      }\n    },\n    \"state_encoder\": {\n      \"hidden_dim\": 128\n    },\n    \"forward_model\": {\n      \"hidden_dim\": 256\n    },\n    \"inverse_model\": {\n      \"hidden_dim\": 256\n    }\n  },\n  \"predictive_model\": {\n    \"learning_rate\": 0.0001,\n    \"hidden_layers\": [\n      256,\n      256\n    ],\n    \"cnn_config\": {\n      \"input_channels\": 3,\n      \"image_height\": 144,\n      \"image_width\": 256,\n      \"conv1\": {\n        \"out_channels\": 32,\n        \"kernel_size\": 8,\n        \"stride\": 4,\n        \"padding\": 0\n      },\n      \"conv2\": {\n        \"out_channels\": 64,\n        \"kernel_size\": 4,\n        \"stride\": 2,\n        \"padding\": 0\n      },\n      \"conv3\": {\n        \"out_channels\": 64,\n        \"kernel_size\": 3,\n        \"stride\": 1,\n        \"padding\": 0\n      }\n    }\n  },\n  \"hrl\": {\n    \"use_hierarchical\": true,\n    \"high_level_policy\": {\n      \"input_size\": 16,\n      \"hidden_layers\": [\n        256,\n        256\n      ],\n      \"output_size\": 4\n    },\n    \"sub_goal_dim\": 3,\n    \"low_level_policy\": {\n      \"input_size\": 19,\n      \"hidden_layers\": [\n        256,\n        256\n      ],\n      \"output_size\": 4\n    }\n  },\n  \"curriculum_learning\": {\n    \"use_curriculum\": true,\n    \"initial_difficulty\": 1,\n    \"difficulty_increment\": 1,\n    \"difficulty_threshold\": 200\n  },\n  \"multi_agent\": {\n    \"use_multi_agent\": true,\n    \"num_agents\": 2,\n    \"hidden_layers\": [\n      256,\n      256\n    ]\n  }\n}"}
{"time": "2024-07-21T15:06:05.718749", "name": "AirSimEnvLogger", "level": "INFO", "message": "DataVisualizer initialized with Seaborn style set to 'whitegrid'."}
{"time": "2024-07-21T15:06:05.719765", "name": "AirSimEnvLogger", "level": "INFO", "message": "Using device: cpu"}
{"time": "2024-07-21T15:06:12.628939", "name": "AirSimEnvLogger", "level": "INFO", "message": "PPOAgent initialized successfully."}
{"time": "2024-07-21T15:06:17.880475", "name": "AirSimEnvLogger", "level": "INFO", "message": "Environment reset and takeoff completed."}
{"time": "2024-07-21T15:06:18.460114", "name": "AirSimEnvLogger", "level": "INFO", "message": "Reset completed. Observation keys: dict_keys(['state', 'visual'])"}
{"time": "2024-07-21T15:06:18.460114", "name": "AirSimEnvLogger", "level": "INFO", "message": "State shape: (16,), Visual shape: (144, 256, 3)"}
{"time": "2024-07-21T15:06:23.649864", "name": "AirSimEnvLogger", "level": "INFO", "message": "Reward breakdown - Distance: -8.537314387274387, Velocity: -0.7330309600353913, Collision: 0, Height: -1.0, Movement: -0.052879256010055546, Smoothness: -0.0, Curiosity: 2.823000192642212, Exploration: 0, Total: -7.997617696571982"}
{"time": "2024-07-21T15:06:23.792228", "name": "AirSimEnvLogger", "level": "INFO", "message": "Action: [-0.26439628 -0.26439628 -0.26439628 -0.26439628], Velocity: (-0.2643962800502777, -0.2643962800502777, -0.2643962800502777), Duration: 0.5, Reward: -7.997617696571982, Done: False"}
{"time": "2024-07-21T15:06:23.896780", "name": "AirSimEnvLogger", "level": "INFO", "message": "Step completed. Observation keys: dict_keys(['state', 'visual'])"}
{"time": "2024-07-21T15:06:23.896780", "name": "AirSimEnvLogger", "level": "INFO", "message": "State shape: (16,), Visual shape: (144, 256, 3)"}
{"time": "2024-07-21T15:06:27.318813", "name": "AirSimEnvLogger", "level": "INFO", "message": "Predictive model loss: 0.1573164314031601"}
{"time": "2024-07-21T15:06:32.535275", "name": "AirSimEnvLogger", "level": "INFO", "message": "Reward breakdown - Distance: -9.138746752489784, Velocity: -0.4632007639958223, Collision: 0, Height: -1.0, Movement: -0.019336587190628054, Smoothness: -0.0, Curiosity: 0.9239609837532043, Exploration: 0.18498252261020992, Total: -9.373303796808113"}
{"time": "2024-07-21T15:06:32.661409", "name": "AirSimEnvLogger", "level": "INFO", "message": "Action: [0.09668294 0.09668294 0.09668294 0.09668294], Velocity: (0.09668293595314026, 0.09668293595314026, 0.09668293595314026), Duration: 0.5, Reward: -9.373303796808113, Done: False"}
{"time": "2024-07-21T15:06:32.722534", "name": "AirSimEnvLogger", "level": "INFO", "message": "Step completed. Observation keys: dict_keys(['state', 'visual'])"}
{"time": "2024-07-21T15:06:32.722534", "name": "AirSimEnvLogger", "level": "INFO", "message": "State shape: (16,), Visual shape: (144, 256, 3)"}
{"time": "2024-07-21T15:06:35.558677", "name": "AirSimEnvLogger", "level": "INFO", "message": "Predictive model loss: 0.047452572733163834"}
{"time": "2024-07-21T15:06:40.362485", "name": "AirSimEnvLogger", "level": "INFO", "message": "Reward breakdown - Distance: -9.263902943094497, Velocity: -0.13462194965032698, Collision: 0, Height: -1.0, Movement: -0.08582771122455597, Smoothness: -0.0, Curiosity: 1.2977185249328613, Exploration: 0.10438579047764592, Total: -9.170060268480155"}
{"time": "2024-07-21T15:06:40.487913", "name": "AirSimEnvLogger", "level": "INFO", "message": "Action: [0.42913856 0.42913856 0.42913856 0.42913856], Velocity: (0.42913855612277985, 0.42913855612277985, 0.42913855612277985), Duration: 0.5, Reward: -9.170060268480155, Done: False"}
{"time": "2024-07-21T15:06:40.550696", "name": "AirSimEnvLogger", "level": "INFO", "message": "Step completed. Observation keys: dict_keys(['state', 'visual'])"}
{"time": "2024-07-21T15:06:40.550696", "name": "AirSimEnvLogger", "level": "INFO", "message": "State shape: (16,), Visual shape: (144, 256, 3)"}
{"time": "2024-07-21T15:06:43.329788", "name": "AirSimEnvLogger", "level": "INFO", "message": "Predictive model loss: 0.024116137996315956"}
{"time": "2024-07-21T15:06:48.329362", "name": "AirSimEnvLogger", "level": "INFO", "message": "Reward breakdown - Distance: -9.342956418604631, Velocity: -0.18901729958519944, Collision: 0, Height: -1.0, Movement: -0.11907327324151994, Smoothness: -0.0, Curiosity: 1.9479552507400513, Exploration: 0.058389168184958845, Total: -8.963716936714366"}
{"time": "2024-07-21T15:06:48.501470", "name": "AirSimEnvLogger", "level": "INFO", "message": "Action: [0.59536637 0.59536637 0.59536637 0.59536637], Velocity: (0.5953663662075996, 0.5953663662075996, 0.5953663662075996), Duration: 0.5, Reward: -8.963716936714366, Done: False"}
{"time": "2024-07-21T15:06:48.596452", "name": "AirSimEnvLogger", "level": "INFO", "message": "Step completed. Observation keys: dict_keys(['state', 'visual'])"}
{"time": "2024-07-21T15:06:48.596452", "name": "AirSimEnvLogger", "level": "INFO", "message": "State shape: (16,), Visual shape: (144, 256, 3)"}
{"time": "2024-07-21T15:06:51.538692", "name": "AirSimEnvLogger", "level": "INFO", "message": "Predictive model loss: 0.020372124388813972"}
{"time": "2024-07-21T15:06:55.921996", "name": "AirSimEnvLogger", "level": "INFO", "message": "Reward breakdown - Distance: -9.593620887214255, Velocity: -0.08994530635256104, Collision: 0, Height: -1.0, Movement: -0.047808886319398884, Smoothness: -0.0, Curiosity: 0.43681299686431885, Exploration: 0.033507838106208, Total: -9.918266362969074"}
{"time": "2024-07-21T15:06:56.046409", "name": "AirSimEnvLogger", "level": "INFO", "message": "Action: [0.23904443 0.23904443 0.23904443 0.23904443], Velocity: (0.2390444315969944, 0.2390444315969944, 0.2390444315969944), Duration: 0.5, Reward: -9.918266362969074, Done: False"}
{"time": "2024-07-21T15:06:56.091477", "name": "AirSimEnvLogger", "level": "INFO", "message": "Step completed. Observation keys: dict_keys(['state', 'visual'])"}
{"time": "2024-07-21T15:06:56.091477", "name": "AirSimEnvLogger", "level": "INFO", "message": "State shape: (16,), Visual shape: (144, 256, 3)"}
{"time": "2024-07-21T15:06:59.016346", "name": "AirSimEnvLogger", "level": "INFO", "message": "Predictive model loss: 0.006978273391723633"}
{"time": "2024-07-21T15:07:04.028533", "name": "AirSimEnvLogger", "level": "INFO", "message": "Reward breakdown - Distance: -9.85169826440182, Velocity: -0.018013674955812506, Collision: 0, Height: -1.0, Movement: -0.0063237067312002185, Smoothness: -0.0, Curiosity: 0.04456177353858948, Exploration: 0.05763924644480213, Total: -10.327528736494592"}
{"time": "2024-07-21T15:07:04.153633", "name": "AirSimEnvLogger", "level": "INFO", "message": "Action: [-0.03161853 -0.03161853 -0.03161853 -0.03161853], Velocity: (-0.03161853365600109, -0.03161853365600109, -0.03161853365600109), Duration: 0.5, Reward: -10.327528736494592, Done: False"}
{"time": "2024-07-21T15:07:04.217275", "name": "AirSimEnvLogger", "level": "INFO", "message": "Step completed. Observation keys: dict_keys(['state', 'visual'])"}
{"time": "2024-07-21T15:07:04.217275", "name": "AirSimEnvLogger", "level": "INFO", "message": "State shape: (16,), Visual shape: (144, 256, 3)"}
{"time": "2024-07-21T15:07:07.198692", "name": "AirSimEnvLogger", "level": "INFO", "message": "Predictive model loss: 0.008090468123555183"}
{"time": "2024-07-21T15:07:12.180107", "name": "AirSimEnvLogger", "level": "INFO", "message": "Reward breakdown - Distance: -10.13676828917405, Velocity: -0.12224443177266792, Collision: 0, Height: -1.0, Movement: -0.06689289789646864, Smoothness: -0.0, Curiosity: 0.503887951374054, Exploration: 0.06249215160866182, Total: -10.44013738884127"}
{"time": "2024-07-21T15:07:12.275412", "name": "AirSimEnvLogger", "level": "INFO", "message": "Action: [-0.33446449 -0.33446449 -0.33446449 -0.33446449], Velocity: (-0.3344644894823432, -0.3344644894823432, -0.3344644894823432), Duration: 0.5, Reward: -10.44013738884127, Done: False"}
{"time": "2024-07-21T15:07:12.322469", "name": "AirSimEnvLogger", "level": "INFO", "message": "Step completed. Observation keys: dict_keys(['state', 'visual'])"}
{"time": "2024-07-21T15:07:12.322469", "name": "AirSimEnvLogger", "level": "INFO", "message": "State shape: (16,), Visual shape: (144, 256, 3)"}
{"time": "2024-07-21T15:07:15.105473", "name": "AirSimEnvLogger", "level": "INFO", "message": "Predictive model loss: 0.022139564156532288"}
{"time": "2024-07-21T15:07:19.726339", "name": "AirSimEnvLogger", "level": "INFO", "message": "Reward breakdown - Distance: -10.161139918823583, Velocity: -0.06345651334579028, Collision: 0, Height: -1.0, Movement: -0.03629631316289306, Smoothness: -0.0, Curiosity: 0.19075673818588257, Exploration: 0.033050901826732565, Total: -10.594509257354481"}
{"time": "2024-07-21T15:07:19.805208", "name": "AirSimEnvLogger", "level": "INFO", "message": "Action: [-0.18148157 -0.18148157 -0.18148157 -0.18148157], Velocity: (-0.18148156581446528, -0.18148156581446528, -0.18148156581446528), Duration: 0.5, Reward: -10.594509257354481, Done: False"}
{"time": "2024-07-21T15:07:19.868557", "name": "AirSimEnvLogger", "level": "INFO", "message": "Step completed. Observation keys: dict_keys(['state', 'visual'])"}
{"time": "2024-07-21T15:07:19.868557", "name": "AirSimEnvLogger", "level": "INFO", "message": "State shape: (16,), Visual shape: (144, 256, 3)"}
{"time": "2024-07-21T15:07:22.792431", "name": "AirSimEnvLogger", "level": "INFO", "message": "Predictive model loss: 0.020095307379961014"}
{"time": "2024-07-21T15:07:27.763608", "name": "AirSimEnvLogger", "level": "INFO", "message": "Reward breakdown - Distance: -10.076307145557221, Velocity: -0.007550631577839004, Collision: 0, Height: -1.0, Movement: -0.0028453450184315445, Smoothness: -0.0, Curiosity: 0.03463318198919296, Exploration: 0.015854131799084174, Total: -10.55987957849357"}
{"time": "2024-07-21T15:07:27.921030", "name": "AirSimEnvLogger", "level": "INFO", "message": "Action: [-0.01422673 -0.01422673 -0.01422673 -0.01422673], Velocity: (-0.014226725092157722, -0.014226725092157722, -0.014226725092157722), Duration: 0.5, Reward: -10.55987957849357, Done: False"}
{"time": "2024-07-21T15:07:28.015052", "name": "AirSimEnvLogger", "level": "INFO", "message": "Step completed. Observation keys: dict_keys(['state', 'visual'])"}
{"time": "2024-07-21T15:07:28.015052", "name": "AirSimEnvLogger", "level": "INFO", "message": "State shape: (16,), Visual shape: (144, 256, 3)"}
{"time": "2024-07-21T15:07:30.893734", "name": "AirSimEnvLogger", "level": "INFO", "message": "Predictive model loss: 0.011675531975924969"}
{"time": "2024-07-21T15:07:35.891442", "name": "AirSimEnvLogger", "level": "INFO", "message": "Reward breakdown - Distance: -10.235270210211043, Velocity: -0.11141033527169202, Collision: 0, Height: -1.0, Movement: -0.06721836233045907, Smoothness: -0.0, Curiosity: 0.5587345361709595, Exploration: 0.01319519047892635, Total: -10.515690907898671"}
{"time": "2024-07-21T15:07:36.016450", "name": "AirSimEnvLogger", "level": "INFO", "message": "Action: [-0.33609181 -0.33609181 -0.33609181 -0.33609181], Velocity: (-0.3360918116522953, -0.3360918116522953, -0.3360918116522953), Duration: 0.5, Reward: -10.515690907898671, Done: False"}
{"time": "2024-07-21T15:07:36.079033", "name": "AirSimEnvLogger", "level": "INFO", "message": "Step completed. Observation keys: dict_keys(['state', 'visual'])"}
{"time": "2024-07-21T15:07:36.079033", "name": "AirSimEnvLogger", "level": "INFO", "message": "State shape: (16,), Visual shape: (144, 256, 3)"}
{"time": "2024-07-21T15:07:39.011068", "name": "AirSimEnvLogger", "level": "INFO", "message": "Predictive model loss: 0.020203847438097"}
{"time": "2024-07-21T15:07:43.855025", "name": "AirSimEnvLogger", "level": "INFO", "message": "Reward breakdown - Distance: -10.427661354344618, Velocity: -0.20764629656550257, Collision: 0, Height: -1.0, Movement: -0.10976859879447148, Smoothness: -0.0, Curiosity: 1.521005630493164, Exploration: 0.04910039929700762, Total: -10.272138467400833"}
{"time": "2024-07-21T15:07:43.963484", "name": "AirSimEnvLogger", "level": "INFO", "message": "Action: [-0.54884299 -0.54884299 -0.54884299 -0.54884299], Velocity: (-0.5488429939723574, -0.5488429939723574, -0.5488429939723574), Duration: 0.5, Reward: -10.272138467400833, Done: False"}
{"time": "2024-07-21T15:07:44.025928", "name": "AirSimEnvLogger", "level": "INFO", "message": "Step completed. Observation keys: dict_keys(['state', 'visual'])"}
{"time": "2024-07-21T15:07:44.025928", "name": "AirSimEnvLogger", "level": "INFO", "message": "State shape: (16,), Visual shape: (144, 256, 3)"}
{"time": "2024-07-21T15:07:46.930503", "name": "AirSimEnvLogger", "level": "INFO", "message": "Predictive model loss: 0.035912878811359406"}
{"time": "2024-07-21T15:07:51.877130", "name": "AirSimEnvLogger", "level": "INFO", "message": "Reward breakdown - Distance: -10.110416689522078, Velocity: -0.04088284619712446, Collision: 0, Height: -1.0, Movement: -0.02127511823200621, Smoothness: -0.0, Curiosity: 0.08999551832675934, Exploration: 0.021996356756950948, Total: -10.58358859392907"}
{"time": "2024-07-21T15:07:52.018173", "name": "AirSimEnvLogger", "level": "INFO", "message": "Action: [0.10637559 0.10637559 0.10637559 0.10637559], Velocity: (0.10637559116003104, 0.10637559116003104, 0.10637559116003104), Duration: 0.5, Reward: -10.58358859392907, Done: False"}
{"time": "2024-07-21T15:07:52.080297", "name": "AirSimEnvLogger", "level": "INFO", "message": "Step completed. Observation keys: dict_keys(['state', 'visual'])"}
{"time": "2024-07-21T15:07:52.080297", "name": "AirSimEnvLogger", "level": "INFO", "message": "State shape: (16,), Visual shape: (144, 256, 3)"}
{"time": "2024-07-21T15:07:55.003321", "name": "AirSimEnvLogger", "level": "INFO", "message": "Predictive model loss: 0.006613536272197962"}
{"time": "2024-07-21T15:08:00.046714", "name": "AirSimEnvLogger", "level": "INFO", "message": "Reward breakdown - Distance: -10.192742839306845, Velocity: -0.07799967031893497, Collision: 0, Height: -1.0, Movement: -0.04679782825696748, Smoothness: -0.0, Curiosity: 0.309664785861969, Exploration: 0.028181478822430963, Total: -10.57595376859654"}
{"time": "2024-07-21T15:08:00.205036", "name": "AirSimEnvLogger", "level": "INFO", "message": "Action: [-0.23398914 -0.23398914 -0.23398914 -0.23398914], Velocity: (-0.2339891412848374, -0.2339891412848374, -0.2339891412848374), Duration: 0.5, Reward: -10.57595376859654, Done: False"}
{"time": "2024-07-21T15:08:00.299354", "name": "AirSimEnvLogger", "level": "INFO", "message": "Step completed. Observation keys: dict_keys(['state', 'visual'])"}
{"time": "2024-07-21T15:08:00.299354", "name": "AirSimEnvLogger", "level": "INFO", "message": "State shape: (16,), Visual shape: (144, 256, 3)"}
{"time": "2024-07-21T15:08:03.205106", "name": "AirSimEnvLogger", "level": "INFO", "message": "Predictive model loss: 0.010729952715337276"}
{"time": "2024-07-21T15:08:08.035260", "name": "AirSimEnvLogger", "level": "INFO", "message": "Reward breakdown - Distance: -10.04895934672994, Velocity: -0.022373053732730415, Collision: 0, Height: -1.0, Movement: -0.010521877616702114, Smoothness: -0.0, Curiosity: 0.03870673477649689, Exploration: 0.007523994124849115, Total: -10.54033989514476"}
{"time": "2024-07-21T15:08:08.113501", "name": "AirSimEnvLogger", "level": "INFO", "message": "Action: [0.05260939 0.05260939 0.05260939 0.05260939], Velocity: (0.052609388083510567, 0.052609388083510567, 0.052609388083510567), Duration: 0.5, Reward: -10.54033989514476, Done: False"}
{"time": "2024-07-21T15:08:08.159993", "name": "AirSimEnvLogger", "level": "INFO", "message": "Step completed. Observation keys: dict_keys(['state', 'visual'])"}
{"time": "2024-07-21T15:08:08.159993", "name": "AirSimEnvLogger", "level": "INFO", "message": "State shape: (16,), Visual shape: (144, 256, 3)"}
{"time": "2024-07-21T15:08:10.812109", "name": "AirSimEnvLogger", "level": "INFO", "message": "Predictive model loss: 0.002762722549960017"}
{"time": "2024-07-21T15:08:15.824854", "name": "AirSimEnvLogger", "level": "INFO", "message": "Reward breakdown - Distance: -10.121515681664402, Velocity: -0.057341753136278005, Collision: 0, Height: -1.0, Movement: -0.03251039047536324, Smoothness: -0.0, Curiosity: 0.16320854425430298, Exploration: 0.007525199103813907, Total: -10.570328285332161"}
{"time": "2024-07-21T15:08:15.840982", "name": "AirSimEnvLogger", "level": "INFO", "message": "Action: [-0.16255195 -0.16255195 -0.16255195 -0.16255195], Velocity: (-0.1625519523768162, -0.1625519523768162, -0.1625519523768162), Duration: 0.5, Reward: -10.570328285332161, Done: False"}
{"time": "2024-07-21T15:08:15.903333", "name": "AirSimEnvLogger", "level": "INFO", "message": "Step completed. Observation keys: dict_keys(['state', 'visual'])"}
{"time": "2024-07-21T15:08:15.903333", "name": "AirSimEnvLogger", "level": "INFO", "message": "State shape: (16,), Visual shape: (144, 256, 3)"}
{"time": "2024-07-21T15:08:18.783266", "name": "AirSimEnvLogger", "level": "INFO", "message": "Predictive model loss: 0.005474381148815155"}
{"time": "2024-07-21T15:08:23.932378", "name": "AirSimEnvLogger", "level": "INFO", "message": "Reward breakdown - Distance: -10.137703405730269, Velocity: -0.04624782810507101, Collision: 0, Height: -1.0, Movement: -0.028796855904147378, Smoothness: -0.0, Curiosity: 0.14771482348442078, Exploration: 0.014900672771422303, Total: -10.586869459076723"}
{"time": "2024-07-21T15:08:24.121282", "name": "AirSimEnvLogger", "level": "INFO", "message": "Action: [-0.14398428 -0.14398428 -0.14398428 -0.14398428], Velocity: (-0.1439842795207369, -0.1439842795207369, -0.1439842795207369), Duration: 0.5, Reward: -10.586869459076723, Done: False"}
{"time": "2024-07-21T15:08:24.183565", "name": "AirSimEnvLogger", "level": "INFO", "message": "Step completed. Observation keys: dict_keys(['state', 'visual'])"}
{"time": "2024-07-21T15:08:24.183565", "name": "AirSimEnvLogger", "level": "INFO", "message": "State shape: (16,), Visual shape: (144, 256, 3)"}
{"time": "2024-07-21T15:08:27.185802", "name": "AirSimEnvLogger", "level": "INFO", "message": "Predictive model loss: 0.005294164642691612"}
{"time": "2024-07-21T15:08:32.094759", "name": "AirSimEnvLogger", "level": "INFO", "message": "Reward breakdown - Distance: -10.322962974252313, Velocity: -0.14574575869552195, Collision: 0, Height: -1.0, Movement: -0.08745696758105624, Smoothness: -0.0, Curiosity: 1.003562569618225, Exploration: 0.02714718069176819, Total: -10.397370829410713"}
{"time": "2024-07-21T15:08:32.219260", "name": "AirSimEnvLogger", "level": "INFO", "message": "Action: [-0.43728484 -0.43728484 -0.43728484 -0.43728484], Velocity: (-0.43728483790528117, -0.43728483790528117, -0.43728483790528117), Duration: 0.5, Reward: -10.397370829410713, Done: False"}
{"time": "2024-07-21T15:08:32.345246", "name": "AirSimEnvLogger", "level": "INFO", "message": "Step completed. Observation keys: dict_keys(['state', 'visual'])"}
{"time": "2024-07-21T15:08:32.345246", "name": "AirSimEnvLogger", "level": "INFO", "message": "State shape: (16,), Visual shape: (144, 256, 3)"}
{"time": "2024-07-21T15:08:35.289030", "name": "AirSimEnvLogger", "level": "INFO", "message": "Predictive model loss: 0.017199214547872543"}
{"time": "2024-07-21T15:08:40.340632", "name": "AirSimEnvLogger", "level": "INFO", "message": "Reward breakdown - Distance: -10.03519470477193, Velocity: -0.05305891114288633, Collision: 0, Height: -1.0, Movement: -0.03243093383871383, Smoothness: -0.0, Curiosity: 0.13918259739875793, Exploration: 0.01590590192586549, Total: -10.492194774642693"}
{"time": "2024-07-21T15:08:40.479681", "name": "AirSimEnvLogger", "level": "INFO", "message": "Action: [0.16215467 0.16215467 0.16215467 0.16215467], Velocity: (0.16215466919356913, 0.16215466919356913, 0.16215466919356913), Duration: 0.5, Reward: -10.492194774642693, Done: False"}
{"time": "2024-07-21T15:08:40.541551", "name": "AirSimEnvLogger", "level": "INFO", "message": "Step completed. Observation keys: dict_keys(['state', 'visual'])"}
{"time": "2024-07-21T15:08:40.541551", "name": "AirSimEnvLogger", "level": "INFO", "message": "State shape: (16,), Visual shape: (144, 256, 3)"}
{"time": "2024-07-21T15:08:43.498579", "name": "AirSimEnvLogger", "level": "INFO", "message": "Predictive model loss: 0.0011661252938210964"}
{"time": "2024-07-21T15:08:48.653469", "name": "AirSimEnvLogger", "level": "INFO", "message": "Reward breakdown - Distance: -10.17387330122136, Velocity: -0.10402691856872726, Collision: 0, Height: -1.0, Movement: -0.05047677212673989, Smoothness: -0.0, Curiosity: 0.3742421269416809, Exploration: 0.01641164932399651, Total: -10.540531044382758"}
{"time": "2024-07-21T15:08:48.810687", "name": "AirSimEnvLogger", "level": "INFO", "message": "Action: [-0.25238386 -0.25238386 -0.25238386 -0.25238386], Velocity: (-0.25238386063369944, -0.25238386063369944, -0.25238386063369944), Duration: 0.5, Reward: -10.540531044382758, Done: False"}
{"time": "2024-07-21T15:08:48.903401", "name": "AirSimEnvLogger", "level": "INFO", "message": "Step completed. Observation keys: dict_keys(['state', 'visual'])"}
{"time": "2024-07-21T15:08:48.903401", "name": "AirSimEnvLogger", "level": "INFO", "message": "State shape: (16,), Visual shape: (144, 256, 3)"}
{"time": "2024-07-21T15:08:51.879281", "name": "AirSimEnvLogger", "level": "INFO", "message": "Predictive model loss: 0.007580197881907225"}
{"time": "2024-07-21T15:08:56.829211", "name": "AirSimEnvLogger", "level": "INFO", "message": "Reward breakdown - Distance: -9.936615692049871, Velocity: -0.07982571116182884, Collision: 0, Height: -1.0, Movement: -0.045333888859954645, Smoothness: -0.0, Curiosity: 0.23741808533668518, Exploration: 0.010344801492369032, Total: -10.360283933549965"}
{"time": "2024-07-21T15:08:56.955757", "name": "AirSimEnvLogger", "level": "INFO", "message": "Action: [0.22666944 0.22666944 0.22666944 0.22666944], Velocity: (0.2266694442997732, 0.2266694442997732, 0.2266694442997732), Duration: 0.5, Reward: -10.360283933549965, Done: False"}
{"time": "2024-07-21T15:08:57.003334", "name": "AirSimEnvLogger", "level": "INFO", "message": "Step completed. Observation keys: dict_keys(['state', 'visual'])"}
{"time": "2024-07-21T15:08:57.003334", "name": "AirSimEnvLogger", "level": "INFO", "message": "State shape: (16,), Visual shape: (144, 256, 3)"}
{"time": "2024-07-21T15:09:00.027978", "name": "AirSimEnvLogger", "level": "INFO", "message": "Predictive model loss: 0.00047663264558650553"}
{"time": "2024-07-21T15:09:05.059839", "name": "AirSimEnvLogger", "level": "INFO", "message": "Reward breakdown - Distance: -9.75693772518964, Velocity: -0.1152243483962964, Collision: 0, Height: -1.0, Movement: -0.07558094398747245, Smoothness: -0.0, Curiosity: 0.6528724431991577, Exploration: 0.05430436177575783, Total: -9.984810899831807"}
{"time": "2024-07-21T15:09:05.202903", "name": "AirSimEnvLogger", "level": "INFO", "message": "Action: [0.37790472 0.37790472 0.37790472 0.37790472], Velocity: (0.3779047199373622, 0.3779047199373622, 0.3779047199373622), Duration: 0.5, Reward: -9.984810899831807, Done: False"}
{"time": "2024-07-21T15:09:05.264516", "name": "AirSimEnvLogger", "level": "INFO", "message": "Step completed. Observation keys: dict_keys(['state', 'visual'])"}
{"time": "2024-07-21T15:09:05.264516", "name": "AirSimEnvLogger", "level": "INFO", "message": "State shape: (16,), Visual shape: (144, 256, 3)"}
{"time": "2024-07-21T15:09:08.080353", "name": "AirSimEnvLogger", "level": "INFO", "message": "Predictive model loss: 0.0035763317719101906"}
{"time": "2024-07-21T15:09:12.371462", "name": "AirSimEnvLogger", "level": "INFO", "message": "Reward breakdown - Distance: -9.870647094891332, Velocity: -0.018541081063435924, Collision: 0, Height: -1.0, Movement: -0.012108386241249037, Smoothness: -0.0, Curiosity: 0.0430259145796299, Exploration: 0.009408474699336875, Total: -10.357733821817494"}
{"time": "2024-07-21T15:09:12.495034", "name": "AirSimEnvLogger", "level": "INFO", "message": "Action: [0.06054193 0.06054193 0.06054193 0.06054193], Velocity: (0.06054193120624518, 0.06054193120624518, 0.06054193120624518), Duration: 0.5, Reward: -10.357733821817494, Done: False"}
{"time": "2024-07-21T15:09:12.558198", "name": "AirSimEnvLogger", "level": "INFO", "message": "Step completed. Observation keys: dict_keys(['state', 'visual'])"}
{"time": "2024-07-21T15:09:12.558198", "name": "AirSimEnvLogger", "level": "INFO", "message": "State shape: (16,), Visual shape: (144, 256, 3)"}
{"time": "2024-07-21T15:09:15.471214", "name": "AirSimEnvLogger", "level": "INFO", "message": "Predictive model loss: 0.0008268192177638412"}
{"time": "2024-07-21T15:09:20.326671", "name": "AirSimEnvLogger", "level": "INFO", "message": "Reward breakdown - Distance: -9.706846201996552, Velocity: -0.12639366523603007, Collision: 0, Height: -1.0, Movement: -0.08221361074986647, Smoothness: -0.0, Curiosity: 0.7955585718154907, Exploration: 0.009018043110380595, Total: -9.878681501159733"}
{"time": "2024-07-21T15:09:20.436879", "name": "AirSimEnvLogger", "level": "INFO", "message": "Action: [0.41106805 0.41106805 0.41106805 0.41106805], Velocity: (0.4110680537493323, 0.4110680537493323, 0.4110680537493323), Duration: 0.5, Reward: -9.878681501159733, Done: False"}
{"time": "2024-07-21T15:09:20.500178", "name": "AirSimEnvLogger", "level": "INFO", "message": "Step completed. Observation keys: dict_keys(['state', 'visual'])"}
{"time": "2024-07-21T15:09:20.500178", "name": "AirSimEnvLogger", "level": "INFO", "message": "State shape: (16,), Visual shape: (144, 256, 3)"}
{"time": "2024-07-21T15:09:23.478410", "name": "AirSimEnvLogger", "level": "INFO", "message": "Predictive model loss: 0.006337056402117014"}
{"time": "2024-07-21T15:09:28.605168", "name": "AirSimEnvLogger", "level": "INFO", "message": "Reward breakdown - Distance: -9.812811876067942, Velocity: -0.037371853016888515, Collision: 0, Height: -1.0, Movement: -0.024520853331399906, Smoothness: -0.0, Curiosity: 0.10540065914392471, Exploration: 0.010494075428823826, Total: -10.2791507432518"}
{"time": "2024-07-21T15:09:28.714918", "name": "AirSimEnvLogger", "level": "INFO", "message": "Action: [0.12260427 0.12260427 0.12260427 0.12260427], Velocity: (0.12260426665699953, 0.12260426665699953, 0.12260426665699953), Duration: 0.5, Reward: -10.2791507432518, Done: False"}
{"time": "2024-07-21T15:09:28.808595", "name": "AirSimEnvLogger", "level": "INFO", "message": "Step completed. Observation keys: dict_keys(['state', 'visual'])"}
{"time": "2024-07-21T15:09:28.808595", "name": "AirSimEnvLogger", "level": "INFO", "message": "State shape: (16,), Visual shape: (144, 256, 3)"}
{"time": "2024-07-21T15:09:31.673085", "name": "AirSimEnvLogger", "level": "INFO", "message": "Predictive model loss: 0.002043942455202341"}
{"time": "2024-07-21T15:09:36.313277", "name": "AirSimEnvLogger", "level": "INFO", "message": "Reward breakdown - Distance: -9.820585561846329, Velocity: -0.05688574063079837, Collision: 0, Height: -1.0, Movement: -0.03559161135093021, Smoothness: -0.0, Curiosity: 0.17695245146751404, Exploration: 0.013938800446397821, Total: -10.261323607473784"}
{"time": "2024-07-21T15:09:36.437734", "name": "AirSimEnvLogger", "level": "INFO", "message": "Action: [0.17795806 0.17795806 0.17795806 0.17795806], Velocity: (0.17795805675465104, 0.17795805675465104, 0.17795805675465104), Duration: 0.5, Reward: -10.261323607473784, Done: False"}
{"time": "2024-07-21T15:09:36.530869", "name": "AirSimEnvLogger", "level": "INFO", "message": "Step completed. Observation keys: dict_keys(['state', 'visual'])"}
{"time": "2024-07-21T15:09:36.530869", "name": "AirSimEnvLogger", "level": "INFO", "message": "State shape: (16,), Visual shape: (144, 256, 3)"}
{"time": "2024-07-21T15:09:39.549974", "name": "AirSimEnvLogger", "level": "INFO", "message": "Predictive model loss: 0.002339982194826007"}
{"time": "2024-07-21T15:09:44.609511", "name": "AirSimEnvLogger", "level": "INFO", "message": "Reward breakdown - Distance: -9.654983770096472, Velocity: -0.13697055018309698, Collision: 0, Height: -1.0, Movement: -0.09395522330470706, Smoothness: -0.0, Curiosity: 1.0762226581573486, Exploration: 0.026359410192032157, Total: -9.689481356401409"}
{"time": "2024-07-21T15:09:44.718180", "name": "AirSimEnvLogger", "level": "INFO", "message": "Action: [0.46977612 0.46977612 0.46977612 0.46977612], Velocity: (0.46977611652353524, 0.46977611652353524, 0.46977611652353524), Duration: 0.5, Reward: -9.689481356401409, Done: False"}
{"time": "2024-07-21T15:09:44.779298", "name": "AirSimEnvLogger", "level": "INFO", "message": "Step completed. Observation keys: dict_keys(['state', 'visual'])"}
{"time": "2024-07-21T15:09:44.779298", "name": "AirSimEnvLogger", "level": "INFO", "message": "State shape: (16,), Visual shape: (144, 256, 3)"}
{"time": "2024-07-21T15:09:47.761943", "name": "AirSimEnvLogger", "level": "INFO", "message": "Predictive model loss: 0.010871022939682007"}
{"time": "2024-07-21T15:09:52.363065", "name": "AirSimEnvLogger", "level": "INFO", "message": "Reward breakdown - Distance: -9.87125544117941, Velocity: -0.012601288137176552, Collision: 0, Height: -1.0, Movement: -0.0024559385862557904, Smoothness: -0.0, Curiosity: 0.03256514295935631, Exploration: 0.008419612672315184, Total: -10.359835185092482"}
{"time": "2024-07-21T15:09:52.472007", "name": "AirSimEnvLogger", "level": "INFO", "message": "Action: [-0.01227969 -0.01227969 -0.01227969 -0.01227969], Velocity: (-0.012279692931278952, -0.012279692931278952, -0.012279692931278952), Duration: 0.5, Reward: -10.359835185092482, Done: False"}
{"time": "2024-07-21T15:09:52.567278", "name": "AirSimEnvLogger", "level": "INFO", "message": "Step completed. Observation keys: dict_keys(['state', 'visual'])"}
{"time": "2024-07-21T15:09:52.567278", "name": "AirSimEnvLogger", "level": "INFO", "message": "State shape: (16,), Visual shape: (144, 256, 3)"}
{"time": "2024-07-21T15:09:55.487102", "name": "AirSimEnvLogger", "level": "INFO", "message": "Predictive model loss: 0.001450380776077509"}
{"time": "2024-07-21T15:10:00.690588", "name": "AirSimEnvLogger", "level": "INFO", "message": "Reward breakdown - Distance: -10.077916448749, Velocity: -0.07401189265829702, Collision: 0, Height: -1.0, Movement: -0.043867013220320585, Smoothness: -0.0, Curiosity: 0.2244262844324112, Exploration: 0.05340637030443451, Total: -10.496414680123088"}
{"time": "2024-07-21T15:10:00.815119", "name": "AirSimEnvLogger", "level": "INFO", "message": "Action: [-0.21933507 -0.21933507 -0.21933507 -0.21933507], Velocity: (-0.21933506610160292, -0.21933506610160292, -0.21933506610160292), Duration: 0.5, Reward: -10.496414680123088, Done: False"}
{"time": "2024-07-21T15:10:00.924248", "name": "AirSimEnvLogger", "level": "INFO", "message": "Step completed. Observation keys: dict_keys(['state', 'visual'])"}
{"time": "2024-07-21T15:10:00.924248", "name": "AirSimEnvLogger", "level": "INFO", "message": "State shape: (16,), Visual shape: (144, 256, 3)"}
{"time": "2024-07-21T15:10:03.207930", "name": "AirSimEnvLogger", "level": "INFO", "message": "Predictive model loss: 0.00197173235937953"}
{"time": "2024-07-21T15:10:07.975077", "name": "AirSimEnvLogger", "level": "INFO", "message": "Reward breakdown - Distance: -10.325555908262503, Velocity: -0.18497227716760323, Collision: 0, Height: -1.0, Movement: -0.09809292423940225, Smoothness: -0.0, Curiosity: 1.1639407873153687, Exploration: 0.05412164251623195, Total: -10.335056617109313"}
{"time": "2024-07-21T15:10:08.100979", "name": "AirSimEnvLogger", "level": "INFO", "message": "Action: [-0.49046462 -0.49046462 -0.49046462 -0.49046462], Velocity: (-0.4904646211970112, -0.4904646211970112, -0.4904646211970112), Duration: 0.5, Reward: -10.335056617109313, Done: False"}
{"time": "2024-07-21T15:10:08.162715", "name": "AirSimEnvLogger", "level": "INFO", "message": "Step completed. Observation keys: dict_keys(['state', 'visual'])"}
{"time": "2024-07-21T15:10:08.163220", "name": "AirSimEnvLogger", "level": "INFO", "message": "State shape: (16,), Visual shape: (144, 256, 3)"}
{"time": "2024-07-21T15:10:10.447662", "name": "AirSimEnvLogger", "level": "INFO", "message": "Predictive model loss: 0.013175143860280514"}
{"time": "2024-07-21T15:10:15.409632", "name": "AirSimEnvLogger", "level": "INFO", "message": "Reward breakdown - Distance: -10.050836749993959, Velocity: -0.05801876976822896, Collision: 0, Height: -1.0, Movement: -0.027112955509540827, Smoothness: -0.0, Curiosity: 0.10841643810272217, Exploration: 0.01557023015487841, Total: -10.52523516534669"}
{"time": "2024-07-21T15:10:15.502974", "name": "AirSimEnvLogger", "level": "INFO", "message": "Action: [0.13556478 0.13556478 0.13556478 0.13556478], Velocity: (0.13556477754770413, 0.13556477754770413, 0.13556477754770413), Duration: 0.5, Reward: -10.52523516534669, Done: False"}
{"time": "2024-07-21T15:10:15.581811", "name": "AirSimEnvLogger", "level": "INFO", "message": "Step completed. Observation keys: dict_keys(['state', 'visual'])"}
{"time": "2024-07-21T15:10:15.581811", "name": "AirSimEnvLogger", "level": "INFO", "message": "State shape: (16,), Visual shape: (144, 256, 3)"}
{"time": "2024-07-21T15:10:18.504117", "name": "AirSimEnvLogger", "level": "INFO", "message": "Predictive model loss: 0.0012343639973551035"}
{"time": "2024-07-21T15:10:22.964810", "name": "AirSimEnvLogger", "level": "INFO", "message": "Reward breakdown - Distance: -10.051195935506616, Velocity: -0.015405424003432377, Collision: 0, Height: -1.0, Movement: -0.008186325103582248, Smoothness: -0.0, Curiosity: 0.03148689121007919, Exploration: 0.03574698115764957, Total: -10.536824438182121"}
{"time": "2024-07-21T15:10:23.041637", "name": "AirSimEnvLogger", "level": "INFO", "message": "Action: [-0.04093163 -0.04093163 -0.04093163 -0.04093163], Velocity: (-0.04093162551791124, -0.04093162551791124, -0.04093162551791124), Duration: 0.5, Reward: -10.536824438182121, Done: False"}
{"time": "2024-07-21T15:10:23.119989", "name": "AirSimEnvLogger", "level": "INFO", "message": "Step completed. Observation keys: dict_keys(['state', 'visual'])"}
{"time": "2024-07-21T15:10:23.119989", "name": "AirSimEnvLogger", "level": "INFO", "message": "State shape: (16,), Visual shape: (144, 256, 3)"}
{"time": "2024-07-21T15:10:26.023414", "name": "AirSimEnvLogger", "level": "INFO", "message": "Predictive model loss: 0.000905893393792212"}
{"time": "2024-07-21T15:10:30.980061", "name": "AirSimEnvLogger", "level": "INFO", "message": "Reward breakdown - Distance: -9.81209494332104, Velocity: -0.11308257310379843, Collision: 0, Height: -1.0, Movement: -0.07206625507745083, Smoothness: -0.0, Curiosity: 0.6050204634666443, Exploration: 0.026789909028163267, Total: -10.06797464184173"}
{"time": "2024-07-21T15:10:31.135300", "name": "AirSimEnvLogger", "level": "INFO", "message": "Action: [0.36033128 0.36033128 0.36033128 0.36033128], Velocity: (0.3603312753872541, 0.3603312753872541, 0.3603312753872541), Duration: 0.5, Reward: -10.06797464184173, Done: False"}
{"time": "2024-07-21T15:10:31.197489", "name": "AirSimEnvLogger", "level": "INFO", "message": "Step completed. Observation keys: dict_keys(['state', 'visual'])"}
{"time": "2024-07-21T15:10:31.197489", "name": "AirSimEnvLogger", "level": "INFO", "message": "State shape: (16,), Visual shape: (144, 256, 3)"}
{"time": "2024-07-21T15:10:34.172585", "name": "AirSimEnvLogger", "level": "INFO", "message": "Predictive model loss: 0.003806555410847068"}
{"time": "2024-07-21T15:10:39.235792", "name": "AirSimEnvLogger", "level": "INFO", "message": "Reward breakdown - Distance: -9.603098258845964, Velocity: -0.16834931568663722, Collision: 0, Height: -1.0, Movement: -0.11219254516796735, Smoothness: -0.0, Curiosity: 1.533277153968811, Exploration: 0.057143269449527856, Total: -9.420424940331769"}
{"time": "2024-07-21T15:10:39.377364", "name": "AirSimEnvLogger", "level": "INFO", "message": "Action: [0.56096273 0.56096273 0.56096273 0.56096273], Velocity: (0.5609627258398368, 0.5609627258398368, 0.5609627258398368), Duration: 0.5, Reward: -9.420424940331769, Done: False"}
{"time": "2024-07-21T15:10:39.440476", "name": "AirSimEnvLogger", "level": "INFO", "message": "Step completed. Observation keys: dict_keys(['state', 'visual'])"}
{"time": "2024-07-21T15:10:39.440476", "name": "AirSimEnvLogger", "level": "INFO", "message": "State shape: (16,), Visual shape: (144, 256, 3)"}
{"time": "2024-07-21T15:10:42.448621", "name": "AirSimEnvLogger", "level": "INFO", "message": "Predictive model loss: 0.014840662479400635"}
{"time": "2024-07-21T15:10:47.421508", "name": "AirSimEnvLogger", "level": "INFO", "message": "Reward breakdown - Distance: -9.876252912961696, Velocity: -0.024749882508368713, Collision: 0, Height: -1.0, Movement: -0.011179066781021808, Smoothness: -0.0, Curiosity: 0.046928297728300095, Exploration: 0.016875258957369476, Total: -10.36290656023836"}
{"time": "2024-07-21T15:10:47.545702", "name": "AirSimEnvLogger", "level": "INFO", "message": "Action: [-0.05589533 -0.05589533 -0.05589533 -0.05589533], Velocity: (-0.055895333905109035, -0.055895333905109035, -0.055895333905109035), Duration: 0.5, Reward: -10.36290656023836, Done: False"}
{"time": "2024-07-21T15:10:47.607753", "name": "AirSimEnvLogger", "level": "INFO", "message": "Step completed. Observation keys: dict_keys(['state', 'visual'])"}
{"time": "2024-07-21T15:10:47.607753", "name": "AirSimEnvLogger", "level": "INFO", "message": "State shape: (16,), Visual shape: (144, 256, 3)"}
{"time": "2024-07-21T15:10:50.604146", "name": "AirSimEnvLogger", "level": "INFO", "message": "Predictive model loss: 0.0012741959653794765"}
{"time": "2024-07-21T15:10:55.615467", "name": "AirSimEnvLogger", "level": "INFO", "message": "Reward breakdown - Distance: -9.742665508643187, Velocity: -0.11054951401511699, Collision: 0, Height: -1.0, Movement: -0.07056988423873105, Smoothness: -0.0, Curiosity: 0.6529353857040405, Exploration: 0.015518176209379031, Total: -9.975425925980721"}
{"time": "2024-07-21T15:10:55.740839", "name": "AirSimEnvLogger", "level": "INFO", "message": "Action: [0.35284942 0.35284942 0.35284942 0.35284942], Velocity: (0.3528494211936552, 0.3528494211936552, 0.3528494211936552), Duration: 0.5, Reward: -9.975425925980721, Done: False"}
{"time": "2024-07-21T15:10:55.834607", "name": "AirSimEnvLogger", "level": "INFO", "message": "Step completed. Observation keys: dict_keys(['state', 'visual'])"}
{"time": "2024-07-21T15:10:55.834607", "name": "AirSimEnvLogger", "level": "INFO", "message": "State shape: (16,), Visual shape: (144, 256, 3)"}
{"time": "2024-07-21T15:10:58.748053", "name": "AirSimEnvLogger", "level": "INFO", "message": "Predictive model loss: 0.007610654458403587"}
{"time": "2024-07-21T15:11:03.528288", "name": "AirSimEnvLogger", "level": "INFO", "message": "Reward breakdown - Distance: -9.579947796083099, Velocity: -0.1646349071836375, Collision: 0, Height: -1.0, Movement: -0.11056218716407379, Smoothness: -0.0, Curiosity: 1.5818194150924683, Exploration: 0.04625992776621783, Total: -9.373159775291846"}
{"time": "2024-07-21T15:11:03.654942", "name": "AirSimEnvLogger", "level": "INFO", "message": "Action: [0.55281094 0.55281094 0.55281094 0.55281094], Velocity: (0.5528109358203689, 0.5528109358203689, 0.5528109358203689), Duration: 0.5, Reward: -9.373159775291846, Done: False"}
{"time": "2024-07-21T15:11:03.670460", "name": "AirSimEnvLogger", "level": "INFO", "message": "Step completed. Observation keys: dict_keys(['state', 'visual'])"}
{"time": "2024-07-21T15:11:03.670460", "name": "AirSimEnvLogger", "level": "INFO", "message": "State shape: (16,), Visual shape: (144, 256, 3)"}
{"time": "2024-07-21T15:11:06.516769", "name": "AirSimEnvLogger", "level": "INFO", "message": "Predictive model loss: 0.019102804362773895"}
{"time": "2024-07-21T15:11:11.430668", "name": "AirSimEnvLogger", "level": "INFO", "message": "Reward breakdown - Distance: -9.893659588325779, Velocity: -0.040865662350957836, Collision: 0, Height: -1.0, Movement: -0.02087832404720505, Smoothness: -0.0, Curiosity: 0.09950833022594452, Exploration: 0.02337617293020826, Total: -10.361750852206963"}
{"time": "2024-07-21T15:11:11.556815", "name": "AirSimEnvLogger", "level": "INFO", "message": "Action: [-0.10439162 -0.10439162 -0.10439162 -0.10439162], Velocity: (-0.10439162023602522, -0.10439162023602522, -0.10439162023602522), Duration: 0.5, Reward: -10.361750852206963, Done: False"}
{"time": "2024-07-21T15:11:11.619595", "name": "AirSimEnvLogger", "level": "INFO", "message": "Step completed. Observation keys: dict_keys(['state', 'visual'])"}
{"time": "2024-07-21T15:11:11.619595", "name": "AirSimEnvLogger", "level": "INFO", "message": "State shape: (16,), Visual shape: (144, 256, 3)"}
{"time": "2024-07-21T15:11:14.571221", "name": "AirSimEnvLogger", "level": "INFO", "message": "Predictive model loss: 0.0022179498337209225"}
{"time": "2024-07-21T15:11:19.475031", "name": "AirSimEnvLogger", "level": "INFO", "message": "Reward breakdown - Distance: -9.814724449187755, Velocity: -0.08470758805561489, Collision: 0, Height: -1.0, Movement: -0.04825679802125832, Smoothness: -0.0, Curiosity: 0.3820393681526184, Exploration: 0.026264885839294386, Total: -10.165631261773521"}
{"time": "2024-07-21T15:11:19.479029", "name": "AirSimEnvLogger", "level": "INFO", "message": "Action: [0.24128399 0.24128399 0.24128399 0.24128399], Velocity: (0.2412839901062916, 0.2412839901062916, 0.2412839901062916), Duration: 0.5, Reward: -10.165631261773521, Done: False"}
{"time": "2024-07-21T15:11:19.554454", "name": "AirSimEnvLogger", "level": "INFO", "message": "Step completed. Observation keys: dict_keys(['state', 'visual'])"}
{"time": "2024-07-21T15:11:19.554454", "name": "AirSimEnvLogger", "level": "INFO", "message": "State shape: (16,), Visual shape: (144, 256, 3)"}
{"time": "2024-07-21T15:11:22.606236", "name": "AirSimEnvLogger", "level": "INFO", "message": "Predictive model loss: 0.006475016474723816"}
{"time": "2024-07-21T15:11:27.339416", "name": "AirSimEnvLogger", "level": "INFO", "message": "Reward breakdown - Distance: -9.738447940911119, Velocity: -0.10156185692976163, Collision: 0, Height: -1.0, Movement: -0.06598722409817646, Smoothness: -0.0, Curiosity: 0.6714843511581421, Exploration: 0.029762302094994517, Total: -9.954132955787747"}
{"time": "2024-07-21T15:11:27.464433", "name": "AirSimEnvLogger", "level": "INFO", "message": "Action: [0.32993612 0.32993612 0.32993612 0.32993612], Velocity: (0.3299361204908823, 0.3299361204908823, 0.3299361204908823), Duration: 0.5, Reward: -9.954132955787747, Done: False"}
{"time": "2024-07-21T15:11:27.527941", "name": "AirSimEnvLogger", "level": "INFO", "message": "Step completed. Observation keys: dict_keys(['state', 'visual'])"}
{"time": "2024-07-21T15:11:27.527941", "name": "AirSimEnvLogger", "level": "INFO", "message": "State shape: (16,), Visual shape: (144, 256, 3)"}
{"time": "2024-07-21T15:11:30.609468", "name": "AirSimEnvLogger", "level": "INFO", "message": "Predictive model loss: 0.010447682812809944"}
{"time": "2024-07-21T15:11:35.092353", "name": "AirSimEnvLogger", "level": "INFO", "message": "Reward breakdown - Distance: -9.585865115491822, Velocity: -0.17252473717466008, Collision: 0, Height: -1.0, Movement: -0.10915302967833017, Smoothness: -0.0, Curiosity: 1.6628444194793701, Exploration: 0.03211217327321446, Total: -9.345198142652656"}
{"time": "2024-07-21T15:11:35.171403", "name": "AirSimEnvLogger", "level": "INFO", "message": "Action: [0.54576515 0.54576515 0.54576515 0.54576515], Velocity: (0.5457651483916508, 0.5457651483916508, 0.5457651483916508), Duration: 0.5, Reward: -9.345198142652656, Done: False"}
{"time": "2024-07-21T15:11:35.251098", "name": "AirSimEnvLogger", "level": "INFO", "message": "Step completed. Observation keys: dict_keys(['state', 'visual'])"}
{"time": "2024-07-21T15:11:35.251098", "name": "AirSimEnvLogger", "level": "INFO", "message": "State shape: (16,), Visual shape: (144, 256, 3)"}
{"time": "2024-07-21T15:11:37.810922", "name": "AirSimEnvLogger", "level": "INFO", "message": "Predictive model loss: 0.02272721566259861"}
{"time": "2024-07-21T15:11:42.809346", "name": "AirSimEnvLogger", "level": "INFO", "message": "Reward breakdown - Distance: -9.899046214893819, Velocity: -0.042202524202264974, Collision: 0, Height: -1.0, Movement: -0.021582902790076866, Smoothness: -0.0, Curiosity: 0.16947093605995178, Exploration: 0.02306291456963665, Total: -10.332957716330055"}
{"time": "2024-07-21T15:11:42.918245", "name": "AirSimEnvLogger", "level": "INFO", "message": "Action: [-0.10791451 -0.10791451 -0.10791451 -0.10791451], Velocity: (-0.10791451395038432, -0.10791451395038432, -0.10791451395038432), Duration: 0.5, Reward: -10.332957716330055, Done: False"}
{"time": "2024-07-21T15:11:42.981341", "name": "AirSimEnvLogger", "level": "INFO", "message": "Step completed. Observation keys: dict_keys(['state', 'visual'])"}
{"time": "2024-07-21T15:11:42.981341", "name": "AirSimEnvLogger", "level": "INFO", "message": "State shape: (16,), Visual shape: (144, 256, 3)"}
{"time": "2024-07-21T15:11:46.012336", "name": "AirSimEnvLogger", "level": "INFO", "message": "Predictive model loss: 0.004509173799306154"}
{"time": "2024-07-21T15:11:51.153679", "name": "AirSimEnvLogger", "level": "INFO", "message": "Reward breakdown - Distance: -9.80524767350589, Velocity: -0.08533424360890268, Collision: 0, Height: -1.0, Movement: -0.05383301907729739, Smoothness: -0.0, Curiosity: 0.5657804012298584, Exploration: 0.0243293672472143, Total: -10.065542023153698"}
{"time": "2024-07-21T15:11:51.264605", "name": "AirSimEnvLogger", "level": "INFO", "message": "Action: [0.2691651 0.2691651 0.2691651 0.2691651], Velocity: (0.2691650953864869, 0.2691650953864869, 0.2691650953864869), Duration: 0.5, Reward: -10.065542023153698, Done: False"}
{"time": "2024-07-21T15:11:51.328286", "name": "AirSimEnvLogger", "level": "INFO", "message": "Step completed. Observation keys: dict_keys(['state', 'visual'])"}
{"time": "2024-07-21T15:11:51.328286", "name": "AirSimEnvLogger", "level": "INFO", "message": "State shape: (16,), Visual shape: (144, 256, 3)"}
{"time": "2024-07-21T15:11:54.365341", "name": "AirSimEnvLogger", "level": "INFO", "message": "Predictive model loss: 0.010945504531264305"}
{"time": "2024-07-21T15:11:59.531545", "name": "AirSimEnvLogger", "level": "INFO", "message": "Reward breakdown - Distance: -9.800064169335698, Velocity: -0.06938514377290593, Collision: 0, Height: -1.0, Movement: -0.044412886768339245, Smoothness: -0.0, Curiosity: 0.4855053722858429, Exploration: 0.02265336509812051, Total: -10.091914670736438"}
{"time": "2024-07-21T15:11:59.672576", "name": "AirSimEnvLogger", "level": "INFO", "message": "Action: [0.22206443 0.22206443 0.22206443 0.22206443], Velocity: (0.22206443384169622, 0.22206443384169622, 0.22206443384169622), Duration: 0.5, Reward: -10.091914670736438, Done: False"}
{"time": "2024-07-21T15:11:59.735499", "name": "AirSimEnvLogger", "level": "INFO", "message": "Step completed. Observation keys: dict_keys(['state', 'visual'])"}
{"time": "2024-07-21T15:11:59.735499", "name": "AirSimEnvLogger", "level": "INFO", "message": "State shape: (16,), Visual shape: (144, 256, 3)"}
{"time": "2024-07-21T15:12:02.581947", "name": "AirSimEnvLogger", "level": "INFO", "message": "Predictive model loss: 0.01083226315677166"}
{"time": "2024-07-21T15:12:07.585979", "name": "AirSimEnvLogger", "level": "INFO", "message": "Reward breakdown - Distance: -10.062507079533432, Velocity: -0.08388599707999303, Collision: 0, Height: -1.0, Movement: -0.04756557361793609, Smoothness: -0.0, Curiosity: 0.3509995639324188, Exploration: 0.035468251069486055, Total: -10.426613203255116"}
{"time": "2024-07-21T15:12:07.644750", "name": "AirSimEnvLogger", "level": "INFO", "message": "Action: [-0.23782787 -0.23782787 -0.23782787 -0.23782787], Velocity: (-0.23782786808968043, -0.23782786808968043, -0.23782786808968043), Duration: 0.5, Reward: -10.426613203255116, Done: False"}
{"time": "2024-07-21T15:12:07.692515", "name": "AirSimEnvLogger", "level": "INFO", "message": "Step completed. Observation keys: dict_keys(['state', 'visual'])"}
{"time": "2024-07-21T15:12:07.692515", "name": "AirSimEnvLogger", "level": "INFO", "message": "State shape: (16,), Visual shape: (144, 256, 3)"}
{"time": "2024-07-21T15:12:10.669965", "name": "AirSimEnvLogger", "level": "INFO", "message": "Predictive model loss: 0.004855751059949398"}
{"time": "2024-07-21T15:12:15.269886", "name": "AirSimEnvLogger", "level": "INFO", "message": "Reward breakdown - Distance: -10.027585946137888, Velocity: -0.0037514184604571644, Collision: 0, Height: -1.0, Movement: -0.0005100160017009026, Smoothness: -0.0, Curiosity: 0.16903644800186157, Exploration: 0.025936444033818225, Total: -10.439807144160593"}
{"time": "2024-07-21T15:12:15.379116", "name": "AirSimEnvLogger", "level": "INFO", "message": "Action: [0.00255008 0.00255008 0.00255008 0.00255008], Velocity: (0.0025500800085045128, 0.0025500800085045128, 0.0025500800085045128), Duration: 0.5, Reward: -10.439807144160593, Done: False"}
{"time": "2024-07-21T15:12:15.442456", "name": "AirSimEnvLogger", "level": "INFO", "message": "Step completed. Observation keys: dict_keys(['state', 'visual'])"}
{"time": "2024-07-21T15:12:15.442456", "name": "AirSimEnvLogger", "level": "INFO", "message": "State shape: (16,), Visual shape: (144, 256, 3)"}
{"time": "2024-07-21T15:12:18.356970", "name": "AirSimEnvLogger", "level": "INFO", "message": "Predictive model loss: 0.005023459438234568"}
{"time": "2024-07-21T15:12:22.669153", "name": "AirSimEnvLogger", "level": "INFO", "message": "Reward breakdown - Distance: -9.814077763482898, Velocity: -0.11283345588447247, Collision: 0, Height: -1.0, Movement: -0.07154866005849816, Smoothness: -0.0, Curiosity: 0.8584502339363098, Exploration: 0.03993931835385811, Total: -9.940436376792057"}
{"time": "2024-07-21T15:12:22.690216", "name": "AirSimEnvLogger", "level": "INFO", "message": "Action: [0.3577433 0.3577433 0.3577433 0.3577433], Velocity: (0.3577433002924908, 0.3577433002924908, 0.3577433002924908), Duration: 0.5, Reward: -9.940436376792057, Done: False"}
{"time": "2024-07-21T15:12:22.750883", "name": "AirSimEnvLogger", "level": "INFO", "message": "Step completed. Observation keys: dict_keys(['state', 'visual'])"}
{"time": "2024-07-21T15:12:22.750883", "name": "AirSimEnvLogger", "level": "INFO", "message": "State shape: (16,), Visual shape: (144, 256, 3)"}
{"time": "2024-07-21T15:12:25.692290", "name": "AirSimEnvLogger", "level": "INFO", "message": "Predictive model loss: 0.01053526159375906"}
{"time": "2024-07-21T15:12:30.860363", "name": "AirSimEnvLogger", "level": "INFO", "message": "Reward breakdown - Distance: -9.731093623415655, Velocity: -0.10667315268035014, Collision: 0, Height: -1.0, Movement: -0.0711176611278056, Smoothness: -0.0, Curiosity: 0.9425386190414429, Exploration: 0.03781097507471129, Total: -9.812710461332946"}
{"time": "2024-07-21T15:12:30.986613", "name": "AirSimEnvLogger", "level": "INFO", "message": "Action: [0.35558831 0.35558831 0.35558831 0.35558831], Velocity: (0.355588305639028, 0.355588305639028, 0.355588305639028), Duration: 0.5, Reward: -9.812710461332946, Done: False"}
{"time": "2024-07-21T15:12:31.049754", "name": "AirSimEnvLogger", "level": "INFO", "message": "Step completed. Observation keys: dict_keys(['state', 'visual'])"}
{"time": "2024-07-21T15:12:31.049754", "name": "AirSimEnvLogger", "level": "INFO", "message": "State shape: (16,), Visual shape: (144, 256, 3)"}
{"time": "2024-07-21T15:12:33.997587", "name": "AirSimEnvLogger", "level": "INFO", "message": "Predictive model loss: 0.013047143816947937"}
{"time": "2024-07-21T15:12:38.896908", "name": "AirSimEnvLogger", "level": "INFO", "message": "Reward breakdown - Distance: -10.017552819749577, Velocity: -0.09343034264293022, Collision: 0, Height: -1.0, Movement: -0.04060058706533914, Smoothness: -0.0, Curiosity: 0.34993207454681396, Exploration: 0.0328691635448152, Total: -10.386788179795206"}
{"time": "2024-07-21T15:12:39.051302", "name": "AirSimEnvLogger", "level": "INFO", "message": "Action: [-0.20300294 -0.20300294 -0.20300294 -0.20300294], Velocity: (-0.20300293532669567, -0.20300293532669567, -0.20300293532669567), Duration: 0.5, Reward: -10.386788179795206, Done: False"}
{"time": "2024-07-21T15:12:39.114585", "name": "AirSimEnvLogger", "level": "INFO", "message": "Step completed. Observation keys: dict_keys(['state', 'visual'])"}
{"time": "2024-07-21T15:12:39.114585", "name": "AirSimEnvLogger", "level": "INFO", "message": "State shape: (16,), Visual shape: (144, 256, 3)"}
{"time": "2024-07-21T15:12:42.111941", "name": "AirSimEnvLogger", "level": "INFO", "message": "Predictive model loss: 0.004695258568972349"}
{"time": "2024-07-21T15:12:47.232647", "name": "AirSimEnvLogger", "level": "INFO", "message": "Reward breakdown - Distance: -10.29075315536479, Velocity: -0.1922525109765769, Collision: 0, Height: -1.0, Movement: -0.09645971116191152, Smoothness: -0.0, Curiosity: 1.146602749824524, Exploration: 0.07333395545931484, Total: -10.308557215965145"}
{"time": "2024-07-21T15:12:47.389107", "name": "AirSimEnvLogger", "level": "INFO", "message": "Action: [-0.48229856 -0.48229856 -0.48229856 -0.48229856], Velocity: (-0.48229855580955755, -0.48229855580955755, -0.48229855580955755), Duration: 0.5, Reward: -10.308557215965145, Done: False"}
{"time": "2024-07-21T15:12:47.496354", "name": "AirSimEnvLogger", "level": "INFO", "message": "Step completed. Observation keys: dict_keys(['state', 'visual'])"}
{"time": "2024-07-21T15:12:47.496354", "name": "AirSimEnvLogger", "level": "INFO", "message": "State shape: (16,), Visual shape: (144, 256, 3)"}
{"time": "2024-07-21T15:12:50.438498", "name": "AirSimEnvLogger", "level": "INFO", "message": "Predictive model loss: 0.013835412450134754"}
{"time": "2024-07-21T15:12:55.345583", "name": "AirSimEnvLogger", "level": "INFO", "message": "Reward breakdown - Distance: -10.414753749862886, Velocity: -0.1685142992293708, Collision: 0, Height: -1.0, Movement: -0.09982370166364314, Smoothness: -0.0, Curiosity: 1.2768919467926025, Exploration: 0.04660065095751434, Total: -10.361227166056132"}
{"time": "2024-07-21T15:12:55.378702", "name": "AirSimEnvLogger", "level": "INFO", "message": "Action: [-0.49911851 -0.49911851 -0.49911851 -0.49911851], Velocity: (-0.4991185083182157, -0.4991185083182157, -0.4991185083182157), Duration: 0.5, Reward: -10.361227166056132, Done: False"}
{"time": "2024-07-21T15:12:55.422334", "name": "AirSimEnvLogger", "level": "INFO", "message": "Step completed. Observation keys: dict_keys(['state', 'visual'])"}
{"time": "2024-07-21T15:12:55.422334", "name": "AirSimEnvLogger", "level": "INFO", "message": "State shape: (16,), Visual shape: (144, 256, 3)"}
{"time": "2024-07-21T15:12:58.255650", "name": "AirSimEnvLogger", "level": "INFO", "message": "Predictive model loss: 0.020202213898301125"}
{"time": "2024-07-21T15:13:02.950168", "name": "AirSimEnvLogger", "level": "INFO", "message": "Reward breakdown - Distance: -10.132624181165228, Velocity: -0.031488513688158935, Collision: 0, Height: -1.0, Movement: -0.014760577537700527, Smoothness: -0.0, Curiosity: 0.208810493350029, Exploration: 0.03079660284372764, Total: -10.539279928519319"}
{"time": "2024-07-21T15:13:03.123938", "name": "AirSimEnvLogger", "level": "INFO", "message": "Action: [0.07380289 0.07380289 0.07380289 0.07380289], Velocity: (0.07380288768850263, 0.07380288768850263, 0.07380288768850263), Duration: 0.5, Reward: -10.539279928519319, Done: False"}
{"time": "2024-07-21T15:13:03.171003", "name": "AirSimEnvLogger", "level": "INFO", "message": "Step completed. Observation keys: dict_keys(['state', 'visual'])"}
{"time": "2024-07-21T15:13:03.171003", "name": "AirSimEnvLogger", "level": "INFO", "message": "State shape: (16,), Visual shape: (144, 256, 3)"}
{"time": "2024-07-21T15:13:06.332004", "name": "AirSimEnvLogger", "level": "INFO", "message": "Predictive model loss: 0.003570795990526676"}
{"time": "2024-07-21T15:13:11.317062", "name": "AirSimEnvLogger", "level": "INFO", "message": "Reward breakdown - Distance: -10.230406842709485, Velocity: -0.09408308299567913, Collision: 0, Height: -1.0, Movement: -0.057101011346735064, Smoothness: -0.0, Curiosity: 0.46850448846817017, Exploration: 0.020527454293153603, Total: -10.544800750249282"}
{"time": "2024-07-21T15:13:11.505512", "name": "AirSimEnvLogger", "level": "INFO", "message": "Action: [-0.28550506 -0.28550506 -0.28550506 -0.28550506], Velocity: (-0.2855050567336753, -0.2855050567336753, -0.2855050567336753), Duration: 0.5, Reward: -10.544800750249282, Done: False"}
{"time": "2024-07-21T15:13:11.568846", "name": "AirSimEnvLogger", "level": "INFO", "message": "Step completed. Observation keys: dict_keys(['state', 'visual'])"}
{"time": "2024-07-21T15:13:11.568846", "name": "AirSimEnvLogger", "level": "INFO", "message": "State shape: (16,), Visual shape: (144, 256, 3)"}
{"time": "2024-07-21T15:13:14.386310", "name": "AirSimEnvLogger", "level": "INFO", "message": "Predictive model loss: 0.007740159519016743"}
{"time": "2024-07-21T15:13:19.538539", "name": "AirSimEnvLogger", "level": "INFO", "message": "Reward breakdown - Distance: -10.407691430566185, Velocity: -0.1888384203430133, Collision: 0, Height: -1.0, Movement: -0.10470992330260948, Smoothness: -0.0, Curiosity: 1.3544540405273438, Exploration: 0.046386839820478275, Total: -10.326077244840185"}
{"time": "2024-07-21T15:13:19.633521", "name": "AirSimEnvLogger", "level": "INFO", "message": "Action: [-0.52354962 -0.52354962 -0.52354962 -0.52354962], Velocity: (-0.5235496165130473, -0.5235496165130473, -0.5235496165130473), Duration: 0.5, Reward: -10.326077244840185, Done: False"}
{"time": "2024-07-21T15:13:19.694720", "name": "AirSimEnvLogger", "level": "INFO", "message": "Step completed. Observation keys: dict_keys(['state', 'visual'])"}
{"time": "2024-07-21T15:13:19.694720", "name": "AirSimEnvLogger", "level": "INFO", "message": "State shape: (16,), Visual shape: (144, 256, 3)"}
{"time": "2024-07-21T15:13:22.357980", "name": "AirSimEnvLogger", "level": "INFO", "message": "Predictive model loss: 0.01973523385822773"}
{"time": "2024-07-21T15:13:27.162016", "name": "AirSimEnvLogger", "level": "INFO", "message": "Reward breakdown - Distance: -10.23907110579186, Velocity: -0.03691320286883909, Collision: 0, Height: -1.0, Movement: -0.023732650297621262, Smoothness: -0.0, Curiosity: 0.1919792890548706, Exploration: 0.006819826776861712, Total: -10.662547362373234"}
{"time": "2024-07-21T15:13:27.272972", "name": "AirSimEnvLogger", "level": "INFO", "message": "Action: [-0.11866325 -0.11866325 -0.11866325 -0.11866325], Velocity: (-0.1186632514881063, -0.1186632514881063, -0.1186632514881063), Duration: 0.5, Reward: -10.662547362373234, Done: False"}
{"time": "2024-07-21T15:13:27.334874", "name": "AirSimEnvLogger", "level": "INFO", "message": "Step completed. Observation keys: dict_keys(['state', 'visual'])"}
{"time": "2024-07-21T15:13:27.334874", "name": "AirSimEnvLogger", "level": "INFO", "message": "State shape: (16,), Visual shape: (144, 256, 3)"}
{"time": "2024-07-21T15:13:30.172161", "name": "AirSimEnvLogger", "level": "INFO", "message": "Predictive model loss: 0.00579258194193244"}
{"time": "2024-07-21T15:13:35.097304", "name": "AirSimEnvLogger", "level": "INFO", "message": "Reward breakdown - Distance: -10.348710978372932, Velocity: -0.1660717384557503, Collision: 0, Height: -1.0, Movement: -0.0828778207390206, Smoothness: -0.0, Curiosity: 0.8812240362167358, Exploration: 0.007216297509041252, Total: -10.497979352064531"}
{"time": "2024-07-21T15:13:35.175915", "name": "AirSimEnvLogger", "level": "INFO", "message": "Action: [-0.4143891 -0.4143891 -0.4143891 -0.4143891], Velocity: (-0.41438910369510296, -0.41438910369510296, -0.41438910369510296), Duration: 0.5, Reward: -10.497979352064531, Done: False"}
{"time": "2024-07-21T15:13:35.253448", "name": "AirSimEnvLogger", "level": "INFO", "message": "Step completed. Observation keys: dict_keys(['state', 'visual'])"}
{"time": "2024-07-21T15:13:35.253448", "name": "AirSimEnvLogger", "level": "INFO", "message": "State shape: (16,), Visual shape: (144, 256, 3)"}
{"time": "2024-07-21T15:13:38.262587", "name": "AirSimEnvLogger", "level": "INFO", "message": "Predictive model loss: 0.01390377152711153"}
{"time": "2024-07-21T15:13:43.325243", "name": "AirSimEnvLogger", "level": "INFO", "message": "Reward breakdown - Distance: -10.252877601997307, Velocity: -0.05812044221228966, Collision: 0, Height: -1.0, Movement: -0.03657860905372584, Smoothness: -0.0, Curiosity: 0.24855385720729828, Exploration: 0.010062892581119287, Total: -10.65930617688895"}
{"time": "2024-07-21T15:13:43.451208", "name": "AirSimEnvLogger", "level": "INFO", "message": "Action: [-0.18289305 -0.18289305 -0.18289305 -0.18289305], Velocity: (-0.1828930452686292, -0.1828930452686292, -0.1828930452686292), Duration: 0.5, Reward: -10.65930617688895, Done: False"}
{"time": "2024-07-21T15:13:43.528439", "name": "AirSimEnvLogger", "level": "INFO", "message": "Step completed. Observation keys: dict_keys(['state', 'visual'])"}
{"time": "2024-07-21T15:13:43.528439", "name": "AirSimEnvLogger", "level": "INFO", "message": "State shape: (16,), Visual shape: (144, 256, 3)"}
{"time": "2024-07-21T15:13:46.408381", "name": "AirSimEnvLogger", "level": "INFO", "message": "Predictive model loss: 0.0060777077451348305"}
{"time": "2024-07-21T15:13:51.535942", "name": "AirSimEnvLogger", "level": "INFO", "message": "Reward breakdown - Distance: -9.938959207588656, Velocity: -0.09370324722385645, Collision: 0, Height: -1.0, Movement: -0.05787011310237903, Smoothness: -0.0, Curiosity: 0.4472541809082031, Exploration: 0.05453490642644248, Total: -10.257063770771433"}
{"time": "2024-07-21T15:13:51.709366", "name": "AirSimEnvLogger", "level": "INFO", "message": "Action: [0.28935057 0.28935057 0.28935057 0.28935057], Velocity: (0.28935056551189514, 0.28935056551189514, 0.28935056551189514), Duration: 0.5, Reward: -10.257063770771433, Done: False"}
{"time": "2024-07-21T15:13:51.740915", "name": "AirSimEnvLogger", "level": "INFO", "message": "Step completed. Observation keys: dict_keys(['state', 'visual'])"}
{"time": "2024-07-21T15:13:51.740915", "name": "AirSimEnvLogger", "level": "INFO", "message": "State shape: (16,), Visual shape: (144, 256, 3)"}
{"time": "2024-07-21T15:13:54.635858", "name": "AirSimEnvLogger", "level": "INFO", "message": "Predictive model loss: 0.0016257950337603688"}
{"time": "2024-07-21T15:13:59.789848", "name": "AirSimEnvLogger", "level": "INFO", "message": "Reward breakdown - Distance: -9.72592684754172, Velocity: -0.1388269182293812, Collision: 0, Height: -1.0, Movement: -0.08925614319631586, Smoothness: -0.0, Curiosity: 1.048414945602417, Exploration: 0.06355031341717164, Total: -9.767348385491399"}
{"time": "2024-07-21T15:13:59.915918", "name": "AirSimEnvLogger", "level": "INFO", "message": "Action: [0.44628072 0.44628072 0.44628072 0.44628072], Velocity: (0.44628071598157926, 0.44628071598157926, 0.44628071598157926), Duration: 0.5, Reward: -9.767348385491399, Done: False"}
{"time": "2024-07-21T15:14:00.010094", "name": "AirSimEnvLogger", "level": "INFO", "message": "Step completed. Observation keys: dict_keys(['state', 'visual'])"}
{"time": "2024-07-21T15:14:00.010094", "name": "AirSimEnvLogger", "level": "INFO", "message": "State shape: (16,), Visual shape: (144, 256, 3)"}
{"time": "2024-07-21T15:14:02.717064", "name": "AirSimEnvLogger", "level": "INFO", "message": "Predictive model loss: 0.009101694449782372"}
{"time": "2024-07-21T15:14:07.608565", "name": "AirSimEnvLogger", "level": "INFO", "message": "Reward breakdown - Distance: -9.790683068979964, Velocity: -0.054572055242688655, Collision: 0, Height: -1.0, Movement: -0.03594282027278905, Smoothness: -0.0, Curiosity: 0.2921631336212158, Exploration: 0.01624362891888706, Total: -10.172233086034202"}
{"time": "2024-07-21T15:14:07.735027", "name": "AirSimEnvLogger", "level": "INFO", "message": "Action: [0.1797141 0.1797141 0.1797141 0.1797141], Velocity: (0.17971410136394522, 0.17971410136394522, 0.17971410136394522), Duration: 0.5, Reward: -10.172233086034202, Done: False"}
{"time": "2024-07-21T15:14:07.797138", "name": "AirSimEnvLogger", "level": "INFO", "message": "Step completed. Observation keys: dict_keys(['state', 'visual'])"}
{"time": "2024-07-21T15:14:07.797138", "name": "AirSimEnvLogger", "level": "INFO", "message": "State shape: (16,), Visual shape: (144, 256, 3)"}
{"time": "2024-07-21T15:14:10.751674", "name": "AirSimEnvLogger", "level": "INFO", "message": "Predictive model loss: 0.004895500838756561"}
{"time": "2024-07-21T15:14:15.695972", "name": "AirSimEnvLogger", "level": "INFO", "message": "Reward breakdown - Distance: -10.088152489207863, Velocity: -0.09581772513933673, Collision: 0, Height: -1.0, Movement: -0.058188007492847416, Smoothness: -0.0, Curiosity: 0.3976612687110901, Exploration: 0.05005988562706856, Total: -10.433037541045858"}
{"time": "2024-07-21T15:14:15.869690", "name": "AirSimEnvLogger", "level": "INFO", "message": "Action: [-0.29094004 -0.29094004 -0.29094004 -0.29094004], Velocity: (-0.2909400374642371, -0.2909400374642371, -0.2909400374642371), Duration: 0.5, Reward: -10.433037541045858, Done: False"}
{"time": "2024-07-21T15:14:15.947825", "name": "AirSimEnvLogger", "level": "INFO", "message": "Step completed. Observation keys: dict_keys(['state', 'visual'])"}
{"time": "2024-07-21T15:14:15.947825", "name": "AirSimEnvLogger", "level": "INFO", "message": "State shape: (16,), Visual shape: (144, 256, 3)"}
{"time": "2024-07-21T15:14:18.905078", "name": "AirSimEnvLogger", "level": "INFO", "message": "Predictive model loss: 0.0011387659469619393"}
{"time": "2024-07-21T15:14:23.985540", "name": "AirSimEnvLogger", "level": "INFO", "message": "Reward breakdown - Distance: -10.273332841501192, Velocity: -0.18976470361453268, Collision: 0, Height: -1.0, Movement: -0.07937796623459814, Smoothness: -0.0, Curiosity: 0.7878140211105347, Exploration: 0.059312111510038894, Total: -10.470383557074644"}
{"time": "2024-07-21T15:14:24.111939", "name": "AirSimEnvLogger", "level": "INFO", "message": "Action: [-0.39688983 -0.39688983 -0.39688983 -0.39688983], Velocity: (-0.3968898311729907, -0.3968898311729907, -0.3968898311729907), Duration: 0.5, Reward: -10.470383557074644, Done: False"}
{"time": "2024-07-21T15:14:24.190503", "name": "AirSimEnvLogger", "level": "INFO", "message": "Step completed. Observation keys: dict_keys(['state', 'visual'])"}
{"time": "2024-07-21T15:14:24.190503", "name": "AirSimEnvLogger", "level": "INFO", "message": "State shape: (16,), Visual shape: (144, 256, 3)"}
{"time": "2024-07-21T15:14:26.985612", "name": "AirSimEnvLogger", "level": "INFO", "message": "Predictive model loss: 0.0068174125626683235"}
{"time": "2024-07-21T15:14:31.475246", "name": "AirSimEnvLogger", "level": "INFO", "message": "Reward breakdown - Distance: -10.404363247315628, Velocity: -0.16104495415744366, Collision: 0, Height: -1.0, Movement: -0.0985057140934038, Smoothness: -0.0, Curiosity: 1.2064435482025146, Exploration: 0.036832470368469795, Total: -10.384148027628738"}
{"time": "2024-07-21T15:14:31.615510", "name": "AirSimEnvLogger", "level": "INFO", "message": "Action: [-0.49252857 -0.49252857 -0.49252857 -0.49252857], Velocity: (-0.49252857046701903, -0.49252857046701903, -0.49252857046701903), Duration: 0.5, Reward: -10.384148027628738, Done: False"}
{"time": "2024-07-21T15:14:31.677557", "name": "AirSimEnvLogger", "level": "INFO", "message": "Step completed. Observation keys: dict_keys(['state', 'visual'])"}
{"time": "2024-07-21T15:14:31.677557", "name": "AirSimEnvLogger", "level": "INFO", "message": "State shape: (16,), Visual shape: (144, 256, 3)"}
{"time": "2024-07-21T15:14:34.598112", "name": "AirSimEnvLogger", "level": "INFO", "message": "Predictive model loss: 0.013640815392136574"}
{"time": "2024-07-21T15:14:39.470115", "name": "AirSimEnvLogger", "level": "INFO", "message": "Reward breakdown - Distance: -10.108095225917783, Velocity: -0.038731602294108956, Collision: 0, Height: -1.0, Movement: -0.020142792386434086, Smoothness: -0.0, Curiosity: 0.11456402391195297, Exploration: 0.02949409347408437, Total: -10.566294475652688"}
{"time": "2024-07-21T15:14:39.611649", "name": "AirSimEnvLogger", "level": "INFO", "message": "Action: [0.10071396 0.10071396 0.10071396 0.10071396], Velocity: (0.10071396193217041, 0.10071396193217041, 0.10071396193217041), Duration: 0.5, Reward: -10.566294475652688, Done: False"}
{"time": "2024-07-21T15:14:39.673714", "name": "AirSimEnvLogger", "level": "INFO", "message": "Step completed. Observation keys: dict_keys(['state', 'visual'])"}
{"time": "2024-07-21T15:14:39.673714", "name": "AirSimEnvLogger", "level": "INFO", "message": "State shape: (16,), Visual shape: (144, 256, 3)"}
{"time": "2024-07-21T15:14:42.597406", "name": "AirSimEnvLogger", "level": "INFO", "message": "Predictive model loss: 0.0009038071730174124"}
{"time": "2024-07-21T15:14:47.419012", "name": "AirSimEnvLogger", "level": "INFO", "message": "Reward breakdown - Distance: -10.09597103875037, Velocity: -0.03048989889334099, Collision: 0, Height: -1.0, Movement: -0.0151959932234776, Smoothness: -0.0, Curiosity: 0.0716477632522583, Exploration: 0.03654637802209319, Total: -10.56960243028884"}
{"time": "2024-07-21T15:14:47.466596", "name": "AirSimEnvLogger", "level": "INFO", "message": "Action: [-0.07597997 -0.07597997 -0.07597997 -0.07597997], Velocity: (-0.075979966117388, -0.075979966117388, -0.075979966117388), Duration: 0.5, Reward: -10.56960243028884, Done: False"}
{"time": "2024-07-21T15:14:47.567054", "name": "AirSimEnvLogger", "level": "INFO", "message": "Step completed. Observation keys: dict_keys(['state', 'visual'])"}
{"time": "2024-07-21T15:14:47.568053", "name": "AirSimEnvLogger", "level": "INFO", "message": "State shape: (16,), Visual shape: (144, 256, 3)"}
{"time": "2024-07-21T15:14:50.226834", "name": "AirSimEnvLogger", "level": "INFO", "message": "Predictive model loss: 0.0006627020193263888"}
{"time": "2024-07-21T15:14:55.114042", "name": "AirSimEnvLogger", "level": "INFO", "message": "Reward breakdown - Distance: -9.858707825206658, Velocity: -0.09906628735629884, Collision: 0, Height: -1.0, Movement: -0.06316814241871775, Smoothness: -0.0, Curiosity: 0.5171423554420471, Exploration: 0.027648064720544097, Total: -10.150456992461546"}
{"time": "2024-07-21T15:14:55.208800", "name": "AirSimEnvLogger", "level": "INFO", "message": "Action: [0.31584071 0.31584071 0.31584071 0.31584071], Velocity: (0.3158407120935887, 0.3158407120935887, 0.3158407120935887), Duration: 0.5, Reward: -10.150456992461546, Done: False"}
{"time": "2024-07-21T15:14:55.255641", "name": "AirSimEnvLogger", "level": "INFO", "message": "Step completed. Observation keys: dict_keys(['state', 'visual'])"}
{"time": "2024-07-21T15:14:55.255641", "name": "AirSimEnvLogger", "level": "INFO", "message": "State shape: (16,), Visual shape: (144, 256, 3)"}
{"time": "2024-07-21T15:14:58.219498", "name": "AirSimEnvLogger", "level": "INFO", "message": "Predictive model loss: 0.0037013832479715347"}
{"time": "2024-07-21T15:15:02.422925", "name": "AirSimEnvLogger", "level": "INFO", "message": "Reward breakdown - Distance: -9.811699270361245, Velocity: -0.06988038661132631, Collision: 0, Height: -1.0, Movement: -0.04702461718552083, Smoothness: -0.0, Curiosity: 0.350069522857666, Exploration: 0.034725815180874246, Total: -10.169362000920453"}
{"time": "2024-07-21T15:15:02.562804", "name": "AirSimEnvLogger", "level": "INFO", "message": "Action: [0.23512309 0.23512309 0.23512309 0.23512309], Velocity: (0.23512308592760414, 0.23512308592760414, 0.23512308592760414), Duration: 0.5, Reward: -10.169362000920453, Done: False"}
{"time": "2024-07-21T15:15:02.623864", "name": "AirSimEnvLogger", "level": "INFO", "message": "Step completed. Observation keys: dict_keys(['state', 'visual'])"}
{"time": "2024-07-21T15:15:02.624372", "name": "AirSimEnvLogger", "level": "INFO", "message": "State shape: (16,), Visual shape: (144, 256, 3)"}
{"time": "2024-07-21T15:15:05.571577", "name": "AirSimEnvLogger", "level": "INFO", "message": "Predictive model loss: 0.004610566888004541"}
{"time": "2024-07-21T15:15:10.679511", "name": "AirSimEnvLogger", "level": "INFO", "message": "Reward breakdown - Distance: -10.081454801899675, Velocity: -0.08601610705843864, Collision: 0, Height: -1.0, Movement: -0.05264710903648154, Smoothness: -0.0, Curiosity: 0.3197546899318695, Exploration: 0.034787031148920906, Total: -10.462892815136822"}
{"time": "2024-07-21T15:15:10.866983", "name": "AirSimEnvLogger", "level": "INFO", "message": "Action: [-0.26323555 -0.26323555 -0.26323555 -0.26323555], Velocity: (-0.26323554518240766, -0.26323554518240766, -0.26323554518240766), Duration: 0.5, Reward: -10.462892815136822, Done: False"}
{"time": "2024-07-21T15:15:10.961412", "name": "AirSimEnvLogger", "level": "INFO", "message": "Step completed. Observation keys: dict_keys(['state', 'visual'])"}
{"time": "2024-07-21T15:15:10.961412", "name": "AirSimEnvLogger", "level": "INFO", "message": "State shape: (16,), Visual shape: (144, 256, 3)"}
{"time": "2024-07-21T15:15:13.854675", "name": "AirSimEnvLogger", "level": "INFO", "message": "Predictive model loss: 0.0007712848600931466"}
{"time": "2024-07-21T15:15:18.518301", "name": "AirSimEnvLogger", "level": "INFO", "message": "Reward breakdown - Distance: -10.33695478160766, Velocity: -0.17621925905719987, Collision: 0, Height: -1.0, Movement: -0.1024829721474827, Smoothness: -0.0, Curiosity: 1.2386080026626587, Exploration: 0.0671908920249944, Total: -10.30257052861468"}
{"time": "2024-07-21T15:15:18.612602", "name": "AirSimEnvLogger", "level": "INFO", "message": "Action: [-0.51241486 -0.51241486 -0.51241486 -0.51241486], Velocity: (-0.5124148607374135, -0.5124148607374135, -0.5124148607374135), Duration: 0.5, Reward: -10.30257052861468, Done: False"}
{"time": "2024-07-21T15:15:18.675828", "name": "AirSimEnvLogger", "level": "INFO", "message": "Step completed. Observation keys: dict_keys(['state', 'visual'])"}
{"time": "2024-07-21T15:15:18.675828", "name": "AirSimEnvLogger", "level": "INFO", "message": "State shape: (16,), Visual shape: (144, 256, 3)"}
{"time": "2024-07-21T15:15:21.344955", "name": "AirSimEnvLogger", "level": "INFO", "message": "Predictive model loss: 0.009925324469804764"}
{"time": "2024-07-21T15:15:25.957314", "name": "AirSimEnvLogger", "level": "INFO", "message": "Reward breakdown - Distance: -10.510387163283124, Velocity: -0.24261163478954126, Collision: 0, Height: -1.0, Movement: -0.12457068443418447, Smoothness: -0.0, Curiosity: 1.9470527172088623, Exploration: 0.05170587739638417, Total: -10.160282515037604"}
{"time": "2024-07-21T15:15:26.034704", "name": "AirSimEnvLogger", "level": "INFO", "message": "Action: [-0.62285342 -0.62285342 -0.62285342 -0.62285342], Velocity: (-0.6228534221709223, -0.6228534221709223, -0.6228534221709223), Duration: 0.5, Reward: -10.160282515037604, Done: False"}
{"time": "2024-07-21T15:15:26.128606", "name": "AirSimEnvLogger", "level": "INFO", "message": "Step completed. Observation keys: dict_keys(['state', 'visual'])"}
{"time": "2024-07-21T15:15:26.128606", "name": "AirSimEnvLogger", "level": "INFO", "message": "State shape: (16,), Visual shape: (144, 256, 3)"}
{"time": "2024-07-21T15:15:29.062546", "name": "AirSimEnvLogger", "level": "INFO", "message": "Predictive model loss: 0.022782111540436745"}
{"time": "2024-07-21T15:15:34.259465", "name": "AirSimEnvLogger", "level": "INFO", "message": "Reward breakdown - Distance: -10.378816751214423, Velocity: -0.09296574812362185, Collision: 0, Height: -1.0, Movement: -0.057244149372582154, Smoothness: -0.0, Curiosity: 0.5312837958335876, Exploration: 0.010518102614437159, Total: -10.66327852177381"}
{"time": "2024-07-21T15:15:34.353678", "name": "AirSimEnvLogger", "level": "INFO", "message": "Action: [-0.28622075 -0.28622075 -0.28622075 -0.28622075], Velocity: (-0.28622074686291077, -0.28622074686291077, -0.28622074686291077), Duration: 0.5, Reward: -10.66327852177381, Done: False"}
{"time": "2024-07-21T15:15:34.429936", "name": "AirSimEnvLogger", "level": "INFO", "message": "Step completed. Observation keys: dict_keys(['state', 'visual'])"}
{"time": "2024-07-21T15:15:34.429936", "name": "AirSimEnvLogger", "level": "INFO", "message": "State shape: (16,), Visual shape: (144, 256, 3)"}
{"time": "2024-07-21T15:15:37.308648", "name": "AirSimEnvLogger", "level": "INFO", "message": "Predictive model loss: 0.01052812859416008"}
{"time": "2024-07-21T15:15:42.063135", "name": "AirSimEnvLogger", "level": "INFO", "message": "Reward breakdown - Distance: -10.017469434545092, Velocity: -0.08033926582183082, Collision: 0, Height: -1.0, Movement: -0.047537342942950866, Smoothness: -0.0, Curiosity: 0.26976361870765686, Exploration: 0.06490494458485856, Total: -10.414530003479502"}
{"time": "2024-07-21T15:15:42.172086", "name": "AirSimEnvLogger", "level": "INFO", "message": "Action: [0.23768671 0.23768671 0.23768671 0.23768671], Velocity: (0.23768671471475433, 0.23768671471475433, 0.23768671471475433), Duration: 0.5, Reward: -10.414530003479502, Done: False"}
{"time": "2024-07-21T15:15:42.234910", "name": "AirSimEnvLogger", "level": "INFO", "message": "Step completed. Observation keys: dict_keys(['state', 'visual'])"}
{"time": "2024-07-21T15:15:42.234910", "name": "AirSimEnvLogger", "level": "INFO", "message": "State shape: (16,), Visual shape: (144, 256, 3)"}
{"time": "2024-07-21T15:15:45.209606", "name": "AirSimEnvLogger", "level": "INFO", "message": "Predictive model loss: 0.00110615196172148"}
{"time": "2024-07-21T15:15:50.279899", "name": "AirSimEnvLogger", "level": "INFO", "message": "Reward breakdown - Distance: -9.978096902958839, Velocity: -0.020911055733398003, Collision: 0, Height: -1.0, Movement: -0.013095407802461457, Smoothness: -0.0, Curiosity: 0.04088519513607025, Exploration: 0.04418768601797687, Total: -10.460581836834153"}
{"time": "2024-07-21T15:15:50.402492", "name": "AirSimEnvLogger", "level": "INFO", "message": "Action: [0.06547704 0.06547704 0.06547704 0.06547704], Velocity: (0.06547703901230728, 0.06547703901230728, 0.06547703901230728), Duration: 0.5, Reward: -10.460581836834153, Done: False"}
{"time": "2024-07-21T15:15:50.494051", "name": "AirSimEnvLogger", "level": "INFO", "message": "Step completed. Observation keys: dict_keys(['state', 'visual'])"}
{"time": "2024-07-21T15:15:50.494051", "name": "AirSimEnvLogger", "level": "INFO", "message": "State shape: (16,), Visual shape: (144, 256, 3)"}
{"time": "2024-07-21T15:15:53.495422", "name": "AirSimEnvLogger", "level": "INFO", "message": "Predictive model loss: 0.0010883454233407974"}
{"time": "2024-07-21T15:15:58.338923", "name": "AirSimEnvLogger", "level": "INFO", "message": "Reward breakdown - Distance: -9.88084003637211, Velocity: -0.06949539990237831, Collision: 0, Height: -1.0, Movement: -0.038411727109848894, Smoothness: -0.0, Curiosity: 0.19501608610153198, Exploration: 0.013917138424175338, Total: -10.319137438298684"}
{"time": "2024-07-21T15:15:58.482312", "name": "AirSimEnvLogger", "level": "INFO", "message": "Action: [0.19205864 0.19205864 0.19205864 0.19205864], Velocity: (0.19205863554924446, 0.19205863554924446, 0.19205863554924446), Duration: 0.5, Reward: -10.319137438298684, Done: False"}
{"time": "2024-07-21T15:15:58.543316", "name": "AirSimEnvLogger", "level": "INFO", "message": "Step completed. Observation keys: dict_keys(['state', 'visual'])"}
{"time": "2024-07-21T15:15:58.543316", "name": "AirSimEnvLogger", "level": "INFO", "message": "State shape: (16,), Visual shape: (144, 256, 3)"}
{"time": "2024-07-21T15:16:01.516937", "name": "AirSimEnvLogger", "level": "INFO", "message": "Predictive model loss: 0.0030191922560334206"}
{"time": "2024-07-21T15:16:06.484412", "name": "AirSimEnvLogger", "level": "INFO", "message": "Reward breakdown - Distance: -9.67742934103931, Velocity: -0.14688598621048243, Collision: 0, Height: -1.0, Movement: -0.0953652811841664, Smoothness: -0.0, Curiosity: 1.113237977027893, Exploration: 0.038797296214094376, Total: -9.696030414506204"}
{"time": "2024-07-21T15:16:06.594959", "name": "AirSimEnvLogger", "level": "INFO", "message": "Action: [0.47682641 0.47682641 0.47682641 0.47682641], Velocity: (0.476826405920832, 0.476826405920832, 0.476826405920832), Duration: 0.5, Reward: -9.696030414506204, Done: False"}
{"time": "2024-07-21T15:16:06.657655", "name": "AirSimEnvLogger", "level": "INFO", "message": "Step completed. Observation keys: dict_keys(['state', 'visual'])"}
{"time": "2024-07-21T15:16:06.657655", "name": "AirSimEnvLogger", "level": "INFO", "message": "State shape: (16,), Visual shape: (144, 256, 3)"}
{"time": "2024-07-21T15:16:09.637968", "name": "AirSimEnvLogger", "level": "INFO", "message": "Predictive model loss: 0.013091162778437138"}
{"time": "2024-07-21T15:16:14.453386", "name": "AirSimEnvLogger", "level": "INFO", "message": "Reward breakdown - Distance: -9.957382358773692, Velocity: -0.050307517848132616, Collision: 0, Height: -1.0, Movement: -0.028476777037158753, Smoothness: -0.0, Curiosity: 0.10315553843975067, Exploration: 0.015790638196500107, Total: -10.430647898542299"}
{"time": "2024-07-21T15:16:14.562182", "name": "AirSimEnvLogger", "level": "INFO", "message": "Action: [-0.14238389 -0.14238389 -0.14238389 -0.14238389], Velocity: (-0.14238388518579376, -0.14238388518579376, -0.14238388518579376), Duration: 0.5, Reward: -10.430647898542299, Done: False"}
{"time": "2024-07-21T15:16:14.624620", "name": "AirSimEnvLogger", "level": "INFO", "message": "Step completed. Observation keys: dict_keys(['state', 'visual'])"}
{"time": "2024-07-21T15:16:14.624620", "name": "AirSimEnvLogger", "level": "INFO", "message": "State shape: (16,), Visual shape: (144, 256, 3)"}
{"time": "2024-07-21T15:16:17.629393", "name": "AirSimEnvLogger", "level": "INFO", "message": "Predictive model loss: 0.0009124440257437527"}
{"time": "2024-07-21T15:16:22.804575", "name": "AirSimEnvLogger", "level": "INFO", "message": "Reward breakdown - Distance: -10.116709779185388, Velocity: -0.07650848284816801, Collision: 0, Height: -1.0, Movement: -0.04563928959775723, Smoothness: -0.0, Curiosity: 0.2530922591686249, Exploration: 0.05612818712911619, Total: -10.521756182559113"}
{"time": "2024-07-21T15:16:22.964005", "name": "AirSimEnvLogger", "level": "INFO", "message": "Action: [-0.22819645 -0.22819645 -0.22819645 -0.22819645], Velocity: (-0.22819644798878616, -0.22819644798878616, -0.22819644798878616), Duration: 0.5, Reward: -10.521756182559113, Done: False"}
{"time": "2024-07-21T15:16:23.041849", "name": "AirSimEnvLogger", "level": "INFO", "message": "Step completed. Observation keys: dict_keys(['state', 'visual'])"}
{"time": "2024-07-21T15:16:23.041849", "name": "AirSimEnvLogger", "level": "INFO", "message": "State shape: (16,), Visual shape: (144, 256, 3)"}
{"time": "2024-07-21T15:16:25.823683", "name": "AirSimEnvLogger", "level": "INFO", "message": "Predictive model loss: 0.0010052763391286135"}
{"time": "2024-07-21T15:16:30.931396", "name": "AirSimEnvLogger", "level": "INFO", "message": "Reward breakdown - Distance: -10.131642233574086, Velocity: -0.047702472687897755, Collision: 0, Height: -1.0, Movement: -0.028011647452954237, Smoothness: -0.0, Curiosity: 0.12661707401275635, Exploration: 0.017952692075049296, Total: -10.591395559241942"}
{"time": "2024-07-21T15:16:31.041232", "name": "AirSimEnvLogger", "level": "INFO", "message": "Action: [-0.14005824 -0.14005824 -0.14005824 -0.14005824], Velocity: (-0.14005823726477118, -0.14005823726477118, -0.14005823726477118), Duration: 0.5, Reward: -10.591395559241942, Done: False"}
{"time": "2024-07-21T15:16:31.087864", "name": "AirSimEnvLogger", "level": "INFO", "message": "Step completed. Observation keys: dict_keys(['state', 'visual'])"}
{"time": "2024-07-21T15:16:31.087864", "name": "AirSimEnvLogger", "level": "INFO", "message": "State shape: (16,), Visual shape: (144, 256, 3)"}
{"time": "2024-07-21T15:16:33.948753", "name": "AirSimEnvLogger", "level": "INFO", "message": "Predictive model loss: 0.0009290826274082065"}
{"time": "2024-07-21T15:16:39.289574", "name": "AirSimEnvLogger", "level": "INFO", "message": "Reward breakdown - Distance: -9.880349291994225, Velocity: -0.09969524709101799, Collision: 0, Height: -1.0, Movement: -0.05908853829401544, Smoothness: -0.0, Curiosity: 0.4265177845954895, Exploration: 0.03517797151212549, Total: -10.215811282768966"}
{"time": "2024-07-21T15:16:39.414366", "name": "AirSimEnvLogger", "level": "INFO", "message": "Action: [0.29544269 0.29544269 0.29544269 0.29544269], Velocity: (0.2954426914700772, 0.2954426914700772, 0.2954426914700772), Duration: 0.5, Reward: -10.215811282768966, Done: False"}
{"time": "2024-07-21T15:16:39.507747", "name": "AirSimEnvLogger", "level": "INFO", "message": "Step completed. Observation keys: dict_keys(['state', 'visual'])"}
{"time": "2024-07-21T15:16:39.507747", "name": "AirSimEnvLogger", "level": "INFO", "message": "State shape: (16,), Visual shape: (144, 256, 3)"}
{"time": "2024-07-21T15:16:42.452485", "name": "AirSimEnvLogger", "level": "INFO", "message": "Predictive model loss: 0.0033293862361460924"}
{"time": "2024-07-21T15:16:47.437323", "name": "AirSimEnvLogger", "level": "INFO", "message": "Reward breakdown - Distance: -9.758258601677941, Velocity: -0.10557119745729486, Collision: 0, Height: -1.0, Movement: -0.06822068304070737, Smoothness: -0.0, Curiosity: 0.6055042743682861, Exploration: 0.046673225124557016, Total: -10.005779486501606"}
{"time": "2024-07-21T15:16:47.514182", "name": "AirSimEnvLogger", "level": "INFO", "message": "Action: [0.34110342 0.34110342 0.34110342 0.34110342], Velocity: (0.3411034152035368, 0.3411034152035368, 0.3411034152035368), Duration: 0.5, Reward: -10.005779486501606, Done: False"}
{"time": "2024-07-21T15:16:47.576819", "name": "AirSimEnvLogger", "level": "INFO", "message": "Step completed. Observation keys: dict_keys(['state', 'visual'])"}
{"time": "2024-07-21T15:16:47.576819", "name": "AirSimEnvLogger", "level": "INFO", "message": "State shape: (16,), Visual shape: (144, 256, 3)"}
{"time": "2024-07-21T15:16:50.611088", "name": "AirSimEnvLogger", "level": "INFO", "message": "Predictive model loss: 0.007443482521921396"}
{"time": "2024-07-21T15:16:55.288014", "name": "AirSimEnvLogger", "level": "INFO", "message": "Reward breakdown - Distance: -9.867379781543836, Velocity: -0.020009376915016402, Collision: 0, Height: -1.0, Movement: -0.013140208573385603, Smoothness: -0.0, Curiosity: 0.07673931121826172, Exploration: 0.008780283528245695, Total: -10.338572778543902"}
{"time": "2024-07-21T15:16:55.459294", "name": "AirSimEnvLogger", "level": "INFO", "message": "Action: [0.06570104 0.06570104 0.06570104 0.06570104], Velocity: (0.06570104286692802, 0.06570104286692802, 0.06570104286692802), Duration: 0.5, Reward: -10.338572778543902, Done: False"}
{"time": "2024-07-21T15:16:55.536912", "name": "AirSimEnvLogger", "level": "INFO", "message": "Step completed. Observation keys: dict_keys(['state', 'visual'])"}
{"time": "2024-07-21T15:16:55.536912", "name": "AirSimEnvLogger", "level": "INFO", "message": "State shape: (16,), Visual shape: (144, 256, 3)"}
{"time": "2024-07-21T15:16:58.568502", "name": "AirSimEnvLogger", "level": "INFO", "message": "Predictive model loss: 0.0022619422525167465"}
{"time": "2024-07-21T15:17:03.656430", "name": "AirSimEnvLogger", "level": "INFO", "message": "Reward breakdown - Distance: -10.153527724785619, Velocity: -0.11428161483503563, Collision: 0, Height: -1.0, Movement: -0.06958931334254914, Smoothness: -0.0, Curiosity: 0.5468392968177795, Exploration: 0.052011793412354845, Total: -10.43380545644603"}
{"time": "2024-07-21T15:17:03.781285", "name": "AirSimEnvLogger", "level": "INFO", "message": "Action: [-0.34794657 -0.34794657 -0.34794657 -0.34794657], Velocity: (-0.3479465667127457, -0.3479465667127457, -0.3479465667127457), Duration: 0.5, Reward: -10.43380545644603, Done: False"}
{"time": "2024-07-21T15:17:03.876834", "name": "AirSimEnvLogger", "level": "INFO", "message": "Step completed. Observation keys: dict_keys(['state', 'visual'])"}
{"time": "2024-07-21T15:17:03.876834", "name": "AirSimEnvLogger", "level": "INFO", "message": "State shape: (16,), Visual shape: (144, 256, 3)"}
{"time": "2024-07-21T15:17:06.850774", "name": "AirSimEnvLogger", "level": "INFO", "message": "Predictive model loss: 0.002133336616680026"}
{"time": "2024-07-21T15:17:12.129035", "name": "AirSimEnvLogger", "level": "INFO", "message": "Reward breakdown - Distance: -10.392540948895261, Velocity: -0.18981698310247086, Collision: 0, Height: -1.0, Movement: -0.11095407430051651, Smoothness: -0.0, Curiosity: 1.482046127319336, Exploration: 0.06425169439463593, Total: -10.244671445337953"}
{"time": "2024-07-21T15:17:12.223872", "name": "AirSimEnvLogger", "level": "INFO", "message": "Action: [-0.55477037 -0.55477037 -0.55477037 -0.55477037], Velocity: (-0.5547703715025826, -0.5547703715025826, -0.5547703715025826), Duration: 0.5, Reward: -10.244671445337953, Done: False"}
{"time": "2024-07-21T15:17:12.286374", "name": "AirSimEnvLogger", "level": "INFO", "message": "Step completed. Observation keys: dict_keys(['state', 'visual'])"}
{"time": "2024-07-21T15:17:12.286374", "name": "AirSimEnvLogger", "level": "INFO", "message": "State shape: (16,), Visual shape: (144, 256, 3)"}
{"time": "2024-07-21T15:17:15.093945", "name": "AirSimEnvLogger", "level": "INFO", "message": "Predictive model loss: 0.013366161845624447"}
{"time": "2024-07-21T15:17:20.086401", "name": "AirSimEnvLogger", "level": "INFO", "message": "Reward breakdown - Distance: -10.456330090532626, Velocity: -0.20375850913022558, Collision: 0, Height: -1.0, Movement: -0.09908411117255135, Smoothness: -0.0, Curiosity: 1.3063528537750244, Exploration: 0.035544896458250846, Total: -10.40783235003583"}
{"time": "2024-07-21T15:17:20.209646", "name": "AirSimEnvLogger", "level": "INFO", "message": "Action: [-0.49542056 -0.49542056 -0.49542056 -0.49542056], Velocity: (-0.49542055586275674, -0.49542055586275674, -0.49542055586275674), Duration: 0.5, Reward: -10.40783235003583, Done: False"}
{"time": "2024-07-21T15:17:20.288274", "name": "AirSimEnvLogger", "level": "INFO", "message": "Step completed. Observation keys: dict_keys(['state', 'visual'])"}
{"time": "2024-07-21T15:17:20.288274", "name": "AirSimEnvLogger", "level": "INFO", "message": "State shape: (16,), Visual shape: (144, 256, 3)"}
{"time": "2024-07-21T15:17:23.213102", "name": "AirSimEnvLogger", "level": "INFO", "message": "Predictive model loss: 0.01774054579436779"}
{"time": "2024-07-21T15:17:28.256810", "name": "AirSimEnvLogger", "level": "INFO", "message": "Reward breakdown - Distance: -10.463909787943065, Velocity: -0.15184991781490403, Collision: 0, Height: -1.0, Movement: -0.09189256236880741, Smoothness: -0.0, Curiosity: 1.1740951538085938, Exploration: 0.011691518615445783, Total: -10.459638122460012"}
{"time": "2024-07-21T15:17:28.366980", "name": "AirSimEnvLogger", "level": "INFO", "message": "Action: [-0.45946281 -0.45946281 -0.45946281 -0.45946281], Velocity: (-0.45946281184403703, -0.45946281184403703, -0.45946281184403703), Duration: 0.5, Reward: -10.459638122460012, Done: False"}
{"time": "2024-07-21T15:17:28.429272", "name": "AirSimEnvLogger", "level": "INFO", "message": "Step completed. Observation keys: dict_keys(['state', 'visual'])"}
{"time": "2024-07-21T15:17:28.429272", "name": "AirSimEnvLogger", "level": "INFO", "message": "State shape: (16,), Visual shape: (144, 256, 3)"}
{"time": "2024-07-21T15:17:31.335075", "name": "AirSimEnvLogger", "level": "INFO", "message": "Predictive model loss: 0.018301978707313538"}
{"time": "2024-07-21T15:17:36.398341", "name": "AirSimEnvLogger", "level": "INFO", "message": "Reward breakdown - Distance: -10.337885326620084, Velocity: -0.09094163102881062, Collision: 0, Height: -1.0, Movement: -0.048999284920244024, Smoothness: -0.0, Curiosity: 0.43329542875289917, Exploration: 0.016705528487608617, Total: -10.668267250552542"}
{"time": "2024-07-21T15:17:36.541698", "name": "AirSimEnvLogger", "level": "INFO", "message": "Action: [-0.24499642 -0.24499642 -0.24499642 -0.24499642], Velocity: (-0.24499642460122012, -0.24499642460122012, -0.24499642460122012), Duration: 0.5, Reward: -10.668267250552542, Done: False"}
{"time": "2024-07-21T15:17:36.604244", "name": "AirSimEnvLogger", "level": "INFO", "message": "Step completed. Observation keys: dict_keys(['state', 'visual'])"}
{"time": "2024-07-21T15:17:36.604244", "name": "AirSimEnvLogger", "level": "INFO", "message": "State shape: (16,), Visual shape: (144, 256, 3)"}
{"time": "2024-07-21T15:17:39.459653", "name": "AirSimEnvLogger", "level": "INFO", "message": "Predictive model loss: 0.00994583498686552"}
{"time": "2024-07-21T15:17:44.649158", "name": "AirSimEnvLogger", "level": "INFO", "message": "Reward breakdown - Distance: -9.99358569256857, Velocity: -0.07965255140281083, Collision: 0, Height: -1.0, Movement: -0.04984029570363532, Smoothness: -0.0, Curiosity: 0.2793174088001251, Exploration: 0.05733713110421447, Total: -10.387269867219436"}
{"time": "2024-07-21T15:17:44.758389", "name": "AirSimEnvLogger", "level": "INFO", "message": "Action: [0.24920148 0.24920148 0.24920148 0.24920148], Velocity: (0.2492014785181766, 0.2492014785181766, 0.2492014785181766), Duration: 0.5, Reward: -10.387269867219436, Done: False"}
{"time": "2024-07-21T15:17:44.837973", "name": "AirSimEnvLogger", "level": "INFO", "message": "Step completed. Observation keys: dict_keys(['state', 'visual'])"}
{"time": "2024-07-21T15:17:44.837973", "name": "AirSimEnvLogger", "level": "INFO", "message": "State shape: (16,), Visual shape: (144, 256, 3)"}
{"time": "2024-07-21T15:17:47.850951", "name": "AirSimEnvLogger", "level": "INFO", "message": "Predictive model loss: 0.0011586399050429463"}
{"time": "2024-07-21T15:17:53.030725", "name": "AirSimEnvLogger", "level": "INFO", "message": "Reward breakdown - Distance: -10.131243462468065, Velocity: -0.07184079570352866, Collision: 0, Height: -1.0, Movement: -0.04152967910397764, Smoothness: -0.0, Curiosity: 0.2421128749847412, Exploration: 0.020859184101442774, Total: -10.546088553917569"}
{"time": "2024-07-21T15:17:53.139774", "name": "AirSimEnvLogger", "level": "INFO", "message": "Action: [-0.2076484 -0.2076484 -0.2076484 -0.2076484], Velocity: (-0.20764839551988817, -0.20764839551988817, -0.20764839551988817), Duration: 0.5, Reward: -10.546088553917569, Done: False"}
{"time": "2024-07-21T15:17:53.234659", "name": "AirSimEnvLogger", "level": "INFO", "message": "Step completed. Observation keys: dict_keys(['state', 'visual'])"}
{"time": "2024-07-21T15:17:53.234659", "name": "AirSimEnvLogger", "level": "INFO", "message": "State shape: (16,), Visual shape: (144, 256, 3)"}
{"time": "2024-07-21T15:17:56.095997", "name": "AirSimEnvLogger", "level": "INFO", "message": "Predictive model loss: 0.00356260035187006"}
{"time": "2024-07-21T15:18:00.911067", "name": "AirSimEnvLogger", "level": "INFO", "message": "Reward breakdown - Distance: -9.963904337997002, Velocity: -0.050790979935119565, Collision: 0, Height: -1.0, Movement: -0.030516839124616415, Smoothness: -0.0, Curiosity: 0.11566314101219177, Exploration: 0.005687861473144289, Total: -10.433382369076298"}
{"time": "2024-07-21T15:18:01.052038", "name": "AirSimEnvLogger", "level": "INFO", "message": "Action: [0.1525842 0.1525842 0.1525842 0.1525842], Velocity: (0.15258419562308206, 0.15258419562308206, 0.15258419562308206), Duration: 0.5, Reward: -10.433382369076298, Done: False"}
{"time": "2024-07-21T15:18:01.099120", "name": "AirSimEnvLogger", "level": "INFO", "message": "Step completed. Observation keys: dict_keys(['state', 'visual'])"}
{"time": "2024-07-21T15:18:01.099120", "name": "AirSimEnvLogger", "level": "INFO", "message": "State shape: (16,), Visual shape: (144, 256, 3)"}
{"time": "2024-07-21T15:18:03.928153", "name": "AirSimEnvLogger", "level": "INFO", "message": "Predictive model loss: 0.0014825102407485247"}
{"time": "2024-07-21T15:18:08.946020", "name": "AirSimEnvLogger", "level": "INFO", "message": "Reward breakdown - Distance: -9.721152439000548, Velocity: -0.1384790712350591, Collision: 0, Height: -1.0, Movement: -0.09141783719155017, Smoothness: -0.0, Curiosity: 0.9579166173934937, Exploration: 0.0541437419609897, Total: -9.809746701248288"}
{"time": "2024-07-21T15:18:09.087740", "name": "AirSimEnvLogger", "level": "INFO", "message": "Action: [0.45708919 0.45708919 0.45708919 0.45708919], Velocity: (0.4570891859577508, 0.4570891859577508, 0.4570891859577508), Duration: 0.5, Reward: -9.809746701248288, Done: False"}
{"time": "2024-07-21T15:18:09.150962", "name": "AirSimEnvLogger", "level": "INFO", "message": "Step completed. Observation keys: dict_keys(['state', 'visual'])"}
{"time": "2024-07-21T15:18:09.150962", "name": "AirSimEnvLogger", "level": "INFO", "message": "State shape: (16,), Visual shape: (144, 256, 3)"}
{"time": "2024-07-21T15:18:12.125578", "name": "AirSimEnvLogger", "level": "INFO", "message": "Predictive model loss: 0.009101825766265392"}
{"time": "2024-07-21T15:18:17.340549", "name": "AirSimEnvLogger", "level": "INFO", "message": "Reward breakdown - Distance: -9.563201804910689, Velocity: -0.1890573575016247, Collision: 0, Height: -1.0, Movement: -0.11263444426105829, Smoothness: -0.0, Curiosity: 1.5442308187484741, Exploration: 0.04874991128904528, Total: -9.387128536455561"}
{"time": "2024-07-21T15:18:17.495857", "name": "AirSimEnvLogger", "level": "INFO", "message": "Action: [0.56317222 0.56317222 0.56317222 0.56317222], Velocity: (0.5631722213052914, 0.5631722213052914, 0.5631722213052914), Duration: 0.5, Reward: -9.387128536455561, Done: False"}
{"time": "2024-07-21T15:18:17.558190", "name": "AirSimEnvLogger", "level": "INFO", "message": "Step completed. Observation keys: dict_keys(['state', 'visual'])"}
{"time": "2024-07-21T15:18:17.558190", "name": "AirSimEnvLogger", "level": "INFO", "message": "State shape: (16,), Visual shape: (144, 256, 3)"}
{"time": "2024-07-21T15:18:20.567178", "name": "AirSimEnvLogger", "level": "INFO", "message": "Predictive model loss: 0.019727477803826332"}
{"time": "2024-07-21T15:18:25.504203", "name": "AirSimEnvLogger", "level": "INFO", "message": "Reward breakdown - Distance: -9.61879635513197, Velocity: -0.10921792008006623, Collision: 0, Height: -1.0, Movement: -0.0711284220340173, Smoothness: -0.0, Curiosity: 0.7098733186721802, Exploration: 0.013647435092578578, Total: -9.8228520110208"}
{"time": "2024-07-21T15:18:25.629104", "name": "AirSimEnvLogger", "level": "INFO", "message": "Action: [0.35564211 0.35564211 0.35564211 0.35564211], Velocity: (0.3556421101700865, 0.3556421101700865, 0.3556421101700865), Duration: 0.5, Reward: -9.8228520110208, Done: False"}
{"time": "2024-07-21T15:18:25.691553", "name": "AirSimEnvLogger", "level": "INFO", "message": "Step completed. Observation keys: dict_keys(['state', 'visual'])"}
{"time": "2024-07-21T15:18:25.691553", "name": "AirSimEnvLogger", "level": "INFO", "message": "State shape: (16,), Visual shape: (144, 256, 3)"}
{"time": "2024-07-21T15:18:27.804402", "name": "AirSimEnvLogger", "level": "INFO", "message": "Predictive model loss: 0.014121280051767826"}
{"time": "2024-07-21T15:18:32.829151", "name": "AirSimEnvLogger", "level": "INFO", "message": "Reward breakdown - Distance: -9.845984762052229, Velocity: -0.01146717528775093, Collision: 0, Height: -1.0, Movement: -0.0008918017209728846, Smoothness: -0.0, Curiosity: 0.044603731483221054, Exploration: 0.03616249907034738, Total: -10.322273164312522"}
{"time": "2024-07-21T15:18:32.922361", "name": "AirSimEnvLogger", "level": "INFO", "message": "Action: [0.00445901 0.00445901 0.00445901 0.00445901], Velocity: (0.004459008604864423, 0.004459008604864423, 0.004459008604864423), Duration: 0.5, Reward: -10.322273164312522, Done: False"}
{"time": "2024-07-21T15:18:33.032175", "name": "AirSimEnvLogger", "level": "INFO", "message": "Step completed. Observation keys: dict_keys(['state', 'visual'])"}
{"time": "2024-07-21T15:18:33.032175", "name": "AirSimEnvLogger", "level": "INFO", "message": "State shape: (16,), Visual shape: (144, 256, 3)"}
{"time": "2024-07-21T15:18:35.866578", "name": "AirSimEnvLogger", "level": "INFO", "message": "Predictive model loss: 0.00261079054325819"}
{"time": "2024-07-21T15:18:40.935474", "name": "AirSimEnvLogger", "level": "INFO", "message": "Reward breakdown - Distance: -10.161510902901666, Velocity: -0.1345283249624009, Collision: 0, Height: -1.0, Movement: -0.0757135167687555, Smoothness: -0.0, Curiosity: 0.6441807150840759, Exploration: 0.06539771220085781, Total: -10.40117651707753"}
{"time": "2024-07-21T15:18:41.045701", "name": "AirSimEnvLogger", "level": "INFO", "message": "Action: [-0.37856758 -0.37856758 -0.37856758 -0.37856758], Velocity: (-0.3785675838437775, -0.3785675838437775, -0.3785675838437775), Duration: 0.5, Reward: -10.40117651707753, Done: False"}
{"time": "2024-07-21T15:18:41.109035", "name": "AirSimEnvLogger", "level": "INFO", "message": "Step completed. Observation keys: dict_keys(['state', 'visual'])"}
{"time": "2024-07-21T15:18:41.109035", "name": "AirSimEnvLogger", "level": "INFO", "message": "State shape: (16,), Visual shape: (144, 256, 3)"}
{"time": "2024-07-21T15:18:44.058617", "name": "AirSimEnvLogger", "level": "INFO", "message": "Predictive model loss: 0.0023780714254826307"}
{"time": "2024-07-21T15:18:49.244565", "name": "AirSimEnvLogger", "level": "INFO", "message": "Reward breakdown - Distance: -10.15227510938061, Velocity: -0.049760955866471154, Collision: 0, Height: -1.0, Movement: -0.030306865273387225, Smoothness: -0.0, Curiosity: 0.1473618447780609, Exploration: 0.0328105230230474, Total: -10.599943246847545"}
{"time": "2024-07-21T15:18:49.384943", "name": "AirSimEnvLogger", "level": "INFO", "message": "Action: [-0.15153433 -0.15153433 -0.15153433 -0.15153433], Velocity: (-0.15153432636693612, -0.15153432636693612, -0.15153432636693612), Duration: 0.5, Reward: -10.599943246847545, Done: False"}
{"time": "2024-07-21T15:18:49.446047", "name": "AirSimEnvLogger", "level": "INFO", "message": "Step completed. Observation keys: dict_keys(['state', 'visual'])"}
{"time": "2024-07-21T15:18:49.446047", "name": "AirSimEnvLogger", "level": "INFO", "message": "State shape: (16,), Visual shape: (144, 256, 3)"}
{"time": "2024-07-21T15:18:52.363558", "name": "AirSimEnvLogger", "level": "INFO", "message": "Predictive model loss: 0.0013134970795363188"}
{"time": "2024-07-21T15:18:57.127510", "name": "AirSimEnvLogger", "level": "INFO", "message": "Reward breakdown - Distance: -10.338134434125987, Velocity: -0.15376275201822853, Collision: 0, Height: -1.0, Movement: -0.09131285026593557, Smoothness: -0.0, Curiosity: 1.0341286659240723, Exploration: 0.02029047176573647, Total: -10.40302466784651"}
{"time": "2024-07-21T15:18:57.175681", "name": "AirSimEnvLogger", "level": "INFO", "message": "Action: [-0.45656425 -0.45656425 -0.45656425 -0.45656425], Velocity: (-0.4565642513296778, -0.4565642513296778, -0.4565642513296778), Duration: 0.5, Reward: -10.40302466784651, Done: False"}
{"time": "2024-07-21T15:18:57.238415", "name": "AirSimEnvLogger", "level": "INFO", "message": "Step completed. Observation keys: dict_keys(['state', 'visual'])"}
{"time": "2024-07-21T15:18:57.238415", "name": "AirSimEnvLogger", "level": "INFO", "message": "State shape: (16,), Visual shape: (144, 256, 3)"}
{"time": "2024-07-21T15:18:59.986823", "name": "AirSimEnvLogger", "level": "INFO", "message": "Predictive model loss: 0.009672059677541256"}
{"time": "2024-07-21T15:19:04.873964", "name": "AirSimEnvLogger", "level": "INFO", "message": "Reward breakdown - Distance: -10.048400436963634, Velocity: -0.05534019912735057, Collision: 0, Height: -1.0, Movement: -0.030185991153500714, Smoothness: -0.0, Curiosity: 0.12760573625564575, Exploration: 0.01607277705595247, Total: -10.512071712103646"}
{"time": "2024-07-21T15:19:05.001290", "name": "AirSimEnvLogger", "level": "INFO", "message": "Action: [0.15092996 0.15092996 0.15092996 0.15092996], Velocity: (0.15092995576750357, 0.15092995576750357, 0.15092995576750357), Duration: 0.5, Reward: -10.512071712103646, Done: False"}
{"time": "2024-07-21T15:19:05.047436", "name": "AirSimEnvLogger", "level": "INFO", "message": "Step completed. Observation keys: dict_keys(['state', 'visual'])"}
{"time": "2024-07-21T15:19:05.047436", "name": "AirSimEnvLogger", "level": "INFO", "message": "State shape: (16,), Visual shape: (144, 256, 3)"}
{"time": "2024-07-21T15:19:07.846666", "name": "AirSimEnvLogger", "level": "INFO", "message": "Predictive model loss: 0.0005613325047306716"}
{"time": "2024-07-21T15:19:13.077816", "name": "AirSimEnvLogger", "level": "INFO", "message": "Reward breakdown - Distance: -9.784235546721082, Velocity: -0.1275335207505235, Collision: 0, Height: -1.0, Movement: -0.08282991927136096, Smoothness: -0.0, Curiosity: 0.8024149537086487, Exploration: 0.07143864633411087, Total: -9.940790092902333"}
{"time": "2024-07-21T15:19:13.203647", "name": "AirSimEnvLogger", "level": "INFO", "message": "Action: [0.4141496 0.4141496 0.4141496 0.4141496], Velocity: (0.41414959635680476, 0.41414959635680476, 0.41414959635680476), Duration: 0.5, Reward: -9.940790092902333, Done: False"}
{"time": "2024-07-21T15:19:13.266329", "name": "AirSimEnvLogger", "level": "INFO", "message": "Step completed. Observation keys: dict_keys(['state', 'visual'])"}
{"time": "2024-07-21T15:19:13.266329", "name": "AirSimEnvLogger", "level": "INFO", "message": "State shape: (16,), Visual shape: (144, 256, 3)"}
{"time": "2024-07-21T15:19:16.210415", "name": "AirSimEnvLogger", "level": "INFO", "message": "Predictive model loss: 0.0055831740610301495"}
{"time": "2024-07-21T15:19:21.082678", "name": "AirSimEnvLogger", "level": "INFO", "message": "Reward breakdown - Distance: -9.846912600242357, Velocity: -0.039600769566189936, Collision: 0, Height: -1.0, Movement: -0.024526891019290255, Smoothness: -0.0, Curiosity: 0.11084242910146713, Exploration: 0.02114823727574103, Total: -10.309514812121499"}
{"time": "2024-07-21T15:19:21.098727", "name": "AirSimEnvLogger", "level": "INFO", "message": "Action: [0.12263446 0.12263446 0.12263446 0.12263446], Velocity: (0.12263445509645127, 0.12263445509645127, 0.12263445509645127), Duration: 0.5, Reward: -10.309514812121499, Done: False"}
{"time": "2024-07-21T15:19:21.176942", "name": "AirSimEnvLogger", "level": "INFO", "message": "Step completed. Observation keys: dict_keys(['state', 'visual'])"}
{"time": "2024-07-21T15:19:21.176942", "name": "AirSimEnvLogger", "level": "INFO", "message": "State shape: (16,), Visual shape: (144, 256, 3)"}
{"time": "2024-07-21T15:19:24.076340", "name": "AirSimEnvLogger", "level": "INFO", "message": "Predictive model loss: 0.002137690782546997"}
{"time": "2024-07-21T15:19:28.470422", "name": "AirSimEnvLogger", "level": "INFO", "message": "Reward breakdown - Distance: -10.129438585930894, Velocity: -0.10735396132206114, Collision: 0, Height: -1.0, Movement: -0.06389597211959683, Smoothness: -0.0, Curiosity: 0.46254757046699524, Exploration: 0.04900872570989266, Total: -10.44842963342841"}
{"time": "2024-07-21T15:19:28.596208", "name": "AirSimEnvLogger", "level": "INFO", "message": "Action: [-0.31947986 -0.31947986 -0.31947986 -0.31947986], Velocity: (-0.3194798605979841, -0.3194798605979841, -0.3194798605979841), Duration: 0.5, Reward: -10.44842963342841, Done: False"}
{"time": "2024-07-21T15:19:28.659307", "name": "AirSimEnvLogger", "level": "INFO", "message": "Step completed. Observation keys: dict_keys(['state', 'visual'])"}
{"time": "2024-07-21T15:19:28.659307", "name": "AirSimEnvLogger", "level": "INFO", "message": "State shape: (16,), Visual shape: (144, 256, 3)"}
{"time": "2024-07-21T15:19:31.558576", "name": "AirSimEnvLogger", "level": "INFO", "message": "Predictive model loss: 0.0019668240565806627"}
{"time": "2024-07-21T15:19:36.298493", "name": "AirSimEnvLogger", "level": "INFO", "message": "Reward breakdown - Distance: -10.072977620171299, Velocity: -0.012671055313769901, Collision: 0, Height: -1.0, Movement: -0.0075905464822189185, Smoothness: -0.0, Curiosity: 0.037927690893411636, Exploration: 0.024798018596988006, Total: -10.556148753310303"}
{"time": "2024-07-21T15:19:36.422796", "name": "AirSimEnvLogger", "level": "INFO", "message": "Action: [-0.03795273 -0.03795273 -0.03795273 -0.03795273], Velocity: (-0.03795273241109459, -0.03795273241109459, -0.03795273241109459), Duration: 0.5, Reward: -10.556148753310303, Done: False"}
{"time": "2024-07-21T15:19:36.469553", "name": "AirSimEnvLogger", "level": "INFO", "message": "Step completed. Observation keys: dict_keys(['state', 'visual'])"}
{"time": "2024-07-21T15:19:36.469553", "name": "AirSimEnvLogger", "level": "INFO", "message": "State shape: (16,), Visual shape: (144, 256, 3)"}
{"time": "2024-07-21T15:19:39.355382", "name": "AirSimEnvLogger", "level": "INFO", "message": "Predictive model loss: 0.00041622252319939435"}
{"time": "2024-07-21T15:19:44.430535", "name": "AirSimEnvLogger", "level": "INFO", "message": "Reward breakdown - Distance: -10.202192986468376, Velocity: -0.09447259726239532, Collision: 0, Height: -1.0, Movement: -0.05679711216361008, Smoothness: -0.0, Curiosity: 0.40982672572135925, Exploration: 0.007923444305814785, Total: -10.548610944594092"}
{"time": "2024-07-21T15:19:44.524286", "name": "AirSimEnvLogger", "level": "INFO", "message": "Action: [-0.28398556 -0.28398556 -0.28398556 -0.28398556], Velocity: (-0.2839855608180504, -0.2839855608180504, -0.2839855608180504), Duration: 0.5, Reward: -10.548610944594092, Done: False"}
{"time": "2024-07-21T15:19:44.635525", "name": "AirSimEnvLogger", "level": "INFO", "message": "Step completed. Observation keys: dict_keys(['state', 'visual'])"}
{"time": "2024-07-21T15:19:44.635525", "name": "AirSimEnvLogger", "level": "INFO", "message": "State shape: (16,), Visual shape: (144, 256, 3)"}
{"time": "2024-07-21T15:19:47.681514", "name": "AirSimEnvLogger", "level": "INFO", "message": "Predictive model loss: 0.0036293601151555777"}
{"time": "2024-07-21T15:19:52.542011", "name": "AirSimEnvLogger", "level": "INFO", "message": "Reward breakdown - Distance: -10.269741574268446, Velocity: -0.1111132010219444, Collision: 0, Height: -1.0, Movement: -0.062155122129473495, Smoothness: -0.0, Curiosity: 0.5224670171737671, Exploration: 0.027287647203361704, Total: -10.564822648964808"}
{"time": "2024-07-21T15:19:52.667527", "name": "AirSimEnvLogger", "level": "INFO", "message": "Action: [-0.31077561 -0.31077561 -0.31077561 -0.31077561], Velocity: (-0.3107756106473675, -0.3107756106473675, -0.3107756106473675), Duration: 0.5, Reward: -10.564822648964808, Done: False"}
{"time": "2024-07-21T15:19:52.729222", "name": "AirSimEnvLogger", "level": "INFO", "message": "Step completed. Observation keys: dict_keys(['state', 'visual'])"}
{"time": "2024-07-21T15:19:52.729222", "name": "AirSimEnvLogger", "level": "INFO", "message": "State shape: (16,), Visual shape: (144, 256, 3)"}
{"time": "2024-07-21T15:19:55.680089", "name": "AirSimEnvLogger", "level": "INFO", "message": "Predictive model loss: 0.006274333223700523"}
{"time": "2024-07-21T15:20:00.876603", "name": "AirSimEnvLogger", "level": "INFO", "message": "Reward breakdown - Distance: -10.435065548162044, Velocity: -0.17310114578337474, Collision: 0, Height: -1.0, Movement: -0.10723697869397869, Smoothness: -0.0, Curiosity: 1.4823604822158813, Exploration: 0.030662653212365665, Total: -10.285027047172715"}
{"time": "2024-07-21T15:20:01.002828", "name": "AirSimEnvLogger", "level": "INFO", "message": "Action: [-0.53618489 -0.53618489 -0.53618489 -0.53618489], Velocity: (-0.5361848934698934, -0.5361848934698934, -0.5361848934698934), Duration: 0.5, Reward: -10.285027047172715, Done: False"}
{"time": "2024-07-21T15:20:01.065037", "name": "AirSimEnvLogger", "level": "INFO", "message": "Step completed. Observation keys: dict_keys(['state', 'visual'])"}
{"time": "2024-07-21T15:20:01.065037", "name": "AirSimEnvLogger", "level": "INFO", "message": "State shape: (16,), Visual shape: (144, 256, 3)"}
{"time": "2024-07-21T15:20:04.130976", "name": "AirSimEnvLogger", "level": "INFO", "message": "Predictive model loss: 0.017612280324101448"}
{"time": "2024-07-21T15:20:09.210052", "name": "AirSimEnvLogger", "level": "INFO", "message": "Reward breakdown - Distance: -10.541137443944704, Velocity: -0.23723986983566173, Collision: 0, Height: -1.0, Movement: -0.11968726976920004, Smoothness: -0.0, Curiosity: 1.9564580917358398, Exploration: 0.03769421539693403, Total: -10.18595821689215"}
{"time": "2024-07-21T15:20:09.319371", "name": "AirSimEnvLogger", "level": "INFO", "message": "Action: [-0.59843635 -0.59843635 -0.59843635 -0.59843635], Velocity: (-0.5984363488460002, -0.5984363488460002, -0.5984363488460002), Duration: 0.5, Reward: -10.18595821689215, Done: False"}
{"time": "2024-07-21T15:20:09.381912", "name": "AirSimEnvLogger", "level": "INFO", "message": "Step completed. Observation keys: dict_keys(['state', 'visual'])"}
{"time": "2024-07-21T15:20:09.381912", "name": "AirSimEnvLogger", "level": "INFO", "message": "State shape: (16,), Visual shape: (144, 256, 3)"}
{"time": "2024-07-21T15:20:12.391068", "name": "AirSimEnvLogger", "level": "INFO", "message": "Predictive model loss: 0.02828074060380459"}
{"time": "2024-07-21T15:20:17.411947", "name": "AirSimEnvLogger", "level": "INFO", "message": "Reward breakdown - Distance: -10.637699211055038, Velocity: -0.29121758396990866, Collision: 0, Height: -1.0, Movement: -0.13600305251384195, Smoothness: -0.0, Curiosity: 2.5987114906311035, Exploration: 0.030109363024261072, Total: -9.991530690370972"}
{"time": "2024-07-21T15:20:17.520323", "name": "AirSimEnvLogger", "level": "INFO", "message": "Action: [-0.68001526 -0.68001526 -0.68001526 -0.68001526], Velocity: (-0.6800152625692097, -0.6800152625692097, -0.6800152625692097), Duration: 0.5, Reward: -9.991530690370972, Done: False"}
{"time": "2024-07-21T15:20:17.613297", "name": "AirSimEnvLogger", "level": "INFO", "message": "Step completed. Observation keys: dict_keys(['state', 'visual'])"}
{"time": "2024-07-21T15:20:17.613297", "name": "AirSimEnvLogger", "level": "INFO", "message": "State shape: (16,), Visual shape: (144, 256, 3)"}
{"time": "2024-07-21T15:20:20.597793", "name": "AirSimEnvLogger", "level": "INFO", "message": "Predictive model loss: 0.040716417133808136"}
{"time": "2024-07-21T15:20:25.660319", "name": "AirSimEnvLogger", "level": "INFO", "message": "Reward breakdown - Distance: -10.384625475199886, Velocity: -0.06650873402190167, Collision: 0, Height: -1.0, Movement: -0.04083133008134572, Smoothness: -0.0, Curiosity: 0.4674920439720154, Exploration: 0.023964039214433002, Total: -10.683424145390077"}
{"time": "2024-07-21T15:20:25.800217", "name": "AirSimEnvLogger", "level": "INFO", "message": "Action: [-0.20415665 -0.20415665 -0.20415665 -0.20415665], Velocity: (-0.2041566504067286, -0.2041566504067286, -0.2041566504067286), Duration: 0.5, Reward: -10.683424145390077, Done: False"}
{"time": "2024-07-21T15:20:25.910391", "name": "AirSimEnvLogger", "level": "INFO", "message": "Step completed. Observation keys: dict_keys(['state', 'visual'])"}
{"time": "2024-07-21T15:20:25.910391", "name": "AirSimEnvLogger", "level": "INFO", "message": "State shape: (16,), Visual shape: (144, 256, 3)"}
{"time": "2024-07-21T15:20:28.874990", "name": "AirSimEnvLogger", "level": "INFO", "message": "Predictive model loss: 0.014597387984395027"}
{"time": "2024-07-21T15:20:33.688068", "name": "AirSimEnvLogger", "level": "INFO", "message": "Reward breakdown - Distance: -10.459832665053542, Velocity: -0.16964844230277737, Collision: 0, Height: -1.0, Movement: -0.09657508266991481, Smoothness: -0.0, Curiosity: 1.4414914846420288, Exploration: 0.021948182544736974, Total: -10.32917901564196"}
{"time": "2024-07-21T15:20:33.703043", "name": "AirSimEnvLogger", "level": "INFO", "message": "Action: [-0.48287541 -0.48287541 -0.48287541 -0.48287541], Velocity: (-0.482875413349574, -0.482875413349574, -0.482875413349574), Duration: 0.5, Reward: -10.32917901564196, Done: False"}
{"time": "2024-07-21T15:20:33.750382", "name": "AirSimEnvLogger", "level": "INFO", "message": "Step completed. Observation keys: dict_keys(['state', 'visual'])"}
{"time": "2024-07-21T15:20:33.750382", "name": "AirSimEnvLogger", "level": "INFO", "message": "State shape: (16,), Visual shape: (144, 256, 3)"}
{"time": "2024-07-21T15:20:36.514781", "name": "AirSimEnvLogger", "level": "INFO", "message": "Predictive model loss: 0.025052305310964584"}
{"time": "2024-07-21T15:20:41.499046", "name": "AirSimEnvLogger", "level": "INFO", "message": "Reward breakdown - Distance: -10.37357585584817, Velocity: -0.09737235716573035, Collision: 0, Height: -1.0, Movement: -0.05994389719280653, Smoothness: -0.0, Curiosity: 0.7506651878356934, Exploration: 0.013357319327388649, Total: -10.550252366366992"}
{"time": "2024-07-21T15:20:41.576751", "name": "AirSimEnvLogger", "level": "INFO", "message": "Action: [-0.29971949 -0.29971949 -0.29971949 -0.29971949], Velocity: (-0.29971948596403264, -0.29971948596403264, -0.29971948596403264), Duration: 0.5, Reward: -10.550252366366992, Done: False"}
{"time": "2024-07-21T15:20:41.637964", "name": "AirSimEnvLogger", "level": "INFO", "message": "Step completed. Observation keys: dict_keys(['state', 'visual'])"}
{"time": "2024-07-21T15:20:41.637964", "name": "AirSimEnvLogger", "level": "INFO", "message": "State shape: (16,), Visual shape: (144, 256, 3)"}
{"time": "2024-07-21T15:20:44.585663", "name": "AirSimEnvLogger", "level": "INFO", "message": "Predictive model loss: 0.017990095540881157"}
{"time": "2024-07-21T15:20:49.420603", "name": "AirSimEnvLogger", "level": "INFO", "message": "Reward breakdown - Distance: -10.408160332513114, Velocity: -0.13510953300321216, Collision: 0, Height: -1.0, Movement: -0.08106583091871467, Smoothness: -0.0, Curiosity: 1.1730797290802002, Exploration: 0.009391190346361105, Total: -10.39540357949722"}
{"time": "2024-07-21T15:20:49.546220", "name": "AirSimEnvLogger", "level": "INFO", "message": "Action: [-0.40532915 -0.40532915 -0.40532915 -0.40532915], Velocity: (-0.4053291545935733, -0.4053291545935733, -0.4053291545935733), Duration: 0.5, Reward: -10.39540357949722, Done: False"}
{"time": "2024-07-21T15:20:49.610038", "name": "AirSimEnvLogger", "level": "INFO", "message": "Step completed. Observation keys: dict_keys(['state', 'visual'])"}
{"time": "2024-07-21T15:20:49.610038", "name": "AirSimEnvLogger", "level": "INFO", "message": "State shape: (16,), Visual shape: (144, 256, 3)"}
{"time": "2024-07-21T15:20:52.575879", "name": "AirSimEnvLogger", "level": "INFO", "message": "Predictive model loss: 0.023080313578248024"}
{"time": "2024-07-21T15:20:57.626987", "name": "AirSimEnvLogger", "level": "INFO", "message": "Reward breakdown - Distance: -10.528708517608404, Velocity: -0.19437158025930606, Collision: 0, Height: -1.0, Movement: -0.11510104404517277, Smoothness: -0.0, Curiosity: 2.1231608390808105, Exploration: 0.028054996738995964, Total: -10.07021299325437"}
{"time": "2024-07-21T15:20:57.753365", "name": "AirSimEnvLogger", "level": "INFO", "message": "Action: [-0.57550522 -0.57550522 -0.57550522 -0.57550522], Velocity: (-0.5755052202258638, -0.5755052202258638, -0.5755052202258638), Duration: 0.5, Reward: -10.07021299325437, Done: False"}
{"time": "2024-07-21T15:20:57.815990", "name": "AirSimEnvLogger", "level": "INFO", "message": "Step completed. Observation keys: dict_keys(['state', 'visual'])"}
{"time": "2024-07-21T15:20:57.815990", "name": "AirSimEnvLogger", "level": "INFO", "message": "State shape: (16,), Visual shape: (144, 256, 3)"}
{"time": "2024-07-21T15:21:00.827023", "name": "AirSimEnvLogger", "level": "INFO", "message": "Predictive model loss: 0.03503039851784706"}
{"time": "2024-07-21T15:21:05.766792", "name": "AirSimEnvLogger", "level": "INFO", "message": "Reward breakdown - Distance: -10.204631113789857, Velocity: -0.024164184817859827, Collision: 0, Height: -1.0, Movement: -0.004765728778500056, Smoothness: -0.0, Curiosity: 0.29962894320487976, Exploration: 0.0262293396196719, Total: -10.562129439550263"}
{"time": "2024-07-21T15:21:05.846075", "name": "AirSimEnvLogger", "level": "INFO", "message": "Action: [0.02382864 0.02382864 0.02382864 0.02382864], Velocity: (0.02382864389250028, 0.02382864389250028, 0.02382864389250028), Duration: 0.5, Reward: -10.562129439550263, Done: False"}
{"time": "2024-07-21T15:21:05.941402", "name": "AirSimEnvLogger", "level": "INFO", "message": "Step completed. Observation keys: dict_keys(['state', 'visual'])"}
{"time": "2024-07-21T15:21:05.941402", "name": "AirSimEnvLogger", "level": "INFO", "message": "State shape: (16,), Visual shape: (144, 256, 3)"}
{"time": "2024-07-21T15:21:08.982322", "name": "AirSimEnvLogger", "level": "INFO", "message": "Predictive model loss: 0.012651202268898487"}
{"time": "2024-07-21T15:21:14.275673", "name": "AirSimEnvLogger", "level": "INFO", "message": "Reward breakdown - Distance: -10.123823615604943, Velocity: -0.01989408968556024, Collision: 0, Height: -1.0, Movement: -0.008622941043546451, Smoothness: -0.0, Curiosity: 0.2954197824001312, Exploration: 0.0470227640800287, Total: -10.477518510536006"}
{"time": "2024-07-21T15:21:14.385331", "name": "AirSimEnvLogger", "level": "INFO", "message": "Action: [-0.04311471 -0.04311471 -0.04311471 -0.04311471], Velocity: (-0.04311470521773225, -0.04311470521773225, -0.04311470521773225), Duration: 0.5, Reward: -10.477518510536006, Done: False"}
{"time": "2024-07-21T15:21:14.446994", "name": "AirSimEnvLogger", "level": "INFO", "message": "Step completed. Observation keys: dict_keys(['state', 'visual'])"}
{"time": "2024-07-21T15:21:14.446994", "name": "AirSimEnvLogger", "level": "INFO", "message": "State shape: (16,), Visual shape: (144, 256, 3)"}
{"time": "2024-07-21T15:21:17.371621", "name": "AirSimEnvLogger", "level": "INFO", "message": "Predictive model loss: 0.013291693292558193"}
{"time": "2024-07-21T15:21:22.323525", "name": "AirSimEnvLogger", "level": "INFO", "message": "Reward breakdown - Distance: -10.257297861733445, Velocity: -0.10464109782875262, Collision: 0, Height: -1.0, Movement: -0.06337109638580216, Smoothness: -0.0, Curiosity: 0.8941020965576172, Exploration: 0.02014505659557794, Total: -10.364875460688477"}
{"time": "2024-07-21T15:21:22.446370", "name": "AirSimEnvLogger", "level": "INFO", "message": "Action: [-0.31685548 -0.31685548 -0.31685548 -0.31685548], Velocity: (-0.31685548192901075, -0.31685548192901075, -0.31685548192901075), Duration: 0.5, Reward: -10.364875460688477, Done: False"}
{"time": "2024-07-21T15:21:22.461075", "name": "AirSimEnvLogger", "level": "INFO", "message": "Step completed. Observation keys: dict_keys(['state', 'visual'])"}
{"time": "2024-07-21T15:21:22.461075", "name": "AirSimEnvLogger", "level": "INFO", "message": "State shape: (16,), Visual shape: (144, 256, 3)"}
{"time": "2024-07-21T15:21:25.377125", "name": "AirSimEnvLogger", "level": "INFO", "message": "Predictive model loss: 0.018190039321780205"}
{"time": "2024-07-21T15:21:30.403683", "name": "AirSimEnvLogger", "level": "INFO", "message": "Reward breakdown - Distance: -9.976271129481734, Velocity: -0.07151400896595453, Collision: 0, Height: -1.0, Movement: -0.04447386943634088, Smoothness: -0.0, Curiosity: 0.4070177674293518, Exploration: 0.018535094365012623, Total: -10.309259618320667"}
{"time": "2024-07-21T15:21:30.543779", "name": "AirSimEnvLogger", "level": "INFO", "message": "Action: [0.22236935 0.22236935 0.22236935 0.22236935], Velocity: (0.22236934718170437, 0.22236934718170437, 0.22236934718170437), Duration: 0.5, Reward: -10.309259618320667, Done: False"}
{"time": "2024-07-21T15:21:30.607031", "name": "AirSimEnvLogger", "level": "INFO", "message": "Step completed. Observation keys: dict_keys(['state', 'visual'])"}
{"time": "2024-07-21T15:21:30.607031", "name": "AirSimEnvLogger", "level": "INFO", "message": "State shape: (16,), Visual shape: (144, 256, 3)"}
{"time": "2024-07-21T15:21:33.509749", "name": "AirSimEnvLogger", "level": "INFO", "message": "Predictive model loss: 0.014189639128744602"}
{"time": "2024-07-21T15:21:38.618166", "name": "AirSimEnvLogger", "level": "INFO", "message": "Reward breakdown - Distance: -10.054926507502321, Velocity: -0.026539275483561317, Collision: 0, Height: -1.0, Movement: -0.015988719049415314, Smoothness: -0.0, Curiosity: 0.33004704117774963, Exploration: 0.02338073424862838, Total: -10.400095349710442"}
{"time": "2024-07-21T15:21:38.681736", "name": "AirSimEnvLogger", "level": "INFO", "message": "Action: [-0.0799436 -0.0799436 -0.0799436 -0.0799436], Velocity: (-0.07994359524707656, -0.07994359524707656, -0.07994359524707656), Duration: 0.5, Reward: -10.400095349710442, Done: False"}
{"time": "2024-07-21T15:21:38.744122", "name": "AirSimEnvLogger", "level": "INFO", "message": "Step completed. Observation keys: dict_keys(['state', 'visual'])"}
{"time": "2024-07-21T15:21:38.744122", "name": "AirSimEnvLogger", "level": "INFO", "message": "State shape: (16,), Visual shape: (144, 256, 3)"}
{"time": "2024-07-21T15:21:41.743877", "name": "AirSimEnvLogger", "level": "INFO", "message": "Predictive model loss: 0.013569937087595463"}
{"time": "2024-07-21T15:21:47.152917", "name": "AirSimEnvLogger", "level": "INFO", "message": "Reward breakdown - Distance: -9.82407838548129, Velocity: -0.10790434051094905, Collision: 0, Height: -1.0, Movement: -0.0681650581045343, Smoothness: -0.0, Curiosity: 0.6505451202392578, Exploration: 0.016809420595085812, Total: -10.05621261730857"}
{"time": "2024-07-21T15:21:47.184483", "name": "AirSimEnvLogger", "level": "INFO", "message": "Action: [0.34082529 0.34082529 0.34082529 0.34082529], Velocity: (0.34082529052267146, 0.34082529052267146, 0.34082529052267146), Duration: 0.5, Reward: -10.05621261730857, Done: False"}
{"time": "2024-07-21T15:21:47.262845", "name": "AirSimEnvLogger", "level": "INFO", "message": "Step completed. Observation keys: dict_keys(['state', 'visual'])"}
{"time": "2024-07-21T15:21:47.262845", "name": "AirSimEnvLogger", "level": "INFO", "message": "State shape: (16,), Visual shape: (144, 256, 3)"}
{"time": "2024-07-21T15:21:50.339574", "name": "AirSimEnvLogger", "level": "INFO", "message": "Predictive model loss: 0.017568470910191536"}
{"time": "2024-07-21T15:21:55.538035", "name": "AirSimEnvLogger", "level": "INFO", "message": "Reward breakdown - Distance: -9.609780085002116, Velocity: -0.17312259554200235, Collision: 0, Height: -1.0, Movement: -0.11024194668150909, Smoothness: -0.0, Curiosity: 1.4560407400131226, Exploration: 0.05661730234680809, Total: -9.468021746965345"}
{"time": "2024-07-21T15:21:55.647080", "name": "AirSimEnvLogger", "level": "INFO", "message": "Action: [0.55120973 0.55120973 0.55120973 0.55120973], Velocity: (0.5512097334075454, 0.5512097334075454, 0.5512097334075454), Duration: 0.5, Reward: -9.468021746965345, Done: False"}
{"time": "2024-07-21T15:21:55.678634", "name": "AirSimEnvLogger", "level": "INFO", "message": "Step completed. Observation keys: dict_keys(['state', 'visual'])"}
{"time": "2024-07-21T15:21:55.678634", "name": "AirSimEnvLogger", "level": "INFO", "message": "State shape: (16,), Visual shape: (144, 256, 3)"}
{"time": "2024-07-21T15:21:58.691588", "name": "AirSimEnvLogger", "level": "INFO", "message": "Predictive model loss: 0.028474153950810432"}
{"time": "2024-07-21T15:22:03.559718", "name": "AirSimEnvLogger", "level": "INFO", "message": "Reward breakdown - Distance: -9.460818473875337, Velocity: -0.19702858759192302, Collision: 0, Height: -1.0, Movement: -0.1312803909699965, Smoothness: -0.0, Curiosity: 2.0641744136810303, Exploration: 0.04374538733206102, Total: -9.031624522461371"}
{"time": "2024-07-21T15:22:03.668907", "name": "AirSimEnvLogger", "level": "INFO", "message": "Action: [0.65640195 0.65640195 0.65640195 0.65640195], Velocity: (0.6564019548499824, 0.6564019548499824, 0.6564019548499824), Duration: 0.5, Reward: -9.031624522461371, Done: False"}
{"time": "2024-07-21T15:22:03.747364", "name": "AirSimEnvLogger", "level": "INFO", "message": "Step completed. Observation keys: dict_keys(['state', 'visual'])"}
{"time": "2024-07-21T15:22:03.747364", "name": "AirSimEnvLogger", "level": "INFO", "message": "State shape: (16,), Visual shape: (144, 256, 3)"}
{"time": "2024-07-21T15:22:06.539804", "name": "AirSimEnvLogger", "level": "INFO", "message": "Predictive model loss: 0.036971431225538254"}
{"time": "2024-07-21T15:22:11.552382", "name": "AirSimEnvLogger", "level": "INFO", "message": "Reward breakdown - Distance: -9.563924386897689, Velocity: -0.12379770763781728, Collision: 0, Height: -1.0, Movement: -0.07557720693552734, Smoothness: -0.0, Curiosity: 0.7978980541229248, Exploration: 0.00994086558877581, Total: -9.732443761230932"}
{"time": "2024-07-21T15:22:11.675587", "name": "AirSimEnvLogger", "level": "INFO", "message": "Action: [0.37788603 0.37788603 0.37788603 0.37788603], Velocity: (0.3778860346776367, 0.3778860346776367, 0.3778860346776367), Duration: 0.5, Reward: -9.732443761230932, Done: False"}
{"time": "2024-07-21T15:22:11.722917", "name": "AirSimEnvLogger", "level": "INFO", "message": "Step completed. Observation keys: dict_keys(['state', 'visual'])"}
{"time": "2024-07-21T15:22:11.722917", "name": "AirSimEnvLogger", "level": "INFO", "message": "State shape: (16,), Visual shape: (144, 256, 3)"}
{"time": "2024-07-21T15:22:14.673580", "name": "AirSimEnvLogger", "level": "INFO", "message": "Predictive model loss: 0.02179531566798687"}
{"time": "2024-07-21T15:22:20.043880", "name": "AirSimEnvLogger", "level": "INFO", "message": "Reward breakdown - Distance: -9.488377379655052, Velocity: -0.1703552012083209, Collision: 0, Height: -1.0, Movement: -0.11394802109700562, Smoothness: -0.0, Curiosity: 1.5843346118927002, Exploration: 0.009728007778694045, Total: -9.290836874866823"}
{"time": "2024-07-21T15:22:20.207412", "name": "AirSimEnvLogger", "level": "INFO", "message": "Action: [0.56974011 0.56974011 0.56974011 0.56974011], Velocity: (0.5697401054850281, 0.5697401054850281, 0.5697401054850281), Duration: 0.5, Reward: -9.290836874866823, Done: False"}
{"time": "2024-07-21T15:22:20.295435", "name": "AirSimEnvLogger", "level": "INFO", "message": "Step completed. Observation keys: dict_keys(['state', 'visual'])"}
{"time": "2024-07-21T15:22:20.295435", "name": "AirSimEnvLogger", "level": "INFO", "message": "State shape: (16,), Visual shape: (144, 256, 3)"}
{"time": "2024-07-21T15:22:23.004962", "name": "AirSimEnvLogger", "level": "INFO", "message": "Predictive model loss: 0.025026114657521248"}
{"time": "2024-07-21T15:22:27.939863", "name": "AirSimEnvLogger", "level": "INFO", "message": "Reward breakdown - Distance: -9.854386725604218, Velocity: -0.0410461217815881, Collision: 0, Height: -1.0, Movement: -0.01918540708073915, Smoothness: -0.0, Curiosity: 0.12679435312747955, Exploration: 0.034413531794548174, Total: -10.306548444280436"}
{"time": "2024-07-21T15:22:28.064296", "name": "AirSimEnvLogger", "level": "INFO", "message": "Action: [-0.09592704 -0.09592704 -0.09592704 -0.09592704], Velocity: (-0.09592703540369574, -0.09592703540369574, -0.09592703540369574), Duration: 0.5, Reward: -10.306548444280436, Done: False"}
{"time": "2024-07-21T15:22:28.142506", "name": "AirSimEnvLogger", "level": "INFO", "message": "Step completed. Observation keys: dict_keys(['state', 'visual'])"}
{"time": "2024-07-21T15:22:28.142506", "name": "AirSimEnvLogger", "level": "INFO", "message": "State shape: (16,), Visual shape: (144, 256, 3)"}
{"time": "2024-07-21T15:22:31.413174", "name": "AirSimEnvLogger", "level": "INFO", "message": "Predictive model loss: 0.003344245022162795"}
{"time": "2024-07-21T15:22:35.987322", "name": "AirSimEnvLogger", "level": "INFO", "message": "Reward breakdown - Distance: -10.196521101751612, Velocity: -0.14701715208379268, Collision: 0, Height: -1.0, Movement: -0.08575212116961152, Smoothness: -0.0, Curiosity: 0.9767941236495972, Exploration: 0.08541984715587703, Total: -10.273123858654497"}
{"time": "2024-07-21T15:22:36.112874", "name": "AirSimEnvLogger", "level": "INFO", "message": "Action: [-0.42876061 -0.42876061 -0.42876061 -0.42876061], Velocity: (-0.4287606058480576, -0.4287606058480576, -0.4287606058480576), Duration: 0.5, Reward: -10.273123858654497, Done: False"}
{"time": "2024-07-21T15:22:36.175445", "name": "AirSimEnvLogger", "level": "INFO", "message": "Step completed. Observation keys: dict_keys(['state', 'visual'])"}
{"time": "2024-07-21T15:22:36.175445", "name": "AirSimEnvLogger", "level": "INFO", "message": "State shape: (16,), Visual shape: (144, 256, 3)"}
{"time": "2024-07-21T15:22:39.305615", "name": "AirSimEnvLogger", "level": "INFO", "message": "Predictive model loss: 0.006593162193894386"}
{"time": "2024-07-21T15:22:44.016894", "name": "AirSimEnvLogger", "level": "INFO", "message": "Reward breakdown - Distance: -10.423970248993374, Velocity: -0.18776982088631902, Collision: 0, Height: -1.0, Movement: -0.11372742233636216, Smoothness: -0.0, Curiosity: 1.8082501888275146, Exploration: 0.0640113071190364, Total: -10.112300545832605"}
{"time": "2024-07-21T15:22:44.125551", "name": "AirSimEnvLogger", "level": "INFO", "message": "Action: [-0.56863711 -0.56863711 -0.56863711 -0.56863711], Velocity: (-0.5686371116818107, -0.5686371116818107, -0.5686371116818107), Duration: 0.5, Reward: -10.112300545832605, Done: False"}
{"time": "2024-07-21T15:22:44.218393", "name": "AirSimEnvLogger", "level": "INFO", "message": "Step completed. Observation keys: dict_keys(['state', 'visual'])"}
{"time": "2024-07-21T15:22:44.218393", "name": "AirSimEnvLogger", "level": "INFO", "message": "State shape: (16,), Visual shape: (144, 256, 3)"}
{"time": "2024-07-21T15:22:47.169656", "name": "AirSimEnvLogger", "level": "INFO", "message": "Predictive model loss: 0.02062726579606533"}
{"time": "2024-07-21T15:22:52.341833", "name": "AirSimEnvLogger", "level": "INFO", "message": "Reward breakdown - Distance: -10.364973729640067, Velocity: -0.10069826045240839, Collision: 0, Height: -1.0, Movement: -0.06289063817740596, Smoothness: -0.0, Curiosity: 0.7899945378303528, Exploration: 0.01863855823070684, Total: -10.522886943122694"}
{"time": "2024-07-21T15:22:52.468714", "name": "AirSimEnvLogger", "level": "INFO", "message": "Action: [-0.31445319 -0.31445319 -0.31445319 -0.31445319], Velocity: (-0.31445319088702983, -0.31445319088702983, -0.31445319088702983), Duration: 0.5, Reward: -10.522886943122694, Done: False"}
{"time": "2024-07-21T15:22:52.532189", "name": "AirSimEnvLogger", "level": "INFO", "message": "Step completed. Observation keys: dict_keys(['state', 'visual'])"}
{"time": "2024-07-21T15:22:52.532189", "name": "AirSimEnvLogger", "level": "INFO", "message": "State shape: (16,), Visual shape: (144, 256, 3)"}
{"time": "2024-07-21T15:22:55.378342", "name": "AirSimEnvLogger", "level": "INFO", "message": "Predictive model loss: 0.015339385718107224"}
{"time": "2024-07-21T15:23:00.407150", "name": "AirSimEnvLogger", "level": "INFO", "message": "Reward breakdown - Distance: -10.306157518135626, Velocity: -0.07905343081283094, Collision: 0, Height: -1.0, Movement: -0.049601101013427566, Smoothness: -0.0, Curiosity: 0.606966495513916, Exploration: 0.016911252371566488, Total: -10.543778845412112"}
{"time": "2024-07-21T15:23:00.564938", "name": "AirSimEnvLogger", "level": "INFO", "message": "Action: [-0.24800551 -0.24800551 -0.24800551 -0.24800551], Velocity: (-0.2480055050671378, -0.2480055050671378, -0.2480055050671378), Duration: 0.5, Reward: -10.543778845412112, Done: False"}
{"time": "2024-07-21T15:23:00.722454", "name": "AirSimEnvLogger", "level": "INFO", "message": "Step completed. Observation keys: dict_keys(['state', 'visual'])"}
{"time": "2024-07-21T15:23:00.722454", "name": "AirSimEnvLogger", "level": "INFO", "message": "State shape: (16,), Visual shape: (144, 256, 3)"}
{"time": "2024-07-21T15:23:03.700576", "name": "AirSimEnvLogger", "level": "INFO", "message": "Predictive model loss: 0.013469203375279903"}
{"time": "2024-07-21T15:23:08.972927", "name": "AirSimEnvLogger", "level": "INFO", "message": "Reward breakdown - Distance: -9.9956016495641, Velocity: -0.07476331064152808, Collision: 0, Height: -1.0, Movement: -0.044646347000000086, Smoothness: -0.0, Curiosity: 0.32009363174438477, Exploration: 0.043798621122427536, Total: -10.368641399488185"}
{"time": "2024-07-21T15:23:09.099504", "name": "AirSimEnvLogger", "level": "INFO", "message": "Action: [0.22323174 0.22323174 0.22323174 0.22323174], Velocity: (0.22323173500000043, 0.22323173500000043, 0.22323173500000043), Duration: 0.5, Reward: -10.368641399488185, Done: False"}
{"time": "2024-07-21T15:23:09.193178", "name": "AirSimEnvLogger", "level": "INFO", "message": "Step completed. Observation keys: dict_keys(['state', 'visual'])"}
{"time": "2024-07-21T15:23:09.193178", "name": "AirSimEnvLogger", "level": "INFO", "message": "State shape: (16,), Visual shape: (144, 256, 3)"}
{"time": "2024-07-21T15:23:12.355865", "name": "AirSimEnvLogger", "level": "INFO", "message": "Predictive model loss: 0.002505091018974781"}
{"time": "2024-07-21T15:23:17.148202", "name": "AirSimEnvLogger", "level": "INFO", "message": "Reward breakdown - Distance: -10.176265120266471, Velocity: -0.09163294052154212, Collision: 0, Height: -1.0, Movement: -0.0538362441292419, Smoothness: -0.0, Curiosity: 0.590944766998291, Exploration: 0.01324955517604522, Total: -10.429342920405812"}
{"time": "2024-07-21T15:23:17.195416", "name": "AirSimEnvLogger", "level": "INFO", "message": "Action: [-0.26918122 -0.26918122 -0.26918122 -0.26918122], Velocity: (-0.2691812206462095, -0.2691812206462095, -0.2691812206462095), Duration: 0.5, Reward: -10.429342920405812, Done: False"}
{"time": "2024-07-21T15:23:17.241431", "name": "AirSimEnvLogger", "level": "INFO", "message": "Step completed. Observation keys: dict_keys(['state', 'visual'])"}
{"time": "2024-07-21T15:23:17.241431", "name": "AirSimEnvLogger", "level": "INFO", "message": "State shape: (16,), Visual shape: (144, 256, 3)"}
{"time": "2024-07-21T15:23:20.138426", "name": "AirSimEnvLogger", "level": "INFO", "message": "Predictive model loss: 0.009886587969958782"}
{"time": "2024-07-21T15:23:25.351624", "name": "AirSimEnvLogger", "level": "INFO", "message": "Reward breakdown - Distance: -10.191037008029964, Velocity: -0.07037453497847102, Collision: 0, Height: -1.0, Movement: -0.03744709480956266, Smoothness: -0.0, Curiosity: 0.4410618543624878, Exploration: 0.03004489454595563, Total: -10.50342907890972"}
{"time": "2024-07-21T15:23:25.446593", "name": "AirSimEnvLogger", "level": "INFO", "message": "Action: [-0.18723547 -0.18723547 -0.18723547 -0.18723547], Velocity: (-0.1872354740478133, -0.1872354740478133, -0.1872354740478133), Duration: 0.5, Reward: -10.50342907890972, Done: False"}
{"time": "2024-07-21T15:23:25.509636", "name": "AirSimEnvLogger", "level": "INFO", "message": "Step completed. Observation keys: dict_keys(['state', 'visual'])"}
{"time": "2024-07-21T15:23:25.509636", "name": "AirSimEnvLogger", "level": "INFO", "message": "State shape: (16,), Visual shape: (144, 256, 3)"}
{"time": "2024-07-21T15:23:28.481086", "name": "AirSimEnvLogger", "level": "INFO", "message": "Predictive model loss: 0.009487166069447994"}
{"time": "2024-07-21T15:23:33.575516", "name": "AirSimEnvLogger", "level": "INFO", "message": "Reward breakdown - Distance: -10.378645020527564, Velocity: -0.16142854495677897, Collision: 0, Height: -1.0, Movement: -0.09488296503402327, Smoothness: -0.0, Curiosity: 1.501624584197998, Exploration: 0.02556626395383634, Total: -10.212922044619589"}
{"time": "2024-07-21T15:23:33.731586", "name": "AirSimEnvLogger", "level": "INFO", "message": "Action: [-0.47441483 -0.47441483 -0.47441483 -0.47441483], Velocity: (-0.47441482517011635, -0.47441482517011635, -0.47441482517011635), Duration: 0.5, Reward: -10.212922044619589, Done: False"}
{"time": "2024-07-21T15:23:33.793628", "name": "AirSimEnvLogger", "level": "INFO", "message": "Step completed. Observation keys: dict_keys(['state', 'visual'])"}
{"time": "2024-07-21T15:23:33.794133", "name": "AirSimEnvLogger", "level": "INFO", "message": "State shape: (16,), Visual shape: (144, 256, 3)"}
{"time": "2024-07-21T15:23:36.696926", "name": "AirSimEnvLogger", "level": "INFO", "message": "Predictive model loss: 0.023401660844683647"}
{"time": "2024-07-21T15:23:41.594584", "name": "AirSimEnvLogger", "level": "INFO", "message": "Reward breakdown - Distance: -10.468614893125887, Velocity: -0.17482832696239223, Collision: 0, Height: -1.0, Movement: -0.09964577552963066, Smoothness: -0.0, Curiosity: 1.7604092359542847, Exploration: 0.03612757591639488, Total: -10.178563500999624"}
{"time": "2024-07-21T15:23:41.719456", "name": "AirSimEnvLogger", "level": "INFO", "message": "Action: [-0.49822888 -0.49822888 -0.49822888 -0.49822888], Velocity: (-0.49822887764815327, -0.49822887764815327, -0.49822887764815327), Duration: 0.5, Reward: -10.178563500999624, Done: False"}
{"time": "2024-07-21T15:23:41.796640", "name": "AirSimEnvLogger", "level": "INFO", "message": "Step completed. Observation keys: dict_keys(['state', 'visual'])"}
{"time": "2024-07-21T15:23:41.796640", "name": "AirSimEnvLogger", "level": "INFO", "message": "State shape: (16,), Visual shape: (144, 256, 3)"}
{"time": "2024-07-21T15:23:44.791240", "name": "AirSimEnvLogger", "level": "INFO", "message": "Predictive model loss: 0.03063318319618702"}
{"time": "2024-07-21T15:23:49.798977", "name": "AirSimEnvLogger", "level": "INFO", "message": "Reward breakdown - Distance: -10.592621993852587, Velocity: -0.20620351793339753, Collision: 0, Height: -1.0, Movement: -0.12598230539405728, Smoothness: -0.0, Curiosity: 2.6854257583618164, Exploration: 0.02816284936663895, Total: -9.859976534304455"}
{"time": "2024-07-21T15:23:49.939403", "name": "AirSimEnvLogger", "level": "INFO", "message": "Action: [-0.62991153 -0.62991153 -0.62991153 -0.62991153], Velocity: (-0.6299115269702864, -0.6299115269702864, -0.6299115269702864), Duration: 0.5, Reward: -9.859976534304455, Done: False"}
{"time": "2024-07-21T15:23:50.001475", "name": "AirSimEnvLogger", "level": "INFO", "message": "Step completed. Observation keys: dict_keys(['state', 'visual'])"}
{"time": "2024-07-21T15:23:50.001475", "name": "AirSimEnvLogger", "level": "INFO", "message": "State shape: (16,), Visual shape: (144, 256, 3)"}
{"time": "2024-07-21T15:23:52.982700", "name": "AirSimEnvLogger", "level": "INFO", "message": "Predictive model loss: 0.04572155699133873"}
{"time": "2024-07-21T15:23:57.969254", "name": "AirSimEnvLogger", "level": "INFO", "message": "Reward breakdown - Distance: -10.207927812148672, Velocity: -0.03561498720677489, Collision: 0, Height: -1.0, Movement: -0.013168264932213304, Smoothness: -0.0, Curiosity: 0.43982043862342834, Exploration: 0.034774182722158674, Total: -10.500187076389134"}
{"time": "2024-07-21T15:23:58.064387", "name": "AirSimEnvLogger", "level": "INFO", "message": "Action: [0.06584132 0.06584132 0.06584132 0.06584132], Velocity: (0.06584132466106651, 0.06584132466106651, 0.06584132466106651), Duration: 0.5, Reward: -10.500187076389134, Done: False"}
{"time": "2024-07-21T15:23:58.126809", "name": "AirSimEnvLogger", "level": "INFO", "message": "Step completed. Observation keys: dict_keys(['state', 'visual'])"}
{"time": "2024-07-21T15:23:58.126809", "name": "AirSimEnvLogger", "level": "INFO", "message": "State shape: (16,), Visual shape: (144, 256, 3)"}
{"time": "2024-07-21T15:24:00.909320", "name": "AirSimEnvLogger", "level": "INFO", "message": "Predictive model loss: 0.011141650378704071"}
{"time": "2024-07-21T15:24:05.928955", "name": "AirSimEnvLogger", "level": "INFO", "message": "Reward breakdown - Distance: -10.27492453343763, Velocity: -0.09745601803498315, Collision: 0, Height: -1.0, Movement: -0.05424769445917106, Smoothness: -0.0, Curiosity: 0.9335887432098389, Exploration: 0.034653573084970815, Total: -10.355352225679125"}
{"time": "2024-07-21T15:24:06.053774", "name": "AirSimEnvLogger", "level": "INFO", "message": "Action: [-0.27123847 -0.27123847 -0.27123847 -0.27123847], Velocity: (-0.2712384722958553, -0.2712384722958553, -0.2712384722958553), Duration: 0.5, Reward: -10.355352225679125, Done: False"}
{"time": "2024-07-21T15:24:06.085342", "name": "AirSimEnvLogger", "level": "INFO", "message": "Step completed. Observation keys: dict_keys(['state', 'visual'])"}
{"time": "2024-07-21T15:24:06.086343", "name": "AirSimEnvLogger", "level": "INFO", "message": "State shape: (16,), Visual shape: (144, 256, 3)"}
{"time": "2024-07-21T15:24:08.806402", "name": "AirSimEnvLogger", "level": "INFO", "message": "Predictive model loss: 0.017199626192450523"}
{"time": "2024-07-21T15:24:13.995811", "name": "AirSimEnvLogger", "level": "INFO", "message": "Reward breakdown - Distance: -10.44885603873483, Velocity: -0.17079900304514617, Collision: 0, Height: -1.0, Movement: -0.10328326485882747, Smoothness: -0.0, Curiosity: 2.077057361602783, Exploration: 0.041536415019658976, Total: -9.997747902937963"}
{"time": "2024-07-21T15:24:14.123078", "name": "AirSimEnvLogger", "level": "INFO", "message": "Action: [-0.51641632 -0.51641632 -0.51641632 -0.51641632], Velocity: (-0.5164163242941373, -0.5164163242941373, -0.5164163242941373), Duration: 0.5, Reward: -9.997747902937963, Done: False"}
{"time": "2024-07-21T15:24:14.249338", "name": "AirSimEnvLogger", "level": "INFO", "message": "Step completed. Observation keys: dict_keys(['state', 'visual'])"}
{"time": "2024-07-21T15:24:14.249338", "name": "AirSimEnvLogger", "level": "INFO", "message": "State shape: (16,), Visual shape: (144, 256, 3)"}
{"time": "2024-07-21T15:24:17.207947", "name": "AirSimEnvLogger", "level": "INFO", "message": "Predictive model loss: 0.03014729544520378"}
{"time": "2024-07-21T15:24:22.327583", "name": "AirSimEnvLogger", "level": "INFO", "message": "Reward breakdown - Distance: -10.356528680012547, Velocity: -0.08702726406776798, Collision: 0, Height: -1.0, Movement: -0.052055706502028044, Smoothness: -0.0, Curiosity: 1.0926954746246338, Exploration: 0.01162467947300826, Total: -10.356575209489714"}
{"time": "2024-07-21T15:24:22.422839", "name": "AirSimEnvLogger", "level": "INFO", "message": "Action: [-0.26027853 -0.26027853 -0.26027853 -0.26027853], Velocity: (-0.2602785325101402, -0.2602785325101402, -0.2602785325101402), Duration: 0.5, Reward: -10.356575209489714, Done: False"}
{"time": "2024-07-21T15:24:22.486453", "name": "AirSimEnvLogger", "level": "INFO", "message": "Step completed. Observation keys: dict_keys(['state', 'visual'])"}
{"time": "2024-07-21T15:24:22.486453", "name": "AirSimEnvLogger", "level": "INFO", "message": "State shape: (16,), Visual shape: (144, 256, 3)"}
{"time": "2024-07-21T15:24:25.420481", "name": "AirSimEnvLogger", "level": "INFO", "message": "Predictive model loss: 0.018636712804436684"}
{"time": "2024-07-21T15:24:30.435054", "name": "AirSimEnvLogger", "level": "INFO", "message": "Reward breakdown - Distance: -10.485437317447117, Velocity: -0.1674093457032207, Collision: 0, Height: -1.0, Movement: -0.10218727088025598, Smoothness: -0.0, Curiosity: 2.250913381576538, Exploration: 0.0097355668643726, Total: -9.951956913225608"}
{"time": "2024-07-21T15:24:30.528894", "name": "AirSimEnvLogger", "level": "INFO", "message": "Action: [-0.51093635 -0.51093635 -0.51093635 -0.51093635], Velocity: (-0.5109363544012798, -0.5109363544012798, -0.5109363544012798), Duration: 0.5, Reward: -9.951956913225608, Done: False"}
{"time": "2024-07-21T15:24:30.575651", "name": "AirSimEnvLogger", "level": "INFO", "message": "Step completed. Observation keys: dict_keys(['state', 'visual'])"}
{"time": "2024-07-21T15:24:30.575651", "name": "AirSimEnvLogger", "level": "INFO", "message": "State shape: (16,), Visual shape: (144, 256, 3)"}
{"time": "2024-07-21T15:24:33.711382", "name": "AirSimEnvLogger", "level": "INFO", "message": "Predictive model loss: 0.028729159384965897"}
{"time": "2024-07-21T15:24:38.791941", "name": "AirSimEnvLogger", "level": "INFO", "message": "Reward breakdown - Distance: -10.195284212248186, Velocity: -0.020542336682349182, Collision: 0, Height: -1.0, Movement: -0.005591341376049397, Smoothness: -0.0, Curiosity: 0.680039644241333, Exploration: 0.01919795107869957, Total: -10.36225510239056"}
{"time": "2024-07-21T15:24:38.853633", "name": "AirSimEnvLogger", "level": "INFO", "message": "Action: [0.02795671 0.02795671 0.02795671 0.02795671], Velocity: (0.027956706880246984, 0.027956706880246984, 0.027956706880246984), Duration: 0.5, Reward: -10.36225510239056, Done: False"}
{"time": "2024-07-21T15:24:38.916924", "name": "AirSimEnvLogger", "level": "INFO", "message": "Step completed. Observation keys: dict_keys(['state', 'visual'])"}
{"time": "2024-07-21T15:24:38.916924", "name": "AirSimEnvLogger", "level": "INFO", "message": "State shape: (16,), Visual shape: (144, 256, 3)"}
{"time": "2024-07-21T15:24:41.881391", "name": "AirSimEnvLogger", "level": "INFO", "message": "Predictive model loss: 0.007631292566657066"}
{"time": "2024-07-21T15:24:46.884095", "name": "AirSimEnvLogger", "level": "INFO", "message": "Reward breakdown - Distance: -9.896416283851632, Velocity: -0.10573157755684781, Collision: 0, Height: -1.0, Movement: -0.06724989241348857, Smoothness: -0.0, Curiosity: 0.9191684722900391, Exploration: 0.07083175228696086, Total: -9.982256475268994"}
{"time": "2024-07-21T15:24:47.009931", "name": "AirSimEnvLogger", "level": "INFO", "message": "Action: [0.33624946 0.33624946 0.33624946 0.33624946], Velocity: (0.33624946206744283, 0.33624946206744283, 0.33624946206744283), Duration: 0.5, Reward: -9.982256475268994, Done: False"}
{"time": "2024-07-21T15:24:47.073056", "name": "AirSimEnvLogger", "level": "INFO", "message": "Step completed. Observation keys: dict_keys(['state', 'visual'])"}
{"time": "2024-07-21T15:24:47.073056", "name": "AirSimEnvLogger", "level": "INFO", "message": "State shape: (16,), Visual shape: (144, 256, 3)"}
{"time": "2024-07-21T15:24:50.118817", "name": "AirSimEnvLogger", "level": "INFO", "message": "Predictive model loss: 0.006637121085077524"}
{"time": "2024-07-21T15:24:54.925912", "name": "AirSimEnvLogger", "level": "INFO", "message": "Reward breakdown - Distance: -9.740760933363505, Velocity: -0.13303389984052777, Collision: 0, Height: -1.0, Movement: -0.07923360976570425, Smoothness: -0.0, Curiosity: 1.0783147811889648, Exploration: 0.04989704568201597, Total: -9.766064444529455"}
{"time": "2024-07-21T15:24:55.068048", "name": "AirSimEnvLogger", "level": "INFO", "message": "Action: [0.39616805 0.39616805 0.39616805 0.39616805], Velocity: (0.3961680488285212, 0.3961680488285212, 0.3961680488285212), Duration: 0.5, Reward: -9.766064444529455, Done: False"}
{"time": "2024-07-21T15:24:55.177439", "name": "AirSimEnvLogger", "level": "INFO", "message": "Step completed. Observation keys: dict_keys(['state', 'visual'])"}
{"time": "2024-07-21T15:24:55.178047", "name": "AirSimEnvLogger", "level": "INFO", "message": "State shape: (16,), Visual shape: (144, 256, 3)"}
{"time": "2024-07-21T15:24:58.107884", "name": "AirSimEnvLogger", "level": "INFO", "message": "Predictive model loss: 0.013336333446204662"}
{"time": "2024-07-21T15:25:02.573436", "name": "AirSimEnvLogger", "level": "INFO", "message": "Reward breakdown - Distance: -9.997993048383153, Velocity: -0.04810105463346957, Collision: 0, Height: -1.0, Movement: -0.026059532597692916, Smoothness: -0.0, Curiosity: 0.6473649144172668, Exploration: 0.021237827029773722, Total: -10.196719506345069"}
{"time": "2024-07-21T15:25:02.667984", "name": "AirSimEnvLogger", "level": "INFO", "message": "Action: [-0.13029766 -0.13029766 -0.13029766 -0.13029766], Velocity: (-0.13029766298846457, -0.13029766298846457, -0.13029766298846457), Duration: 0.5, Reward: -10.196719506345069, Done: False"}
{"time": "2024-07-21T15:25:02.730864", "name": "AirSimEnvLogger", "level": "INFO", "message": "Step completed. Observation keys: dict_keys(['state', 'visual'])"}
{"time": "2024-07-21T15:25:02.730864", "name": "AirSimEnvLogger", "level": "INFO", "message": "State shape: (16,), Visual shape: (144, 256, 3)"}
{"time": "2024-07-21T15:25:05.758742", "name": "AirSimEnvLogger", "level": "INFO", "message": "Predictive model loss: 0.0037898668088018894"}
{"time": "2024-07-21T15:25:10.806858", "name": "AirSimEnvLogger", "level": "INFO", "message": "Reward breakdown - Distance: -9.876611358303563, Velocity: -0.06871770929729708, Collision: 0, Height: -1.0, Movement: -0.043720572970791606, Smoothness: -0.0, Curiosity: 0.6063529849052429, Exploration: 0.015191278453043223, Total: -10.10912752210606"}
{"time": "2024-07-21T15:25:10.839048", "name": "AirSimEnvLogger", "level": "INFO", "message": "Action: [0.21860286 0.21860286 0.21860286 0.21860286], Velocity: (0.21860286485395802, 0.21860286485395802, 0.21860286485395802), Duration: 0.5, Reward: -10.10912752210606, Done: False"}
{"time": "2024-07-21T15:25:10.901556", "name": "AirSimEnvLogger", "level": "INFO", "message": "Step completed. Observation keys: dict_keys(['state', 'visual'])"}
{"time": "2024-07-21T15:25:10.901556", "name": "AirSimEnvLogger", "level": "INFO", "message": "State shape: (16,), Visual shape: (144, 256, 3)"}
{"time": "2024-07-21T15:25:13.879168", "name": "AirSimEnvLogger", "level": "INFO", "message": "Predictive model loss: 0.009429915808141232"}
{"time": "2024-07-21T15:25:37.633117", "name": "AirSimEnvLogger", "level": "INFO", "message": "Initialized with state_dim: 16, action_dim: 4"}
{"time": "2024-07-21T15:25:37.654863", "name": "AirSimEnvLogger", "level": "INFO", "message": "Initializing AirSimEnv"}
{"time": "2024-07-21T15:25:37.655863", "name": "AirSimEnvLogger", "level": "INFO", "message": "Configuration: {\n  \"learning_rate\": 0.0001,\n  \"gamma\": 0.99,\n  \"tau\": 0.95,\n  \"batch_size\": 64,\n  \"num_timesteps\": 2000000,\n  \"ppo\": {\n    \"learning_rate\": 0.0003,\n    \"n_steps\": 2048,\n    \"batch_size\": 64,\n    \"n_epochs\": 2000,\n    \"gamma\": 0.99,\n    \"gae_lambda\": 0.95,\n    \"clip_range\": 0.3,\n    \"ent_coef\": 0.02,\n    \"vf_coef\": 0.5,\n    \"max_grad_norm\": 0.5,\n    \"use_sde\": true,\n    \"sde_sample_freq\": 4,\n    \"tensorboard_log\": \"logs/tensorboard_logs/ppo_airsim_tensorboard/\",\n    \"verbose\": 1,\n    \"seed\": null,\n    \"device\": \"auto\",\n    \"continuous\": true,\n    \"save_freq\": 10000\n  },\n  \"environment\": {\n    \"env_name\": \"Africa_001\",\n    \"reward_threshold\": 250,\n    \"max_episode_steps\": 1000,\n    \"state_dim\": 16,\n    \"action_dim\": 4,\n    \"reward_scale\": 20,\n    \"proximity_threshold\": 5.0,\n    \"collision_penalty\": 25,\n    \"height_target\": -10,\n    \"height_tolerance\": 1.0,\n    \"height_penalty\": 1,\n    \"movement_penalty\": 0.1,\n    \"smoothness_penalty\": 0.1,\n    \"duration\": 0.1,\n    \"exploration_area\": {\n      \"x_min\": -2000,\n      \"x_max\": 2000,\n      \"y_min\": -2000,\n      \"y_max\": 2000,\n      \"z_min\": -200,\n      \"z_max\": 200\n    }\n  },\n  \"policy_network\": {\n    \"input_size\": 16,\n    \"hidden_layers\": [\n      256,\n      256,\n      256\n    ],\n    \"output_size\": 4,\n    \"use_batch_norm\": true,\n    \"use_dropout\": true,\n    \"dropout_rate\": 0.2,\n    \"use_attention\": false,\n    \"num_action_heads\": 1\n  },\n  \"critic_network\": {\n    \"input_size\": 16,\n    \"hidden_layers\": [\n      256,\n      256\n    ],\n    \"output_size\": 1,\n    \"use_batch_norm\": true,\n    \"use_dropout\": true,\n    \"dropout_rate\": 0.2,\n    \"use_attention\": true\n  },\n  \"exploration\": {\n    \"strategy\": \"epsilon_decay\",\n    \"initial_epsilon\": 1.0,\n    \"min_epsilon\": 0.05,\n    \"epsilon_decay_rate\": 0.9995\n  },\n  \"model_checkpointing\": {\n    \"checkpoint_interval\": 10,\n    \"save_best_only\": true,\n    \"checkpoint_dir\": \"models/checkpoints\"\n  },\n  \"logging\": {\n    \"log_interval\": 10,\n    \"log_dir\": \"logs/\",\n    \"tensorboard\": true,\n    \"tensorboard_log_dir\": \"logs/tensorboard_logs\",\n    \"model_save_path\": \"models/saved_models\"\n  },\n  \"advanced_training_techniques\": {\n    \"gradient_clipping\": 0.5,\n    \"use_gae\": true,\n    \"gae_lambda\": 0.95,\n    \"normalize_advantages\": true\n  },\n  \"early_stopping\": {\n    \"patience\": 10\n  },\n  \"reward_adjustments\": {\n    \"collision_penalty\": 50,\n    \"reward_threshold\": 250\n  },\n  \"shared_components\": {\n    \"residual_block\": {\n      \"input_dim\": 128,\n      \"hidden_dim\": 128,\n      \"dropout_rate\": 0.2\n    },\n    \"attention_layer\": {\n      \"input_dim\": 128,\n      \"hidden_dim\": 128\n    }\n  },\n  \"icm\": {\n    \"state_dim\": 16,\n    \"action_dim\": 4,\n    \"image_channels\": 3,\n    \"image_height\": 144,\n    \"image_width\": 256,\n    \"cnn\": {\n      \"input_channels\": 3,\n      \"conv1\": {\n        \"out_channels\": 32,\n        \"kernel_size\": 8,\n        \"stride\": 4,\n        \"padding\": 0\n      },\n      \"conv2\": {\n        \"out_channels\": 64,\n        \"kernel_size\": 4,\n        \"stride\": 2,\n        \"padding\": 0\n      },\n      \"conv3\": {\n        \"out_channels\": 64,\n        \"kernel_size\": 3,\n        \"stride\": 1,\n        \"padding\": 0\n      }\n    },\n    \"state_encoder\": {\n      \"hidden_dim\": 128\n    },\n    \"forward_model\": {\n      \"hidden_dim\": 256\n    },\n    \"inverse_model\": {\n      \"hidden_dim\": 256\n    }\n  },\n  \"predictive_model\": {\n    \"learning_rate\": 0.0001,\n    \"hidden_layers\": [\n      256,\n      256\n    ],\n    \"cnn_config\": {\n      \"input_channels\": 3,\n      \"image_height\": 144,\n      \"image_width\": 256,\n      \"conv1\": {\n        \"out_channels\": 32,\n        \"kernel_size\": 8,\n        \"stride\": 4,\n        \"padding\": 0\n      },\n      \"conv2\": {\n        \"out_channels\": 64,\n        \"kernel_size\": 4,\n        \"stride\": 2,\n        \"padding\": 0\n      },\n      \"conv3\": {\n        \"out_channels\": 64,\n        \"kernel_size\": 3,\n        \"stride\": 1,\n        \"padding\": 0\n      }\n    }\n  },\n  \"hrl\": {\n    \"use_hierarchical\": true,\n    \"high_level_policy\": {\n      \"input_size\": 16,\n      \"hidden_layers\": [\n        256,\n        256\n      ],\n      \"output_size\": 4\n    },\n    \"sub_goal_dim\": 3,\n    \"low_level_policy\": {\n      \"input_size\": 19,\n      \"hidden_layers\": [\n        256,\n        256\n      ],\n      \"output_size\": 4\n    }\n  },\n  \"curriculum_learning\": {\n    \"use_curriculum\": true,\n    \"initial_difficulty\": 1,\n    \"difficulty_increment\": 1,\n    \"difficulty_threshold\": 200\n  },\n  \"multi_agent\": {\n    \"use_multi_agent\": true,\n    \"num_agents\": 2,\n    \"hidden_layers\": [\n      256,\n      256\n    ]\n  }\n}"}
{"time": "2024-07-21T15:25:39.244942", "name": "AirSimEnvLogger", "level": "INFO", "message": "DataVisualizer initialized with Seaborn style set to 'whitegrid'."}
{"time": "2024-07-21T15:25:39.245941", "name": "AirSimEnvLogger", "level": "INFO", "message": "Using device: cpu"}
{"time": "2024-07-21T15:25:43.648926", "name": "AirSimEnvLogger", "level": "ERROR", "message": "An error occurred in main: __init__() takes 2 positional arguments but 4 were given"}
{"time": "2024-07-21T15:25:44.386618", "name": "AirSimEnvLogger", "level": "INFO", "message": "Environment closed."}
{"time": "2024-07-21T15:25:44.450550", "name": "AirSimEnvLogger", "level": "INFO", "message": "Training script execution finished."}
{"time": "2024-07-21T15:28:52.831257", "name": "AirSimEnvLogger", "level": "INFO", "message": "Initialized with state_dim: 16, action_dim: 4"}
{"time": "2024-07-21T15:28:52.858330", "name": "AirSimEnvLogger", "level": "INFO", "message": "Initializing AirSimEnv"}
{"time": "2024-07-21T15:28:52.858870", "name": "AirSimEnvLogger", "level": "INFO", "message": "Configuration: {\n  \"learning_rate\": 0.0001,\n  \"gamma\": 0.99,\n  \"tau\": 0.95,\n  \"batch_size\": 64,\n  \"num_timesteps\": 2000000,\n  \"ppo\": {\n    \"learning_rate\": 0.0003,\n    \"n_steps\": 2048,\n    \"batch_size\": 64,\n    \"n_epochs\": 2000,\n    \"gamma\": 0.99,\n    \"gae_lambda\": 0.95,\n    \"clip_range\": 0.3,\n    \"ent_coef\": 0.02,\n    \"vf_coef\": 0.5,\n    \"max_grad_norm\": 0.5,\n    \"use_sde\": true,\n    \"sde_sample_freq\": 4,\n    \"tensorboard_log\": \"logs/tensorboard_logs/ppo_airsim_tensorboard/\",\n    \"verbose\": 1,\n    \"seed\": null,\n    \"device\": \"auto\",\n    \"continuous\": true,\n    \"save_freq\": 10000\n  },\n  \"environment\": {\n    \"env_name\": \"Africa_001\",\n    \"reward_threshold\": 250,\n    \"max_episode_steps\": 1000,\n    \"state_dim\": 16,\n    \"action_dim\": 4,\n    \"reward_scale\": 20,\n    \"proximity_threshold\": 5.0,\n    \"collision_penalty\": 25,\n    \"height_target\": -10,\n    \"height_tolerance\": 1.0,\n    \"height_penalty\": 1,\n    \"movement_penalty\": 0.1,\n    \"smoothness_penalty\": 0.1,\n    \"duration\": 0.1,\n    \"exploration_area\": {\n      \"x_min\": -2000,\n      \"x_max\": 2000,\n      \"y_min\": -2000,\n      \"y_max\": 2000,\n      \"z_min\": -200,\n      \"z_max\": 200\n    }\n  },\n  \"policy_network\": {\n    \"input_size\": 16,\n    \"hidden_layers\": [\n      256,\n      256,\n      256\n    ],\n    \"output_size\": 4,\n    \"use_batch_norm\": true,\n    \"use_dropout\": true,\n    \"dropout_rate\": 0.2,\n    \"use_attention\": false,\n    \"num_action_heads\": 1\n  },\n  \"critic_network\": {\n    \"input_size\": 16,\n    \"hidden_layers\": [\n      256,\n      256\n    ],\n    \"output_size\": 1,\n    \"use_batch_norm\": true,\n    \"use_dropout\": true,\n    \"dropout_rate\": 0.2,\n    \"use_attention\": true\n  },\n  \"exploration\": {\n    \"strategy\": \"epsilon_decay\",\n    \"initial_epsilon\": 1.0,\n    \"min_epsilon\": 0.05,\n    \"epsilon_decay_rate\": 0.9995\n  },\n  \"model_checkpointing\": {\n    \"checkpoint_interval\": 10,\n    \"save_best_only\": true,\n    \"checkpoint_dir\": \"models/checkpoints\"\n  },\n  \"logging\": {\n    \"log_interval\": 10,\n    \"log_dir\": \"logs/\",\n    \"tensorboard\": true,\n    \"tensorboard_log_dir\": \"logs/tensorboard_logs\",\n    \"model_save_path\": \"models/saved_models\"\n  },\n  \"advanced_training_techniques\": {\n    \"gradient_clipping\": 0.5,\n    \"use_gae\": true,\n    \"gae_lambda\": 0.95,\n    \"normalize_advantages\": true\n  },\n  \"early_stopping\": {\n    \"patience\": 10\n  },\n  \"reward_adjustments\": {\n    \"collision_penalty\": 50,\n    \"reward_threshold\": 250\n  },\n  \"shared_components\": {\n    \"residual_block\": {\n      \"input_dim\": 128,\n      \"hidden_dim\": 128,\n      \"dropout_rate\": 0.2\n    },\n    \"attention_layer\": {\n      \"input_dim\": 128,\n      \"hidden_dim\": 128\n    }\n  },\n  \"icm\": {\n    \"state_dim\": 16,\n    \"action_dim\": 4,\n    \"image_channels\": 3,\n    \"image_height\": 144,\n    \"image_width\": 256,\n    \"cnn\": {\n      \"input_channels\": 3,\n      \"conv1\": {\n        \"out_channels\": 32,\n        \"kernel_size\": 8,\n        \"stride\": 4,\n        \"padding\": 0\n      },\n      \"conv2\": {\n        \"out_channels\": 64,\n        \"kernel_size\": 4,\n        \"stride\": 2,\n        \"padding\": 0\n      },\n      \"conv3\": {\n        \"out_channels\": 64,\n        \"kernel_size\": 3,\n        \"stride\": 1,\n        \"padding\": 0\n      }\n    },\n    \"state_encoder\": {\n      \"hidden_dim\": 128\n    },\n    \"forward_model\": {\n      \"hidden_dim\": 256\n    },\n    \"inverse_model\": {\n      \"hidden_dim\": 256\n    }\n  },\n  \"predictive_model\": {\n    \"learning_rate\": 0.0001,\n    \"hidden_layers\": [\n      256,\n      256\n    ],\n    \"cnn_config\": {\n      \"input_channels\": 3,\n      \"image_height\": 144,\n      \"image_width\": 256,\n      \"conv1\": {\n        \"out_channels\": 32,\n        \"kernel_size\": 8,\n        \"stride\": 4,\n        \"padding\": 0\n      },\n      \"conv2\": {\n        \"out_channels\": 64,\n        \"kernel_size\": 4,\n        \"stride\": 2,\n        \"padding\": 0\n      },\n      \"conv3\": {\n        \"out_channels\": 64,\n        \"kernel_size\": 3,\n        \"stride\": 1,\n        \"padding\": 0\n      }\n    }\n  },\n  \"hrl\": {\n    \"use_hierarchical\": true,\n    \"high_level_policy\": {\n      \"input_size\": 16,\n      \"hidden_layers\": [\n        256,\n        256\n      ],\n      \"output_size\": 4\n    },\n    \"sub_goal_dim\": 3,\n    \"low_level_policy\": {\n      \"input_size\": 19,\n      \"hidden_layers\": [\n        256,\n        256\n      ],\n      \"output_size\": 4\n    }\n  },\n  \"curriculum_learning\": {\n    \"use_curriculum\": true,\n    \"initial_difficulty\": 1,\n    \"max_difficulty\": 10,\n    \"difficulty_increment\": 0.5,\n    \"reward_threshold\": 50\n  },\n  \"multi_agent\": {\n    \"use_multi_agent\": true,\n    \"num_agents\": 2,\n    \"hidden_layers\": [\n      256,\n      256\n    ]\n  }\n}"}
{"time": "2024-07-21T15:28:54.388439", "name": "AirSimEnvLogger", "level": "INFO", "message": "DataVisualizer initialized with Seaborn style set to 'whitegrid'."}
{"time": "2024-07-21T15:28:54.388439", "name": "AirSimEnvLogger", "level": "INFO", "message": "Using device: cpu"}
{"time": "2024-07-21T15:29:00.044360", "name": "AirSimEnvLogger", "level": "INFO", "message": "PPOAgent initialized successfully."}
{"time": "2024-07-21T15:29:05.030011", "name": "AirSimEnvLogger", "level": "INFO", "message": "Environment reset and takeoff completed."}
{"time": "2024-07-21T15:29:05.656138", "name": "AirSimEnvLogger", "level": "INFO", "message": "Reset completed. Observation keys: dict_keys(['state', 'visual'])"}
{"time": "2024-07-21T15:29:05.656138", "name": "AirSimEnvLogger", "level": "INFO", "message": "State shape: (16,), Visual shape: (144, 256, 3)"}
{"time": "2024-07-21T15:29:11.671248", "name": "AirSimEnvLogger", "level": "INFO", "message": "Reward breakdown - Distance: -9.614561102824306, Velocity: -0.17204010711519885, Movement: 0.43252655286410635, Collision: 0, Height: -1.0, Movement Penalty: -0.09988772869110107, Smoothness: -0.0, Curiosity: 1.3084137439727783, Exploration: 0, Total: -8.812741516507623"}
{"time": "2024-07-21T15:29:11.813168", "name": "AirSimEnvLogger", "level": "INFO", "message": "Action: [-0.49943864 -0.49943864 -0.49943864 -0.49943864], Velocity: (-0.49943864345550537, -0.49943864345550537, -0.49943864345550537), Duration: 1.0, Reward: -8.812741516507623, Done: False"}
{"time": "2024-07-21T15:29:11.874193", "name": "AirSimEnvLogger", "level": "INFO", "message": "Step completed. Observation keys: dict_keys(['state', 'visual'])"}
{"time": "2024-07-21T15:29:11.874193", "name": "AirSimEnvLogger", "level": "INFO", "message": "State shape: (16,), Visual shape: (144, 256, 3)"}
{"time": "2024-07-21T15:29:15.361902", "name": "AirSimEnvLogger", "level": "INFO", "message": "Predictive model loss: 0.025348786264657974"}
{"time": "2024-07-21T15:29:20.995765", "name": "AirSimEnvLogger", "level": "INFO", "message": "Reward breakdown - Distance: -10.09595598087787, Velocity: -0.031859382348853646, Movement: 0.172019898283861, Collision: 0, Height: -1.0, Movement Penalty: -0.03972629383206368, Smoothness: -0.0, Curiosity: 0.35525965690612793, Exploration: 0.8214963628684021, Total: -10.050718459903187"}
{"time": "2024-07-21T15:29:21.151343", "name": "AirSimEnvLogger", "level": "INFO", "message": "Action: [-0.19863147 -0.19863147 -0.19863147 -0.19863147], Velocity: (-0.19863146916031837, -0.19863146916031837, -0.19863146916031837), Duration: 1.0, Reward: -10.050718459903187, Done: False"}
{"time": "2024-07-21T15:29:21.230906", "name": "AirSimEnvLogger", "level": "INFO", "message": "Step completed. Observation keys: dict_keys(['state', 'visual'])"}
{"time": "2024-07-21T15:29:21.230906", "name": "AirSimEnvLogger", "level": "INFO", "message": "State shape: (16,), Visual shape: (144, 256, 3)"}
{"time": "2024-07-21T15:29:24.071786", "name": "AirSimEnvLogger", "level": "INFO", "message": "Predictive model loss: 0.0093222726136446"}
{"time": "2024-07-21T15:29:29.864637", "name": "AirSimEnvLogger", "level": "INFO", "message": "Reward breakdown - Distance: -10.543088378539114, Velocity: -0.04395662180476603, Movement: 0.5055195494825352, Collision: 0, Height: -1.0, Movement Penalty: -0.116744739189744, Smoothness: -0.0, Curiosity: 2.5467934608459473, Exploration: 0.31949596881469305, Total: -8.41480613971358"}
{"time": "2024-07-21T15:29:29.880721", "name": "AirSimEnvLogger", "level": "INFO", "message": "Action: [-0.5837237 -0.5837237 -0.5837237 -0.5837237], Velocity: (-0.58372369594872, -0.58372369594872, -0.58372369594872), Duration: 1.0, Reward: -8.41480613971358, Done: False"}
{"time": "2024-07-21T15:29:29.958813", "name": "AirSimEnvLogger", "level": "INFO", "message": "Step completed. Observation keys: dict_keys(['state', 'visual'])"}
{"time": "2024-07-21T15:29:29.958813", "name": "AirSimEnvLogger", "level": "INFO", "message": "State shape: (16,), Visual shape: (144, 256, 3)"}
{"time": "2024-07-21T15:29:32.802395", "name": "AirSimEnvLogger", "level": "INFO", "message": "Predictive model loss: 0.06253871321678162"}
{"time": "2024-07-21T15:29:38.620866", "name": "AirSimEnvLogger", "level": "INFO", "message": "Reward breakdown - Distance: -10.445492714002768, Velocity: -0.056614282887171095, Movement: 0.31914719788897994, Collision: 0, Height: -1.0, Movement Penalty: -0.07370388824492694, Smoothness: -0.0, Curiosity: 1.7457008361816406, Exploration: 0.20451702925259277, Total: -9.150585725799754"}
{"time": "2024-07-21T15:29:38.715220", "name": "AirSimEnvLogger", "level": "INFO", "message": "Action: [-0.36851944 -0.36851944 -0.36851944 -0.36851944], Velocity: (-0.36851944122463465, -0.36851944122463465, -0.36851944122463465), Duration: 1.0, Reward: -9.150585725799754, Done: False"}
{"time": "2024-07-21T15:29:38.824207", "name": "AirSimEnvLogger", "level": "INFO", "message": "Step completed. Observation keys: dict_keys(['state', 'visual'])"}
{"time": "2024-07-21T15:29:38.824207", "name": "AirSimEnvLogger", "level": "INFO", "message": "State shape: (16,), Visual shape: (144, 256, 3)"}
{"time": "2024-07-21T15:29:41.454283", "name": "AirSimEnvLogger", "level": "INFO", "message": "Predictive model loss: 0.06001318246126175"}
{"time": "2024-07-21T15:29:47.760510", "name": "AirSimEnvLogger", "level": "INFO", "message": "Reward breakdown - Distance: -9.965104107547987, Velocity: -0.023583893375421803, Movement: 0.13292933551547936, Collision: 0, Height: -1.0, Movement Penalty: -0.030698715057224036, Smoothness: -0.0, Curiosity: 0.49454012513160706, Exploration: 0.1996930112599288, Total: -9.923732229720583"}
{"time": "2024-07-21T15:29:47.914183", "name": "AirSimEnvLogger", "level": "INFO", "message": "Action: [0.15349358 0.15349358 0.15349358 0.15349358], Velocity: (0.15349357528612018, 0.15349357528612018, 0.15349357528612018), Duration: 1.0, Reward: -9.923732229720583, Done: False"}
{"time": "2024-07-21T15:29:48.008576", "name": "AirSimEnvLogger", "level": "INFO", "message": "Step completed. Observation keys: dict_keys(['state', 'visual'])"}
{"time": "2024-07-21T15:29:48.008576", "name": "AirSimEnvLogger", "level": "INFO", "message": "State shape: (16,), Visual shape: (144, 256, 3)"}
{"time": "2024-07-21T15:29:50.932987", "name": "AirSimEnvLogger", "level": "INFO", "message": "Predictive model loss: 0.015042601153254509"}
{"time": "2024-07-21T15:29:56.777376", "name": "AirSimEnvLogger", "level": "INFO", "message": "Reward breakdown - Distance: -9.734351846264337, Velocity: -0.039197440587441054, Movement: 0.2816095123579682, Collision: 0, Height: -1.0, Movement Penalty: -0.06503493110649287, Smoothness: -0.0, Curiosity: 0.6387184858322144, Exploration: 0.2868347350637472, Total: -9.526673249249335"}
{"time": "2024-07-21T15:29:56.871069", "name": "AirSimEnvLogger", "level": "INFO", "message": "Action: [0.32517466 0.32517466 0.32517466 0.32517466], Velocity: (0.3251746555324644, 0.3251746555324644, 0.3251746555324644), Duration: 1.0, Reward: -9.526673249249335, Done: False"}
{"time": "2024-07-21T15:29:56.933834", "name": "AirSimEnvLogger", "level": "INFO", "message": "Step completed. Observation keys: dict_keys(['state', 'visual'])"}
{"time": "2024-07-21T15:29:56.933834", "name": "AirSimEnvLogger", "level": "INFO", "message": "State shape: (16,), Visual shape: (144, 256, 3)"}
{"time": "2024-07-21T15:29:59.753438", "name": "AirSimEnvLogger", "level": "INFO", "message": "Predictive model loss: 0.008507788181304932"}
{"time": "2024-07-21T15:30:05.943774", "name": "AirSimEnvLogger", "level": "INFO", "message": "Reward breakdown - Distance: -9.41734830386744, Velocity: -0.08504731025089685, Movement: 0.5722110963510545, Collision: 0, Height: -1.0, Movement Penalty: -0.1321464922046289, Smoothness: -0.0, Curiosity: 2.168203115463257, Exploration: 0.2863198516194808, Total: -7.6777600461699596"}
{"time": "2024-07-21T15:30:06.054686", "name": "AirSimEnvLogger", "level": "INFO", "message": "Action: [0.66073246 0.66073246 0.66073246 0.66073246], Velocity: (0.6607324610231444, 0.6607324610231444, 0.6607324610231444), Duration: 1.0, Reward: -7.6777600461699596, Done: False"}
{"time": "2024-07-21T15:30:06.132781", "name": "AirSimEnvLogger", "level": "INFO", "message": "Step completed. Observation keys: dict_keys(['state', 'visual'])"}
{"time": "2024-07-21T15:30:06.132781", "name": "AirSimEnvLogger", "level": "INFO", "message": "State shape: (16,), Visual shape: (144, 256, 3)"}
{"time": "2024-07-21T15:30:08.998725", "name": "AirSimEnvLogger", "level": "INFO", "message": "Predictive model loss: 0.0352761335670948"}
{"time": "2024-07-21T15:30:14.975970", "name": "AirSimEnvLogger", "level": "INFO", "message": "Reward breakdown - Distance: -9.633585845248902, Velocity: -0.05070123260554181, Movement: 0.28256172830165366, Collision: 0, Height: -1.0, Movement Penalty: -0.06525483595905826, Smoothness: -0.0, Curiosity: 0.6191284656524658, Exploration: 0.15202173206676414, Total: -9.477631280498931"}
{"time": "2024-07-21T15:30:15.101956", "name": "AirSimEnvLogger", "level": "INFO", "message": "Action: [0.32627418 0.32627418 0.32627418 0.32627418], Velocity: (0.3262741797952913, 0.3262741797952913, 0.3262741797952913), Duration: 1.0, Reward: -9.477631280498931, Done: False"}
{"time": "2024-07-21T15:30:15.164838", "name": "AirSimEnvLogger", "level": "INFO", "message": "Step completed. Observation keys: dict_keys(['state', 'visual'])"}
{"time": "2024-07-21T15:30:15.164838", "name": "AirSimEnvLogger", "level": "INFO", "message": "State shape: (16,), Visual shape: (144, 256, 3)"}
{"time": "2024-07-21T15:30:18.240408", "name": "AirSimEnvLogger", "level": "INFO", "message": "Predictive model loss: 0.019899848848581314"}
{"time": "2024-07-21T15:30:24.039836", "name": "AirSimEnvLogger", "level": "INFO", "message": "Reward breakdown - Distance: -10.230179915803276, Velocity: -0.028412664816001222, Movement: 0.2898189099692195, Collision: 0, Height: -1.0, Movement Penalty: -0.06693081027478912, Smoothness: -0.0, Curiosity: 0.6889470219612122, Exploration: 0.3037390916654122, Total: -9.967104926982325"}
{"time": "2024-07-21T15:30:24.133937", "name": "AirSimEnvLogger", "level": "INFO", "message": "Action: [-0.33465405 -0.33465405 -0.33465405 -0.33465405], Velocity: (-0.33465405137394555, -0.33465405137394555, -0.33465405137394555), Duration: 1.0, Reward: -9.967104926982325, Done: False"}
{"time": "2024-07-21T15:30:24.197642", "name": "AirSimEnvLogger", "level": "INFO", "message": "Step completed. Observation keys: dict_keys(['state', 'visual'])"}
{"time": "2024-07-21T15:30:24.197642", "name": "AirSimEnvLogger", "level": "INFO", "message": "State shape: (16,), Visual shape: (144, 256, 3)"}
{"time": "2024-07-21T15:30:26.922637", "name": "AirSimEnvLogger", "level": "INFO", "message": "Predictive model loss: 0.006392229348421097"}
{"time": "2024-07-21T15:30:32.915688", "name": "AirSimEnvLogger", "level": "INFO", "message": "Reward breakdown - Distance: -10.427636607264208, Velocity: -0.06653714220041684, Movement: 0.3827301991316984, Collision: 0, Height: -1.0, Movement Penalty: -0.08838775339827408, Smoothness: -0.0, Curiosity: 1.4803942441940308, Exploration: 0.35054334085511396, Total: -9.36388275771424"}
{"time": "2024-07-21T15:30:33.055098", "name": "AirSimEnvLogger", "level": "INFO", "message": "Action: [-0.44193877 -0.44193877 -0.44193877 -0.44193877], Velocity: (-0.44193876699137036, -0.44193876699137036, -0.44193876699137036), Duration: 1.0, Reward: -9.36388275771424, Done: False"}
{"time": "2024-07-21T15:30:33.118666", "name": "AirSimEnvLogger", "level": "INFO", "message": "Step completed. Observation keys: dict_keys(['state', 'visual'])"}
{"time": "2024-07-21T15:30:33.118666", "name": "AirSimEnvLogger", "level": "INFO", "message": "State shape: (16,), Visual shape: (144, 256, 3)"}
{"time": "2024-07-21T15:30:36.104006", "name": "AirSimEnvLogger", "level": "INFO", "message": "Predictive model loss: 0.026096640154719353"}
{"time": "2024-07-21T15:30:41.974405", "name": "AirSimEnvLogger", "level": "INFO", "message": "Reward breakdown - Distance: -10.718495184924288, Velocity: -0.051860624311785376, Movement: 0.6018784651678085, Collision: 0, Height: -1.0, Movement Penalty: -0.13899787755362922, Smoothness: -0.0, Curiosity: 3.928715229034424, Exploration: 0.283468990541664, Total: -7.215004104149782"}
{"time": "2024-07-21T15:30:42.099668", "name": "AirSimEnvLogger", "level": "INFO", "message": "Action: [-0.69498939 -0.69498939 -0.69498939 -0.69498939], Velocity: (-0.6949893877681461, -0.6949893877681461, -0.6949893877681461), Duration: 1.0, Reward: -7.215004104149782, Done: False"}
{"time": "2024-07-21T15:30:42.178367", "name": "AirSimEnvLogger", "level": "INFO", "message": "Step completed. Observation keys: dict_keys(['state', 'visual'])"}
{"time": "2024-07-21T15:30:42.178367", "name": "AirSimEnvLogger", "level": "INFO", "message": "State shape: (16,), Visual shape: (144, 256, 3)"}
{"time": "2024-07-21T15:30:45.035505", "name": "AirSimEnvLogger", "level": "INFO", "message": "Predictive model loss: 0.09066463261842728"}
{"time": "2024-07-21T15:30:51.088650", "name": "AirSimEnvLogger", "level": "INFO", "message": "Reward breakdown - Distance: -10.591789590965142, Velocity: -0.07682168785255002, Movement: 0.40504462976746264, Collision: 0, Height: -1.0, Movement Penalty: -0.09354105041202275, Smoothness: -0.0, Curiosity: 2.9765429496765137, Exploration: 0.19580740697178026, Total: -8.06795738350894"}
{"time": "2024-07-21T15:30:51.167648", "name": "AirSimEnvLogger", "level": "INFO", "message": "Action: [-0.46770525 -0.46770525 -0.46770525 -0.46770525], Velocity: (-0.4677052520601137, -0.4677052520601137, -0.4677052520601137), Duration: 1.0, Reward: -8.06795738350894, Done: False"}
{"time": "2024-07-21T15:30:51.230333", "name": "AirSimEnvLogger", "level": "INFO", "message": "Step completed. Observation keys: dict_keys(['state', 'visual'])"}
{"time": "2024-07-21T15:30:51.230333", "name": "AirSimEnvLogger", "level": "INFO", "message": "State shape: (16,), Visual shape: (144, 256, 3)"}
{"time": "2024-07-21T15:30:54.277219", "name": "AirSimEnvLogger", "level": "INFO", "message": "Predictive model loss: 0.08942160755395889"}
{"time": "2024-07-21T15:31:00.131903", "name": "AirSimEnvLogger", "level": "INFO", "message": "Reward breakdown - Distance: -10.359171462692844, Velocity: -0.0333073886754857, Movement: 0.19166784607429332, Collision: 0, Height: -1.0, Movement Penalty: -0.044263793010395604, Smoothness: -0.0, Curiosity: 2.013113021850586, Exploration: 0.1159656159085534, Total: -8.818015486105635"}
{"time": "2024-07-21T15:31:00.240012", "name": "AirSimEnvLogger", "level": "INFO", "message": "Action: [-0.22131897 -0.22131897 -0.22131897 -0.22131897], Velocity: (-0.221318965051978, -0.221318965051978, -0.221318965051978), Duration: 1.0, Reward: -8.818015486105635, Done: False"}
{"time": "2024-07-21T15:31:00.302283", "name": "AirSimEnvLogger", "level": "INFO", "message": "Step completed. Observation keys: dict_keys(['state', 'visual'])"}
{"time": "2024-07-21T15:31:00.302283", "name": "AirSimEnvLogger", "level": "INFO", "message": "State shape: (16,), Visual shape: (144, 256, 3)"}
{"time": "2024-07-21T15:31:03.111315", "name": "AirSimEnvLogger", "level": "INFO", "message": "Predictive model loss: 0.06683352589607239"}
{"time": "2024-07-21T15:31:08.937371", "name": "AirSimEnvLogger", "level": "INFO", "message": "Reward breakdown - Distance: -10.718165560861038, Velocity: -0.10198687916427925, Movement: 0.5288375399613315, Collision: 0, Height: -1.0, Movement Penalty: -0.12212979842170171, Smoothness: -0.0, Curiosity: 5.364080429077148, Exploration: 0.16083729353692058, Total: -5.814318885803092"}
{"time": "2024-07-21T15:31:09.014315", "name": "AirSimEnvLogger", "level": "INFO", "message": "Action: [-0.61064899 -0.61064899 -0.61064899 -0.61064899], Velocity: (-0.6106489921085085, -0.6106489921085085, -0.6106489921085085), Duration: 1.0, Reward: -5.814318885803092, Done: False"}
{"time": "2024-07-21T15:31:09.077588", "name": "AirSimEnvLogger", "level": "INFO", "message": "Step completed. Observation keys: dict_keys(['state', 'visual'])"}
{"time": "2024-07-21T15:31:09.077588", "name": "AirSimEnvLogger", "level": "INFO", "message": "State shape: (16,), Visual shape: (144, 256, 3)"}
{"time": "2024-07-21T15:31:11.835584", "name": "AirSimEnvLogger", "level": "INFO", "message": "Predictive model loss: 0.1640063375234604"}
{"time": "2024-07-21T15:31:17.939703", "name": "AirSimEnvLogger", "level": "INFO", "message": "Reward breakdown - Distance: -10.133665583643483, Velocity: -0.011597582462700698, Movement: 0.06741513329434626, Collision: 0, Height: -1.0, Movement Penalty: -0.015568858141978127, Smoothness: -0.0, Curiosity: 2.0217602252960205, Exploration: 0.08065090177106472, Total: -8.592861719596169"}
{"time": "2024-07-21T15:31:18.049139", "name": "AirSimEnvLogger", "level": "INFO", "message": "Action: [0.07784429 0.07784429 0.07784429 0.07784429], Velocity: (0.07784429070989063, 0.07784429070989063, 0.07784429070989063), Duration: 1.0, Reward: -8.592861719596169, Done: False"}
{"time": "2024-07-21T15:31:18.112158", "name": "AirSimEnvLogger", "level": "INFO", "message": "Step completed. Observation keys: dict_keys(['state', 'visual'])"}
{"time": "2024-07-21T15:31:18.112158", "name": "AirSimEnvLogger", "level": "INFO", "message": "State shape: (16,), Visual shape: (144, 256, 3)"}
{"time": "2024-07-21T15:31:20.965187", "name": "AirSimEnvLogger", "level": "INFO", "message": "Predictive model loss: 0.05900371074676514"}
{"time": "2024-07-21T15:31:27.134721", "name": "AirSimEnvLogger", "level": "INFO", "message": "Reward breakdown - Distance: -9.628781140390766, Velocity: -0.07014283172988799, Movement: 0.4433862766205411, Collision: 0, Height: -1.0, Movement Penalty: -0.10239567446474213, Smoothness: -0.0, Curiosity: 2.0288023948669434, Exploration: 0.420730734986058, Total: -7.999348718155512"}
{"time": "2024-07-21T15:31:27.230509", "name": "AirSimEnvLogger", "level": "INFO", "message": "Action: [0.51197837 0.51197837 0.51197837 0.51197837], Velocity: (0.5119783723237106, 0.5119783723237106, 0.5119783723237106), Duration: 1.0, Reward: -7.999348718155512, Done: False"}
{"time": "2024-07-21T15:31:27.291896", "name": "AirSimEnvLogger", "level": "INFO", "message": "Step completed. Observation keys: dict_keys(['state', 'visual'])"}
{"time": "2024-07-21T15:31:27.291896", "name": "AirSimEnvLogger", "level": "INFO", "message": "State shape: (16,), Visual shape: (144, 256, 3)"}
{"time": "2024-07-21T15:31:30.188674", "name": "AirSimEnvLogger", "level": "INFO", "message": "Predictive model loss: 0.01884705200791359"}
{"time": "2024-07-21T15:31:36.101393", "name": "AirSimEnvLogger", "level": "INFO", "message": "Reward breakdown - Distance: -10.233294417545078, Velocity: -0.03481325820519606, Movement: 0.20491151235037353, Collision: 0, Height: -1.0, Movement Penalty: -0.04732228672621659, Smoothness: -0.0, Curiosity: 2.351763963699341, Exploration: 0.037213424860465485, Total: -8.371426223582406"}
{"time": "2024-07-21T15:31:36.211418", "name": "AirSimEnvLogger", "level": "INFO", "message": "Action: [-0.23661143 -0.23661143 -0.23661143 -0.23661143], Velocity: (-0.23661143363108295, -0.23661143363108295, -0.23661143363108295), Duration: 1.0, Reward: -8.371426223582406, Done: False"}
{"time": "2024-07-21T15:31:36.304960", "name": "AirSimEnvLogger", "level": "INFO", "message": "Step completed. Observation keys: dict_keys(['state', 'visual'])"}
{"time": "2024-07-21T15:31:36.304960", "name": "AirSimEnvLogger", "level": "INFO", "message": "State shape: (16,), Visual shape: (144, 256, 3)"}
{"time": "2024-07-21T15:31:39.109241", "name": "AirSimEnvLogger", "level": "INFO", "message": "Predictive model loss: 0.04590431600809097"}
{"time": "2024-07-21T15:31:45.048260", "name": "AirSimEnvLogger", "level": "INFO", "message": "Reward breakdown - Distance: -10.471190853209238, Velocity: -0.06139418065103781, Movement: 0.3210448876623169, Collision: 0, Height: -1.0, Movement Penalty: -0.07414214092551674, Smoothness: -0.0, Curiosity: 3.6751229763031006, Exploration: 0.3405934902000527, Total: -7.215995578415264"}
{"time": "2024-07-21T15:31:45.157563", "name": "AirSimEnvLogger", "level": "INFO", "message": "Action: [-0.3707107 -0.3707107 -0.3707107 -0.3707107], Velocity: (-0.3707107046275837, -0.3707107046275837, -0.3707107046275837), Duration: 1.0, Reward: -7.215995578415264, Done: False"}
{"time": "2024-07-21T15:31:45.204638", "name": "AirSimEnvLogger", "level": "INFO", "message": "Step completed. Observation keys: dict_keys(['state', 'visual'])"}
{"time": "2024-07-21T15:31:45.204638", "name": "AirSimEnvLogger", "level": "INFO", "message": "State shape: (16,), Visual shape: (144, 256, 3)"}
{"time": "2024-07-21T15:31:48.115852", "name": "AirSimEnvLogger", "level": "INFO", "message": "Predictive model loss: 0.07253023982048035"}
{"time": "2024-07-21T15:31:53.943560", "name": "AirSimEnvLogger", "level": "INFO", "message": "Reward breakdown - Distance: -10.236677462290691, Velocity: -0.009131293795834964, Movement: 0.05578784163490582, Collision: 0, Height: -1.0, Movement Penalty: -0.012883650154168437, Smoothness: -0.0, Curiosity: 2.523552179336548, Exploration: 0.03992770019046863, Total: -8.203486568538118"}
{"time": "2024-07-21T15:31:54.084810", "name": "AirSimEnvLogger", "level": "INFO", "message": "Action: [-0.06441825 -0.06441825 -0.06441825 -0.06441825], Velocity: (-0.06441825077084218, -0.06441825077084218, -0.06441825077084218), Duration: 1.0, Reward: -8.203486568538118, Done: False"}
{"time": "2024-07-21T15:31:54.148128", "name": "AirSimEnvLogger", "level": "INFO", "message": "Step completed. Observation keys: dict_keys(['state', 'visual'])"}
{"time": "2024-07-21T15:31:54.148128", "name": "AirSimEnvLogger", "level": "INFO", "message": "State shape: (16,), Visual shape: (144, 256, 3)"}
{"time": "2024-07-21T15:31:57.057820", "name": "AirSimEnvLogger", "level": "INFO", "message": "Predictive model loss: 0.03453578054904938"}
{"time": "2024-07-21T15:32:02.837100", "name": "AirSimEnvLogger", "level": "INFO", "message": "Reward breakdown - Distance: -9.696362511390001, Velocity: -0.07142676156463436, Movement: 0.399646636408143, Collision: 0, Height: -1.0, Movement Penalty: -0.09229443724438796, Smoothness: -0.0, Curiosity: 2.048673629760742, Exploration: 0.3002641364503965, Total: -8.075967495927186"}
{"time": "2024-07-21T15:32:02.917004", "name": "AirSimEnvLogger", "level": "INFO", "message": "Action: [0.46147219 0.46147219 0.46147219 0.46147219], Velocity: (0.46147218622193975, 0.46147218622193975, 0.46147218622193975), Duration: 1.0, Reward: -8.075967495927186, Done: False"}
{"time": "2024-07-21T15:32:02.964164", "name": "AirSimEnvLogger", "level": "INFO", "message": "Step completed. Observation keys: dict_keys(['state', 'visual'])"}
{"time": "2024-07-21T15:32:02.964164", "name": "AirSimEnvLogger", "level": "INFO", "message": "State shape: (16,), Visual shape: (144, 256, 3)"}
{"time": "2024-07-21T15:32:05.834292", "name": "AirSimEnvLogger", "level": "INFO", "message": "Predictive model loss: 0.013038602657616138"}
{"time": "2024-07-21T15:32:11.879511", "name": "AirSimEnvLogger", "level": "INFO", "message": "Reward breakdown - Distance: -9.3572623042127, Velocity: -0.06857666790060668, Movement: 0.6328034226115539, Collision: 0, Height: -1.0, Movement Penalty: -0.14613969055555884, Smoothness: -0.0, Curiosity: 2.8574273586273193, Exploration: 0.39599839843905177, Total: -6.900090346846621"}
{"time": "2024-07-21T15:32:11.989540", "name": "AirSimEnvLogger", "level": "INFO", "message": "Action: [0.73069845 0.73069845 0.73069845 0.73069845], Velocity: (0.7306984527777942, 0.7306984527777942, 0.7306984527777942), Duration: 1.0, Reward: -6.900090346846621, Done: False"}
{"time": "2024-07-21T15:32:12.084805", "name": "AirSimEnvLogger", "level": "INFO", "message": "Step completed. Observation keys: dict_keys(['state', 'visual'])"}
{"time": "2024-07-21T15:32:12.084805", "name": "AirSimEnvLogger", "level": "INFO", "message": "State shape: (16,), Visual shape: (144, 256, 3)"}
{"time": "2024-07-21T15:32:14.969505", "name": "AirSimEnvLogger", "level": "INFO", "message": "Predictive model loss: 0.0657591000199318"}
{"time": "2024-07-21T15:32:20.715091", "name": "AirSimEnvLogger", "level": "INFO", "message": "Reward breakdown - Distance: -9.21083897288663, Velocity: -0.07486757994109092, Movement: 0.7191677671781368, Collision: 0, Height: -1.0, Movement Penalty: -0.16608468158911976, Smoothness: -0.0, Curiosity: 3.4153294563293457, Exploration: 0.31972586399105996, Total: -6.211818179223069"}
{"time": "2024-07-21T15:32:20.840535", "name": "AirSimEnvLogger", "level": "INFO", "message": "Action: [0.83042341 0.83042341 0.83042341 0.83042341], Velocity: (0.8304234079455988, 0.8304234079455988, 0.8304234079455988), Duration: 1.0, Reward: -6.211818179223069, Done: False"}
{"time": "2024-07-21T15:32:20.949831", "name": "AirSimEnvLogger", "level": "INFO", "message": "Step completed. Observation keys: dict_keys(['state', 'visual'])"}
{"time": "2024-07-21T15:32:20.949831", "name": "AirSimEnvLogger", "level": "INFO", "message": "State shape: (16,), Visual shape: (144, 256, 3)"}
{"time": "2024-07-21T15:32:23.953679", "name": "AirSimEnvLogger", "level": "INFO", "message": "Predictive model loss: 0.14046615362167358"}
{"time": "2024-07-21T15:32:30.158904", "name": "AirSimEnvLogger", "level": "INFO", "message": "Reward breakdown - Distance: -9.347697681168865, Velocity: -0.08510850537275663, Movement: 0.5481472602464594, Collision: 0, Height: -1.0, Movement Penalty: -0.12658918730353969, Smoothness: -0.0, Curiosity: 2.091301679611206, Exploration: 0.20082053315539847, Total: -7.70527210668646"}
{"time": "2024-07-21T15:32:30.220715", "name": "AirSimEnvLogger", "level": "INFO", "message": "Action: [0.63294594 0.63294594 0.63294594 0.63294594], Velocity: (0.6329459365176984, 0.6329459365176984, 0.6329459365176984), Duration: 1.0, Reward: -7.70527210668646, Done: False"}
{"time": "2024-07-21T15:32:30.283991", "name": "AirSimEnvLogger", "level": "INFO", "message": "Step completed. Observation keys: dict_keys(['state', 'visual'])"}
{"time": "2024-07-21T15:32:30.283991", "name": "AirSimEnvLogger", "level": "INFO", "message": "State shape: (16,), Visual shape: (144, 256, 3)"}
{"time": "2024-07-21T15:32:33.231155", "name": "AirSimEnvLogger", "level": "INFO", "message": "Predictive model loss: 0.15162122249603271"}
{"time": "2024-07-21T15:32:39.336929", "name": "AirSimEnvLogger", "level": "INFO", "message": "Reward breakdown - Distance: -9.246746485250018, Velocity: -0.1080877422443835, Movement: 0.7070319254455159, Collision: 0, Height: -1.0, Movement Penalty: -0.1632820289926512, Smoothness: -0.0, Curiosity: 3.7551214694976807, Exploration: 0.21313260465209402, Total: -5.936069835840747"}
{"time": "2024-07-21T15:32:39.462249", "name": "AirSimEnvLogger", "level": "INFO", "message": "Action: [0.81641014 0.81641014 0.81641014 0.81641014], Velocity: (0.8164101449632559, 0.8164101449632559, 0.8164101449632559), Duration: 1.0, Reward: -5.936069835840747, Done: False"}
{"time": "2024-07-21T15:32:39.493945", "name": "AirSimEnvLogger", "level": "INFO", "message": "Step completed. Observation keys: dict_keys(['state', 'visual'])"}
{"time": "2024-07-21T15:32:39.493945", "name": "AirSimEnvLogger", "level": "INFO", "message": "State shape: (16,), Visual shape: (144, 256, 3)"}
{"time": "2024-07-21T15:32:42.301420", "name": "AirSimEnvLogger", "level": "INFO", "message": "Predictive model loss: 0.23846954107284546"}
{"time": "2024-07-21T15:32:48.555521", "name": "AirSimEnvLogger", "level": "INFO", "message": "Reward breakdown - Distance: -9.241814842157757, Velocity: -0.11856956523468636, Movement: 0.7332415330867411, Collision: 0, Height: -1.0, Movement Penalty: -0.16933487860345756, Smoothness: -0.0, Curiosity: 4.795995712280273, Exploration: 0.2843400134651814, Total: -4.874291507973545"}
{"time": "2024-07-21T15:32:48.679126", "name": "AirSimEnvLogger", "level": "INFO", "message": "Action: [0.84667439 0.84667439 0.84667439 0.84667439], Velocity: (0.8466743930172878, 0.8466743930172878, 0.8466743930172878), Duration: 1.0, Reward: -4.874291507973545, Done: False"}
{"time": "2024-07-21T15:32:48.741735", "name": "AirSimEnvLogger", "level": "INFO", "message": "Step completed. Observation keys: dict_keys(['state', 'visual'])"}
{"time": "2024-07-21T15:32:48.741735", "name": "AirSimEnvLogger", "level": "INFO", "message": "State shape: (16,), Visual shape: (144, 256, 3)"}
{"time": "2024-07-21T15:32:51.594151", "name": "AirSimEnvLogger", "level": "INFO", "message": "Predictive model loss: 0.31259992718696594"}
{"time": "2024-07-21T15:32:57.681613", "name": "AirSimEnvLogger", "level": "INFO", "message": "Reward breakdown - Distance: -9.753334140564107, Velocity: -0.028753110906492886, Movement: 0.15516288329579186, Collision: 0, Height: -1.0, Movement Penalty: -0.03583333297562557, Smoothness: -0.0, Curiosity: 0.8935874104499817, Exploration: 0.15984342244949196, Total: -9.322051916867792"}
{"time": "2024-07-21T15:32:57.759208", "name": "AirSimEnvLogger", "level": "INFO", "message": "Action: [0.17916666 0.17916666 0.17916666 0.17916666], Velocity: (0.17916666487812782, 0.17916666487812782, 0.17916666487812782), Duration: 1.0, Reward: -9.322051916867792, Done: False"}
{"time": "2024-07-21T15:32:57.822166", "name": "AirSimEnvLogger", "level": "INFO", "message": "Step completed. Observation keys: dict_keys(['state', 'visual'])"}
{"time": "2024-07-21T15:32:57.822166", "name": "AirSimEnvLogger", "level": "INFO", "message": "State shape: (16,), Visual shape: (144, 256, 3)"}
{"time": "2024-07-21T15:33:00.704442", "name": "AirSimEnvLogger", "level": "INFO", "message": "Predictive model loss: 0.1797233670949936"}
{"time": "2024-07-21T15:33:06.649838", "name": "AirSimEnvLogger", "level": "INFO", "message": "Reward breakdown - Distance: -9.69983481558925, Velocity: -0.061708460826306946, Movement: 0.3394714406949829, Collision: 0, Height: -1.0, Movement Penalty: -0.07839757106697538, Smoothness: -0.0, Curiosity: 2.0683298110961914, Exploration: 0.14002807121445054, Total: -8.097142178032556"}
{"time": "2024-07-21T15:33:06.774410", "name": "AirSimEnvLogger", "level": "INFO", "message": "Action: [0.39198786 0.39198786 0.39198786 0.39198786], Velocity: (0.3919878553348769, 0.3919878553348769, 0.3919878553348769), Duration: 1.0, Reward: -8.097142178032556, Done: False"}
{"time": "2024-07-21T15:33:06.789744", "name": "AirSimEnvLogger", "level": "INFO", "message": "Step completed. Observation keys: dict_keys(['state', 'visual'])"}
{"time": "2024-07-21T15:33:06.789744", "name": "AirSimEnvLogger", "level": "INFO", "message": "State shape: (16,), Visual shape: (144, 256, 3)"}
{"time": "2024-07-21T15:33:09.667087", "name": "AirSimEnvLogger", "level": "INFO", "message": "Predictive model loss: 0.22192926704883575"}
{"time": "2024-07-21T15:33:15.615107", "name": "AirSimEnvLogger", "level": "INFO", "message": "Reward breakdown - Distance: -9.593621670856056, Velocity: -0.08207795415018806, Movement: 0.49557447386426406, Collision: 0, Height: -1.0, Movement Penalty: -0.114448022355616, Smoothness: -0.0, Curiosity: 3.933405876159668, Exploration: 0.22617683209409475, Total: -6.104246503566576"}
{"time": "2024-07-21T15:33:15.709673", "name": "AirSimEnvLogger", "level": "INFO", "message": "Action: [0.57224011 0.57224011 0.57224011 0.57224011], Velocity: (0.57224011177808, 0.57224011177808, 0.57224011177808), Duration: 1.0, Reward: -6.104246503566576, Done: False"}
{"time": "2024-07-21T15:33:15.756829", "name": "AirSimEnvLogger", "level": "INFO", "message": "Step completed. Observation keys: dict_keys(['state', 'visual'])"}
{"time": "2024-07-21T15:33:15.756829", "name": "AirSimEnvLogger", "level": "INFO", "message": "State shape: (16,), Visual shape: (144, 256, 3)"}
{"time": "2024-07-21T15:33:18.652719", "name": "AirSimEnvLogger", "level": "INFO", "message": "Predictive model loss: 0.2923852205276489"}
{"time": "2024-07-21T15:33:24.431721", "name": "AirSimEnvLogger", "level": "INFO", "message": "Reward breakdown - Distance: -9.619200099135835, Velocity: -0.031369626035921985, Movement: 0.486882147846044, Collision: 0, Height: -1.0, Movement Penalty: -0.11244061564901467, Smoothness: -0.0, Curiosity: 4.807024002075195, Exploration: 0.2050646943878461, Total: -5.256204987081088"}
{"time": "2024-07-21T15:33:24.509546", "name": "AirSimEnvLogger", "level": "INFO", "message": "Action: [0.56220308 0.56220308 0.56220308 0.56220308], Velocity: (0.5622030782450733, 0.5622030782450733, 0.5622030782450733), Duration: 1.0, Reward: -5.256204987081088, Done: False"}
{"time": "2024-07-21T15:33:24.619240", "name": "AirSimEnvLogger", "level": "INFO", "message": "Step completed. Observation keys: dict_keys(['state', 'visual'])"}
{"time": "2024-07-21T15:33:24.619240", "name": "AirSimEnvLogger", "level": "INFO", "message": "State shape: (16,), Visual shape: (144, 256, 3)"}
{"time": "2024-07-21T15:33:27.503274", "name": "AirSimEnvLogger", "level": "INFO", "message": "Predictive model loss: 0.3368881940841675"}
{"time": "2024-07-21T15:33:33.407401", "name": "AirSimEnvLogger", "level": "INFO", "message": "Reward breakdown - Distance: -9.632057592610794, Velocity: -0.08885463270755607, Movement: 0.5499820906659039, Collision: 0, Height: -1.0, Movement Penalty: -0.12701292323817312, Smoothness: -0.0, Curiosity: 6.632537841796875, Exploration: 0.19017192757035073, Total: -3.451174639669354"}
{"time": "2024-07-21T15:33:33.517007", "name": "AirSimEnvLogger", "level": "INFO", "message": "Action: [0.63506462 0.63506462 0.63506462 0.63506462], Velocity: (0.6350646161908655, 0.6350646161908655, 0.6350646161908655), Duration: 1.0, Reward: -3.451174639669354, Done: False"}
{"time": "2024-07-21T15:33:33.548009", "name": "AirSimEnvLogger", "level": "INFO", "message": "Step completed. Observation keys: dict_keys(['state', 'visual'])"}
{"time": "2024-07-21T15:33:33.548009", "name": "AirSimEnvLogger", "level": "INFO", "message": "State shape: (16,), Visual shape: (144, 256, 3)"}
{"time": "2024-07-21T15:33:36.490753", "name": "AirSimEnvLogger", "level": "INFO", "message": "Predictive model loss: 0.41913866996765137"}
{"time": "2024-07-21T15:33:42.358458", "name": "AirSimEnvLogger", "level": "INFO", "message": "Reward breakdown - Distance: -9.607485959773204, Velocity: -0.06385151530338198, Movement: 0.7006926191994957, Collision: 0, Height: -1.0, Movement Penalty: -0.16181802892560512, Smoothness: -0.0, Curiosity: 10.20175552368164, Exploration: 0.2623909597631615, Total: 0.1654222853487528"}
{"time": "2024-07-21T15:33:42.466535", "name": "AirSimEnvLogger", "level": "INFO", "message": "Action: [0.80909014 0.80909014 0.80909014 0.80909014], Velocity: (0.8090901446280255, 0.8090901446280255, 0.8090901446280255), Duration: 1.0, Reward: 0.1654222853487528, Done: False"}
{"time": "2024-07-21T15:33:42.591935", "name": "AirSimEnvLogger", "level": "INFO", "message": "Step completed. Observation keys: dict_keys(['state', 'visual'])"}
{"time": "2024-07-21T15:33:42.591935", "name": "AirSimEnvLogger", "level": "INFO", "message": "State shape: (16,), Visual shape: (144, 256, 3)"}
{"time": "2024-07-21T15:33:45.471509", "name": "AirSimEnvLogger", "level": "INFO", "message": "Predictive model loss: 0.5714067816734314"}
{"time": "2024-07-21T15:33:51.391030", "name": "AirSimEnvLogger", "level": "INFO", "message": "Reward breakdown - Distance: -9.668484883932384, Velocity: -0.06178392762268092, Movement: 0.7591360606128643, Collision: 0, Height: -1.0, Movement Penalty: -0.17531496357855572, Smoothness: -0.0, Curiosity: 13.45190715789795, Exploration: 0.2954262440801932, Total: 3.363813484038266"}
{"time": "2024-07-21T15:33:51.530815", "name": "AirSimEnvLogger", "level": "INFO", "message": "Action: [0.87657482 0.87657482 0.87657482 0.87657482], Velocity: (0.8765748178927786, 0.8765748178927786, 0.8765748178927786), Duration: 1.0, Reward: 3.363813484038266, Done: False"}
{"time": "2024-07-21T15:33:51.594497", "name": "AirSimEnvLogger", "level": "INFO", "message": "Step completed. Observation keys: dict_keys(['state', 'visual'])"}
{"time": "2024-07-21T15:33:51.594497", "name": "AirSimEnvLogger", "level": "INFO", "message": "State shape: (16,), Visual shape: (144, 256, 3)"}
{"time": "2024-07-21T15:33:54.379772", "name": "AirSimEnvLogger", "level": "INFO", "message": "Predictive model loss: 0.7347251772880554"}
{"time": "2024-07-21T15:34:00.167811", "name": "AirSimEnvLogger", "level": "INFO", "message": "Reward breakdown - Distance: -10.244450335714474, Velocity: -0.009071811706331506, Movement: 0.04949332992046609, Collision: 0, Height: -1.0, Movement Penalty: -0.011429994941068822, Smoothness: -0.0, Curiosity: 6.510580062866211, Exploration: 0.21277721310505415, Total: -4.184624626286403"}
{"time": "2024-07-21T15:34:00.277563", "name": "AirSimEnvLogger", "level": "INFO", "message": "Action: [-0.05714997 -0.05714997 -0.05714997 -0.05714997], Velocity: (-0.05714997470534411, -0.05714997470534411, -0.05714997470534411), Duration: 1.0, Reward: -4.184624626286403, Done: False"}
{"time": "2024-07-21T15:34:00.340001", "name": "AirSimEnvLogger", "level": "INFO", "message": "Step completed. Observation keys: dict_keys(['state', 'visual'])"}
{"time": "2024-07-21T15:34:00.340001", "name": "AirSimEnvLogger", "level": "INFO", "message": "State shape: (16,), Visual shape: (144, 256, 3)"}
{"time": "2024-07-21T15:34:03.298385", "name": "AirSimEnvLogger", "level": "INFO", "message": "Predictive model loss: 0.45934391021728516"}
{"time": "2024-07-21T15:34:09.108180", "name": "AirSimEnvLogger", "level": "INFO", "message": "Reward breakdown - Distance: -10.612120937114641, Velocity: -0.07453689279416627, Movement: 0.4500172706556454, Collision: 0, Height: -1.0, Movement Penalty: -0.10392703694120703, Smoothness: -0.0, Curiosity: 5.270089149475098, Exploration: 0.5111645486588634, Total: -5.720878731306237"}
{"time": "2024-07-21T15:34:09.217594", "name": "AirSimEnvLogger", "level": "INFO", "message": "Action: [-0.51963518 -0.51963518 -0.51963518 -0.51963518], Velocity: (-0.5196351847060351, -0.5196351847060351, -0.5196351847060351), Duration: 1.0, Reward: -5.720878731306237, Done: False"}
{"time": "2024-07-21T15:34:09.311912", "name": "AirSimEnvLogger", "level": "INFO", "message": "Step completed. Observation keys: dict_keys(['state', 'visual'])"}
{"time": "2024-07-21T15:34:09.311912", "name": "AirSimEnvLogger", "level": "INFO", "message": "State shape: (16,), Visual shape: (144, 256, 3)"}
{"time": "2024-07-21T15:34:12.147861", "name": "AirSimEnvLogger", "level": "INFO", "message": "Predictive model loss: 0.29111745953559875"}
{"time": "2024-07-21T15:34:17.816322", "name": "AirSimEnvLogger", "level": "INFO", "message": "Reward breakdown - Distance: -10.327188594178757, Velocity: -0.0054144294899325035, Movement: 0.027864507135563585, Collision: 0, Height: -1.0, Movement Penalty: -0.006435032278221554, Smoothness: -0.0, Curiosity: 5.548956394195557, Exploration: 0.0698178697966083, Total: -5.262032018019107"}
{"time": "2024-07-21T15:34:17.910727", "name": "AirSimEnvLogger", "level": "INFO", "message": "Action: [0.03217516 0.03217516 0.03217516 0.03217516], Velocity: (0.032175161391107765, 0.032175161391107765, 0.032175161391107765), Duration: 1.0, Reward: -5.262032018019107, Done: False"}
{"time": "2024-07-21T15:34:17.988990", "name": "AirSimEnvLogger", "level": "INFO", "message": "Step completed. Observation keys: dict_keys(['state', 'visual'])"}
{"time": "2024-07-21T15:34:17.988990", "name": "AirSimEnvLogger", "level": "INFO", "message": "State shape: (16,), Visual shape: (144, 256, 3)"}
{"time": "2024-07-21T15:34:20.820048", "name": "AirSimEnvLogger", "level": "INFO", "message": "Predictive model loss: 0.36896443367004395"}
{"time": "2024-07-21T15:34:26.707537", "name": "AirSimEnvLogger", "level": "INFO", "message": "Reward breakdown - Distance: -10.023732397395483, Velocity: -0.05929601894161146, Movement: 0.4392709190947472, Collision: 0, Height: -1.0, Movement Penalty: -0.10144527335461065, Smoothness: -0.0, Curiosity: 9.56267261505127, Exploration: 0.3710533397877774, Total: -0.8708718240912268"}
{"time": "2024-07-21T15:34:26.816375", "name": "AirSimEnvLogger", "level": "INFO", "message": "Action: [0.50722637 0.50722637 0.50722637 0.50722637], Velocity: (0.5072263667730532, 0.5072263667730532, 0.5072263667730532), Duration: 1.0, Reward: -0.8708718240912268, Done: False"}
{"time": "2024-07-21T15:34:26.831838", "name": "AirSimEnvLogger", "level": "INFO", "message": "Step completed. Observation keys: dict_keys(['state', 'visual'])"}
{"time": "2024-07-21T15:34:26.831838", "name": "AirSimEnvLogger", "level": "INFO", "message": "State shape: (16,), Visual shape: (144, 256, 3)"}
{"time": "2024-07-21T15:34:29.569401", "name": "AirSimEnvLogger", "level": "INFO", "message": "Predictive model loss: 0.5497702956199646"}
{"time": "2024-07-21T15:34:35.406437", "name": "AirSimEnvLogger", "level": "INFO", "message": "Reward breakdown - Distance: -10.228354097405301, Velocity: -0.009123207836564243, Movement: 0.06538471667746071, Collision: 0, Height: -1.0, Movement Penalty: -0.015099953509847741, Smoothness: -0.0, Curiosity: 7.2196879386901855, Exploration: 0.11191087243571692, Total: -3.4822350952586363"}
{"time": "2024-07-21T15:34:35.500706", "name": "AirSimEnvLogger", "level": "INFO", "message": "Action: [0.07549977 0.07549977 0.07549977 0.07549977], Velocity: (0.0754997675492387, 0.0754997675492387, 0.0754997675492387), Duration: 1.0, Reward: -3.4822350952586363, Done: False"}
{"time": "2024-07-21T15:34:35.594942", "name": "AirSimEnvLogger", "level": "INFO", "message": "Step completed. Observation keys: dict_keys(['state', 'visual'])"}
{"time": "2024-07-21T15:34:35.594942", "name": "AirSimEnvLogger", "level": "INFO", "message": "State shape: (16,), Visual shape: (144, 256, 3)"}
{"time": "2024-07-21T15:34:38.468024", "name": "AirSimEnvLogger", "level": "INFO", "message": "Predictive model loss: 0.45757463574409485"}
{"time": "2024-07-21T15:34:44.411701", "name": "AirSimEnvLogger", "level": "INFO", "message": "Reward breakdown - Distance: -10.559011302018716, Velocity: -0.058535092611282466, Movement: 0.369160632436605, Collision: 0, Height: -1.0, Movement Penalty: -0.08525399620459456, Smoothness: -0.0, Curiosity: 5.49835205078125, Exploration: 0.3189610237149578, Total: -5.4840962346053255"}
{"time": "2024-07-21T15:34:44.551578", "name": "AirSimEnvLogger", "level": "INFO", "message": "Action: [-0.42626998 -0.42626998 -0.42626998 -0.42626998], Velocity: (-0.42626998102297275, -0.42626998102297275, -0.42626998102297275), Duration: 1.0, Reward: -5.4840962346053255, Done: False"}
{"time": "2024-07-21T15:34:44.582671", "name": "AirSimEnvLogger", "level": "INFO", "message": "Step completed. Observation keys: dict_keys(['state', 'visual'])"}
{"time": "2024-07-21T15:34:44.582671", "name": "AirSimEnvLogger", "level": "INFO", "message": "State shape: (16,), Visual shape: (144, 256, 3)"}
{"time": "2024-07-21T15:34:47.468800", "name": "AirSimEnvLogger", "level": "INFO", "message": "Predictive model loss: 0.29908254742622375"}
{"time": "2024-07-21T15:34:53.336291", "name": "AirSimEnvLogger", "level": "INFO", "message": "Reward breakdown - Distance: -10.729780587894858, Velocity: -0.09299630109364256, Movement: 0.5630749508423306, Collision: 0, Height: -1.0, Movement Penalty: -0.13003658977710195, Smoothness: -0.0, Curiosity: 4.8486151695251465, Exploration: 0.3781669953094913, Total: -6.289674441328517"}
{"time": "2024-07-21T15:34:53.478712", "name": "AirSimEnvLogger", "level": "INFO", "message": "Action: [-0.65018295 -0.65018295 -0.65018295 -0.65018295], Velocity: (-0.6501829488855098, -0.6501829488855098, -0.6501829488855098), Duration: 1.0, Reward: -6.289674441328517, Done: False"}
{"time": "2024-07-21T15:34:53.557042", "name": "AirSimEnvLogger", "level": "INFO", "message": "Step completed. Observation keys: dict_keys(['state', 'visual'])"}
{"time": "2024-07-21T15:34:53.557042", "name": "AirSimEnvLogger", "level": "INFO", "message": "State shape: (16,), Visual shape: (144, 256, 3)"}
{"time": "2024-07-21T15:34:56.596150", "name": "AirSimEnvLogger", "level": "INFO", "message": "Predictive model loss: 0.19447672367095947"}
{"time": "2024-07-21T15:35:02.594934", "name": "AirSimEnvLogger", "level": "INFO", "message": "Reward breakdown - Distance: -10.219571352940504, Velocity: -0.02079307160405111, Movement: 0.14868193432486662, Collision: 0, Height: -1.0, Movement Penalty: -0.03433662192243841, Smoothness: -0.0, Curiosity: 5.256308555603027, Exploration: 0.12202802365672506, Total: -5.433628499212574"}
{"time": "2024-07-21T15:35:02.736058", "name": "AirSimEnvLogger", "level": "INFO", "message": "Action: [0.17168311 0.17168311 0.17168311 0.17168311], Velocity: (0.17168310961219202, 0.17168310961219202, 0.17168310961219202), Duration: 1.0, Reward: -5.433628499212574, Done: False"}
{"time": "2024-07-21T15:35:02.799203", "name": "AirSimEnvLogger", "level": "INFO", "message": "Step completed. Observation keys: dict_keys(['state', 'visual'])"}
{"time": "2024-07-21T15:35:02.799203", "name": "AirSimEnvLogger", "level": "INFO", "message": "State shape: (16,), Visual shape: (144, 256, 3)"}
{"time": "2024-07-21T15:35:05.808349", "name": "AirSimEnvLogger", "level": "INFO", "message": "Predictive model loss: 0.3167564570903778"}
{"time": "2024-07-21T15:35:11.883926", "name": "AirSimEnvLogger", "level": "INFO", "message": "Reward breakdown - Distance: -9.934085468094928, Velocity: -0.06690096526670297, Movement: 0.4861979014603195, Collision: 0, Height: -1.0, Movement Penalty: -0.11228259571501864, Smoothness: -0.0, Curiosity: 9.184707641601562, Exploration: 0.46750477678111185, Total: -1.1366154160134438"}
{"time": "2024-07-21T15:35:12.010075", "name": "AirSimEnvLogger", "level": "INFO", "message": "Action: [0.56141298 0.56141298 0.56141298 0.56141298], Velocity: (0.5614129785750932, 0.5614129785750932, 0.5614129785750932), Duration: 1.0, Reward: -1.1366154160134438, Done: False"}
{"time": "2024-07-21T15:35:12.074095", "name": "AirSimEnvLogger", "level": "INFO", "message": "Step completed. Observation keys: dict_keys(['state', 'visual'])"}
{"time": "2024-07-21T15:35:12.074095", "name": "AirSimEnvLogger", "level": "INFO", "message": "State shape: (16,), Visual shape: (144, 256, 3)"}
{"time": "2024-07-21T15:35:15.111790", "name": "AirSimEnvLogger", "level": "INFO", "message": "Predictive model loss: 0.48864027857780457"}
{"time": "2024-07-21T15:35:21.569649", "name": "AirSimEnvLogger", "level": "INFO", "message": "Reward breakdown - Distance: -10.334060565791283, Velocity: -0.0282678085561455, Movement: 0.164224429661156, Collision: 0, Height: -1.0, Movement Penalty: -0.03792600746895247, Smoothness: -0.0, Curiosity: 5.214900970458984, Exploration: 0.04306878290499731, Total: -5.608052139701678"}
{"time": "2024-07-21T15:35:21.616522", "name": "AirSimEnvLogger", "level": "INFO", "message": "Action: [-0.18963004 -0.18963004 -0.18963004 -0.18963004], Velocity: (-0.18963003734476236, -0.18963003734476236, -0.18963003734476236), Duration: 1.0, Reward: -5.608052139701678, Done: False"}
{"time": "2024-07-21T15:35:21.679268", "name": "AirSimEnvLogger", "level": "INFO", "message": "Step completed. Observation keys: dict_keys(['state', 'visual'])"}
{"time": "2024-07-21T15:35:21.679268", "name": "AirSimEnvLogger", "level": "INFO", "message": "State shape: (16,), Visual shape: (144, 256, 3)"}
{"time": "2024-07-21T15:35:24.633582", "name": "AirSimEnvLogger", "level": "INFO", "message": "Predictive model loss: 0.3057638108730316"}
{"time": "2024-07-21T15:35:30.466270", "name": "AirSimEnvLogger", "level": "INFO", "message": "Reward breakdown - Distance: -10.273928937616327, Velocity: -0.005316084805818667, Movement: 0.03276863839532664, Collision: 0, Height: -1.0, Movement Penalty: -0.0075675928794077365, Smoothness: -0.0, Curiosity: 5.776591777801514, Exploration: 0.17832638458545216, Total: -4.9560498869051"}
{"time": "2024-07-21T15:35:30.559949", "name": "AirSimEnvLogger", "level": "INFO", "message": "Action: [0.03783796 0.03783796 0.03783796 0.03783796], Velocity: (0.03783796439703868, 0.03783796439703868, 0.03783796439703868), Duration: 1.0, Reward: -4.9560498869051, Done: False"}
{"time": "2024-07-21T15:35:30.621986", "name": "AirSimEnvLogger", "level": "INFO", "message": "Step completed. Observation keys: dict_keys(['state', 'visual'])"}
{"time": "2024-07-21T15:35:30.621986", "name": "AirSimEnvLogger", "level": "INFO", "message": "State shape: (16,), Visual shape: (144, 256, 3)"}
{"time": "2024-07-21T15:35:33.572144", "name": "AirSimEnvLogger", "level": "INFO", "message": "Predictive model loss: 0.3461875021457672"}
{"time": "2024-07-21T15:35:39.498178", "name": "AirSimEnvLogger", "level": "INFO", "message": "Reward breakdown - Distance: -10.484858129563948, Velocity: -0.05381864989488847, Movement: 0.31104618782361193, Collision: 0, Height: -1.0, Movement Penalty: -0.0718330401081477, Smoothness: -0.0, Curiosity: 4.512038707733154, Exploration: 0.10476846830244262, Total: -6.446474592869489"}
{"time": "2024-07-21T15:35:39.620265", "name": "AirSimEnvLogger", "level": "INFO", "message": "Action: [-0.3591652 -0.3591652 -0.3591652 -0.3591652], Velocity: (-0.35916520054073847, -0.35916520054073847, -0.35916520054073847), Duration: 1.0, Reward: -6.446474592869489, Done: False"}
{"time": "2024-07-21T15:35:39.636308", "name": "AirSimEnvLogger", "level": "INFO", "message": "Step completed. Observation keys: dict_keys(['state', 'visual'])"}
{"time": "2024-07-21T15:35:39.636308", "name": "AirSimEnvLogger", "level": "INFO", "message": "State shape: (16,), Visual shape: (144, 256, 3)"}
{"time": "2024-07-21T15:35:42.502468", "name": "AirSimEnvLogger", "level": "INFO", "message": "Predictive model loss: 0.23288856446743011"}
{"time": "2024-07-21T15:35:48.581063", "name": "AirSimEnvLogger", "level": "INFO", "message": "Reward breakdown - Distance: -10.236403124998064, Velocity: -0.014197940735342241, Movement: 0.09259130616177112, Collision: 0, Height: -1.0, Movement Penalty: -0.021383046214847046, Smoothness: -0.0, Curiosity: 5.395857334136963, Exploration: 0.0277356777153388, Total: -5.333315119304884"}
{"time": "2024-07-21T15:35:48.676114", "name": "AirSimEnvLogger", "level": "INFO", "message": "Action: [0.10691523 0.10691523 0.10691523 0.10691523], Velocity: (0.10691523107423523, 0.10691523107423523, 0.10691523107423523), Duration: 1.0, Reward: -5.333315119304884, Done: False"}
{"time": "2024-07-21T15:35:48.706554", "name": "AirSimEnvLogger", "level": "INFO", "message": "Step completed. Observation keys: dict_keys(['state', 'visual'])"}
{"time": "2024-07-21T15:35:48.706554", "name": "AirSimEnvLogger", "level": "INFO", "message": "State shape: (16,), Visual shape: (144, 256, 3)"}
{"time": "2024-07-21T15:35:51.704933", "name": "AirSimEnvLogger", "level": "INFO", "message": "Predictive model loss: 0.3128349184989929"}
{"time": "2024-07-21T15:35:57.748269", "name": "AirSimEnvLogger", "level": "INFO", "message": "Reward breakdown - Distance: -10.141984523649805, Velocity: -0.029710146041511284, Movement: 0.17328141321121446, Collision: 0, Height: -1.0, Movement Penalty: -0.040017628225221376, Smoothness: -0.0, Curiosity: 6.295618057250977, Exploration: 0.2072576787412071, Total: -4.297417631155542"}
{"time": "2024-07-21T15:35:57.839901", "name": "AirSimEnvLogger", "level": "INFO", "message": "Action: [0.20008814 0.20008814 0.20008814 0.20008814], Velocity: (0.20008814112610687, 0.20008814112610687, 0.20008814112610687), Duration: 1.0, Reward: -4.297417631155542, Done: False"}
{"time": "2024-07-21T15:35:57.871733", "name": "AirSimEnvLogger", "level": "INFO", "message": "Step completed. Observation keys: dict_keys(['state', 'visual'])"}
{"time": "2024-07-21T15:35:57.871733", "name": "AirSimEnvLogger", "level": "INFO", "message": "State shape: (16,), Visual shape: (144, 256, 3)"}
{"time": "2024-07-21T15:36:00.822774", "name": "AirSimEnvLogger", "level": "INFO", "message": "Predictive model loss: 0.35609742999076843"}
{"time": "2024-07-21T15:36:06.391464", "name": "AirSimEnvLogger", "level": "INFO", "message": "Reward breakdown - Distance: -9.94718331827469, Velocity: -0.031160929583369332, Movement: 0.5196454333412281, Collision: 0, Height: -1.0, Movement Penalty: -0.12000697232908714, Smoothness: -0.0, Curiosity: 10.712013244628906, Exploration: 0.2543556877469361, Total: 0.33296251608090477"}
{"time": "2024-07-21T15:36:06.517750", "name": "AirSimEnvLogger", "level": "INFO", "message": "Action: [0.60003486 0.60003486 0.60003486 0.60003486], Velocity: (0.6000348616454356, 0.6000348616454356, 0.6000348616454356), Duration: 1.0, Reward: 0.33296251608090477, Done: False"}
{"time": "2024-07-21T15:36:06.566068", "name": "AirSimEnvLogger", "level": "INFO", "message": "Step completed. Observation keys: dict_keys(['state', 'visual'])"}
{"time": "2024-07-21T15:36:06.566068", "name": "AirSimEnvLogger", "level": "INFO", "message": "State shape: (16,), Visual shape: (144, 256, 3)"}
{"time": "2024-07-21T15:36:09.560276", "name": "AirSimEnvLogger", "level": "INFO", "message": "Predictive model loss: 0.5408284068107605"}
{"time": "2024-07-21T15:36:15.295043", "name": "AirSimEnvLogger", "level": "INFO", "message": "Reward breakdown - Distance: -9.99825533483957, Velocity: -0.08450328698574917, Movement: 0.49139968748822666, Collision: 0, Height: -1.0, Movement Penalty: -0.11348389674041026, Smoothness: -0.0, Curiosity: 12.248441696166992, Exploration: 0.2656616957368196, Total: 1.8148922305264623"}
{"time": "2024-07-21T15:36:15.374303", "name": "AirSimEnvLogger", "level": "INFO", "message": "Action: [0.56741948 0.56741948 0.56741948 0.56741948], Velocity: (0.5674194837020513, 0.5674194837020513, 0.5674194837020513), Duration: 1.0, Reward: 1.8148922305264623, Done: False"}
{"time": "2024-07-21T15:36:15.421365", "name": "AirSimEnvLogger", "level": "INFO", "message": "Step completed. Observation keys: dict_keys(['state', 'visual'])"}
{"time": "2024-07-21T15:36:15.421365", "name": "AirSimEnvLogger", "level": "INFO", "message": "State shape: (16,), Visual shape: (144, 256, 3)"}
{"time": "2024-07-21T15:36:18.354294", "name": "AirSimEnvLogger", "level": "INFO", "message": "Predictive model loss: 0.6340818405151367"}
{"time": "2024-07-21T15:36:24.185056", "name": "AirSimEnvLogger", "level": "INFO", "message": "Reward breakdown - Distance: -10.193710660980406, Velocity: -0.043961899150728165, Movement: 0.2658523805146375, Collision: 0, Height: -1.0, Movement Penalty: -0.06139597738193151, Smoothness: -0.0, Curiosity: 11.177961349487305, Exploration: 0.09676431590424357, Total: 0.508631635830886"}
{"time": "2024-07-21T15:36:24.294192", "name": "AirSimEnvLogger", "level": "INFO", "message": "Action: [0.30697989 0.30697989 0.30697989 0.30697989], Velocity: (0.30697988690965755, 0.30697988690965755, 0.30697988690965755), Duration: 1.0, Reward: 0.508631635830886, Done: False"}
{"time": "2024-07-21T15:36:24.324912", "name": "AirSimEnvLogger", "level": "INFO", "message": "Step completed. Observation keys: dict_keys(['state', 'visual'])"}
{"time": "2024-07-21T15:36:24.324912", "name": "AirSimEnvLogger", "level": "INFO", "message": "State shape: (16,), Visual shape: (144, 256, 3)"}
{"time": "2024-07-21T15:36:27.223273", "name": "AirSimEnvLogger", "level": "INFO", "message": "Predictive model loss: 0.6135286688804626"}
{"time": "2024-07-21T15:36:33.183928", "name": "AirSimEnvLogger", "level": "INFO", "message": "Reward breakdown - Distance: -10.57625825778699, Velocity: -0.041816943613042265, Movement: 0.27931806823173816, Collision: 0, Height: -1.0, Movement Penalty: -0.06450574475324812, Smoothness: -0.0, Curiosity: 7.924701690673828, Exploration: 0.28557685560168694, Total: -3.083203927510258"}
{"time": "2024-07-21T15:36:33.307730", "name": "AirSimEnvLogger", "level": "INFO", "message": "Action: [-0.32252872 -0.32252872 -0.32252872 -0.32252872], Velocity: (-0.3225287237662406, -0.3225287237662406, -0.3225287237662406), Duration: 1.0, Reward: -3.083203927510258, Done: False"}
{"time": "2024-07-21T15:36:33.401157", "name": "AirSimEnvLogger", "level": "INFO", "message": "Step completed. Observation keys: dict_keys(['state', 'visual'])"}
{"time": "2024-07-21T15:36:33.401157", "name": "AirSimEnvLogger", "level": "INFO", "message": "State shape: (16,), Visual shape: (144, 256, 3)"}
{"time": "2024-07-21T15:36:36.343708", "name": "AirSimEnvLogger", "level": "INFO", "message": "Predictive model loss: 0.408012330532074"}
{"time": "2024-07-21T15:36:42.395856", "name": "AirSimEnvLogger", "level": "INFO", "message": "Reward breakdown - Distance: -10.804228738086106, Velocity: -0.10714034801272092, Movement: 0.5660311405663147, Collision: 0, Height: -1.0, Movement Penalty: -0.13071929255026907, Smoothness: -0.0, Curiosity: 6.808797836303711, Exploration: 0.43521058130916396, Total: -4.392161789478408"}
{"time": "2024-07-21T15:36:42.471959", "name": "AirSimEnvLogger", "level": "INFO", "message": "Action: [-0.65359646 -0.65359646 -0.65359646 -0.65359646], Velocity: (-0.6535964627513453, -0.6535964627513453, -0.6535964627513453), Duration: 1.0, Reward: -4.392161789478408, Done: False"}
{"time": "2024-07-21T15:36:42.534302", "name": "AirSimEnvLogger", "level": "INFO", "message": "Step completed. Observation keys: dict_keys(['state', 'visual'])"}
{"time": "2024-07-21T15:36:42.534302", "name": "AirSimEnvLogger", "level": "INFO", "message": "State shape: (16,), Visual shape: (144, 256, 3)"}
{"time": "2024-07-21T15:36:45.444312", "name": "AirSimEnvLogger", "level": "INFO", "message": "Predictive model loss: 0.26166319847106934"}
{"time": "2024-07-21T15:36:51.193832", "name": "AirSimEnvLogger", "level": "INFO", "message": "Reward breakdown - Distance: -10.727325992197185, Velocity: -0.07186379640741575, Movement: 0.45487791083125995, Collision: 0, Height: -1.0, Movement Penalty: -0.10504955370673702, Smoothness: -0.0, Curiosity: 5.325860023498535, Exploration: 0.24789773900626735, Total: -5.840477737704942"}
{"time": "2024-07-21T15:36:51.333890", "name": "AirSimEnvLogger", "level": "INFO", "message": "Action: [-0.52524777 -0.52524777 -0.52524777 -0.52524777], Velocity: (-0.525247768533685, -0.525247768533685, -0.525247768533685), Duration: 1.0, Reward: -5.840477737704942, Done: False"}
{"time": "2024-07-21T15:36:51.396406", "name": "AirSimEnvLogger", "level": "INFO", "message": "Step completed. Observation keys: dict_keys(['state', 'visual'])"}
{"time": "2024-07-21T15:36:51.396406", "name": "AirSimEnvLogger", "level": "INFO", "message": "State shape: (16,), Visual shape: (144, 256, 3)"}
{"time": "2024-07-21T15:36:54.364832", "name": "AirSimEnvLogger", "level": "INFO", "message": "Predictive model loss: 0.20472322404384613"}
{"time": "2024-07-21T15:37:00.095775", "name": "AirSimEnvLogger", "level": "INFO", "message": "Reward breakdown - Distance: -10.795719978665607, Velocity: -0.0654335074852026, Movement: 0.6251206811943345, Collision: 0, Height: -1.0, Movement Penalty: -0.1443654374254205, Smoothness: -0.0, Curiosity: 4.737236022949219, Exploration: 0.2176811950381485, Total: -6.499626454951638"}
{"time": "2024-07-21T15:37:00.143108", "name": "AirSimEnvLogger", "level": "INFO", "message": "Action: [-0.72182719 -0.72182719 -0.72182719 -0.72182719], Velocity: (-0.7218271871271025, -0.7218271871271025, -0.7218271871271025), Duration: 1.0, Reward: -6.499626454951638, Done: False"}
{"time": "2024-07-21T15:37:00.236683", "name": "AirSimEnvLogger", "level": "INFO", "message": "Step completed. Observation keys: dict_keys(['state', 'visual'])"}
{"time": "2024-07-21T15:37:00.237682", "name": "AirSimEnvLogger", "level": "INFO", "message": "State shape: (16,), Visual shape: (144, 256, 3)"}
{"time": "2024-07-21T15:37:03.229917", "name": "AirSimEnvLogger", "level": "INFO", "message": "Predictive model loss: 0.11787058413028717"}
{"time": "2024-07-21T15:37:09.538900", "name": "AirSimEnvLogger", "level": "INFO", "message": "Reward breakdown - Distance: -10.472580480997737, Velocity: -0.009847223410284848, Movement: 0.2285450403860728, Collision: 0, Height: -1.0, Movement Penalty: -0.052780216235541216, Smoothness: -0.0, Curiosity: 3.004380702972412, Exploration: 0.12687962659289523, Total: -7.934395988713706"}
{"time": "2024-07-21T15:37:09.663603", "name": "AirSimEnvLogger", "level": "INFO", "message": "Action: [-0.26390108 -0.26390108 -0.26390108 -0.26390108], Velocity: (-0.26390108117770605, -0.26390108117770605, -0.26390108117770605), Duration: 1.0, Reward: -7.934395988713706, Done: False"}
{"time": "2024-07-21T15:37:09.726988", "name": "AirSimEnvLogger", "level": "INFO", "message": "Step completed. Observation keys: dict_keys(['state', 'visual'])"}
{"time": "2024-07-21T15:37:09.726988", "name": "AirSimEnvLogger", "level": "INFO", "message": "State shape: (16,), Visual shape: (144, 256, 3)"}
{"time": "2024-07-21T15:37:12.703970", "name": "AirSimEnvLogger", "level": "INFO", "message": "Predictive model loss: 0.10989519953727722"}
{"time": "2024-07-21T15:37:18.880493", "name": "AirSimEnvLogger", "level": "INFO", "message": "Reward breakdown - Distance: -10.129973418088763, Velocity: -0.022872749465423923, Movement: 0.1303600916909289, Collision: 0, Height: -1.0, Movement Penalty: -0.030105373611736843, Smoothness: -0.0, Curiosity: 3.851043701171875, Exploration: 0.27191679894241677, Total: -6.715478402075813"}
{"time": "2024-07-21T15:37:18.988577", "name": "AirSimEnvLogger", "level": "INFO", "message": "Action: [0.15052687 0.15052687 0.15052687 0.15052687], Velocity: (0.1505268680586842, 0.1505268680586842, 0.1505268680586842), Duration: 1.0, Reward: -6.715478402075813, Done: False"}
{"time": "2024-07-21T15:37:19.050908", "name": "AirSimEnvLogger", "level": "INFO", "message": "Step completed. Observation keys: dict_keys(['state', 'visual'])"}
{"time": "2024-07-21T15:37:19.050908", "name": "AirSimEnvLogger", "level": "INFO", "message": "State shape: (16,), Visual shape: (144, 256, 3)"}
{"time": "2024-07-21T15:37:21.728472", "name": "AirSimEnvLogger", "level": "INFO", "message": "Predictive model loss: 0.15106631815433502"}
{"time": "2024-07-21T15:37:27.975603", "name": "AirSimEnvLogger", "level": "INFO", "message": "Reward breakdown - Distance: -9.844957215504504, Velocity: -0.07188397972423234, Movement: 0.4880999418715466, Collision: 0, Height: -1.0, Movement Penalty: -0.11272185313239125, Smoothness: -0.0, Curiosity: 7.556431293487549, Exploration: 0.35726398304827595, Total: -2.7015705385924544"}
{"time": "2024-07-21T15:37:28.102270", "name": "AirSimEnvLogger", "level": "INFO", "message": "Action: [0.56360927 0.56360927 0.56360927 0.56360927], Velocity: (0.5636092656619562, 0.5636092656619562, 0.5636092656619562), Duration: 1.0, Reward: -2.7015705385924544, Done: False"}
{"time": "2024-07-21T15:37:28.133358", "name": "AirSimEnvLogger", "level": "INFO", "message": "Step completed. Observation keys: dict_keys(['state', 'visual'])"}
{"time": "2024-07-21T15:37:28.133358", "name": "AirSimEnvLogger", "level": "INFO", "message": "State shape: (16,), Visual shape: (144, 256, 3)"}
{"time": "2024-07-21T15:37:31.057841", "name": "AirSimEnvLogger", "level": "INFO", "message": "Predictive model loss: 0.26826566457748413"}
{"time": "2024-07-21T15:37:37.242834", "name": "AirSimEnvLogger", "level": "INFO", "message": "Reward breakdown - Distance: -9.746708396872053, Velocity: -0.0928120239054558, Movement: 0.6768146686863947, Collision: 0, Height: -1.0, Movement Penalty: -0.15630365246303096, Smoothness: -0.0, Curiosity: 11.760554313659668, Exploration: 0.3685677276949683, Total: 1.6059375191514917"}
{"time": "2024-07-21T15:37:37.369645", "name": "AirSimEnvLogger", "level": "INFO", "message": "Action: [0.78151826 0.78151826 0.78151826 0.78151826], Velocity: (0.7815182623151548, 0.7815182623151548, 0.7815182623151548), Duration: 1.0, Reward: 1.6059375191514917, Done: False"}
{"time": "2024-07-21T15:37:37.432727", "name": "AirSimEnvLogger", "level": "INFO", "message": "Step completed. Observation keys: dict_keys(['state', 'visual'])"}
{"time": "2024-07-21T15:37:37.432727", "name": "AirSimEnvLogger", "level": "INFO", "message": "State shape: (16,), Visual shape: (144, 256, 3)"}
{"time": "2024-07-21T15:37:40.434273", "name": "AirSimEnvLogger", "level": "INFO", "message": "Predictive model loss: 0.4064730405807495"}
{"time": "2024-07-21T15:37:46.128956", "name": "AirSimEnvLogger", "level": "INFO", "message": "Reward breakdown - Distance: -9.786842463819559, Velocity: -0.06298281456736445, Movement: 0.7710243497441234, Collision: 0, Height: -1.0, Movement Penalty: -0.17806044635061036, Smoothness: -0.0, Curiosity: 15.893390655517578, Exploration: 0.3218872272888035, Total: 5.69319715830658"}
{"time": "2024-07-21T15:37:46.223675", "name": "AirSimEnvLogger", "level": "INFO", "message": "Action: [0.89030223 0.89030223 0.89030223 0.89030223], Velocity: (0.8903022317530516, 0.8903022317530516, 0.8903022317530516), Duration: 1.0, Reward: 5.69319715830658, Done: False"}
{"time": "2024-07-21T15:37:46.302100", "name": "AirSimEnvLogger", "level": "INFO", "message": "Step completed. Observation keys: dict_keys(['state', 'visual'])"}
{"time": "2024-07-21T15:37:46.302100", "name": "AirSimEnvLogger", "level": "INFO", "message": "State shape: (16,), Visual shape: (144, 256, 3)"}
{"time": "2024-07-21T15:37:49.237862", "name": "AirSimEnvLogger", "level": "INFO", "message": "Predictive model loss: 0.5511857271194458"}
{"time": "2024-07-21T15:37:55.265360", "name": "AirSimEnvLogger", "level": "INFO", "message": "Reward breakdown - Distance: -9.929591990481132, Velocity: -0.12408319516400437, Movement: 0.7581166788711797, Collision: 0, Height: -1.0, Movement Penalty: -0.17507954744936827, Smoothness: -0.0, Curiosity: 18.839519500732422, Exploration: 0.27643177073695746, Total: 8.47969505932167"}
{"time": "2024-07-21T15:37:55.358287", "name": "AirSimEnvLogger", "level": "INFO", "message": "Action: [0.87539774 0.87539774 0.87539774 0.87539774], Velocity: (0.8753977372468413, 0.8753977372468413, 0.8753977372468413), Duration: 1.0, Reward: 8.47969505932167, Done: False"}
{"time": "2024-07-21T15:37:55.419911", "name": "AirSimEnvLogger", "level": "INFO", "message": "Step completed. Observation keys: dict_keys(['state', 'visual'])"}
{"time": "2024-07-21T15:37:55.419911", "name": "AirSimEnvLogger", "level": "INFO", "message": "State shape: (16,), Visual shape: (144, 256, 3)"}
{"time": "2024-07-21T15:37:58.355440", "name": "AirSimEnvLogger", "level": "INFO", "message": "Predictive model loss: 0.6697343587875366"}
{"time": "2024-07-21T15:38:04.265399", "name": "AirSimEnvLogger", "level": "INFO", "message": "Reward breakdown - Distance: -10.263634375397082, Velocity: -0.04706222143116578, Movement: 0.3436661914190566, Collision: 0, Height: -1.0, Movement Penalty: -0.07936630725086631, Smoothness: -0.0, Curiosity: 15.329765319824219, Exploration: 0.15520467254911302, Total: 4.605551910143551"}
{"time": "2024-07-21T15:38:04.312731", "name": "AirSimEnvLogger", "level": "INFO", "message": "Action: [0.39683154 0.39683154 0.39683154 0.39683154], Velocity: (0.39683153625433154, 0.39683153625433154, 0.39683153625433154), Duration: 1.0, Reward: 4.605551910143551, Done: False"}
{"time": "2024-07-21T15:38:04.374710", "name": "AirSimEnvLogger", "level": "INFO", "message": "Step completed. Observation keys: dict_keys(['state', 'visual'])"}
{"time": "2024-07-21T15:38:04.374710", "name": "AirSimEnvLogger", "level": "INFO", "message": "State shape: (16,), Visual shape: (144, 256, 3)"}
{"time": "2024-07-21T15:38:07.307769", "name": "AirSimEnvLogger", "level": "INFO", "message": "Predictive model loss: 0.5655396580696106"}
{"time": "2024-07-21T15:38:13.484145", "name": "AirSimEnvLogger", "level": "INFO", "message": "Reward breakdown - Distance: -10.33296159851296, Velocity: -0.06937604397084343, Movement: 0.523187446523115, Collision: 0, Height: -1.0, Movement Penalty: -0.12082496523470135, Smoothness: -0.0, Curiosity: 19.604522705078125, Exploration: 0.1375474253172013, Total: 8.809093169886923"}
{"time": "2024-07-21T15:38:13.595614", "name": "AirSimEnvLogger", "level": "INFO", "message": "Action: [0.60412483 0.60412483 0.60412483 0.60412483], Velocity: (0.6041248261735067, 0.6041248261735067, 0.6041248261735067), Duration: 1.0, Reward: 8.809093169886923, Done: False"}
{"time": "2024-07-21T15:38:13.656657", "name": "AirSimEnvLogger", "level": "INFO", "message": "Step completed. Observation keys: dict_keys(['state', 'visual'])"}
{"time": "2024-07-21T15:38:13.656657", "name": "AirSimEnvLogger", "level": "INFO", "message": "State shape: (16,), Visual shape: (144, 256, 3)"}
{"time": "2024-07-21T15:38:16.435651", "name": "AirSimEnvLogger", "level": "INFO", "message": "Predictive model loss: 0.672691285610199"}
{"time": "2024-07-21T15:38:22.791926", "name": "AirSimEnvLogger", "level": "INFO", "message": "Reward breakdown - Distance: -10.39211654039433, Velocity: -0.1140687740663304, Movement: 0.6879068032293478, Collision: 0, Height: -1.0, Movement Penalty: -0.15886527120873556, Smoothness: -0.0, Curiosity: 25.361896514892578, Exploration: 0.28762792171149937, Total: 14.541401835933"}
{"time": "2024-07-21T15:38:22.823498", "name": "AirSimEnvLogger", "level": "INFO", "message": "Action: [0.79432636 0.79432636 0.79432636 0.79432636], Velocity: (0.7943263560436777, 0.7943263560436777, 0.7943263560436777), Duration: 1.0, Reward: 14.541401835933, Done: False"}
{"time": "2024-07-21T15:38:22.871575", "name": "AirSimEnvLogger", "level": "INFO", "message": "Step completed. Observation keys: dict_keys(['state', 'visual'])"}
{"time": "2024-07-21T15:38:22.871575", "name": "AirSimEnvLogger", "level": "INFO", "message": "State shape: (16,), Visual shape: (144, 256, 3)"}
{"time": "2024-07-21T15:38:25.757153", "name": "AirSimEnvLogger", "level": "INFO", "message": "Predictive model loss: 0.8138813376426697"}
{"time": "2024-07-21T15:38:31.673357", "name": "AirSimEnvLogger", "level": "INFO", "message": "Reward breakdown - Distance: -10.548297300577307, Velocity: -0.08558847229069358, Movement: 0.6905872598186416, Collision: 0, Height: -1.0, Movement Penalty: -0.1594842961420875, Smoothness: -0.0, Curiosity: 29.304359436035156, Exploration: 0.27416499449400933, Total: 18.32750130526597"}
{"time": "2024-07-21T15:38:31.783460", "name": "AirSimEnvLogger", "level": "INFO", "message": "Action: [0.79742148 0.79742148 0.79742148 0.79742148], Velocity: (0.7974214807104375, 0.7974214807104375, 0.7974214807104375), Duration: 1.0, Reward: 18.32750130526597, Done: False"}
{"time": "2024-07-21T15:38:31.846273", "name": "AirSimEnvLogger", "level": "INFO", "message": "Step completed. Observation keys: dict_keys(['state', 'visual'])"}
{"time": "2024-07-21T15:38:31.846273", "name": "AirSimEnvLogger", "level": "INFO", "message": "State shape: (16,), Visual shape: (144, 256, 3)"}
{"time": "2024-07-21T15:38:34.543898", "name": "AirSimEnvLogger", "level": "INFO", "message": "Predictive model loss: 0.8832322359085083"}
{"time": "2024-07-21T15:38:40.798280", "name": "AirSimEnvLogger", "level": "INFO", "message": "Reward breakdown - Distance: -10.717868990196664, Velocity: -0.10713322142737704, Movement: 0.774999480865727, Collision: 0, Height: -1.0, Movement Penalty: -0.17897846355985908, Smoothness: -0.0, Curiosity: 35.26026153564453, Exploration: 0.2650524687817851, Total: 24.111651986666214"}
{"time": "2024-07-21T15:38:40.939404", "name": "AirSimEnvLogger", "level": "INFO", "message": "Action: [0.89489232 0.89489232 0.89489232 0.89489232], Velocity: (0.8948923177992953, 0.8948923177992953, 0.8948923177992953), Duration: 1.0, Reward: 24.111651986666214, Done: False"}
{"time": "2024-07-21T15:38:40.987014", "name": "AirSimEnvLogger", "level": "INFO", "message": "Step completed. Observation keys: dict_keys(['state', 'visual'])"}
{"time": "2024-07-21T15:38:40.987014", "name": "AirSimEnvLogger", "level": "INFO", "message": "State shape: (16,), Visual shape: (144, 256, 3)"}
{"time": "2024-07-21T15:38:43.959238", "name": "AirSimEnvLogger", "level": "INFO", "message": "Predictive model loss: 0.9865942001342773"}
{"time": "2024-07-21T15:38:49.912538", "name": "AirSimEnvLogger", "level": "INFO", "message": "Reward breakdown - Distance: -10.938298121809877, Velocity: -0.12641537302044817, Movement: 0.8183541946064129, Collision: 0, Height: -1.0, Movement Penalty: -0.18899080581938876, Smoothness: -0.0, Curiosity: 41.48979568481445, Exploration: 0.2959780429849216, Total: 30.127005159924266"}
{"time": "2024-07-21T15:38:50.022003", "name": "AirSimEnvLogger", "level": "INFO", "message": "Action: [0.94495403 0.94495403 0.94495403 0.94495403], Velocity: (0.9449540290969438, 0.9449540290969438, 0.9449540290969438), Duration: 1.0, Reward: 30.127005159924266, Done: False"}
{"time": "2024-07-21T15:38:50.100811", "name": "AirSimEnvLogger", "level": "INFO", "message": "Step completed. Observation keys: dict_keys(['state', 'visual'])"}
{"time": "2024-07-21T15:38:50.100811", "name": "AirSimEnvLogger", "level": "INFO", "message": "State shape: (16,), Visual shape: (144, 256, 3)"}
{"time": "2024-07-21T15:38:52.993110", "name": "AirSimEnvLogger", "level": "INFO", "message": "Predictive model loss: 1.0623544454574585"}
{"time": "2024-07-21T15:38:58.967814", "name": "AirSimEnvLogger", "level": "INFO", "message": "Reward breakdown - Distance: -11.189283326745809, Velocity: -0.10468069653816107, Movement: 0.8359223584918374, Collision: 0, Height: -1.0, Movement Penalty: -0.19304799947875567, Smoothness: -0.0, Curiosity: 47.709228515625, Exploration: 0.2918542569775246, Total: 36.09710872877969"}
{"time": "2024-07-21T15:38:59.046490", "name": "AirSimEnvLogger", "level": "INFO", "message": "Action: [0.96524 0.96524 0.96524 0.96524], Velocity: (0.9652399973937783, 0.9652399973937783, 0.9652399973937783), Duration: 1.0, Reward: 36.09710872877969, Done: False"}
{"time": "2024-07-21T15:38:59.078038", "name": "AirSimEnvLogger", "level": "INFO", "message": "Step completed. Observation keys: dict_keys(['state', 'visual'])"}
{"time": "2024-07-21T15:38:59.078038", "name": "AirSimEnvLogger", "level": "INFO", "message": "State shape: (16,), Visual shape: (144, 256, 3)"}
{"time": "2024-07-21T15:39:01.943753", "name": "AirSimEnvLogger", "level": "INFO", "message": "Predictive model loss: 1.0951104164123535"}
{"time": "2024-07-21T15:39:07.865543", "name": "AirSimEnvLogger", "level": "INFO", "message": "Reward breakdown - Distance: -11.466020478113315, Velocity: -0.11306729348107648, Movement: 0.7319357904159625, Collision: 0, Height: -1.0, Movement Penalty: -0.16903333025047096, Smoothness: -0.0, Curiosity: 51.25620651245117, Exploration: 0.2456349425028487, Total: 39.353329687298405"}
{"time": "2024-07-21T15:39:07.990523", "name": "AirSimEnvLogger", "level": "INFO", "message": "Action: [0.84516665 0.84516665 0.84516665 0.84516665], Velocity: (0.8451666512523548, 0.8451666512523548, 0.8451666512523548), Duration: 1.0, Reward: 39.353329687298405, Done: False"}
{"time": "2024-07-21T15:39:08.069262", "name": "AirSimEnvLogger", "level": "INFO", "message": "Step completed. Observation keys: dict_keys(['state', 'visual'])"}
{"time": "2024-07-21T15:39:08.069262", "name": "AirSimEnvLogger", "level": "INFO", "message": "State shape: (16,), Visual shape: (144, 256, 3)"}
{"time": "2024-07-21T15:39:11.122620", "name": "AirSimEnvLogger", "level": "INFO", "message": "Predictive model loss: 1.0189988613128662"}
{"time": "2024-07-21T15:39:16.380703", "name": "AirSimEnvLogger", "level": "INFO", "message": "Reward breakdown - Distance: -11.773712479271538, Velocity: -0.008150325580048795, Movement: 0.04141967172432112, Collision: 0, Height: -1.0, Movement Penalty: -0.009565463447913092, Smoothness: -0.0, Curiosity: 41.93588638305664, Exploration: 0.23938381186902424, Total: 29.717433170274422"}
{"time": "2024-07-21T15:39:16.504174", "name": "AirSimEnvLogger", "level": "INFO", "message": "Action: [0.04782732 0.04782732 0.04782732 0.04782732], Velocity: (0.04782731723956546, 0.04782731723956546, 0.04782731723956546), Duration: 1.0, Reward: 29.717433170274422, Done: False"}
{"time": "2024-07-21T15:39:16.534577", "name": "AirSimEnvLogger", "level": "INFO", "message": "Step completed. Observation keys: dict_keys(['state', 'visual'])"}
{"time": "2024-07-21T15:39:16.534577", "name": "AirSimEnvLogger", "level": "INFO", "message": "State shape: (16,), Visual shape: (144, 256, 3)"}
{"time": "2024-07-21T15:39:19.517277", "name": "AirSimEnvLogger", "level": "INFO", "message": "Predictive model loss: 0.6103212833404541"}
{"time": "2024-07-21T15:39:25.681716", "name": "AirSimEnvLogger", "level": "INFO", "message": "Reward breakdown - Distance: -11.909801881406544, Velocity: -0.045425299134504125, Movement: 0.21791487633683515, Collision: 0, Height: -1.0, Movement Penalty: -0.05032528500539832, Smoothness: -0.0, Curiosity: 38.34402084350586, Exploration: 0.3836525992773081, Total: 26.0232619702041"}
{"time": "2024-07-21T15:39:25.805884", "name": "AirSimEnvLogger", "level": "INFO", "message": "Action: [-0.25162643 -0.25162643 -0.25162643 -0.25162643], Velocity: (-0.25162642502699156, -0.25162642502699156, -0.25162642502699156), Duration: 1.0, Reward: 26.0232619702041, Done: False"}
{"time": "2024-07-21T15:39:25.821409", "name": "AirSimEnvLogger", "level": "INFO", "message": "Step completed. Observation keys: dict_keys(['state', 'visual'])"}
{"time": "2024-07-21T15:39:25.821409", "name": "AirSimEnvLogger", "level": "INFO", "message": "State shape: (16,), Visual shape: (144, 256, 3)"}
{"time": "2024-07-21T15:39:28.375273", "name": "AirSimEnvLogger", "level": "INFO", "message": "Predictive model loss: 0.36582469940185547"}
{"time": "2024-07-21T15:39:34.463642", "name": "AirSimEnvLogger", "level": "INFO", "message": "Reward breakdown - Distance: -11.937564731579188, Velocity: -0.08797284179776198, Movement: 0.4851570859810311, Collision: 0, Height: -1.0, Movement Penalty: -0.11204222967616109, Smoothness: -0.0, Curiosity: 33.68349838256836, Exploration: 0.31489089389603003, Total: 21.32146214960475"}
{"time": "2024-07-21T15:39:34.540992", "name": "AirSimEnvLogger", "level": "INFO", "message": "Action: [-0.56021115 -0.56021115 -0.56021115 -0.56021115], Velocity: (-0.5602111483808054, -0.5602111483808054, -0.5602111483808054), Duration: 1.0, Reward: 21.32146214960475, Done: False"}
{"time": "2024-07-21T15:39:34.619001", "name": "AirSimEnvLogger", "level": "INFO", "message": "Step completed. Observation keys: dict_keys(['state', 'visual'])"}
{"time": "2024-07-21T15:39:34.619001", "name": "AirSimEnvLogger", "level": "INFO", "message": "State shape: (16,), Visual shape: (144, 256, 3)"}
{"time": "2024-07-21T15:39:37.628760", "name": "AirSimEnvLogger", "level": "INFO", "message": "Predictive model loss: 0.20378659665584564"}
{"time": "2024-07-21T15:39:43.603013", "name": "AirSimEnvLogger", "level": "INFO", "message": "Reward breakdown - Distance: -11.748593363936234, Velocity: -0.004647930958857676, Movement: 0.0419951759026203, Collision: 0, Height: -1.0, Movement Penalty: -0.009698370444817406, Smoothness: -0.0, Curiosity: 36.81371307373047, Exploration: 0.05262960986593102, Total: 24.577789866371475"}
{"time": "2024-07-21T15:39:43.742582", "name": "AirSimEnvLogger", "level": "INFO", "message": "Action: [0.04849185 0.04849185 0.04849185 0.04849185], Velocity: (0.04849185222408703, 0.04849185222408703, 0.04849185222408703), Duration: 1.0, Reward: 24.577789866371475, Done: False"}
{"time": "2024-07-21T15:39:43.805182", "name": "AirSimEnvLogger", "level": "INFO", "message": "Step completed. Observation keys: dict_keys(['state', 'visual'])"}
{"time": "2024-07-21T15:39:43.805182", "name": "AirSimEnvLogger", "level": "INFO", "message": "State shape: (16,), Visual shape: (144, 256, 3)"}
{"time": "2024-07-21T15:39:46.762336", "name": "AirSimEnvLogger", "level": "INFO", "message": "Predictive model loss: 0.12009178847074509"}
{"time": "2024-07-21T15:39:52.806585", "name": "AirSimEnvLogger", "level": "INFO", "message": "Reward breakdown - Distance: -11.689436057960004, Velocity: -0.014942918402538204, Movement: 0.08018152187785667, Collision: 0, Height: -1.0, Movement Penalty: -0.018517129296085767, Smoothness: -0.0, Curiosity: 37.74980545043945, Exploration: 0.22374076435905824, Total: 25.612302324856635"}
{"time": "2024-07-21T15:39:52.899984", "name": "AirSimEnvLogger", "level": "INFO", "message": "Action: [0.09258565 0.09258565 0.09258565 0.09258565], Velocity: (0.09258564648042883, 0.09258564648042883, 0.09258564648042883), Duration: 1.0, Reward: 25.612302324856635, Done: False"}
{"time": "2024-07-21T15:39:52.946426", "name": "AirSimEnvLogger", "level": "INFO", "message": "Step completed. Observation keys: dict_keys(['state', 'visual'])"}
{"time": "2024-07-21T15:39:52.946426", "name": "AirSimEnvLogger", "level": "INFO", "message": "State shape: (16,), Visual shape: (144, 256, 3)"}
{"time": "2024-07-21T15:39:55.960914", "name": "AirSimEnvLogger", "level": "INFO", "message": "Predictive model loss: 0.13534444570541382"}
{"time": "2024-07-21T15:40:01.995038", "name": "AirSimEnvLogger", "level": "INFO", "message": "Reward breakdown - Distance: -11.678525053843462, Velocity: -0.04270806933882148, Movement: 0.24629905542715796, Collision: 0, Height: -1.0, Movement Penalty: -0.056880330380808086, Smoothness: -0.0, Curiosity: 41.33144760131836, Exploration: 0.1340744390974007, Total: 29.185530564102816"}
{"time": "2024-07-21T15:40:02.167779", "name": "AirSimEnvLogger", "level": "INFO", "message": "Action: [0.28440165 0.28440165 0.28440165 0.28440165], Velocity: (0.28440165190404043, 0.28440165190404043, 0.28440165190404043), Duration: 1.0, Reward: 29.185530564102816, Done: False"}
{"time": "2024-07-21T15:40:02.198104", "name": "AirSimEnvLogger", "level": "INFO", "message": "Step completed. Observation keys: dict_keys(['state', 'visual'])"}
{"time": "2024-07-21T15:40:02.198104", "name": "AirSimEnvLogger", "level": "INFO", "message": "State shape: (16,), Visual shape: (144, 256, 3)"}
{"time": "2024-07-21T15:40:05.240335", "name": "AirSimEnvLogger", "level": "INFO", "message": "Predictive model loss: 0.17071551084518433"}
{"time": "2024-07-21T15:40:11.161397", "name": "AirSimEnvLogger", "level": "INFO", "message": "Reward breakdown - Distance: -11.71359810000335, Velocity: -0.06422001719428408, Movement: 0.5518150982109108, Collision: 0, Height: -1.0, Movement Penalty: -0.12743623819798766, Smoothness: -0.0, Curiosity: 49.84965515136719, Exploration: 0.27960286985124827, Total: 37.70747970436073"}
{"time": "2024-07-21T15:40:11.254889", "name": "AirSimEnvLogger", "level": "INFO", "message": "Action: [0.63718119 0.63718119 0.63718119 0.63718119], Velocity: (0.6371811909899383, 0.6371811909899383, 0.6371811909899383), Duration: 1.0, Reward: 37.70747970436073, Done: False"}
{"time": "2024-07-21T15:40:11.333479", "name": "AirSimEnvLogger", "level": "INFO", "message": "Step completed. Observation keys: dict_keys(['state', 'visual'])"}
{"time": "2024-07-21T15:40:11.333479", "name": "AirSimEnvLogger", "level": "INFO", "message": "State shape: (16,), Visual shape: (144, 256, 3)"}
{"time": "2024-07-21T15:40:14.343943", "name": "AirSimEnvLogger", "level": "INFO", "message": "Predictive model loss: 0.13559414446353912"}
{"time": "2024-07-21T15:40:20.374884", "name": "AirSimEnvLogger", "level": "INFO", "message": "Reward breakdown - Distance: -11.856851349352352, Velocity: -0.11207911069748834, Movement: 0.6907318610875743, Collision: 0, Height: -1.0, Movement Penalty: -0.1595176903747049, Smoothness: -0.0, Curiosity: 57.88017272949219, Exploration: 0.3376379737323958, Total: 45.606713818393445"}
{"time": "2024-07-21T15:40:20.516165", "name": "AirSimEnvLogger", "level": "INFO", "message": "Action: [0.79758845 0.79758845 0.79758845 0.79758845], Velocity: (0.7975884518735245, 0.7975884518735245, 0.7975884518735245), Duration: 1.0, Reward: 45.606713818393445, Done: False"}
{"time": "2024-07-21T15:40:20.595031", "name": "AirSimEnvLogger", "level": "INFO", "message": "Step completed. Observation keys: dict_keys(['state', 'visual'])"}
{"time": "2024-07-21T15:40:20.595031", "name": "AirSimEnvLogger", "level": "INFO", "message": "State shape: (16,), Visual shape: (144, 256, 3)"}
{"time": "2024-07-21T15:40:23.753255", "name": "AirSimEnvLogger", "level": "INFO", "message": "Predictive model loss: 0.07738036662340164"}
{"time": "2024-07-21T15:40:29.847614", "name": "AirSimEnvLogger", "level": "INFO", "message": "Reward breakdown - Distance: -12.0887010759276, Velocity: -0.11927994301593854, Movement: 0.7678337977910219, Collision: 0, Height: -1.0, Movement Penalty: -0.1773236199390157, Smoothness: -0.0, Curiosity: 66.11954498291016, Exploration: 0.3031180236937841, Total: 53.60746797985177"}
{"time": "2024-07-21T15:40:29.864307", "name": "AirSimEnvLogger", "level": "INFO", "message": "Action: [0.8866181 0.8866181 0.8866181 0.8866181], Velocity: (0.8866180996950783, 0.8866180996950783, 0.8866180996950783), Duration: 1.0, Reward: 53.60746797985177, Done: False"}
{"time": "2024-07-21T15:40:29.941194", "name": "AirSimEnvLogger", "level": "INFO", "message": "Step completed. Observation keys: dict_keys(['state', 'visual'])"}
{"time": "2024-07-21T15:40:29.941194", "name": "AirSimEnvLogger", "level": "INFO", "message": "State shape: (16,), Visual shape: (144, 256, 3)"}
{"time": "2024-07-21T15:40:33.004935", "name": "AirSimEnvLogger", "level": "INFO", "message": "Predictive model loss: 0.02450638823211193"}
{"time": "2024-07-21T15:40:39.094752", "name": "AirSimEnvLogger", "level": "INFO", "message": "Reward breakdown - Distance: -12.341269559671538, Velocity: -0.010754695196674161, Movement: 0.04710929214537045, Collision: 0, Height: -1.0, Movement Penalty: -0.010879425000584942, Smoothness: -0.0, Curiosity: 53.80894088745117, Exploration: 0.2074042164769075, Total: 41.015454416449714"}
{"time": "2024-07-21T15:40:39.251092", "name": "AirSimEnvLogger", "level": "INFO", "message": "Action: [-0.05439713 -0.05439713 -0.05439713 -0.05439713], Velocity: (-0.05439712500292471, -0.05439712500292471, -0.05439712500292471), Duration: 1.0, Reward: 41.015454416449714, Done: False"}
{"time": "2024-07-21T15:40:39.330287", "name": "AirSimEnvLogger", "level": "INFO", "message": "Step completed. Observation keys: dict_keys(['state', 'visual'])"}
{"time": "2024-07-21T15:40:39.330287", "name": "AirSimEnvLogger", "level": "INFO", "message": "State shape: (16,), Visual shape: (144, 256, 3)"}
{"time": "2024-07-21T15:40:42.193099", "name": "AirSimEnvLogger", "level": "INFO", "message": "Predictive model loss: 0.0649547278881073"}
{"time": "2024-07-21T15:40:48.132098", "name": "AirSimEnvLogger", "level": "INFO", "message": "Reward breakdown - Distance: -12.424485895194827, Velocity: -0.03311352461983217, Movement: 0.36900751955166244, Collision: 0, Height: -1.0, Movement Penalty: -0.08521863629845937, Smoothness: -0.0, Curiosity: 62.09170913696289, Exploration: 0.15173310370422025, Total: 49.207862237746056"}
{"time": "2024-07-21T15:40:48.241684", "name": "AirSimEnvLogger", "level": "INFO", "message": "Action: [0.42609318 0.42609318 0.42609318 0.42609318], Velocity: (0.4260931814922968, 0.4260931814922968, 0.4260931814922968), Duration: 1.0, Reward: 49.207862237746056, Done: False"}
{"time": "2024-07-21T15:40:48.304839", "name": "AirSimEnvLogger", "level": "INFO", "message": "Step completed. Observation keys: dict_keys(['state', 'visual'])"}
{"time": "2024-07-21T15:40:48.305344", "name": "AirSimEnvLogger", "level": "INFO", "message": "State shape: (16,), Visual shape: (144, 256, 3)"}
{"time": "2024-07-21T15:40:51.223652", "name": "AirSimEnvLogger", "level": "INFO", "message": "Predictive model loss: 0.010988228023052216"}
{"time": "2024-07-21T15:40:57.156852", "name": "AirSimEnvLogger", "level": "INFO", "message": "Reward breakdown - Distance: -12.520101658078964, Velocity: -0.03774630999970765, Movement: 0.270657318194963, Collision: 0, Height: -1.0, Movement Penalty: -0.06250563020720164, Smoothness: -0.0, Curiosity: 63.294742584228516, Exploration: 0.19289470089830482, Total: 50.32187128579989"}
{"time": "2024-07-21T15:40:57.298629", "name": "AirSimEnvLogger", "level": "INFO", "message": "Action: [0.31252815 0.31252815 0.31252815 0.31252815], Velocity: (0.3125281510360082, 0.3125281510360082, 0.3125281510360082), Duration: 1.0, Reward: 50.32187128579989, Done: False"}
{"time": "2024-07-21T15:40:57.378175", "name": "AirSimEnvLogger", "level": "INFO", "message": "Step completed. Observation keys: dict_keys(['state', 'visual'])"}
{"time": "2024-07-21T15:40:57.378175", "name": "AirSimEnvLogger", "level": "INFO", "message": "State shape: (16,), Visual shape: (144, 256, 3)"}
{"time": "2024-07-21T15:41:00.207142", "name": "AirSimEnvLogger", "level": "INFO", "message": "Predictive model loss: 0.008154264651238918"}
{"time": "2024-07-21T15:41:06.143939", "name": "AirSimEnvLogger", "level": "INFO", "message": "Reward breakdown - Distance: -12.651181081381475, Velocity: -0.08023716949642344, Movement: 0.5658584289020746, Collision: 0, Height: -1.0, Movement Penalty: -0.1306794064999326, Smoothness: -0.0, Curiosity: 73.27193450927734, Exploration: 0.19656177211876086, Total: 60.17181939532986"}
{"time": "2024-07-21T15:41:06.301082", "name": "AirSimEnvLogger", "level": "INFO", "message": "Action: [0.65339703 0.65339703 0.65339703 0.65339703], Velocity: (0.653397032499663, 0.653397032499663, 0.653397032499663), Duration: 1.0, Reward: 60.17181939532986, Done: False"}
{"time": "2024-07-21T15:41:06.348528", "name": "AirSimEnvLogger", "level": "INFO", "message": "Step completed. Observation keys: dict_keys(['state', 'visual'])"}
{"time": "2024-07-21T15:41:06.348528", "name": "AirSimEnvLogger", "level": "INFO", "message": "State shape: (16,), Visual shape: (144, 256, 3)"}
{"time": "2024-07-21T15:41:09.321439", "name": "AirSimEnvLogger", "level": "INFO", "message": "Predictive model loss: 0.04230218753218651"}
{"time": "2024-07-21T15:41:15.306530", "name": "AirSimEnvLogger", "level": "INFO", "message": "Reward breakdown - Distance: -12.85173464964636, Velocity: -0.11243871105453804, Movement: 0.6770106345025905, Collision: 0, Height: -1.0, Movement Penalty: -0.156348908829724, Smoothness: -0.0, Curiosity: 82.16191864013672, Exploration: 0.3193466519808606, Total: 68.88899688375601"}
{"time": "2024-07-21T15:41:15.414773", "name": "AirSimEnvLogger", "level": "INFO", "message": "Action: [0.78174454 0.78174454 0.78174454 0.78174454], Velocity: (0.7817445441486199, 0.7817445441486199, 0.7817445441486199), Duration: 1.0, Reward: 68.88899688375601, Done: False"}
{"time": "2024-07-21T15:41:15.491465", "name": "AirSimEnvLogger", "level": "INFO", "message": "Step completed. Observation keys: dict_keys(['state', 'visual'])"}
{"time": "2024-07-21T15:41:15.491465", "name": "AirSimEnvLogger", "level": "INFO", "message": "State shape: (16,), Visual shape: (144, 256, 3)"}
{"time": "2024-07-21T15:41:18.399362", "name": "AirSimEnvLogger", "level": "INFO", "message": "Predictive model loss: 0.10877823829650879"}
{"time": "2024-07-21T15:41:24.139854", "name": "AirSimEnvLogger", "level": "INFO", "message": "Reward breakdown - Distance: -13.009798732315442, Velocity: -0.012316445408699883, Movement: 0.057972959977671934, Collision: 0, Height: -1.0, Movement Penalty: -0.013388281619531317, Smoothness: -0.0, Curiosity: 70.23609924316406, Exploration: 0.16587328541471053, Total: 56.76464179554024"}
{"time": "2024-07-21T15:41:24.280698", "name": "AirSimEnvLogger", "level": "INFO", "message": "Action: [-0.06694141 -0.06694141 -0.06694141 -0.06694141], Velocity: (-0.06694140809765659, -0.06694140809765659, -0.06694140809765659), Duration: 1.0, Reward: 56.76464179554024, Done: False"}
{"time": "2024-07-21T15:41:24.342489", "name": "AirSimEnvLogger", "level": "INFO", "message": "Step completed. Observation keys: dict_keys(['state', 'visual'])"}
{"time": "2024-07-21T15:41:24.342489", "name": "AirSimEnvLogger", "level": "INFO", "message": "State shape: (16,), Visual shape: (144, 256, 3)"}
{"time": "2024-07-21T15:41:27.147261", "name": "AirSimEnvLogger", "level": "INFO", "message": "Predictive model loss: 0.04557746276259422"}
{"time": "2024-07-21T15:41:32.922233", "name": "AirSimEnvLogger", "level": "INFO", "message": "Reward breakdown - Distance: -13.076822052943537, Velocity: -0.004668529996036015, Movement: 0.03531760125974579, Collision: 0, Height: -1.0, Movement Penalty: -0.00815625063777844, Smoothness: -0.0, Curiosity: 71.61782836914062, Exploration: 0.2503430868701845, Total: 58.098984712035104"}
{"time": "2024-07-21T15:41:33.061898", "name": "AirSimEnvLogger", "level": "INFO", "message": "Action: [0.04078125 0.04078125 0.04078125 0.04078125], Velocity: (0.0407812531888922, 0.0407812531888922, 0.0407812531888922), Duration: 1.0, Reward: 58.098984712035104, Done: False"}
{"time": "2024-07-21T15:41:33.077957", "name": "AirSimEnvLogger", "level": "INFO", "message": "Step completed. Observation keys: dict_keys(['state', 'visual'])"}
{"time": "2024-07-21T15:41:33.077957", "name": "AirSimEnvLogger", "level": "INFO", "message": "State shape: (16,), Visual shape: (144, 256, 3)"}
{"time": "2024-07-21T15:41:36.074722", "name": "AirSimEnvLogger", "level": "INFO", "message": "Predictive model loss: 0.03434443846344948"}
{"time": "2024-07-21T15:41:41.846327", "name": "AirSimEnvLogger", "level": "INFO", "message": "Reward breakdown - Distance: -13.14794083562725, Velocity: -0.06596999276638357, Movement: 0.4367599645524541, Collision: 0, Height: -1.0, Movement Penalty: -0.1008653932422443, Smoothness: -0.0, Curiosity: 81.97900390625, Exploration: 0.21616104798239175, Total: 68.38489681079828"}
{"time": "2024-07-21T15:41:41.955652", "name": "AirSimEnvLogger", "level": "INFO", "message": "Action: [0.50432697 0.50432697 0.50432697 0.50432697], Velocity: (0.5043269662112215, 0.5043269662112215, 0.5043269662112215), Duration: 1.0, Reward: 68.38489681079828, Done: False"}
{"time": "2024-07-21T15:41:42.032858", "name": "AirSimEnvLogger", "level": "INFO", "message": "Step completed. Observation keys: dict_keys(['state', 'visual'])"}
{"time": "2024-07-21T15:41:42.032858", "name": "AirSimEnvLogger", "level": "INFO", "message": "State shape: (16,), Visual shape: (144, 256, 3)"}
{"time": "2024-07-21T15:41:44.966746", "name": "AirSimEnvLogger", "level": "INFO", "message": "Predictive model loss: 0.04493115469813347"}
{"time": "2024-07-21T15:41:50.970595", "name": "AirSimEnvLogger", "level": "INFO", "message": "Reward breakdown - Distance: -13.31525059206794, Velocity: -0.059911214295022115, Movement: 0.6512316840815188, Collision: 0, Height: -1.0, Movement Penalty: -0.15039551524371128, Smoothness: -0.0, Curiosity: 93.00689697265625, Exploration: 0.36797658652000004, Total: 79.28626455220797"}
{"time": "2024-07-21T15:41:51.111943", "name": "AirSimEnvLogger", "level": "INFO", "message": "Action: [0.75197758 0.75197758 0.75197758 0.75197758], Velocity: (0.7519775762185563, 0.7519775762185563, 0.7519775762185563), Duration: 1.0, Reward: 79.28626455220797, Done: False"}
{"time": "2024-07-21T15:41:51.190585", "name": "AirSimEnvLogger", "level": "INFO", "message": "Step completed. Observation keys: dict_keys(['state', 'visual'])"}
{"time": "2024-07-21T15:41:51.190585", "name": "AirSimEnvLogger", "level": "INFO", "message": "State shape: (16,), Visual shape: (144, 256, 3)"}
{"time": "2024-07-21T15:41:54.042609", "name": "AirSimEnvLogger", "level": "INFO", "message": "Predictive model loss: 0.06448247283697128"}
{"time": "2024-07-21T15:41:59.976328", "name": "AirSimEnvLogger", "level": "INFO", "message": "Reward breakdown - Distance: -13.422577546016003, Velocity: -0.009643593911179416, Movement: 0.07585668988856765, Collision: 0, Height: -1.0, Movement Penalty: -0.017518352130799397, Smoothness: -0.0, Curiosity: 80.68440246582031, Exploration: 0.12114434966070033, Total: 66.79058452135415"}
{"time": "2024-07-21T15:42:00.008918", "name": "AirSimEnvLogger", "level": "INFO", "message": "Action: [-0.08759176 -0.08759176 -0.08759176 -0.08759176], Velocity: (-0.08759176065399699, -0.08759176065399699, -0.08759176065399699), Duration: 1.0, Reward: 66.79058452135415, Done: False"}
{"time": "2024-07-21T15:42:00.070238", "name": "AirSimEnvLogger", "level": "INFO", "message": "Step completed. Observation keys: dict_keys(['state', 'visual'])"}
{"time": "2024-07-21T15:42:00.070238", "name": "AirSimEnvLogger", "level": "INFO", "message": "State shape: (16,), Visual shape: (144, 256, 3)"}
{"time": "2024-07-21T15:42:03.025488", "name": "AirSimEnvLogger", "level": "INFO", "message": "Predictive model loss: 0.011695997789502144"}
{"time": "2024-07-21T15:42:08.986845", "name": "AirSimEnvLogger", "level": "INFO", "message": "Reward breakdown - Distance: -13.427624432376888, Velocity: -0.06439831047118943, Movement: 0.4051333582114853, Collision: 0, Height: -1.0, Movement Penalty: -0.09356154136843925, Smoothness: -0.0, Curiosity: 73.27825164794922, Exploration: 0.4445055504011453, Total: 59.45636156058286"}
{"time": "2024-07-21T15:42:09.097434", "name": "AirSimEnvLogger", "level": "INFO", "message": "Action: [-0.46780771 -0.46780771 -0.46780771 -0.46780771], Velocity: (-0.46780770684219625, -0.46780770684219625, -0.46780770684219625), Duration: 1.0, Reward: 59.45636156058286, Done: False"}
{"time": "2024-07-21T15:42:09.128972", "name": "AirSimEnvLogger", "level": "INFO", "message": "Step completed. Observation keys: dict_keys(['state', 'visual'])"}
{"time": "2024-07-21T15:42:09.128972", "name": "AirSimEnvLogger", "level": "INFO", "message": "State shape: (16,), Visual shape: (144, 256, 3)"}
{"time": "2024-07-21T15:42:12.082964", "name": "AirSimEnvLogger", "level": "INFO", "message": "Predictive model loss: 0.060604456812143326"}
{"time": "2024-07-21T15:42:17.740689", "name": "AirSimEnvLogger", "level": "INFO", "message": "Reward breakdown - Distance: -13.32052854922621, Velocity: -0.08781680397194759, Movement: 0.481084492516909, Collision: 0, Height: -1.0, Movement Penalty: -0.11110170450303676, Smoothness: -0.0, Curiosity: 67.86429595947266, Exploration: 0.30276210435097034, Total: 54.116421990550826"}
{"time": "2024-07-21T15:42:17.882821", "name": "AirSimEnvLogger", "level": "INFO", "message": "Action: [-0.55550852 -0.55550852 -0.55550852 -0.55550852], Velocity: (-0.5555085225151838, -0.5555085225151838, -0.5555085225151838), Duration: 1.0, Reward: 54.116421990550826, Done: False"}
{"time": "2024-07-21T15:42:17.961150", "name": "AirSimEnvLogger", "level": "INFO", "message": "Step completed. Observation keys: dict_keys(['state', 'visual'])"}
{"time": "2024-07-21T15:42:17.961150", "name": "AirSimEnvLogger", "level": "INFO", "message": "State shape: (16,), Visual shape: (144, 256, 3)"}
{"time": "2024-07-21T15:42:20.759674", "name": "AirSimEnvLogger", "level": "INFO", "message": "Predictive model loss: 0.132494255900383"}
{"time": "2024-07-21T15:42:26.433443", "name": "AirSimEnvLogger", "level": "INFO", "message": "Reward breakdown - Distance: -13.155420044457802, Velocity: -0.06380889684697126, Movement: 0.6529779859345771, Collision: 0, Height: -1.0, Movement Penalty: -0.1507988063816911, Smoothness: -0.0, Curiosity: 60.752830505371094, Exploration: 0.2853149729788383, Total: 47.17266952985372"}
{"time": "2024-07-21T15:42:26.544321", "name": "AirSimEnvLogger", "level": "INFO", "message": "Action: [-0.75399403 -0.75399403 -0.75399403 -0.75399403], Velocity: (-0.7539940319084555, -0.7539940319084555, -0.7539940319084555), Duration: 1.0, Reward: 47.17266952985372, Done: False"}
{"time": "2024-07-21T15:42:26.589947", "name": "AirSimEnvLogger", "level": "INFO", "message": "Step completed. Observation keys: dict_keys(['state', 'visual'])"}
{"time": "2024-07-21T15:42:26.589947", "name": "AirSimEnvLogger", "level": "INFO", "message": "State shape: (16,), Visual shape: (144, 256, 3)"}
{"time": "2024-07-21T15:42:29.292441", "name": "AirSimEnvLogger", "level": "INFO", "message": "Predictive model loss: 0.2118525356054306"}
{"time": "2024-07-21T15:42:34.954251", "name": "AirSimEnvLogger", "level": "INFO", "message": "Reward breakdown - Distance: -12.978778338154914, Velocity: -0.01978017333979383, Movement: 0.10554400352260856, Collision: 0, Height: -1.0, Movement Penalty: -0.024374343538051547, Smoothness: -0.0, Curiosity: 67.76917266845703, Exploration: 0.16020960297806014, Total: 54.32785351037723"}
{"time": "2024-07-21T15:42:35.080024", "name": "AirSimEnvLogger", "level": "INFO", "message": "Action: [0.12187172 0.12187172 0.12187172 0.12187172], Velocity: (0.12187171769025773, 0.12187171769025773, 0.12187171769025773), Duration: 1.0, Reward: 54.32785351037723, Done: False"}
{"time": "2024-07-21T15:42:35.143209", "name": "AirSimEnvLogger", "level": "INFO", "message": "Step completed. Observation keys: dict_keys(['state', 'visual'])"}
{"time": "2024-07-21T15:42:35.143209", "name": "AirSimEnvLogger", "level": "INFO", "message": "State shape: (16,), Visual shape: (144, 256, 3)"}
{"time": "2024-07-21T15:42:37.498934", "name": "AirSimEnvLogger", "level": "INFO", "message": "Predictive model loss: 0.09063160419464111"}
{"time": "2024-07-21T15:42:43.290571", "name": "AirSimEnvLogger", "level": "INFO", "message": "Reward breakdown - Distance: -12.916405680042391, Velocity: -0.0034281781096229887, Movement: 0.02289889726282821, Collision: 0, Height: -1.0, Movement Penalty: -0.005288273799535781, Smoothness: -0.0, Curiosity: 66.00225067138672, Exploration: 0.2610973062503205, Total: 52.64611626268797"}
{"time": "2024-07-21T15:42:43.399700", "name": "AirSimEnvLogger", "level": "INFO", "message": "Action: [-0.02644137 -0.02644137 -0.02644137 -0.02644137], Velocity: (-0.026441368997678905, -0.026441368997678905, -0.026441368997678905), Duration: 1.0, Reward: 52.64611626268797, Done: False"}
{"time": "2024-07-21T15:42:43.431464", "name": "AirSimEnvLogger", "level": "INFO", "message": "Step completed. Observation keys: dict_keys(['state', 'visual'])"}
{"time": "2024-07-21T15:42:43.431464", "name": "AirSimEnvLogger", "level": "INFO", "message": "State shape: (16,), Visual shape: (144, 256, 3)"}
{"time": "2024-07-21T15:42:46.463013", "name": "AirSimEnvLogger", "level": "INFO", "message": "Predictive model loss: 0.04738466441631317"}
{"time": "2024-07-21T15:42:51.770832", "name": "AirSimEnvLogger", "level": "INFO", "message": "Reward breakdown - Distance: -12.952572902119352, Velocity: -0.0380258337733952, Movement: 0.40389128700240967, Collision: 0, Height: -1.0, Movement Penalty: -0.09327469730967425, Smoothness: -0.0, Curiosity: 75.87943267822266, Exploration: 0.17555122164374024, Total: 62.473341405229526"}
{"time": "2024-07-21T15:42:51.881147", "name": "AirSimEnvLogger", "level": "INFO", "message": "Action: [0.46637349 0.46637349 0.46637349 0.46637349], Velocity: (0.46637348654837124, 0.46637348654837124, 0.46637348654837124), Duration: 1.0, Reward: 62.473341405229526, Done: False"}
{"time": "2024-07-21T15:42:51.944301", "name": "AirSimEnvLogger", "level": "INFO", "message": "Step completed. Observation keys: dict_keys(['state', 'visual'])"}
{"time": "2024-07-21T15:42:51.944301", "name": "AirSimEnvLogger", "level": "INFO", "message": "State shape: (16,), Visual shape: (144, 256, 3)"}
{"time": "2024-07-21T15:42:54.622286", "name": "AirSimEnvLogger", "level": "INFO", "message": "Predictive model loss: 0.021914450451731682"}
{"time": "2024-07-21T15:43:00.514997", "name": "AirSimEnvLogger", "level": "INFO", "message": "Reward breakdown - Distance: -13.09262968367997, Velocity: -0.09146587113671896, Movement: 0.6342936457719535, Collision: 0, Height: -1.0, Movement Penalty: -0.1464838428526826, Smoothness: -0.0, Curiosity: 86.57183837890625, Exploration: 0.3769646043067744, Total: 73.07232315608489"}
{"time": "2024-07-21T15:43:00.607735", "name": "AirSimEnvLogger", "level": "INFO", "message": "Action: [0.73241921 0.73241921 0.73241921 0.73241921], Velocity: (0.7324192142634129, 0.7324192142634129, 0.7324192142634129), Duration: 1.0, Reward: 73.07232315608489, Done: False"}
{"time": "2024-07-21T15:43:00.639317", "name": "AirSimEnvLogger", "level": "INFO", "message": "Step completed. Observation keys: dict_keys(['state', 'visual'])"}
{"time": "2024-07-21T15:43:00.639317", "name": "AirSimEnvLogger", "level": "INFO", "message": "State shape: (16,), Visual shape: (144, 256, 3)"}
{"time": "2024-07-21T15:43:03.434165", "name": "AirSimEnvLogger", "level": "INFO", "message": "Predictive model loss: 0.09396776556968689"}
{"time": "2024-07-21T15:43:08.961288", "name": "AirSimEnvLogger", "level": "INFO", "message": "Reward breakdown - Distance: -13.201295426218595, Velocity: -0.011108127602422541, Movement: 0.11010237012331173, Collision: 0, Height: -1.0, Movement Penalty: -0.025427053211643937, Smoothness: -0.0, Curiosity: 74.08613586425781, Exploration: 0.11944470421098348, Total: 60.41390271245895"}
{"time": "2024-07-21T15:43:09.085554", "name": "AirSimEnvLogger", "level": "INFO", "message": "Action: [-0.12713527 -0.12713527 -0.12713527 -0.12713527], Velocity: (-0.12713526605821968, -0.12713526605821968, -0.12713526605821968), Duration: 1.0, Reward: 60.41390271245895, Done: False"}
{"time": "2024-07-21T15:43:09.148314", "name": "AirSimEnvLogger", "level": "INFO", "message": "Step completed. Observation keys: dict_keys(['state', 'visual'])"}
{"time": "2024-07-21T15:43:09.148314", "name": "AirSimEnvLogger", "level": "INFO", "message": "State shape: (16,), Visual shape: (144, 256, 3)"}
{"time": "2024-07-21T15:43:11.949705", "name": "AirSimEnvLogger", "level": "INFO", "message": "Predictive model loss: 0.04469144716858864"}
{"time": "2024-07-21T15:43:17.689603", "name": "AirSimEnvLogger", "level": "INFO", "message": "Reward breakdown - Distance: -13.29735626714909, Velocity: -0.04429920212330423, Movement: 0.311113883270859, Collision: 0, Height: -1.0, Movement Penalty: -0.07184867370202411, Smoothness: -0.0, Curiosity: 82.8777847290039, Exploration: 0.11656230328630093, Total: 69.11043947820524"}
{"time": "2024-07-21T15:43:17.799135", "name": "AirSimEnvLogger", "level": "INFO", "message": "Action: [0.35924337 0.35924337 0.35924337 0.35924337], Velocity: (0.3592433685101205, 0.3592433685101205, 0.3592433685101205), Duration: 1.0, Reward: 69.11043947820524, Done: False"}
{"time": "2024-07-21T15:43:17.877471", "name": "AirSimEnvLogger", "level": "INFO", "message": "Step completed. Observation keys: dict_keys(['state', 'visual'])"}
{"time": "2024-07-21T15:43:17.877471", "name": "AirSimEnvLogger", "level": "INFO", "message": "State shape: (16,), Visual shape: (144, 256, 3)"}
{"time": "2024-07-21T15:43:20.845965", "name": "AirSimEnvLogger", "level": "INFO", "message": "Predictive model loss: 0.11622384935617447"}
{"time": "2024-07-21T15:43:26.745505", "name": "AirSimEnvLogger", "level": "INFO", "message": "Reward breakdown - Distance: -13.403452281177673, Velocity: -0.056588930659579796, Movement: 0.41211158672777454, Collision: 0, Height: -1.0, Movement Penalty: -0.09517309421337777, Smoothness: -0.0, Curiosity: 89.07013702392578, Exploration: 0.2710201800532597, Total: 75.2334695661296"}
{"time": "2024-07-21T15:43:26.854383", "name": "AirSimEnvLogger", "level": "INFO", "message": "Action: [0.47586547 0.47586547 0.47586547 0.47586547], Velocity: (0.47586547106688887, 0.47586547106688887, 0.47586547106688887), Duration: 1.0, Reward: 75.2334695661296, Done: False"}
{"time": "2024-07-21T15:43:26.916561", "name": "AirSimEnvLogger", "level": "INFO", "message": "Step completed. Observation keys: dict_keys(['state', 'visual'])"}
{"time": "2024-07-21T15:43:26.916561", "name": "AirSimEnvLogger", "level": "INFO", "message": "State shape: (16,), Visual shape: (144, 256, 3)"}
{"time": "2024-07-21T15:43:29.847920", "name": "AirSimEnvLogger", "level": "INFO", "message": "Predictive model loss: 0.16801749169826508"}
{"time": "2024-07-21T15:43:36.030298", "name": "AirSimEnvLogger", "level": "INFO", "message": "Reward breakdown - Distance: -13.484459415948239, Velocity: -0.004452096010672549, Movement: 0.049898304113404325, Collision: 0, Height: -1.0, Movement Penalty: -0.01152351972479192, Smoothness: -0.0, Curiosity: 84.06645965576172, Exploration: 0.06084672377162793, Total: 70.09677377939336"}
{"time": "2024-07-21T15:43:36.173158", "name": "AirSimEnvLogger", "level": "INFO", "message": "Action: [0.0576176 0.0576176 0.0576176 0.0576176], Velocity: (0.0576175986239596, 0.0576175986239596, 0.0576175986239596), Duration: 1.0, Reward: 70.09677377939336, Done: False"}
{"time": "2024-07-21T15:43:36.204217", "name": "AirSimEnvLogger", "level": "INFO", "message": "Step completed. Observation keys: dict_keys(['state', 'visual'])"}
{"time": "2024-07-21T15:43:36.204723", "name": "AirSimEnvLogger", "level": "INFO", "message": "State shape: (16,), Visual shape: (144, 256, 3)"}
{"time": "2024-07-21T15:43:39.231959", "name": "AirSimEnvLogger", "level": "INFO", "message": "Predictive model loss: 0.10226933658123016"}
{"time": "2024-07-21T15:43:45.235045", "name": "AirSimEnvLogger", "level": "INFO", "message": "Reward breakdown - Distance: -13.485893030056513, Velocity: -0.07141258472595852, Movement: 0.40595230134068433, Collision: 0, Height: -1.0, Movement Penalty: -0.09375066818287686, Smoothness: -0.0, Curiosity: 75.0792465209961, Exploration: 0.3410616874055629, Total: 61.17461440866652"}
{"time": "2024-07-21T15:43:45.360840", "name": "AirSimEnvLogger", "level": "INFO", "message": "Action: [-0.46875334 -0.46875334 -0.46875334 -0.46875334], Velocity: (-0.4687533409143843, -0.4687533409143843, -0.4687533409143843), Duration: 1.0, Reward: 61.17461440866652, Done: False"}
{"time": "2024-07-21T15:43:45.423164", "name": "AirSimEnvLogger", "level": "INFO", "message": "Step completed. Observation keys: dict_keys(['state', 'visual'])"}
{"time": "2024-07-21T15:43:45.423164", "name": "AirSimEnvLogger", "level": "INFO", "message": "State shape: (16,), Visual shape: (144, 256, 3)"}
{"time": "2024-07-21T15:43:48.431234", "name": "AirSimEnvLogger", "level": "INFO", "message": "Predictive model loss: 0.02464885637164116"}
{"time": "2024-07-21T15:43:54.514441", "name": "AirSimEnvLogger", "level": "INFO", "message": "Reward breakdown - Distance: -13.474251968270412, Velocity: -0.028934435065117114, Movement: 0.20460026672838597, Collision: 0, Height: -1.0, Movement Penalty: -0.04725040762876115, Smoothness: -0.0, Curiosity: 83.9984359741211, Exploration: 0.01180785192753137, Total: 70.0290252018151"}
{"time": "2024-07-21T15:43:54.621654", "name": "AirSimEnvLogger", "level": "INFO", "message": "Action: [0.23625204 0.23625204 0.23625204 0.23625204], Velocity: (0.23625203814380574, 0.23625203814380574, 0.23625203814380574), Duration: 1.0, Reward: 70.0290252018151, Done: False"}
{"time": "2024-07-21T15:43:54.700737", "name": "AirSimEnvLogger", "level": "INFO", "message": "Step completed. Observation keys: dict_keys(['state', 'visual'])"}
{"time": "2024-07-21T15:43:54.700737", "name": "AirSimEnvLogger", "level": "INFO", "message": "State shape: (16,), Visual shape: (144, 256, 3)"}
{"time": "2024-07-21T15:43:57.753985", "name": "AirSimEnvLogger", "level": "INFO", "message": "Predictive model loss: 0.02419404126703739"}
{"time": "2024-07-21T15:44:03.734183", "name": "AirSimEnvLogger", "level": "INFO", "message": "Reward breakdown - Distance: -13.430937535529777, Velocity: -0.032590968580894344, Movement: 0.1789233228992835, Collision: 0, Height: -1.0, Movement Penalty: -0.04132057145608147, Smoothness: -0.0, Curiosity: 77.31478118896484, Exploration: 0.08710429927934367, Total: 63.405007524889086"}
{"time": "2024-07-21T15:44:03.843944", "name": "AirSimEnvLogger", "level": "INFO", "message": "Action: [-0.20660286 -0.20660286 -0.20660286 -0.20660286], Velocity: (-0.20660285728040734, -0.20660285728040734, -0.20660285728040734), Duration: 1.0, Reward: 63.405007524889086, Done: False"}
{"time": "2024-07-21T15:44:03.875723", "name": "AirSimEnvLogger", "level": "INFO", "message": "Step completed. Observation keys: dict_keys(['state', 'visual'])"}
{"time": "2024-07-21T15:44:03.875723", "name": "AirSimEnvLogger", "level": "INFO", "message": "State shape: (16,), Visual shape: (144, 256, 3)"}
{"time": "2024-07-21T15:44:06.858208", "name": "AirSimEnvLogger", "level": "INFO", "message": "Predictive model loss: 0.0049750301986932755"}
{"time": "2024-07-21T15:44:12.896848", "name": "AirSimEnvLogger", "level": "INFO", "message": "Reward breakdown - Distance: -13.378766338748061, Velocity: -0.04889232488027132, Movement: 0.32034884574541594, Collision: 0, Height: -1.0, Movement Penalty: -0.07398139693028072, Smoothness: -0.0, Curiosity: 72.63774108886719, Exploration: 0.24679339208632478, Total: 58.81870613775017"}
{"time": "2024-07-21T15:44:13.022358", "name": "AirSimEnvLogger", "level": "INFO", "message": "Action: [-0.36990698 -0.36990698 -0.36990698 -0.36990698], Velocity: (-0.3699069846514036, -0.3699069846514036, -0.3699069846514036), Duration: 1.0, Reward: 58.81870613775017, Done: False"}
{"time": "2024-07-21T15:44:13.085907", "name": "AirSimEnvLogger", "level": "INFO", "message": "Step completed. Observation keys: dict_keys(['state', 'visual'])"}
{"time": "2024-07-21T15:44:13.085907", "name": "AirSimEnvLogger", "level": "INFO", "message": "State shape: (16,), Visual shape: (144, 256, 3)"}
{"time": "2024-07-21T15:44:16.105042", "name": "AirSimEnvLogger", "level": "INFO", "message": "Predictive model loss: 0.04087219759821892"}
{"time": "2024-07-21T15:44:21.412141", "name": "AirSimEnvLogger", "level": "INFO", "message": "Reward breakdown - Distance: -13.277797408713612, Velocity: -0.008151089897287571, Movement: 0.3852534219228595, Collision: 0, Height: -1.0, Movement Penalty: -0.08897046674135496, Smoothness: -0.0, Curiosity: 68.26104736328125, Exploration: 0.1928586783301897, Total: 54.53624258729237"}
{"time": "2024-07-21T15:44:21.475762", "name": "AirSimEnvLogger", "level": "INFO", "message": "Action: [-0.44485233 -0.44485233 -0.44485233 -0.44485233], Velocity: (-0.4448523337067748, -0.4448523337067748, -0.4448523337067748), Duration: 1.0, Reward: 54.53624258729237, Done: False"}
{"time": "2024-07-21T15:44:21.519917", "name": "AirSimEnvLogger", "level": "INFO", "message": "Step completed. Observation keys: dict_keys(['state', 'visual'])"}
{"time": "2024-07-21T15:44:21.520917", "name": "AirSimEnvLogger", "level": "INFO", "message": "State shape: (16,), Visual shape: (144, 256, 3)"}
{"time": "2024-07-21T15:44:24.380917", "name": "AirSimEnvLogger", "level": "INFO", "message": "Predictive model loss: 0.09311705082654953"}
{"time": "2024-07-21T15:44:30.626076", "name": "AirSimEnvLogger", "level": "INFO", "message": "Reward breakdown - Distance: -13.155423955712617, Velocity: -0.031951446721156976, Movement: 0.27770801731878103, Collision: 0, Height: -1.0, Movement Penalty: -0.0641339194220462, Smoothness: -0.0, Curiosity: 66.32835388183594, Exploration: 0.11159282906241347, Total: 52.702213294849166"}
{"time": "2024-07-21T15:44:30.735032", "name": "AirSimEnvLogger", "level": "INFO", "message": "Action: [-0.3206696 -0.3206696 -0.3206696 -0.3206696], Velocity: (-0.32066959711023096, -0.32066959711023096, -0.32066959711023096), Duration: 1.0, Reward: 52.702213294849166, Done: False"}
{"time": "2024-07-21T15:44:30.829703", "name": "AirSimEnvLogger", "level": "INFO", "message": "Step completed. Observation keys: dict_keys(['state', 'visual'])"}
{"time": "2024-07-21T15:44:30.829703", "name": "AirSimEnvLogger", "level": "INFO", "message": "State shape: (16,), Visual shape: (144, 256, 3)"}
{"time": "2024-07-21T15:44:33.786042", "name": "AirSimEnvLogger", "level": "INFO", "message": "Predictive model loss: 0.11639398336410522"}
{"time": "2024-07-21T15:44:39.919525", "name": "AirSimEnvLogger", "level": "INFO", "message": "Reward breakdown - Distance: -13.091674719618789, Velocity: -0.053926694720578705, Movement: 0.2923387315255986, Collision: 0, Height: -1.0, Movement Penalty: -0.06751273813634323, Smoothness: -0.0, Curiosity: 75.8900375366211, Exploration: 0.24474109119800985, Total: 62.3564316518512"}
{"time": "2024-07-21T15:44:40.076013", "name": "AirSimEnvLogger", "level": "INFO", "message": "Action: [0.33756369 0.33756369 0.33756369 0.33756369], Velocity: (0.33756369068171616, 0.33756369068171616, 0.33756369068171616), Duration: 1.0, Reward: 62.3564316518512, Done: False"}
{"time": "2024-07-21T15:44:40.139392", "name": "AirSimEnvLogger", "level": "INFO", "message": "Step completed. Observation keys: dict_keys(['state', 'visual'])"}
{"time": "2024-07-21T15:44:40.139392", "name": "AirSimEnvLogger", "level": "INFO", "message": "State shape: (16,), Visual shape: (144, 256, 3)"}
{"time": "2024-07-21T15:44:43.179320", "name": "AirSimEnvLogger", "level": "INFO", "message": "Predictive model loss: 0.04809563606977463"}
{"time": "2024-07-21T15:44:49.219378", "name": "AirSimEnvLogger", "level": "INFO", "message": "Reward breakdown - Distance: -13.109627769642051, Velocity: -0.016568699394424524, Movement: 0.08498366107766958, Collision: 0, Height: -1.0, Movement Penalty: -0.019626135839964982, Smoothness: -0.0, Curiosity: 73.98028564453125, Exploration: 0.20251773530509892, Total: 60.41766472870082"}
{"time": "2024-07-21T15:44:49.311894", "name": "AirSimEnvLogger", "level": "INFO", "message": "Action: [0.09813068 0.09813068 0.09813068 0.09813068], Velocity: (0.0981306791998249, 0.0981306791998249, 0.0981306791998249), Duration: 1.0, Reward: 60.41766472870082, Done: False"}
{"time": "2024-07-21T15:44:49.389648", "name": "AirSimEnvLogger", "level": "INFO", "message": "Step completed. Observation keys: dict_keys(['state', 'visual'])"}
{"time": "2024-07-21T15:44:49.389648", "name": "AirSimEnvLogger", "level": "INFO", "message": "State shape: (16,), Visual shape: (144, 256, 3)"}
{"time": "2024-07-21T15:44:52.269207", "name": "AirSimEnvLogger", "level": "INFO", "message": "Predictive model loss: 0.02242211066186428"}
{"time": "2024-07-21T15:44:58.566404", "name": "AirSimEnvLogger", "level": "INFO", "message": "Reward breakdown - Distance: -13.21362552935312, Velocity: -0.04727318902387965, Movement: 0.47240137060810283, Collision: 0, Height: -1.0, Movement Penalty: -0.10909642339445454, Smoothness: -0.0, Curiosity: 84.79529571533203, Exploration: 0.15392583476172664, Total: 71.12393378925962"}
{"time": "2024-07-21T15:44:58.676091", "name": "AirSimEnvLogger", "level": "INFO", "message": "Action: [0.54548212 0.54548212 0.54548212 0.54548212], Velocity: (0.5454821169722727, 0.5454821169722727, 0.5454821169722727), Duration: 1.0, Reward: 71.12393378925962, Done: False"}
{"time": "2024-07-21T15:44:58.754249", "name": "AirSimEnvLogger", "level": "INFO", "message": "Step completed. Observation keys: dict_keys(['state', 'visual'])"}
{"time": "2024-07-21T15:44:58.754249", "name": "AirSimEnvLogger", "level": "INFO", "message": "State shape: (16,), Visual shape: (144, 256, 3)"}
{"time": "2024-07-21T15:45:01.770024", "name": "AirSimEnvLogger", "level": "INFO", "message": "Predictive model loss: 0.016884515061974525"}
{"time": "2024-07-21T15:45:07.992006", "name": "AirSimEnvLogger", "level": "INFO", "message": "Reward breakdown - Distance: -13.400989128193, Velocity: -0.1177078169729651, Movement: 0.6689268235596632, Collision: 0, Height: -1.0, Movement Penalty: -0.15448203266013316, Smoothness: -0.0, Curiosity: 95.91716003417969, Exploration: 0.36309927285707655, Total: 82.1043216960148"}
{"time": "2024-07-21T15:45:08.115872", "name": "AirSimEnvLogger", "level": "INFO", "message": "Action: [0.77241016 0.77241016 0.77241016 0.77241016], Velocity: (0.7724101633006657, 0.7724101633006657, 0.7724101633006657), Duration: 1.0, Reward: 82.1043216960148, Done: False"}
{"time": "2024-07-21T15:45:08.193895", "name": "AirSimEnvLogger", "level": "INFO", "message": "Step completed. Observation keys: dict_keys(['state', 'visual'])"}
{"time": "2024-07-21T15:45:08.193895", "name": "AirSimEnvLogger", "level": "INFO", "message": "State shape: (16,), Visual shape: (144, 256, 3)"}
{"time": "2024-07-21T15:45:11.172969", "name": "AirSimEnvLogger", "level": "INFO", "message": "Predictive model loss: 0.0754832774400711"}
{"time": "2024-07-21T15:45:17.329109", "name": "AirSimEnvLogger", "level": "INFO", "message": "Reward breakdown - Distance: -13.580639329025113, Velocity: -0.05071829186025026, Movement: 0.3408100656779404, Collision: 0, Height: -1.0, Movement Penalty: -0.07870671326467718, Smoothness: -0.0, Curiosity: 93.710693359375, Exploration: 0.15145767136627103, Total: 79.66817751814068"}
{"time": "2024-07-21T15:45:17.454943", "name": "AirSimEnvLogger", "level": "INFO", "message": "Action: [0.39353357 0.39353357 0.39353357 0.39353357], Velocity: (0.3935335663233859, 0.3935335663233859, 0.3935335663233859), Duration: 1.0, Reward: 79.66817751814068, Done: False"}
{"time": "2024-07-21T15:45:17.486020", "name": "AirSimEnvLogger", "level": "INFO", "message": "Step completed. Observation keys: dict_keys(['state', 'visual'])"}
{"time": "2024-07-21T15:45:17.486020", "name": "AirSimEnvLogger", "level": "INFO", "message": "State shape: (16,), Visual shape: (144, 256, 3)"}
{"time": "2024-07-21T15:45:20.456677", "name": "AirSimEnvLogger", "level": "INFO", "message": "Predictive model loss: 0.07906585931777954"}
{"time": "2024-07-21T15:45:26.578559", "name": "AirSimEnvLogger", "level": "INFO", "message": "Reward breakdown - Distance: -13.65773732590542, Velocity: -0.03601140073813698, Movement: 0.19268681276979763, Collision: 0, Height: -1.0, Movement Penalty: -0.04449911328877348, Smoothness: -0.0, Curiosity: 84.21617889404297, Exploration: 0.29360194280833385, Total: 70.12709547205303"}
{"time": "2024-07-21T15:45:26.734455", "name": "AirSimEnvLogger", "level": "INFO", "message": "Action: [-0.22249557 -0.22249557 -0.22249557 -0.22249557], Velocity: (-0.22249556644386737, -0.22249556644386737, -0.22249556644386737), Duration: 1.0, Reward: 70.12709547205303, Done: False"}
{"time": "2024-07-21T15:45:26.811694", "name": "AirSimEnvLogger", "level": "INFO", "message": "Step completed. Observation keys: dict_keys(['state', 'visual'])"}
{"time": "2024-07-21T15:45:26.811694", "name": "AirSimEnvLogger", "level": "INFO", "message": "State shape: (16,), Visual shape: (144, 256, 3)"}
{"time": "2024-07-21T15:45:29.794469", "name": "AirSimEnvLogger", "level": "INFO", "message": "Predictive model loss: 0.03653644770383835"}
{"time": "2024-07-21T15:45:35.874630", "name": "AirSimEnvLogger", "level": "INFO", "message": "Reward breakdown - Distance: -13.602187232805024, Velocity: -0.053762958801052675, Movement: 0.5266927156880815, Collision: 0, Height: -1.0, Movement Penalty: -0.12163447247309156, Smoothness: -0.0, Curiosity: 75.7376708984375, Exploration: 0.43015763833996207, Total: 61.74196337053035"}
{"time": "2024-07-21T15:45:35.984667", "name": "AirSimEnvLogger", "level": "INFO", "message": "Action: [-0.60817236 -0.60817236 -0.60817236 -0.60817236], Velocity: (-0.6081723623654578, -0.6081723623654578, -0.6081723623654578), Duration: 1.0, Reward: 61.74196337053035, Done: False"}
{"time": "2024-07-21T15:45:36.016497", "name": "AirSimEnvLogger", "level": "INFO", "message": "Step completed. Observation keys: dict_keys(['state', 'visual'])"}
{"time": "2024-07-21T15:45:36.016497", "name": "AirSimEnvLogger", "level": "INFO", "message": "State shape: (16,), Visual shape: (144, 256, 3)"}
{"time": "2024-07-21T15:45:38.686590", "name": "AirSimEnvLogger", "level": "INFO", "message": "Predictive model loss: 0.029669880867004395"}
{"time": "2024-07-21T15:45:44.879129", "name": "AirSimEnvLogger", "level": "INFO", "message": "Reward breakdown - Distance: -13.511721154495483, Velocity: -0.01318230454412278, Movement: 0.07325235764461709, Collision: 0, Height: -1.0, Movement Penalty: -0.016916907361957768, Smoothness: -0.0, Curiosity: 78.95375061035156, Exploration: 0.086003585880233, Total: 64.9622889265434"}
{"time": "2024-07-21T15:45:45.036966", "name": "AirSimEnvLogger", "level": "INFO", "message": "Action: [-0.08458454 -0.08458454 -0.08458454 -0.08458454], Velocity: (-0.08458453680978884, -0.08458453680978884, -0.08458453680978884), Duration: 1.0, Reward: 64.9622889265434, Done: False"}
{"time": "2024-07-21T15:45:45.099313", "name": "AirSimEnvLogger", "level": "INFO", "message": "Step completed. Observation keys: dict_keys(['state', 'visual'])"}
{"time": "2024-07-21T15:45:45.099313", "name": "AirSimEnvLogger", "level": "INFO", "message": "State shape: (16,), Visual shape: (144, 256, 3)"}
{"time": "2024-07-21T15:45:48.034446", "name": "AirSimEnvLogger", "level": "INFO", "message": "Predictive model loss: 0.00861362461000681"}
{"time": "2024-07-21T15:45:53.778574", "name": "AirSimEnvLogger", "level": "INFO", "message": "Reward breakdown - Distance: -13.47573277394233, Velocity: -0.02938966704202531, Movement: 0.19028036994814734, Collision: 0, Height: -1.0, Movement Penalty: -0.043943369124425785, Smoothness: -0.0, Curiosity: 84.42588806152344, Exploration: 0.2703925609586606, Total: 70.51407417712792"}
{"time": "2024-07-21T15:45:53.842591", "name": "AirSimEnvLogger", "level": "INFO", "message": "Action: [0.21971685 0.21971685 0.21971685 0.21971685], Velocity: (0.2197168456221289, 0.2197168456221289, 0.2197168456221289), Duration: 1.0, Reward: 70.51407417712792, Done: False"}
{"time": "2024-07-21T15:45:53.918759", "name": "AirSimEnvLogger", "level": "INFO", "message": "Step completed. Observation keys: dict_keys(['state', 'visual'])"}
{"time": "2024-07-21T15:45:53.918759", "name": "AirSimEnvLogger", "level": "INFO", "message": "State shape: (16,), Visual shape: (144, 256, 3)"}
