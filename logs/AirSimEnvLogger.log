2024-07-20 15:41:14,945 - AirSimEnvLogger - INFO - Initializing AirSimEnv
2024-07-20 15:41:14,947 - AirSimEnvLogger - INFO - Configuration: {
  "learning_rate": 0.0001,
  "gamma": 0.99,
  "tau": 0.95,
  "batch_size": 64,
  "num_timesteps": 2000000,
  "ppo": {
    "learning_rate": 0.0003,
    "n_steps": 2048,
    "batch_size": 64,
    "n_epochs": 2000,
    "gamma": 0.99,
    "gae_lambda": 0.95,
    "clip_range": 0.2,
    "ent_coef": 0.01,
    "vf_coef": 0.5,
    "max_grad_norm": 0.5,
    "use_sde": true,
    "sde_sample_freq": 4,
    "tensorboard_log": "logs/tensorboard_logs/ppo_airsim_tensorboard/",
    "verbose": 1,
    "seed": null,
    "device": "auto",
    "continuous": true,
    "save_freq": 10000
  },
  "policy_network": {
    "input_size": 16,
    "hidden_layers": [
      256,
      256
    ],
    "output_size": 4,
    "use_batch_norm": true,
    "use_dropout": true,
    "dropout_rate": 0.2,
    "use_attention": true,
    "num_action_heads": 1
  },
  "critic_network": {
    "input_size": 15,
    "hidden_layers": [
      256,
      256
    ],
    "output_size": 1,
    "use_batch_norm": true,
    "use_dropout": true,
    "dropout_rate": 0.2,
    "use_attention": true
  },
  "environment": {
    "env_name": "Africa_001",
    "reward_threshold": 250,
    "max_env_steps": 1000,
    "state_dim": 15,
    "action_dim": 4,
    "reward_scale": 20,
    "proximity_threshold": 5.0,
    "collision_penalty": 25,
    "height_target": -10,
    "height_tolerance": 1.0,
    "height_penalty": 1,
    "movement_penalty": 0.5,
    "smoothness_penalty": 0.5,
    "duration": 0.1,
    "exploration_area": {
      "x_min": -1000,
      "x_max": 1000,
      "y_min": -1000,
      "y_max": 1000,
      "z_min": -100,
      "z_max": 100
    }
  },
  "exploration": {
    "strategy": "epsilon_decay",
    "initial_epsilon": 1.0,
    "min_epsilon": 0.05,
    "epsilon_decay_rate": 0.995
  },
  "model_checkpointing": {
    "checkpoint_interval": 10,
    "save_best_only": true,
    "checkpoint_dir": "models/checkpoints"
  },
  "logging": {
    "log_interval": 10,
    "log_dir": "logs/",
    "tensorboard": true,
    "tensorboard_log_dir": "logs/tensorboard_logs",
    "model_save_path": "models/saved_models"
  },
  "advanced_training_techniques": {
    "gradient_clipping": 0.5,
    "use_gae": true,
    "gae_lambda": 0.95,
    "normalize_advantages": true
  },
  "early_stopping": {
    "patience": 5
  },
  "reward_adjustments": {
    "collision_penalty": 50,
    "reward_threshold": 250
  },
  "shared_components": {
    "residual_block": {
      "input_dim": 128,
      "hidden_dim": 128,
      "dropout_rate": 0.2
    },
    "attention_layer": {
      "input_dim": 128,
      "hidden_dim": 128
    }
  },
  "icm": {
    "state_dim": 16,
    "action_dim": 3,
    "image_channels": 3,
    "image_height": 144,
    "image_width": 256,
    "cnn": {
      "conv1": {
        "out_channels": 32,
        "kernel_size": 8,
        "stride": 4
      },
      "conv2": {
        "out_channels": 64,
        "kernel_size": 4,
        "stride": 2
      },
      "conv3": {
        "out_channels": 64,
        "kernel_size": 3,
        "stride": 1
      }
    },
    "state_encoder": {
      "hidden_dim": 128
    },
    "forward_model": {
      "hidden_dim": 256
    },
    "inverse_model": {
      "hidden_dim": 256
    }
  },
  "predictive_model": {
    "learning_rate": 0.0001,
    "hidden_layers": [
      256,
      256
    ]
  },
  "hrl": {
    "use_hierarchical": true,
    "high_level_policy": {
      "input_size": 15,
      "hidden_layers": [
        256,
        256
      ],
      "output_size": 4
    },
    "sub_goal_dim": 3,
    "low_level_policy": {
      "input_size": 18,
      "hidden_layers": [
        256,
        256
      ],
      "output_size": 4
    }
  },
  "curriculum_learning": {
    "use_curriculum": true,
    "initial_difficulty": 1,
    "difficulty_increment": 1,
    "difficulty_threshold": 200
  },
  "multi_agent": {
    "use_multi_agent": true,
    "num_agents": 2,
    "hidden_layers": [
      256,
      256
    ]
  }
}
2024-07-20 15:41:15,995 - AirSimEnvLogger - INFO - PPOAgent initialization started.
2024-07-20 15:41:16,042 - AirSimEnvLogger - INFO - Using device: cpu
2024-07-20 15:41:21,320 - AirSimEnvLogger - INFO - PPOAgent initialized successfully.
2024-07-20 15:43:23,658 - AirSimEnvLogger - INFO - Initializing AirSimEnv
2024-07-20 15:43:23,660 - AirSimEnvLogger - INFO - Configuration: {
  "learning_rate": 0.0001,
  "gamma": 0.99,
  "tau": 0.95,
  "batch_size": 64,
  "num_timesteps": 2000000,
  "ppo": {
    "learning_rate": 0.0003,
    "n_steps": 2048,
    "batch_size": 64,
    "n_epochs": 2000,
    "gamma": 0.99,
    "gae_lambda": 0.95,
    "clip_range": 0.2,
    "ent_coef": 0.01,
    "vf_coef": 0.5,
    "max_grad_norm": 0.5,
    "use_sde": true,
    "sde_sample_freq": 4,
    "tensorboard_log": "logs/tensorboard_logs/ppo_airsim_tensorboard/",
    "verbose": 1,
    "seed": null,
    "device": "auto",
    "continuous": true,
    "save_freq": 10000
  },
  "policy_network": {
    "input_size": 16,
    "hidden_layers": [
      256,
      256
    ],
    "output_size": 4,
    "use_batch_norm": true,
    "use_dropout": true,
    "dropout_rate": 0.2,
    "use_attention": true,
    "num_action_heads": 1
  },
  "critic_network": {
    "input_size": 15,
    "hidden_layers": [
      256,
      256
    ],
    "output_size": 1,
    "use_batch_norm": true,
    "use_dropout": true,
    "dropout_rate": 0.2,
    "use_attention": true
  },
  "environment": {
    "env_name": "Africa_001",
    "reward_threshold": 250,
    "max_env_steps": 1000,
    "state_dim": 15,
    "action_dim": 4,
    "reward_scale": 20,
    "proximity_threshold": 5.0,
    "collision_penalty": 25,
    "height_target": -10,
    "height_tolerance": 1.0,
    "height_penalty": 1,
    "movement_penalty": 0.5,
    "smoothness_penalty": 0.5,
    "duration": 0.1,
    "exploration_area": {
      "x_min": -1000,
      "x_max": 1000,
      "y_min": -1000,
      "y_max": 1000,
      "z_min": -100,
      "z_max": 100
    }
  },
  "exploration": {
    "strategy": "epsilon_decay",
    "initial_epsilon": 1.0,
    "min_epsilon": 0.05,
    "epsilon_decay_rate": 0.995
  },
  "model_checkpointing": {
    "checkpoint_interval": 10,
    "save_best_only": true,
    "checkpoint_dir": "models/checkpoints"
  },
  "logging": {
    "log_interval": 10,
    "log_dir": "logs/",
    "tensorboard": true,
    "tensorboard_log_dir": "logs/tensorboard_logs",
    "model_save_path": "models/saved_models"
  },
  "advanced_training_techniques": {
    "gradient_clipping": 0.5,
    "use_gae": true,
    "gae_lambda": 0.95,
    "normalize_advantages": true
  },
  "early_stopping": {
    "patience": 5
  },
  "reward_adjustments": {
    "collision_penalty": 50,
    "reward_threshold": 250
  },
  "shared_components": {
    "residual_block": {
      "input_dim": 128,
      "hidden_dim": 128,
      "dropout_rate": 0.2
    },
    "attention_layer": {
      "input_dim": 128,
      "hidden_dim": 128
    }
  },
  "icm": {
    "state_dim": 16,
    "action_dim": 3,
    "image_channels": 3,
    "image_height": 144,
    "image_width": 256,
    "cnn": {
      "conv1": {
        "out_channels": 32,
        "kernel_size": 8,
        "stride": 4
      },
      "conv2": {
        "out_channels": 64,
        "kernel_size": 4,
        "stride": 2
      },
      "conv3": {
        "out_channels": 64,
        "kernel_size": 3,
        "stride": 1
      }
    },
    "state_encoder": {
      "hidden_dim": 128
    },
    "forward_model": {
      "hidden_dim": 256
    },
    "inverse_model": {
      "hidden_dim": 256
    }
  },
  "predictive_model": {
    "learning_rate": 0.0001,
    "hidden_layers": [
      256,
      256
    ]
  },
  "hrl": {
    "use_hierarchical": true,
    "high_level_policy": {
      "input_size": 15,
      "hidden_layers": [
        256,
        256
      ],
      "output_size": 4
    },
    "sub_goal_dim": 3,
    "low_level_policy": {
      "input_size": 18,
      "hidden_layers": [
        256,
        256
      ],
      "output_size": 4
    }
  },
  "curriculum_learning": {
    "use_curriculum": true,
    "initial_difficulty": 1,
    "difficulty_increment": 1,
    "difficulty_threshold": 200
  },
  "multi_agent": {
    "use_multi_agent": true,
    "num_agents": 2,
    "hidden_layers": [
      256,
      256
    ]
  }
}
2024-07-20 15:43:24,768 - AirSimEnvLogger - INFO - PPOAgent initialization started.
2024-07-20 15:43:24,817 - AirSimEnvLogger - INFO - Using device: cpu
2024-07-20 15:43:29,860 - AirSimEnvLogger - INFO - PPOAgent initialized successfully.
2024-07-20 15:44:42,634 - AirSimEnvLogger - INFO - Initializing AirSimEnv
2024-07-20 15:44:42,636 - AirSimEnvLogger - INFO - Configuration: {
  "learning_rate": 0.0001,
  "gamma": 0.99,
  "tau": 0.95,
  "batch_size": 64,
  "num_timesteps": 2000000,
  "ppo": {
    "learning_rate": 0.0003,
    "n_steps": 2048,
    "batch_size": 64,
    "n_epochs": 2000,
    "gamma": 0.99,
    "gae_lambda": 0.95,
    "clip_range": 0.2,
    "ent_coef": 0.01,
    "vf_coef": 0.5,
    "max_grad_norm": 0.5,
    "use_sde": true,
    "sde_sample_freq": 4,
    "tensorboard_log": "logs/tensorboard_logs/ppo_airsim_tensorboard/",
    "verbose": 1,
    "seed": null,
    "device": "auto",
    "continuous": true,
    "save_freq": 10000
  },
  "policy_network": {
    "input_size": 16,
    "hidden_layers": [
      256,
      256
    ],
    "output_size": 4,
    "use_batch_norm": true,
    "use_dropout": true,
    "dropout_rate": 0.2,
    "use_attention": true,
    "num_action_heads": 1
  },
  "critic_network": {
    "input_size": 15,
    "hidden_layers": [
      256,
      256
    ],
    "output_size": 1,
    "use_batch_norm": true,
    "use_dropout": true,
    "dropout_rate": 0.2,
    "use_attention": true
  },
  "environment": {
    "env_name": "Africa_001",
    "reward_threshold": 250,
    "max_env_steps": 1000,
    "state_dim": 15,
    "action_dim": 4,
    "reward_scale": 20,
    "proximity_threshold": 5.0,
    "collision_penalty": 25,
    "height_target": -10,
    "height_tolerance": 1.0,
    "height_penalty": 1,
    "movement_penalty": 0.5,
    "smoothness_penalty": 0.5,
    "duration": 0.1,
    "exploration_area": {
      "x_min": -1000,
      "x_max": 1000,
      "y_min": -1000,
      "y_max": 1000,
      "z_min": -100,
      "z_max": 100
    }
  },
  "exploration": {
    "strategy": "epsilon_decay",
    "initial_epsilon": 1.0,
    "min_epsilon": 0.05,
    "epsilon_decay_rate": 0.995
  },
  "model_checkpointing": {
    "checkpoint_interval": 10,
    "save_best_only": true,
    "checkpoint_dir": "models/checkpoints"
  },
  "logging": {
    "log_interval": 10,
    "log_dir": "logs/",
    "tensorboard": true,
    "tensorboard_log_dir": "logs/tensorboard_logs",
    "model_save_path": "models/saved_models"
  },
  "advanced_training_techniques": {
    "gradient_clipping": 0.5,
    "use_gae": true,
    "gae_lambda": 0.95,
    "normalize_advantages": true
  },
  "early_stopping": {
    "patience": 5
  },
  "reward_adjustments": {
    "collision_penalty": 50,
    "reward_threshold": 250
  },
  "shared_components": {
    "residual_block": {
      "input_dim": 128,
      "hidden_dim": 128,
      "dropout_rate": 0.2
    },
    "attention_layer": {
      "input_dim": 128,
      "hidden_dim": 128
    }
  },
  "icm": {
    "state_dim": 16,
    "action_dim": 3,
    "image_channels": 3,
    "image_height": 144,
    "image_width": 256,
    "cnn": {
      "conv1": {
        "out_channels": 32,
        "kernel_size": 8,
        "stride": 4
      },
      "conv2": {
        "out_channels": 64,
        "kernel_size": 4,
        "stride": 2
      },
      "conv3": {
        "out_channels": 64,
        "kernel_size": 3,
        "stride": 1
      }
    },
    "state_encoder": {
      "hidden_dim": 128
    },
    "forward_model": {
      "hidden_dim": 256
    },
    "inverse_model": {
      "hidden_dim": 256
    }
  },
  "predictive_model": {
    "learning_rate": 0.0001,
    "hidden_layers": [
      256,
      256
    ]
  },
  "hrl": {
    "use_hierarchical": true,
    "high_level_policy": {
      "input_size": 15,
      "hidden_layers": [
        256,
        256
      ],
      "output_size": 4
    },
    "sub_goal_dim": 3,
    "low_level_policy": {
      "input_size": 18,
      "hidden_layers": [
        256,
        256
      ],
      "output_size": 4
    }
  },
  "curriculum_learning": {
    "use_curriculum": true,
    "initial_difficulty": 1,
    "difficulty_increment": 1,
    "difficulty_threshold": 200
  },
  "multi_agent": {
    "use_multi_agent": true,
    "num_agents": 2,
    "hidden_layers": [
      256,
      256
    ]
  }
}
2024-07-20 15:44:43,621 - AirSimEnvLogger - INFO - DataVisualizer initialized with Seaborn style set to 'whitegrid'.
2024-07-20 15:44:43,667 - AirSimEnvLogger - INFO - PPOAgent initialization started.
2024-07-20 15:44:43,699 - AirSimEnvLogger - INFO - Using device: cpu
2024-07-20 15:44:49,339 - AirSimEnvLogger - INFO - PPOAgent initialized successfully.
2024-07-20 15:46:04,918 - AirSimEnvLogger - INFO - Initializing AirSimEnv
2024-07-20 15:46:04,920 - AirSimEnvLogger - INFO - Configuration: {
  "learning_rate": 0.0001,
  "gamma": 0.99,
  "tau": 0.95,
  "batch_size": 64,
  "num_timesteps": 2000000,
  "ppo": {
    "learning_rate": 0.0003,
    "n_steps": 2048,
    "batch_size": 64,
    "n_epochs": 2000,
    "gamma": 0.99,
    "gae_lambda": 0.95,
    "clip_range": 0.2,
    "ent_coef": 0.01,
    "vf_coef": 0.5,
    "max_grad_norm": 0.5,
    "use_sde": true,
    "sde_sample_freq": 4,
    "tensorboard_log": "logs/tensorboard_logs/ppo_airsim_tensorboard/",
    "verbose": 1,
    "seed": null,
    "device": "auto",
    "continuous": true,
    "save_freq": 10000
  },
  "policy_network": {
    "input_size": 16,
    "hidden_layers": [
      256,
      256
    ],
    "output_size": 4,
    "use_batch_norm": true,
    "use_dropout": true,
    "dropout_rate": 0.2,
    "use_attention": true,
    "num_action_heads": 1
  },
  "critic_network": {
    "input_size": 15,
    "hidden_layers": [
      256,
      256
    ],
    "output_size": 1,
    "use_batch_norm": true,
    "use_dropout": true,
    "dropout_rate": 0.2,
    "use_attention": true
  },
  "environment": {
    "env_name": "Africa_001",
    "reward_threshold": 250,
    "max_env_steps": 1000,
    "state_dim": 15,
    "action_dim": 4,
    "reward_scale": 20,
    "proximity_threshold": 5.0,
    "collision_penalty": 25,
    "height_target": -10,
    "height_tolerance": 1.0,
    "height_penalty": 1,
    "movement_penalty": 0.5,
    "smoothness_penalty": 0.5,
    "duration": 0.1,
    "exploration_area": {
      "x_min": -1000,
      "x_max": 1000,
      "y_min": -1000,
      "y_max": 1000,
      "z_min": -100,
      "z_max": 100
    }
  },
  "exploration": {
    "strategy": "epsilon_decay",
    "initial_epsilon": 1.0,
    "min_epsilon": 0.05,
    "epsilon_decay_rate": 0.995
  },
  "model_checkpointing": {
    "checkpoint_interval": 10,
    "save_best_only": true,
    "checkpoint_dir": "models/checkpoints"
  },
  "logging": {
    "log_interval": 10,
    "log_dir": "logs/",
    "tensorboard": true,
    "tensorboard_log_dir": "logs/tensorboard_logs",
    "model_save_path": "models/saved_models"
  },
  "advanced_training_techniques": {
    "gradient_clipping": 0.5,
    "use_gae": true,
    "gae_lambda": 0.95,
    "normalize_advantages": true
  },
  "early_stopping": {
    "patience": 5
  },
  "reward_adjustments": {
    "collision_penalty": 50,
    "reward_threshold": 250
  },
  "shared_components": {
    "residual_block": {
      "input_dim": 128,
      "hidden_dim": 128,
      "dropout_rate": 0.2
    },
    "attention_layer": {
      "input_dim": 128,
      "hidden_dim": 128
    }
  },
  "icm": {
    "state_dim": 16,
    "action_dim": 3,
    "image_channels": 3,
    "image_height": 144,
    "image_width": 256,
    "cnn": {
      "conv1": {
        "out_channels": 32,
        "kernel_size": 8,
        "stride": 4
      },
      "conv2": {
        "out_channels": 64,
        "kernel_size": 4,
        "stride": 2
      },
      "conv3": {
        "out_channels": 64,
        "kernel_size": 3,
        "stride": 1
      }
    },
    "state_encoder": {
      "hidden_dim": 128
    },
    "forward_model": {
      "hidden_dim": 256
    },
    "inverse_model": {
      "hidden_dim": 256
    }
  },
  "predictive_model": {
    "learning_rate": 0.0001,
    "hidden_layers": [
      256,
      256
    ]
  },
  "hrl": {
    "use_hierarchical": true,
    "high_level_policy": {
      "input_size": 15,
      "hidden_layers": [
        256,
        256
      ],
      "output_size": 4
    },
    "sub_goal_dim": 3,
    "low_level_policy": {
      "input_size": 18,
      "hidden_layers": [
        256,
        256
      ],
      "output_size": 4
    }
  },
  "curriculum_learning": {
    "use_curriculum": true,
    "initial_difficulty": 1,
    "difficulty_increment": 1,
    "difficulty_threshold": 200
  },
  "multi_agent": {
    "use_multi_agent": true,
    "num_agents": 2,
    "hidden_layers": [
      256,
      256
    ]
  }
}
2024-07-20 15:46:05,951 - AirSimEnvLogger - INFO - DataVisualizer initialized with Seaborn style set to 'whitegrid'.
2024-07-20 15:46:06,013 - AirSimEnvLogger - INFO - PPOAgent initialization started.
2024-07-20 15:46:06,014 - AirSimEnvLogger - INFO - Using device: cpu
2024-07-20 15:46:11,468 - AirSimEnvLogger - INFO - PPOAgent initialized successfully.
2024-07-20 15:49:28,668 - AirSimEnvLogger - INFO - Initializing AirSimEnv
2024-07-20 15:49:28,669 - AirSimEnvLogger - INFO - Configuration: {
  "learning_rate": 0.0001,
  "gamma": 0.99,
  "tau": 0.95,
  "batch_size": 64,
  "num_timesteps": 2000000,
  "ppo": {
    "learning_rate": 0.0003,
    "n_steps": 2048,
    "batch_size": 64,
    "n_epochs": 2000,
    "gamma": 0.99,
    "gae_lambda": 0.95,
    "clip_range": 0.2,
    "ent_coef": 0.01,
    "vf_coef": 0.5,
    "max_grad_norm": 0.5,
    "use_sde": true,
    "sde_sample_freq": 4,
    "tensorboard_log": "logs/tensorboard_logs/ppo_airsim_tensorboard/",
    "verbose": 1,
    "seed": null,
    "device": "auto",
    "continuous": true,
    "save_freq": 10000
  },
  "policy_network": {
    "input_size": 16,
    "hidden_layers": [
      256,
      256
    ],
    "output_size": 4,
    "use_batch_norm": true,
    "use_dropout": true,
    "dropout_rate": 0.2,
    "use_attention": true,
    "num_action_heads": 1
  },
  "critic_network": {
    "input_size": 15,
    "hidden_layers": [
      256,
      256
    ],
    "output_size": 1,
    "use_batch_norm": true,
    "use_dropout": true,
    "dropout_rate": 0.2,
    "use_attention": true
  },
  "environment": {
    "env_name": "Africa_001",
    "reward_threshold": 250,
    "max_env_steps": 1000,
    "state_dim": 15,
    "action_dim": 4,
    "reward_scale": 20,
    "proximity_threshold": 5.0,
    "collision_penalty": 25,
    "height_target": -10,
    "height_tolerance": 1.0,
    "height_penalty": 1,
    "movement_penalty": 0.5,
    "smoothness_penalty": 0.5,
    "duration": 0.1,
    "exploration_area": {
      "x_min": -1000,
      "x_max": 1000,
      "y_min": -1000,
      "y_max": 1000,
      "z_min": -100,
      "z_max": 100
    }
  },
  "exploration": {
    "strategy": "epsilon_decay",
    "initial_epsilon": 1.0,
    "min_epsilon": 0.05,
    "epsilon_decay_rate": 0.995
  },
  "model_checkpointing": {
    "checkpoint_interval": 10,
    "save_best_only": true,
    "checkpoint_dir": "models/checkpoints"
  },
  "logging": {
    "log_interval": 10,
    "log_dir": "logs/",
    "tensorboard": true,
    "tensorboard_log_dir": "logs/tensorboard_logs",
    "model_save_path": "models/saved_models"
  },
  "advanced_training_techniques": {
    "gradient_clipping": 0.5,
    "use_gae": true,
    "gae_lambda": 0.95,
    "normalize_advantages": true
  },
  "early_stopping": {
    "patience": 5
  },
  "reward_adjustments": {
    "collision_penalty": 50,
    "reward_threshold": 250
  },
  "shared_components": {
    "residual_block": {
      "input_dim": 128,
      "hidden_dim": 128,
      "dropout_rate": 0.2
    },
    "attention_layer": {
      "input_dim": 128,
      "hidden_dim": 128
    }
  },
  "icm": {
    "state_dim": 16,
    "action_dim": 3,
    "image_channels": 3,
    "image_height": 144,
    "image_width": 256,
    "cnn": {
      "conv1": {
        "out_channels": 32,
        "kernel_size": 8,
        "stride": 4
      },
      "conv2": {
        "out_channels": 64,
        "kernel_size": 4,
        "stride": 2
      },
      "conv3": {
        "out_channels": 64,
        "kernel_size": 3,
        "stride": 1
      }
    },
    "state_encoder": {
      "hidden_dim": 128
    },
    "forward_model": {
      "hidden_dim": 256
    },
    "inverse_model": {
      "hidden_dim": 256
    }
  },
  "predictive_model": {
    "learning_rate": 0.0001,
    "hidden_layers": [
      256,
      256
    ]
  },
  "hrl": {
    "use_hierarchical": true,
    "high_level_policy": {
      "input_size": 15,
      "hidden_layers": [
        256,
        256
      ],
      "output_size": 4
    },
    "sub_goal_dim": 3,
    "low_level_policy": {
      "input_size": 18,
      "hidden_layers": [
        256,
        256
      ],
      "output_size": 4
    }
  },
  "curriculum_learning": {
    "use_curriculum": true,
    "initial_difficulty": 1,
    "difficulty_increment": 1,
    "difficulty_threshold": 200
  },
  "multi_agent": {
    "use_multi_agent": true,
    "num_agents": 2,
    "hidden_layers": [
      256,
      256
    ]
  }
}
2024-07-20 15:49:29,691 - AirSimEnvLogger - INFO - DataVisualizer initialized with Seaborn style set to 'whitegrid'.
2024-07-20 15:49:29,737 - AirSimEnvLogger - INFO - PPOAgent initialization started.
2024-07-20 15:49:29,783 - AirSimEnvLogger - INFO - Using device: cpu
2024-07-20 15:49:36,026 - AirSimEnvLogger - INFO - PPOAgent initialized successfully.
2024-07-20 15:52:57,468 - AirSimEnvLogger - INFO - Initializing AirSimEnv
2024-07-20 15:52:57,469 - AirSimEnvLogger - INFO - Configuration: {
  "learning_rate": 0.0001,
  "gamma": 0.99,
  "tau": 0.95,
  "batch_size": 64,
  "num_timesteps": 2000000,
  "ppo": {
    "learning_rate": 0.0003,
    "n_steps": 2048,
    "batch_size": 64,
    "n_epochs": 2000,
    "gamma": 0.99,
    "gae_lambda": 0.95,
    "clip_range": 0.2,
    "ent_coef": 0.01,
    "vf_coef": 0.5,
    "max_grad_norm": 0.5,
    "use_sde": true,
    "sde_sample_freq": 4,
    "tensorboard_log": "logs/tensorboard_logs/ppo_airsim_tensorboard/",
    "verbose": 1,
    "seed": null,
    "device": "auto",
    "continuous": true,
    "save_freq": 10000
  },
  "policy_network": {
    "input_size": 16,
    "hidden_layers": [
      256,
      256
    ],
    "output_size": 4,
    "use_batch_norm": true,
    "use_dropout": true,
    "dropout_rate": 0.2,
    "use_attention": true,
    "num_action_heads": 1
  },
  "critic_network": {
    "input_size": 15,
    "hidden_layers": [
      256,
      256
    ],
    "output_size": 1,
    "use_batch_norm": true,
    "use_dropout": true,
    "dropout_rate": 0.2,
    "use_attention": true
  },
  "environment": {
    "env_name": "Africa_001",
    "reward_threshold": 250,
    "max_env_steps": 1000,
    "state_dim": 15,
    "action_dim": 4,
    "reward_scale": 20,
    "proximity_threshold": 5.0,
    "collision_penalty": 25,
    "height_target": -10,
    "height_tolerance": 1.0,
    "height_penalty": 1,
    "movement_penalty": 0.5,
    "smoothness_penalty": 0.5,
    "duration": 0.1,
    "exploration_area": {
      "x_min": -1000,
      "x_max": 1000,
      "y_min": -1000,
      "y_max": 1000,
      "z_min": -100,
      "z_max": 100
    }
  },
  "exploration": {
    "strategy": "epsilon_decay",
    "initial_epsilon": 1.0,
    "min_epsilon": 0.05,
    "epsilon_decay_rate": 0.995
  },
  "model_checkpointing": {
    "checkpoint_interval": 10,
    "save_best_only": true,
    "checkpoint_dir": "models/checkpoints"
  },
  "logging": {
    "log_interval": 10,
    "log_dir": "logs/",
    "tensorboard": true,
    "tensorboard_log_dir": "logs/tensorboard_logs",
    "model_save_path": "models/saved_models"
  },
  "advanced_training_techniques": {
    "gradient_clipping": 0.5,
    "use_gae": true,
    "gae_lambda": 0.95,
    "normalize_advantages": true
  },
  "early_stopping": {
    "patience": 5
  },
  "reward_adjustments": {
    "collision_penalty": 50,
    "reward_threshold": 250
  },
  "shared_components": {
    "residual_block": {
      "input_dim": 128,
      "hidden_dim": 128,
      "dropout_rate": 0.2
    },
    "attention_layer": {
      "input_dim": 128,
      "hidden_dim": 128
    }
  },
  "icm": {
    "state_dim": 16,
    "action_dim": 3,
    "image_channels": 3,
    "image_height": 144,
    "image_width": 256,
    "cnn": {
      "conv1": {
        "out_channels": 32,
        "kernel_size": 8,
        "stride": 4
      },
      "conv2": {
        "out_channels": 64,
        "kernel_size": 4,
        "stride": 2
      },
      "conv3": {
        "out_channels": 64,
        "kernel_size": 3,
        "stride": 1
      }
    },
    "state_encoder": {
      "hidden_dim": 128
    },
    "forward_model": {
      "hidden_dim": 256
    },
    "inverse_model": {
      "hidden_dim": 256
    }
  },
  "predictive_model": {
    "learning_rate": 0.0001,
    "hidden_layers": [
      256,
      256
    ]
  },
  "hrl": {
    "use_hierarchical": true,
    "high_level_policy": {
      "input_size": 15,
      "hidden_layers": [
        256,
        256
      ],
      "output_size": 4
    },
    "sub_goal_dim": 3,
    "low_level_policy": {
      "input_size": 18,
      "hidden_layers": [
        256,
        256
      ],
      "output_size": 4
    }
  },
  "curriculum_learning": {
    "use_curriculum": true,
    "initial_difficulty": 1,
    "difficulty_increment": 1,
    "difficulty_threshold": 200
  },
  "multi_agent": {
    "use_multi_agent": true,
    "num_agents": 2,
    "hidden_layers": [
      256,
      256
    ]
  }
}
2024-07-20 15:52:58,466 - AirSimEnvLogger - INFO - DataVisualizer initialized with Seaborn style set to 'whitegrid'.
2024-07-20 15:52:58,511 - AirSimEnvLogger - INFO - PPOAgent initialization started.
2024-07-20 15:52:58,559 - AirSimEnvLogger - INFO - Using device: cpu
2024-07-20 15:53:04,382 - AirSimEnvLogger - INFO - PPOAgent initialized successfully.
2024-07-20 15:55:00,562 - AirSimEnvLogger - INFO - Initializing AirSimEnv
2024-07-20 15:55:00,564 - AirSimEnvLogger - INFO - Configuration: {
  "learning_rate": 0.0001,
  "gamma": 0.99,
  "tau": 0.95,
  "batch_size": 64,
  "num_timesteps": 2000000,
  "ppo": {
    "learning_rate": 0.0003,
    "n_steps": 2048,
    "batch_size": 64,
    "n_epochs": 2000,
    "gamma": 0.99,
    "gae_lambda": 0.95,
    "clip_range": 0.2,
    "ent_coef": 0.01,
    "vf_coef": 0.5,
    "max_grad_norm": 0.5,
    "use_sde": true,
    "sde_sample_freq": 4,
    "tensorboard_log": "logs/tensorboard_logs/ppo_airsim_tensorboard/",
    "verbose": 1,
    "seed": null,
    "device": "auto",
    "continuous": true,
    "save_freq": 10000
  },
  "policy_network": {
    "input_size": 16,
    "hidden_layers": [
      256,
      256
    ],
    "output_size": 4,
    "use_batch_norm": true,
    "use_dropout": true,
    "dropout_rate": 0.2,
    "use_attention": true,
    "num_action_heads": 1
  },
  "critic_network": {
    "input_size": 15,
    "hidden_layers": [
      256,
      256
    ],
    "output_size": 1,
    "use_batch_norm": true,
    "use_dropout": true,
    "dropout_rate": 0.2,
    "use_attention": true
  },
  "environment": {
    "env_name": "Africa_001",
    "reward_threshold": 250,
    "max_env_steps": 1000,
    "state_dim": 15,
    "action_dim": 4,
    "reward_scale": 20,
    "proximity_threshold": 5.0,
    "collision_penalty": 25,
    "height_target": -10,
    "height_tolerance": 1.0,
    "height_penalty": 1,
    "movement_penalty": 0.5,
    "smoothness_penalty": 0.5,
    "duration": 0.1,
    "exploration_area": {
      "x_min": -1000,
      "x_max": 1000,
      "y_min": -1000,
      "y_max": 1000,
      "z_min": -100,
      "z_max": 100
    }
  },
  "exploration": {
    "strategy": "epsilon_decay",
    "initial_epsilon": 1.0,
    "min_epsilon": 0.05,
    "epsilon_decay_rate": 0.995
  },
  "model_checkpointing": {
    "checkpoint_interval": 10,
    "save_best_only": true,
    "checkpoint_dir": "models/checkpoints"
  },
  "logging": {
    "log_interval": 10,
    "log_dir": "logs/",
    "tensorboard": true,
    "tensorboard_log_dir": "logs/tensorboard_logs",
    "model_save_path": "models/saved_models"
  },
  "advanced_training_techniques": {
    "gradient_clipping": 0.5,
    "use_gae": true,
    "gae_lambda": 0.95,
    "normalize_advantages": true
  },
  "early_stopping": {
    "patience": 5
  },
  "reward_adjustments": {
    "collision_penalty": 50,
    "reward_threshold": 250
  },
  "shared_components": {
    "residual_block": {
      "input_dim": 128,
      "hidden_dim": 128,
      "dropout_rate": 0.2
    },
    "attention_layer": {
      "input_dim": 128,
      "hidden_dim": 128
    }
  },
  "icm": {
    "state_dim": 16,
    "action_dim": 3,
    "image_channels": 3,
    "image_height": 144,
    "image_width": 256,
    "cnn": {
      "conv1": {
        "out_channels": 32,
        "kernel_size": 8,
        "stride": 4
      },
      "conv2": {
        "out_channels": 64,
        "kernel_size": 4,
        "stride": 2
      },
      "conv3": {
        "out_channels": 64,
        "kernel_size": 3,
        "stride": 1
      }
    },
    "state_encoder": {
      "hidden_dim": 128
    },
    "forward_model": {
      "hidden_dim": 256
    },
    "inverse_model": {
      "hidden_dim": 256
    }
  },
  "predictive_model": {
    "learning_rate": 0.0001,
    "hidden_layers": [
      256,
      256
    ]
  },
  "hrl": {
    "use_hierarchical": true,
    "high_level_policy": {
      "input_size": 15,
      "hidden_layers": [
        256,
        256
      ],
      "output_size": 4
    },
    "sub_goal_dim": 3,
    "low_level_policy": {
      "input_size": 18,
      "hidden_layers": [
        256,
        256
      ],
      "output_size": 4
    }
  },
  "curriculum_learning": {
    "use_curriculum": true,
    "initial_difficulty": 1,
    "difficulty_increment": 1,
    "difficulty_threshold": 200
  },
  "multi_agent": {
    "use_multi_agent": true,
    "num_agents": 2,
    "hidden_layers": [
      256,
      256
    ]
  }
}
2024-07-20 15:55:01,598 - AirSimEnvLogger - INFO - DataVisualizer initialized with Seaborn style set to 'whitegrid'.
2024-07-20 15:55:01,645 - AirSimEnvLogger - INFO - PPOAgent initialization started.
2024-07-20 15:55:01,692 - AirSimEnvLogger - INFO - Using device: cpu
2024-07-20 15:55:06,641 - AirSimEnvLogger - INFO - PPOAgent initialized successfully.
2024-07-20 15:57:29,613 - AirSimEnvLogger - INFO - Initializing AirSimEnv
2024-07-20 15:57:29,615 - AirSimEnvLogger - INFO - Configuration: {
  "learning_rate": 0.0001,
  "gamma": 0.99,
  "tau": 0.95,
  "batch_size": 64,
  "num_timesteps": 2000000,
  "ppo": {
    "learning_rate": 0.0003,
    "n_steps": 2048,
    "batch_size": 64,
    "n_epochs": 2000,
    "gamma": 0.99,
    "gae_lambda": 0.95,
    "clip_range": 0.2,
    "ent_coef": 0.01,
    "vf_coef": 0.5,
    "max_grad_norm": 0.5,
    "use_sde": true,
    "sde_sample_freq": 4,
    "tensorboard_log": "logs/tensorboard_logs/ppo_airsim_tensorboard/",
    "verbose": 1,
    "seed": null,
    "device": "auto",
    "continuous": true,
    "save_freq": 10000
  },
  "policy_network": {
    "input_size": 16,
    "hidden_layers": [
      256,
      256
    ],
    "output_size": 4,
    "use_batch_norm": true,
    "use_dropout": true,
    "dropout_rate": 0.2,
    "use_attention": true,
    "num_action_heads": 1
  },
  "critic_network": {
    "input_size": 15,
    "hidden_layers": [
      256,
      256
    ],
    "output_size": 1,
    "use_batch_norm": true,
    "use_dropout": true,
    "dropout_rate": 0.2,
    "use_attention": true
  },
  "environment": {
    "env_name": "Africa_001",
    "reward_threshold": 250,
    "max_env_steps": 1000,
    "state_dim": 15,
    "action_dim": 4,
    "reward_scale": 20,
    "proximity_threshold": 5.0,
    "collision_penalty": 25,
    "height_target": -10,
    "height_tolerance": 1.0,
    "height_penalty": 1,
    "movement_penalty": 0.5,
    "smoothness_penalty": 0.5,
    "duration": 0.1,
    "exploration_area": {
      "x_min": -1000,
      "x_max": 1000,
      "y_min": -1000,
      "y_max": 1000,
      "z_min": -100,
      "z_max": 100
    }
  },
  "exploration": {
    "strategy": "epsilon_decay",
    "initial_epsilon": 1.0,
    "min_epsilon": 0.05,
    "epsilon_decay_rate": 0.995
  },
  "model_checkpointing": {
    "checkpoint_interval": 10,
    "save_best_only": true,
    "checkpoint_dir": "models/checkpoints"
  },
  "logging": {
    "log_interval": 10,
    "log_dir": "logs/",
    "tensorboard": true,
    "tensorboard_log_dir": "logs/tensorboard_logs",
    "model_save_path": "models/saved_models"
  },
  "advanced_training_techniques": {
    "gradient_clipping": 0.5,
    "use_gae": true,
    "gae_lambda": 0.95,
    "normalize_advantages": true
  },
  "early_stopping": {
    "patience": 5
  },
  "reward_adjustments": {
    "collision_penalty": 50,
    "reward_threshold": 250
  },
  "shared_components": {
    "residual_block": {
      "input_dim": 128,
      "hidden_dim": 128,
      "dropout_rate": 0.2
    },
    "attention_layer": {
      "input_dim": 128,
      "hidden_dim": 128
    }
  },
  "icm": {
    "state_dim": 16,
    "action_dim": 3,
    "image_channels": 3,
    "image_height": 144,
    "image_width": 256,
    "cnn": {
      "conv1": {
        "out_channels": 32,
        "kernel_size": 8,
        "stride": 4
      },
      "conv2": {
        "out_channels": 64,
        "kernel_size": 4,
        "stride": 2
      },
      "conv3": {
        "out_channels": 64,
        "kernel_size": 3,
        "stride": 1
      }
    },
    "state_encoder": {
      "hidden_dim": 128
    },
    "forward_model": {
      "hidden_dim": 256
    },
    "inverse_model": {
      "hidden_dim": 256
    }
  },
  "predictive_model": {
    "learning_rate": 0.0001,
    "hidden_layers": [
      256,
      256
    ]
  },
  "hrl": {
    "use_hierarchical": true,
    "high_level_policy": {
      "input_size": 15,
      "hidden_layers": [
        256,
        256
      ],
      "output_size": 4
    },
    "sub_goal_dim": 3,
    "low_level_policy": {
      "input_size": 18,
      "hidden_layers": [
        256,
        256
      ],
      "output_size": 4
    }
  },
  "curriculum_learning": {
    "use_curriculum": true,
    "initial_difficulty": 1,
    "difficulty_increment": 1,
    "difficulty_threshold": 200
  },
  "multi_agent": {
    "use_multi_agent": true,
    "num_agents": 2,
    "hidden_layers": [
      256,
      256
    ]
  }
}
2024-07-20 15:57:31,253 - AirSimEnvLogger - ERROR - Error initializing policy network: mat1 and mat2 shapes cannot be multiplied (1x36864 and 9216x4096)
2024-07-20 16:00:14,043 - AirSimEnvLogger - INFO - Initializing AirSimEnv
2024-07-20 16:00:14,044 - AirSimEnvLogger - INFO - Configuration: {
  "learning_rate": 0.0001,
  "gamma": 0.99,
  "tau": 0.95,
  "batch_size": 64,
  "num_timesteps": 2000000,
  "ppo": {
    "learning_rate": 0.0003,
    "n_steps": 2048,
    "batch_size": 64,
    "n_epochs": 2000,
    "gamma": 0.99,
    "gae_lambda": 0.95,
    "clip_range": 0.2,
    "ent_coef": 0.01,
    "vf_coef": 0.5,
    "max_grad_norm": 0.5,
    "use_sde": true,
    "sde_sample_freq": 4,
    "tensorboard_log": "logs/tensorboard_logs/ppo_airsim_tensorboard/",
    "verbose": 1,
    "seed": null,
    "device": "auto",
    "continuous": true,
    "save_freq": 10000
  },
  "policy_network": {
    "input_size": 16,
    "hidden_layers": [
      256,
      256
    ],
    "output_size": 4,
    "use_batch_norm": true,
    "use_dropout": true,
    "dropout_rate": 0.2,
    "use_attention": true,
    "num_action_heads": 1
  },
  "critic_network": {
    "input_size": 15,
    "hidden_layers": [
      256,
      256
    ],
    "output_size": 1,
    "use_batch_norm": true,
    "use_dropout": true,
    "dropout_rate": 0.2,
    "use_attention": true
  },
  "environment": {
    "env_name": "Africa_001",
    "reward_threshold": 250,
    "max_env_steps": 1000,
    "state_dim": 15,
    "action_dim": 4,
    "reward_scale": 20,
    "proximity_threshold": 5.0,
    "collision_penalty": 25,
    "height_target": -10,
    "height_tolerance": 1.0,
    "height_penalty": 1,
    "movement_penalty": 0.5,
    "smoothness_penalty": 0.5,
    "duration": 0.1,
    "exploration_area": {
      "x_min": -1000,
      "x_max": 1000,
      "y_min": -1000,
      "y_max": 1000,
      "z_min": -100,
      "z_max": 100
    }
  },
  "exploration": {
    "strategy": "epsilon_decay",
    "initial_epsilon": 1.0,
    "min_epsilon": 0.05,
    "epsilon_decay_rate": 0.995
  },
  "model_checkpointing": {
    "checkpoint_interval": 10,
    "save_best_only": true,
    "checkpoint_dir": "models/checkpoints"
  },
  "logging": {
    "log_interval": 10,
    "log_dir": "logs/",
    "tensorboard": true,
    "tensorboard_log_dir": "logs/tensorboard_logs",
    "model_save_path": "models/saved_models"
  },
  "advanced_training_techniques": {
    "gradient_clipping": 0.5,
    "use_gae": true,
    "gae_lambda": 0.95,
    "normalize_advantages": true
  },
  "early_stopping": {
    "patience": 5
  },
  "reward_adjustments": {
    "collision_penalty": 50,
    "reward_threshold": 250
  },
  "shared_components": {
    "residual_block": {
      "input_dim": 128,
      "hidden_dim": 128,
      "dropout_rate": 0.2
    },
    "attention_layer": {
      "input_dim": 128,
      "hidden_dim": 128
    }
  },
  "icm": {
    "state_dim": 16,
    "action_dim": 3,
    "image_channels": 3,
    "image_height": 144,
    "image_width": 256,
    "cnn": {
      "conv1": {
        "out_channels": 32,
        "kernel_size": 8,
        "stride": 4
      },
      "conv2": {
        "out_channels": 64,
        "kernel_size": 4,
        "stride": 2
      },
      "conv3": {
        "out_channels": 64,
        "kernel_size": 3,
        "stride": 1
      }
    },
    "state_encoder": {
      "hidden_dim": 128
    },
    "forward_model": {
      "hidden_dim": 256
    },
    "inverse_model": {
      "hidden_dim": 256
    }
  },
  "predictive_model": {
    "learning_rate": 0.0001,
    "hidden_layers": [
      256,
      256
    ]
  },
  "hrl": {
    "use_hierarchical": true,
    "high_level_policy": {
      "input_size": 15,
      "hidden_layers": [
        256,
        256
      ],
      "output_size": 4
    },
    "sub_goal_dim": 3,
    "low_level_policy": {
      "input_size": 18,
      "hidden_layers": [
        256,
        256
      ],
      "output_size": 4
    }
  },
  "curriculum_learning": {
    "use_curriculum": true,
    "initial_difficulty": 1,
    "difficulty_increment": 1,
    "difficulty_threshold": 200
  },
  "multi_agent": {
    "use_multi_agent": true,
    "num_agents": 2,
    "hidden_layers": [
      256,
      256
    ]
  }
}
2024-07-20 16:00:15,167 - AirSimEnvLogger - INFO - DataVisualizer initialized with Seaborn style set to 'whitegrid'.
2024-07-20 16:00:15,199 - AirSimEnvLogger - INFO - PPOAgent initialization started.
2024-07-20 16:00:15,246 - AirSimEnvLogger - INFO - Using device: cpu
2024-07-20 16:00:20,838 - AirSimEnvLogger - INFO - PPOAgent initialized successfully.
2024-07-20 16:01:41,026 - AirSimEnvLogger - INFO - Initializing AirSimEnv
2024-07-20 16:01:41,027 - AirSimEnvLogger - INFO - Configuration: {
  "learning_rate": 0.0001,
  "gamma": 0.99,
  "tau": 0.95,
  "batch_size": 64,
  "num_timesteps": 2000000,
  "ppo": {
    "learning_rate": 0.0003,
    "n_steps": 2048,
    "batch_size": 64,
    "n_epochs": 2000,
    "gamma": 0.99,
    "gae_lambda": 0.95,
    "clip_range": 0.2,
    "ent_coef": 0.01,
    "vf_coef": 0.5,
    "max_grad_norm": 0.5,
    "use_sde": true,
    "sde_sample_freq": 4,
    "tensorboard_log": "logs/tensorboard_logs/ppo_airsim_tensorboard/",
    "verbose": 1,
    "seed": null,
    "device": "auto",
    "continuous": true,
    "save_freq": 10000
  },
  "policy_network": {
    "input_size": 16,
    "hidden_layers": [
      256,
      256
    ],
    "output_size": 4,
    "use_batch_norm": true,
    "use_dropout": true,
    "dropout_rate": 0.2,
    "use_attention": true,
    "num_action_heads": 1
  },
  "critic_network": {
    "input_size": 15,
    "hidden_layers": [
      256,
      256
    ],
    "output_size": 1,
    "use_batch_norm": true,
    "use_dropout": true,
    "dropout_rate": 0.2,
    "use_attention": true
  },
  "environment": {
    "env_name": "Africa_001",
    "reward_threshold": 250,
    "max_env_steps": 1000,
    "state_dim": 15,
    "action_dim": 4,
    "reward_scale": 20,
    "proximity_threshold": 5.0,
    "collision_penalty": 25,
    "height_target": -10,
    "height_tolerance": 1.0,
    "height_penalty": 1,
    "movement_penalty": 0.5,
    "smoothness_penalty": 0.5,
    "duration": 0.1,
    "exploration_area": {
      "x_min": -1000,
      "x_max": 1000,
      "y_min": -1000,
      "y_max": 1000,
      "z_min": -100,
      "z_max": 100
    }
  },
  "exploration": {
    "strategy": "epsilon_decay",
    "initial_epsilon": 1.0,
    "min_epsilon": 0.05,
    "epsilon_decay_rate": 0.995
  },
  "model_checkpointing": {
    "checkpoint_interval": 10,
    "save_best_only": true,
    "checkpoint_dir": "models/checkpoints"
  },
  "logging": {
    "log_interval": 10,
    "log_dir": "logs/",
    "tensorboard": true,
    "tensorboard_log_dir": "logs/tensorboard_logs",
    "model_save_path": "models/saved_models"
  },
  "advanced_training_techniques": {
    "gradient_clipping": 0.5,
    "use_gae": true,
    "gae_lambda": 0.95,
    "normalize_advantages": true
  },
  "early_stopping": {
    "patience": 5
  },
  "reward_adjustments": {
    "collision_penalty": 50,
    "reward_threshold": 250
  },
  "shared_components": {
    "residual_block": {
      "input_dim": 128,
      "hidden_dim": 128,
      "dropout_rate": 0.2
    },
    "attention_layer": {
      "input_dim": 128,
      "hidden_dim": 128
    }
  },
  "icm": {
    "state_dim": 16,
    "action_dim": 3,
    "image_channels": 3,
    "image_height": 144,
    "image_width": 256,
    "cnn": {
      "conv1": {
        "out_channels": 32,
        "kernel_size": 8,
        "stride": 4
      },
      "conv2": {
        "out_channels": 64,
        "kernel_size": 4,
        "stride": 2
      },
      "conv3": {
        "out_channels": 64,
        "kernel_size": 3,
        "stride": 1
      }
    },
    "state_encoder": {
      "hidden_dim": 128
    },
    "forward_model": {
      "hidden_dim": 256
    },
    "inverse_model": {
      "hidden_dim": 256
    }
  },
  "predictive_model": {
    "learning_rate": 0.0001,
    "hidden_layers": [
      256,
      256
    ]
  },
  "hrl": {
    "use_hierarchical": true,
    "high_level_policy": {
      "input_size": 15,
      "hidden_layers": [
        256,
        256
      ],
      "output_size": 4
    },
    "sub_goal_dim": 3,
    "low_level_policy": {
      "input_size": 18,
      "hidden_layers": [
        256,
        256
      ],
      "output_size": 4
    }
  },
  "curriculum_learning": {
    "use_curriculum": true,
    "initial_difficulty": 1,
    "difficulty_increment": 1,
    "difficulty_threshold": 200
  },
  "multi_agent": {
    "use_multi_agent": true,
    "num_agents": 2,
    "hidden_layers": [
      256,
      256
    ]
  }
}
2024-07-20 16:01:42,224 - AirSimEnvLogger - INFO - DataVisualizer initialized with Seaborn style set to 'whitegrid'.
2024-07-20 16:01:42,270 - AirSimEnvLogger - INFO - PPOAgent initialization started.
2024-07-20 16:01:42,315 - AirSimEnvLogger - INFO - Using device: cpu
2024-07-20 16:01:48,090 - AirSimEnvLogger - INFO - PPOAgent initialized successfully.
2024-07-20 16:05:16,629 - AirSimEnvLogger - INFO - Initializing AirSimEnv
2024-07-20 16:05:16,631 - AirSimEnvLogger - INFO - Configuration: {
  "learning_rate": 0.0001,
  "gamma": 0.99,
  "tau": 0.95,
  "batch_size": 64,
  "num_timesteps": 2000000,
  "ppo": {
    "learning_rate": 0.0003,
    "n_steps": 2048,
    "batch_size": 64,
    "n_epochs": 2000,
    "gamma": 0.99,
    "gae_lambda": 0.95,
    "clip_range": 0.2,
    "ent_coef": 0.01,
    "vf_coef": 0.5,
    "max_grad_norm": 0.5,
    "use_sde": true,
    "sde_sample_freq": 4,
    "tensorboard_log": "logs/tensorboard_logs/ppo_airsim_tensorboard/",
    "verbose": 1,
    "seed": null,
    "device": "auto",
    "continuous": true,
    "save_freq": 10000
  },
  "policy_network": {
    "input_size": 16,
    "hidden_layers": [
      256,
      256
    ],
    "output_size": 4,
    "use_batch_norm": true,
    "use_dropout": true,
    "dropout_rate": 0.2,
    "use_attention": true,
    "num_action_heads": 1
  },
  "critic_network": {
    "input_size": 15,
    "hidden_layers": [
      256,
      256
    ],
    "output_size": 1,
    "use_batch_norm": true,
    "use_dropout": true,
    "dropout_rate": 0.2,
    "use_attention": true
  },
  "environment": {
    "env_name": "Africa_001",
    "reward_threshold": 250,
    "max_env_steps": 1000,
    "state_dim": 15,
    "action_dim": 4,
    "reward_scale": 20,
    "proximity_threshold": 5.0,
    "collision_penalty": 25,
    "height_target": -10,
    "height_tolerance": 1.0,
    "height_penalty": 1,
    "movement_penalty": 0.5,
    "smoothness_penalty": 0.5,
    "duration": 0.1,
    "exploration_area": {
      "x_min": -1000,
      "x_max": 1000,
      "y_min": -1000,
      "y_max": 1000,
      "z_min": -100,
      "z_max": 100
    }
  },
  "exploration": {
    "strategy": "epsilon_decay",
    "initial_epsilon": 1.0,
    "min_epsilon": 0.05,
    "epsilon_decay_rate": 0.995
  },
  "model_checkpointing": {
    "checkpoint_interval": 10,
    "save_best_only": true,
    "checkpoint_dir": "models/checkpoints"
  },
  "logging": {
    "log_interval": 10,
    "log_dir": "logs/",
    "tensorboard": true,
    "tensorboard_log_dir": "logs/tensorboard_logs",
    "model_save_path": "models/saved_models"
  },
  "advanced_training_techniques": {
    "gradient_clipping": 0.5,
    "use_gae": true,
    "gae_lambda": 0.95,
    "normalize_advantages": true
  },
  "early_stopping": {
    "patience": 5
  },
  "reward_adjustments": {
    "collision_penalty": 50,
    "reward_threshold": 250
  },
  "shared_components": {
    "residual_block": {
      "input_dim": 128,
      "hidden_dim": 128,
      "dropout_rate": 0.2
    },
    "attention_layer": {
      "input_dim": 128,
      "hidden_dim": 128
    }
  },
  "icm": {
    "state_dim": 16,
    "action_dim": 3,
    "image_channels": 3,
    "image_height": 144,
    "image_width": 256,
    "cnn": {
      "conv1": {
        "out_channels": 32,
        "kernel_size": 8,
        "stride": 4
      },
      "conv2": {
        "out_channels": 64,
        "kernel_size": 4,
        "stride": 2
      },
      "conv3": {
        "out_channels": 64,
        "kernel_size": 3,
        "stride": 1
      }
    },
    "state_encoder": {
      "hidden_dim": 128
    },
    "forward_model": {
      "hidden_dim": 256
    },
    "inverse_model": {
      "hidden_dim": 256
    }
  },
  "predictive_model": {
    "learning_rate": 0.0001,
    "hidden_layers": [
      256,
      256
    ]
  },
  "hrl": {
    "use_hierarchical": true,
    "high_level_policy": {
      "input_size": 15,
      "hidden_layers": [
        256,
        256
      ],
      "output_size": 4
    },
    "sub_goal_dim": 3,
    "low_level_policy": {
      "input_size": 18,
      "hidden_layers": [
        256,
        256
      ],
      "output_size": 4
    }
  },
  "curriculum_learning": {
    "use_curriculum": true,
    "initial_difficulty": 1,
    "difficulty_increment": 1,
    "difficulty_threshold": 200
  },
  "multi_agent": {
    "use_multi_agent": true,
    "num_agents": 2,
    "hidden_layers": [
      256,
      256
    ]
  }
}
2024-07-20 16:05:17,796 - AirSimEnvLogger - INFO - DataVisualizer initialized with Seaborn style set to 'whitegrid'.
2024-07-20 16:05:17,841 - AirSimEnvLogger - INFO - PPOAgent initialization started.
2024-07-20 16:05:17,887 - AirSimEnvLogger - INFO - State dimension: 16
2024-07-20 16:05:17,919 - AirSimEnvLogger - INFO - Visual dimensions: 84x84x4
2024-07-20 16:05:17,965 - AirSimEnvLogger - INFO - Using device: cpu
2024-07-20 16:05:23,547 - AirSimEnvLogger - INFO - PPOAgent initialized successfully.
2024-07-20 16:07:24,306 - AirSimEnvLogger - INFO - Initializing AirSimEnv
2024-07-20 16:07:24,307 - AirSimEnvLogger - INFO - Configuration: {
  "learning_rate": 0.0001,
  "gamma": 0.99,
  "tau": 0.95,
  "batch_size": 64,
  "num_timesteps": 2000000,
  "ppo": {
    "learning_rate": 0.0003,
    "n_steps": 2048,
    "batch_size": 64,
    "n_epochs": 2000,
    "gamma": 0.99,
    "gae_lambda": 0.95,
    "clip_range": 0.2,
    "ent_coef": 0.01,
    "vf_coef": 0.5,
    "max_grad_norm": 0.5,
    "use_sde": true,
    "sde_sample_freq": 4,
    "tensorboard_log": "logs/tensorboard_logs/ppo_airsim_tensorboard/",
    "verbose": 1,
    "seed": null,
    "device": "auto",
    "continuous": true,
    "save_freq": 10000
  },
  "policy_network": {
    "input_size": 16,
    "hidden_layers": [
      256,
      256
    ],
    "output_size": 4,
    "use_batch_norm": true,
    "use_dropout": true,
    "dropout_rate": 0.2,
    "use_attention": true,
    "num_action_heads": 1
  },
  "critic_network": {
    "input_size": 15,
    "hidden_layers": [
      256,
      256
    ],
    "output_size": 1,
    "use_batch_norm": true,
    "use_dropout": true,
    "dropout_rate": 0.2,
    "use_attention": true
  },
  "environment": {
    "env_name": "Africa_001",
    "reward_threshold": 250,
    "max_env_steps": 1000,
    "state_dim": 15,
    "action_dim": 4,
    "reward_scale": 20,
    "proximity_threshold": 5.0,
    "collision_penalty": 25,
    "height_target": -10,
    "height_tolerance": 1.0,
    "height_penalty": 1,
    "movement_penalty": 0.5,
    "smoothness_penalty": 0.5,
    "duration": 0.1,
    "exploration_area": {
      "x_min": -1000,
      "x_max": 1000,
      "y_min": -1000,
      "y_max": 1000,
      "z_min": -100,
      "z_max": 100
    }
  },
  "exploration": {
    "strategy": "epsilon_decay",
    "initial_epsilon": 1.0,
    "min_epsilon": 0.05,
    "epsilon_decay_rate": 0.995
  },
  "model_checkpointing": {
    "checkpoint_interval": 10,
    "save_best_only": true,
    "checkpoint_dir": "models/checkpoints"
  },
  "logging": {
    "log_interval": 10,
    "log_dir": "logs/",
    "tensorboard": true,
    "tensorboard_log_dir": "logs/tensorboard_logs",
    "model_save_path": "models/saved_models"
  },
  "advanced_training_techniques": {
    "gradient_clipping": 0.5,
    "use_gae": true,
    "gae_lambda": 0.95,
    "normalize_advantages": true
  },
  "early_stopping": {
    "patience": 5
  },
  "reward_adjustments": {
    "collision_penalty": 50,
    "reward_threshold": 250
  },
  "shared_components": {
    "residual_block": {
      "input_dim": 128,
      "hidden_dim": 128,
      "dropout_rate": 0.2
    },
    "attention_layer": {
      "input_dim": 128,
      "hidden_dim": 128
    }
  },
  "icm": {
    "state_dim": 16,
    "action_dim": 3,
    "image_channels": 3,
    "image_height": 144,
    "image_width": 256,
    "cnn": {
      "conv1": {
        "out_channels": 32,
        "kernel_size": 8,
        "stride": 4
      },
      "conv2": {
        "out_channels": 64,
        "kernel_size": 4,
        "stride": 2
      },
      "conv3": {
        "out_channels": 64,
        "kernel_size": 3,
        "stride": 1
      }
    },
    "state_encoder": {
      "hidden_dim": 128
    },
    "forward_model": {
      "hidden_dim": 256
    },
    "inverse_model": {
      "hidden_dim": 256
    }
  },
  "predictive_model": {
    "learning_rate": 0.0001,
    "hidden_layers": [
      256,
      256
    ]
  },
  "hrl": {
    "use_hierarchical": true,
    "high_level_policy": {
      "input_size": 15,
      "hidden_layers": [
        256,
        256
      ],
      "output_size": 4
    },
    "sub_goal_dim": 3,
    "low_level_policy": {
      "input_size": 18,
      "hidden_layers": [
        256,
        256
      ],
      "output_size": 4
    }
  },
  "curriculum_learning": {
    "use_curriculum": true,
    "initial_difficulty": 1,
    "difficulty_increment": 1,
    "difficulty_threshold": 200
  },
  "multi_agent": {
    "use_multi_agent": true,
    "num_agents": 2,
    "hidden_layers": [
      256,
      256
    ]
  }
}
2024-07-20 16:07:25,434 - AirSimEnvLogger - INFO - DataVisualizer initialized with Seaborn style set to 'whitegrid'.
2024-07-20 16:07:25,479 - AirSimEnvLogger - INFO - PPOAgent initialization started.
2024-07-20 16:07:25,527 - AirSimEnvLogger - INFO - State dimension: 16
2024-07-20 16:07:25,575 - AirSimEnvLogger - INFO - Visual dimensions: 84x84x4
2024-07-20 16:07:25,623 - AirSimEnvLogger - INFO - Using device: cpu
2024-07-20 16:07:29,296 - AirSimEnvLogger - INFO - Policy Network: state_dim=16, action_dim=4, continuous=True
2024-07-20 16:07:29,343 - AirSimEnvLogger - INFO - Visual input: 144x256x3
2024-07-20 16:07:29,390 - AirSimEnvLogger - INFO - Critic Network: state_dim=15
2024-07-20 16:07:31,468 - AirSimEnvLogger - INFO - PPOAgent initialized successfully.
2024-07-20 16:10:05,133 - AirSimEnvLogger - INFO - Initializing AirSimEnv
2024-07-20 16:10:05,134 - AirSimEnvLogger - INFO - Configuration: {
  "learning_rate": 0.0001,
  "gamma": 0.99,
  "tau": 0.95,
  "batch_size": 64,
  "num_timesteps": 2000000,
  "ppo": {
    "learning_rate": 0.0003,
    "n_steps": 2048,
    "batch_size": 64,
    "n_epochs": 2000,
    "gamma": 0.99,
    "gae_lambda": 0.95,
    "clip_range": 0.2,
    "ent_coef": 0.01,
    "vf_coef": 0.5,
    "max_grad_norm": 0.5,
    "use_sde": true,
    "sde_sample_freq": 4,
    "tensorboard_log": "logs/tensorboard_logs/ppo_airsim_tensorboard/",
    "verbose": 1,
    "seed": null,
    "device": "auto",
    "continuous": true,
    "save_freq": 10000
  },
  "policy_network": {
    "input_size": 16,
    "hidden_layers": [
      256,
      256
    ],
    "output_size": 4,
    "use_batch_norm": true,
    "use_dropout": true,
    "dropout_rate": 0.2,
    "use_attention": true,
    "num_action_heads": 1
  },
  "critic_network": {
    "input_size": 15,
    "hidden_layers": [
      256,
      256
    ],
    "output_size": 1,
    "use_batch_norm": true,
    "use_dropout": true,
    "dropout_rate": 0.2,
    "use_attention": true
  },
  "environment": {
    "env_name": "Africa_001",
    "reward_threshold": 250,
    "max_env_steps": 1000,
    "state_dim": 15,
    "action_dim": 4,
    "reward_scale": 20,
    "proximity_threshold": 5.0,
    "collision_penalty": 25,
    "height_target": -10,
    "height_tolerance": 1.0,
    "height_penalty": 1,
    "movement_penalty": 0.5,
    "smoothness_penalty": 0.5,
    "duration": 0.1,
    "exploration_area": {
      "x_min": -1000,
      "x_max": 1000,
      "y_min": -1000,
      "y_max": 1000,
      "z_min": -100,
      "z_max": 100
    }
  },
  "exploration": {
    "strategy": "epsilon_decay",
    "initial_epsilon": 1.0,
    "min_epsilon": 0.05,
    "epsilon_decay_rate": 0.995
  },
  "model_checkpointing": {
    "checkpoint_interval": 10,
    "save_best_only": true,
    "checkpoint_dir": "models/checkpoints"
  },
  "logging": {
    "log_interval": 10,
    "log_dir": "logs/",
    "tensorboard": true,
    "tensorboard_log_dir": "logs/tensorboard_logs",
    "model_save_path": "models/saved_models"
  },
  "advanced_training_techniques": {
    "gradient_clipping": 0.5,
    "use_gae": true,
    "gae_lambda": 0.95,
    "normalize_advantages": true
  },
  "early_stopping": {
    "patience": 5
  },
  "reward_adjustments": {
    "collision_penalty": 50,
    "reward_threshold": 250
  },
  "shared_components": {
    "residual_block": {
      "input_dim": 128,
      "hidden_dim": 128,
      "dropout_rate": 0.2
    },
    "attention_layer": {
      "input_dim": 128,
      "hidden_dim": 128
    }
  },
  "icm": {
    "state_dim": 16,
    "action_dim": 3,
    "image_channels": 3,
    "image_height": 144,
    "image_width": 256,
    "cnn": {
      "conv1": {
        "out_channels": 32,
        "kernel_size": 8,
        "stride": 4
      },
      "conv2": {
        "out_channels": 64,
        "kernel_size": 4,
        "stride": 2
      },
      "conv3": {
        "out_channels": 64,
        "kernel_size": 3,
        "stride": 1
      }
    },
    "state_encoder": {
      "hidden_dim": 128
    },
    "forward_model": {
      "hidden_dim": 256
    },
    "inverse_model": {
      "hidden_dim": 256
    }
  },
  "predictive_model": {
    "learning_rate": 0.0001,
    "hidden_layers": [
      256,
      256
    ]
  },
  "hrl": {
    "use_hierarchical": true,
    "high_level_policy": {
      "input_size": 15,
      "hidden_layers": [
        256,
        256
      ],
      "output_size": 4
    },
    "sub_goal_dim": 3,
    "low_level_policy": {
      "input_size": 18,
      "hidden_layers": [
        256,
        256
      ],
      "output_size": 4
    }
  },
  "curriculum_learning": {
    "use_curriculum": true,
    "initial_difficulty": 1,
    "difficulty_increment": 1,
    "difficulty_threshold": 200
  },
  "multi_agent": {
    "use_multi_agent": true,
    "num_agents": 2,
    "hidden_layers": [
      256,
      256
    ]
  }
}
2024-07-20 16:10:06,216 - AirSimEnvLogger - INFO - DataVisualizer initialized with Seaborn style set to 'whitegrid'.
2024-07-20 16:10:06,277 - AirSimEnvLogger - INFO - PPOAgent initialization started.
2024-07-20 16:10:06,309 - AirSimEnvLogger - INFO - State dimension: 16
2024-07-20 16:10:06,355 - AirSimEnvLogger - INFO - Visual dimensions: 84x84x4
2024-07-20 16:10:06,387 - AirSimEnvLogger - INFO - Using device: cpu
2024-07-20 16:10:09,844 - AirSimEnvLogger - INFO - Policy Network: state_dim=16, action_dim=4, continuous=True
2024-07-20 16:10:09,876 - AirSimEnvLogger - INFO - Visual input: 144x256x3
2024-07-20 16:10:09,923 - AirSimEnvLogger - INFO - Total input size: 110608
2024-07-20 16:10:09,970 - AirSimEnvLogger - INFO - Critic Network: state_dim=15
2024-07-20 16:10:12,005 - AirSimEnvLogger - INFO - PPOAgent initialized successfully.
2024-07-20 16:12:32,256 - AirSimEnvLogger - INFO - Initializing AirSimEnv
2024-07-20 16:12:32,257 - AirSimEnvLogger - INFO - Configuration: {
  "learning_rate": 0.0001,
  "gamma": 0.99,
  "tau": 0.95,
  "batch_size": 64,
  "num_timesteps": 2000000,
  "ppo": {
    "learning_rate": 0.0003,
    "n_steps": 2048,
    "batch_size": 64,
    "n_epochs": 2000,
    "gamma": 0.99,
    "gae_lambda": 0.95,
    "clip_range": 0.2,
    "ent_coef": 0.01,
    "vf_coef": 0.5,
    "max_grad_norm": 0.5,
    "use_sde": true,
    "sde_sample_freq": 4,
    "tensorboard_log": "logs/tensorboard_logs/ppo_airsim_tensorboard/",
    "verbose": 1,
    "seed": null,
    "device": "auto",
    "continuous": true,
    "save_freq": 10000
  },
  "policy_network": {
    "input_size": 16,
    "hidden_layers": [
      256,
      256
    ],
    "output_size": 4,
    "use_batch_norm": true,
    "use_dropout": true,
    "dropout_rate": 0.2,
    "use_attention": true,
    "num_action_heads": 1
  },
  "critic_network": {
    "input_size": 15,
    "hidden_layers": [
      256,
      256
    ],
    "output_size": 1,
    "use_batch_norm": true,
    "use_dropout": true,
    "dropout_rate": 0.2,
    "use_attention": true
  },
  "environment": {
    "env_name": "Africa_001",
    "reward_threshold": 250,
    "max_env_steps": 1000,
    "state_dim": 15,
    "action_dim": 4,
    "reward_scale": 20,
    "proximity_threshold": 5.0,
    "collision_penalty": 25,
    "height_target": -10,
    "height_tolerance": 1.0,
    "height_penalty": 1,
    "movement_penalty": 0.5,
    "smoothness_penalty": 0.5,
    "duration": 0.1,
    "exploration_area": {
      "x_min": -1000,
      "x_max": 1000,
      "y_min": -1000,
      "y_max": 1000,
      "z_min": -100,
      "z_max": 100
    }
  },
  "exploration": {
    "strategy": "epsilon_decay",
    "initial_epsilon": 1.0,
    "min_epsilon": 0.05,
    "epsilon_decay_rate": 0.995
  },
  "model_checkpointing": {
    "checkpoint_interval": 10,
    "save_best_only": true,
    "checkpoint_dir": "models/checkpoints"
  },
  "logging": {
    "log_interval": 10,
    "log_dir": "logs/",
    "tensorboard": true,
    "tensorboard_log_dir": "logs/tensorboard_logs",
    "model_save_path": "models/saved_models"
  },
  "advanced_training_techniques": {
    "gradient_clipping": 0.5,
    "use_gae": true,
    "gae_lambda": 0.95,
    "normalize_advantages": true
  },
  "early_stopping": {
    "patience": 5
  },
  "reward_adjustments": {
    "collision_penalty": 50,
    "reward_threshold": 250
  },
  "shared_components": {
    "residual_block": {
      "input_dim": 128,
      "hidden_dim": 128,
      "dropout_rate": 0.2
    },
    "attention_layer": {
      "input_dim": 128,
      "hidden_dim": 128
    }
  },
  "icm": {
    "state_dim": 16,
    "action_dim": 3,
    "image_channels": 3,
    "image_height": 144,
    "image_width": 256,
    "cnn": {
      "conv1": {
        "out_channels": 32,
        "kernel_size": 8,
        "stride": 4
      },
      "conv2": {
        "out_channels": 64,
        "kernel_size": 4,
        "stride": 2
      },
      "conv3": {
        "out_channels": 64,
        "kernel_size": 3,
        "stride": 1
      }
    },
    "state_encoder": {
      "hidden_dim": 128
    },
    "forward_model": {
      "hidden_dim": 256
    },
    "inverse_model": {
      "hidden_dim": 256
    }
  },
  "predictive_model": {
    "learning_rate": 0.0001,
    "hidden_layers": [
      256,
      256
    ]
  },
  "hrl": {
    "use_hierarchical": true,
    "high_level_policy": {
      "input_size": 15,
      "hidden_layers": [
        256,
        256
      ],
      "output_size": 4
    },
    "sub_goal_dim": 3,
    "low_level_policy": {
      "input_size": 18,
      "hidden_layers": [
        256,
        256
      ],
      "output_size": 4
    }
  },
  "curriculum_learning": {
    "use_curriculum": true,
    "initial_difficulty": 1,
    "difficulty_increment": 1,
    "difficulty_threshold": 200
  },
  "multi_agent": {
    "use_multi_agent": true,
    "num_agents": 2,
    "hidden_layers": [
      256,
      256
    ]
  }
}
2024-07-20 16:12:33,259 - AirSimEnvLogger - INFO - DataVisualizer initialized with Seaborn style set to 'whitegrid'.
2024-07-20 16:12:33,304 - AirSimEnvLogger - INFO - PPOAgent initialization started.
2024-07-20 16:12:33,352 - AirSimEnvLogger - INFO - State dimension: 16
2024-07-20 16:12:33,399 - AirSimEnvLogger - INFO - Visual dimensions: 84x84x4
2024-07-20 16:12:33,446 - AirSimEnvLogger - INFO - Using device: cpu
2024-07-20 16:12:36,992 - AirSimEnvLogger - INFO - Policy Network: state_dim=16, action_dim=4, continuous=True
2024-07-20 16:12:37,039 - AirSimEnvLogger - INFO - Visual input: 144x256x3
2024-07-20 16:12:37,085 - AirSimEnvLogger - INFO - Total input size: 110608
2024-07-20 16:12:37,148 - AirSimEnvLogger - INFO - Critic Network: state_dim=15
2024-07-20 16:12:39,324 - AirSimEnvLogger - INFO - PPOAgent initialized successfully.
2024-07-20 16:14:28,877 - AirSimEnvLogger - INFO - Initializing AirSimEnv
2024-07-20 16:14:28,878 - AirSimEnvLogger - INFO - Configuration: {
  "learning_rate": 0.0001,
  "gamma": 0.99,
  "tau": 0.95,
  "batch_size": 64,
  "num_timesteps": 2000000,
  "ppo": {
    "learning_rate": 0.0003,
    "n_steps": 2048,
    "batch_size": 64,
    "n_epochs": 2000,
    "gamma": 0.99,
    "gae_lambda": 0.95,
    "clip_range": 0.2,
    "ent_coef": 0.01,
    "vf_coef": 0.5,
    "max_grad_norm": 0.5,
    "use_sde": true,
    "sde_sample_freq": 4,
    "tensorboard_log": "logs/tensorboard_logs/ppo_airsim_tensorboard/",
    "verbose": 1,
    "seed": null,
    "device": "auto",
    "continuous": true,
    "save_freq": 10000
  },
  "policy_network": {
    "input_size": 16,
    "hidden_layers": [
      256,
      256
    ],
    "output_size": 4,
    "use_batch_norm": true,
    "use_dropout": true,
    "dropout_rate": 0.2,
    "use_attention": true,
    "num_action_heads": 1
  },
  "critic_network": {
    "input_size": 15,
    "hidden_layers": [
      256,
      256
    ],
    "output_size": 1,
    "use_batch_norm": true,
    "use_dropout": true,
    "dropout_rate": 0.2,
    "use_attention": true
  },
  "environment": {
    "env_name": "Africa_001",
    "reward_threshold": 250,
    "max_env_steps": 1000,
    "state_dim": 15,
    "action_dim": 4,
    "reward_scale": 20,
    "proximity_threshold": 5.0,
    "collision_penalty": 25,
    "height_target": -10,
    "height_tolerance": 1.0,
    "height_penalty": 1,
    "movement_penalty": 0.5,
    "smoothness_penalty": 0.5,
    "duration": 0.1,
    "exploration_area": {
      "x_min": -1000,
      "x_max": 1000,
      "y_min": -1000,
      "y_max": 1000,
      "z_min": -100,
      "z_max": 100
    }
  },
  "exploration": {
    "strategy": "epsilon_decay",
    "initial_epsilon": 1.0,
    "min_epsilon": 0.05,
    "epsilon_decay_rate": 0.995
  },
  "model_checkpointing": {
    "checkpoint_interval": 10,
    "save_best_only": true,
    "checkpoint_dir": "models/checkpoints"
  },
  "logging": {
    "log_interval": 10,
    "log_dir": "logs/",
    "tensorboard": true,
    "tensorboard_log_dir": "logs/tensorboard_logs",
    "model_save_path": "models/saved_models"
  },
  "advanced_training_techniques": {
    "gradient_clipping": 0.5,
    "use_gae": true,
    "gae_lambda": 0.95,
    "normalize_advantages": true
  },
  "early_stopping": {
    "patience": 5
  },
  "reward_adjustments": {
    "collision_penalty": 50,
    "reward_threshold": 250
  },
  "shared_components": {
    "residual_block": {
      "input_dim": 128,
      "hidden_dim": 128,
      "dropout_rate": 0.2
    },
    "attention_layer": {
      "input_dim": 128,
      "hidden_dim": 128
    }
  },
  "icm": {
    "state_dim": 16,
    "action_dim": 3,
    "image_channels": 3,
    "image_height": 144,
    "image_width": 256,
    "cnn": {
      "conv1": {
        "out_channels": 32,
        "kernel_size": 8,
        "stride": 4
      },
      "conv2": {
        "out_channels": 64,
        "kernel_size": 4,
        "stride": 2
      },
      "conv3": {
        "out_channels": 64,
        "kernel_size": 3,
        "stride": 1
      }
    },
    "state_encoder": {
      "hidden_dim": 128
    },
    "forward_model": {
      "hidden_dim": 256
    },
    "inverse_model": {
      "hidden_dim": 256
    }
  },
  "predictive_model": {
    "learning_rate": 0.0001,
    "hidden_layers": [
      256,
      256
    ]
  },
  "hrl": {
    "use_hierarchical": true,
    "high_level_policy": {
      "input_size": 15,
      "hidden_layers": [
        256,
        256
      ],
      "output_size": 4
    },
    "sub_goal_dim": 3,
    "low_level_policy": {
      "input_size": 18,
      "hidden_layers": [
        256,
        256
      ],
      "output_size": 4
    }
  },
  "curriculum_learning": {
    "use_curriculum": true,
    "initial_difficulty": 1,
    "difficulty_increment": 1,
    "difficulty_threshold": 200
  },
  "multi_agent": {
    "use_multi_agent": true,
    "num_agents": 2,
    "hidden_layers": [
      256,
      256
    ]
  }
}
2024-07-20 16:14:29,891 - AirSimEnvLogger - INFO - DataVisualizer initialized with Seaborn style set to 'whitegrid'.
2024-07-20 16:14:29,936 - AirSimEnvLogger - INFO - PPOAgent initialization started.
2024-07-20 16:14:29,983 - AirSimEnvLogger - INFO - State dimension: 16
2024-07-20 16:14:30,030 - AirSimEnvLogger - INFO - Visual dimensions: 84x84x4
2024-07-20 16:14:30,092 - AirSimEnvLogger - INFO - Using device: cpu
2024-07-20 16:14:33,999 - AirSimEnvLogger - INFO - Policy Network: state_dim=16, action_dim=4, continuous=True
2024-07-20 16:14:34,030 - AirSimEnvLogger - INFO - Visual input: 144x256x3
2024-07-20 16:14:34,077 - AirSimEnvLogger - INFO - Total input size: 110608
2024-07-20 16:14:34,123 - AirSimEnvLogger - INFO - Critic Network: state_dim=15
2024-07-20 16:14:36,127 - AirSimEnvLogger - INFO - PPOAgent initialized successfully.
2024-07-20 16:26:13,545 - AirSimEnvLogger - INFO - Initializing AirSimEnv
2024-07-20 16:26:13,546 - AirSimEnvLogger - INFO - Configuration: {
  "learning_rate": 0.0001,
  "gamma": 0.99,
  "tau": 0.95,
  "batch_size": 64,
  "num_timesteps": 2000000,
  "ppo": {
    "learning_rate": 0.0003,
    "n_steps": 2048,
    "batch_size": 64,
    "n_epochs": 2000,
    "gamma": 0.99,
    "gae_lambda": 0.95,
    "clip_range": 0.2,
    "ent_coef": 0.01,
    "vf_coef": 0.5,
    "max_grad_norm": 0.5,
    "use_sde": true,
    "sde_sample_freq": 4,
    "tensorboard_log": "logs/tensorboard_logs/ppo_airsim_tensorboard/",
    "verbose": 1,
    "seed": null,
    "device": "auto",
    "continuous": true,
    "save_freq": 10000
  },
  "policy_network": {
    "input_size": 16,
    "hidden_layers": [
      256,
      256
    ],
    "output_size": 4,
    "use_batch_norm": true,
    "use_dropout": true,
    "dropout_rate": 0.2,
    "use_attention": true,
    "num_action_heads": 1
  },
  "critic_network": {
    "input_size": 15,
    "hidden_layers": [
      256,
      256
    ],
    "output_size": 1,
    "use_batch_norm": true,
    "use_dropout": true,
    "dropout_rate": 0.2,
    "use_attention": true
  },
  "environment": {
    "env_name": "Africa_001",
    "reward_threshold": 250,
    "max_env_steps": 1000,
    "state_dim": 15,
    "action_dim": 4,
    "reward_scale": 20,
    "proximity_threshold": 5.0,
    "collision_penalty": 25,
    "height_target": -10,
    "height_tolerance": 1.0,
    "height_penalty": 1,
    "movement_penalty": 0.5,
    "smoothness_penalty": 0.5,
    "duration": 0.1,
    "exploration_area": {
      "x_min": -1000,
      "x_max": 1000,
      "y_min": -1000,
      "y_max": 1000,
      "z_min": -100,
      "z_max": 100
    }
  },
  "exploration": {
    "strategy": "epsilon_decay",
    "initial_epsilon": 1.0,
    "min_epsilon": 0.05,
    "epsilon_decay_rate": 0.995
  },
  "model_checkpointing": {
    "checkpoint_interval": 10,
    "save_best_only": true,
    "checkpoint_dir": "models/checkpoints"
  },
  "logging": {
    "log_interval": 10,
    "log_dir": "logs/",
    "tensorboard": true,
    "tensorboard_log_dir": "logs/tensorboard_logs",
    "model_save_path": "models/saved_models"
  },
  "advanced_training_techniques": {
    "gradient_clipping": 0.5,
    "use_gae": true,
    "gae_lambda": 0.95,
    "normalize_advantages": true
  },
  "early_stopping": {
    "patience": 5
  },
  "reward_adjustments": {
    "collision_penalty": 50,
    "reward_threshold": 250
  },
  "shared_components": {
    "residual_block": {
      "input_dim": 128,
      "hidden_dim": 128,
      "dropout_rate": 0.2
    },
    "attention_layer": {
      "input_dim": 128,
      "hidden_dim": 128
    }
  },
  "icm": {
    "state_dim": 16,
    "action_dim": 3,
    "image_channels": 3,
    "image_height": 144,
    "image_width": 256,
    "cnn": {
      "conv1": {
        "out_channels": 32,
        "kernel_size": 8,
        "stride": 4
      },
      "conv2": {
        "out_channels": 64,
        "kernel_size": 4,
        "stride": 2
      },
      "conv3": {
        "out_channels": 64,
        "kernel_size": 3,
        "stride": 1
      }
    },
    "state_encoder": {
      "hidden_dim": 128
    },
    "forward_model": {
      "hidden_dim": 256
    },
    "inverse_model": {
      "hidden_dim": 256
    }
  },
  "predictive_model": {
    "learning_rate": 0.0001,
    "hidden_layers": [
      256,
      256
    ]
  },
  "hrl": {
    "use_hierarchical": true,
    "high_level_policy": {
      "input_size": 15,
      "hidden_layers": [
        256,
        256
      ],
      "output_size": 4
    },
    "sub_goal_dim": 3,
    "low_level_policy": {
      "input_size": 18,
      "hidden_layers": [
        256,
        256
      ],
      "output_size": 4
    }
  },
  "curriculum_learning": {
    "use_curriculum": true,
    "initial_difficulty": 1,
    "difficulty_increment": 1,
    "difficulty_threshold": 200
  },
  "multi_agent": {
    "use_multi_agent": true,
    "num_agents": 2,
    "hidden_layers": [
      256,
      256
    ]
  }
}
2024-07-20 16:26:14,710 - AirSimEnvLogger - INFO - DataVisualizer initialized with Seaborn style set to 'whitegrid'.
2024-07-20 16:26:14,756 - AirSimEnvLogger - INFO - PPOAgent initialization started.
2024-07-20 16:26:14,788 - AirSimEnvLogger - INFO - State dimension: 16
2024-07-20 16:26:14,835 - AirSimEnvLogger - INFO - Visual dimensions: 84x84x4
2024-07-20 16:26:14,883 - AirSimEnvLogger - INFO - Using device: cpu
2024-07-20 16:26:18,496 - AirSimEnvLogger - INFO - Policy Network: state_dim=16, action_dim=4, continuous=True
2024-07-20 16:26:18,542 - AirSimEnvLogger - INFO - Visual input: 144x256x3
2024-07-20 16:26:18,589 - AirSimEnvLogger - INFO - Total input size: 110608
2024-07-20 16:26:18,651 - AirSimEnvLogger - INFO - Critic Network: state_dim=15
2024-07-20 16:26:20,801 - AirSimEnvLogger - INFO - PPOAgent initialized successfully.
2024-07-20 16:28:33,548 - AirSimEnvLogger - INFO - Initializing AirSimEnv
2024-07-20 16:28:33,550 - AirSimEnvLogger - INFO - Configuration: {
  "learning_rate": 0.0001,
  "gamma": 0.99,
  "tau": 0.95,
  "batch_size": 64,
  "num_timesteps": 2000000,
  "ppo": {
    "learning_rate": 0.0003,
    "n_steps": 2048,
    "batch_size": 64,
    "n_epochs": 2000,
    "gamma": 0.99,
    "gae_lambda": 0.95,
    "clip_range": 0.2,
    "ent_coef": 0.01,
    "vf_coef": 0.5,
    "max_grad_norm": 0.5,
    "use_sde": true,
    "sde_sample_freq": 4,
    "tensorboard_log": "logs/tensorboard_logs/ppo_airsim_tensorboard/",
    "verbose": 1,
    "seed": null,
    "device": "auto",
    "continuous": true,
    "save_freq": 10000
  },
  "policy_network": {
    "input_size": 16,
    "hidden_layers": [
      256,
      256
    ],
    "output_size": 4,
    "use_batch_norm": true,
    "use_dropout": true,
    "dropout_rate": 0.2,
    "use_attention": true,
    "num_action_heads": 1
  },
  "critic_network": {
    "input_size": 15,
    "hidden_layers": [
      256,
      256
    ],
    "output_size": 1,
    "use_batch_norm": true,
    "use_dropout": true,
    "dropout_rate": 0.2,
    "use_attention": true
  },
  "environment": {
    "env_name": "Africa_001",
    "reward_threshold": 250,
    "max_env_steps": 1000,
    "state_dim": 15,
    "action_dim": 4,
    "reward_scale": 20,
    "proximity_threshold": 5.0,
    "collision_penalty": 25,
    "height_target": -10,
    "height_tolerance": 1.0,
    "height_penalty": 1,
    "movement_penalty": 0.5,
    "smoothness_penalty": 0.5,
    "duration": 0.1,
    "exploration_area": {
      "x_min": -1000,
      "x_max": 1000,
      "y_min": -1000,
      "y_max": 1000,
      "z_min": -100,
      "z_max": 100
    }
  },
  "exploration": {
    "strategy": "epsilon_decay",
    "initial_epsilon": 1.0,
    "min_epsilon": 0.05,
    "epsilon_decay_rate": 0.995
  },
  "model_checkpointing": {
    "checkpoint_interval": 10,
    "save_best_only": true,
    "checkpoint_dir": "models/checkpoints"
  },
  "logging": {
    "log_interval": 10,
    "log_dir": "logs/",
    "tensorboard": true,
    "tensorboard_log_dir": "logs/tensorboard_logs",
    "model_save_path": "models/saved_models"
  },
  "advanced_training_techniques": {
    "gradient_clipping": 0.5,
    "use_gae": true,
    "gae_lambda": 0.95,
    "normalize_advantages": true
  },
  "early_stopping": {
    "patience": 5
  },
  "reward_adjustments": {
    "collision_penalty": 50,
    "reward_threshold": 250
  },
  "shared_components": {
    "residual_block": {
      "input_dim": 128,
      "hidden_dim": 128,
      "dropout_rate": 0.2
    },
    "attention_layer": {
      "input_dim": 128,
      "hidden_dim": 128
    }
  },
  "icm": {
    "state_dim": 16,
    "action_dim": 3,
    "image_channels": 3,
    "image_height": 144,
    "image_width": 256,
    "cnn": {
      "conv1": {
        "out_channels": 32,
        "kernel_size": 8,
        "stride": 4
      },
      "conv2": {
        "out_channels": 64,
        "kernel_size": 4,
        "stride": 2
      },
      "conv3": {
        "out_channels": 64,
        "kernel_size": 3,
        "stride": 1
      }
    },
    "state_encoder": {
      "hidden_dim": 128
    },
    "forward_model": {
      "hidden_dim": 256
    },
    "inverse_model": {
      "hidden_dim": 256
    }
  },
  "predictive_model": {
    "learning_rate": 0.0001,
    "hidden_layers": [
      256,
      256
    ]
  },
  "hrl": {
    "use_hierarchical": true,
    "high_level_policy": {
      "input_size": 15,
      "hidden_layers": [
        256,
        256
      ],
      "output_size": 4
    },
    "sub_goal_dim": 3,
    "low_level_policy": {
      "input_size": 18,
      "hidden_layers": [
        256,
        256
      ],
      "output_size": 4
    }
  },
  "curriculum_learning": {
    "use_curriculum": true,
    "initial_difficulty": 1,
    "difficulty_increment": 1,
    "difficulty_threshold": 200
  },
  "multi_agent": {
    "use_multi_agent": true,
    "num_agents": 2,
    "hidden_layers": [
      256,
      256
    ]
  }
}
2024-07-20 16:28:34,456 - AirSimEnvLogger - INFO - DataVisualizer initialized with Seaborn style set to 'whitegrid'.
2024-07-20 16:28:34,458 - AirSimEnvLogger - INFO - PPOAgent initialization started.
2024-07-20 16:28:34,469 - AirSimEnvLogger - INFO - State dimension: 16
2024-07-20 16:28:34,485 - AirSimEnvLogger - INFO - Visual dimensions: 84x84x4
2024-07-20 16:28:34,486 - AirSimEnvLogger - INFO - Using device: cpu
2024-07-20 16:28:38,285 - AirSimEnvLogger - INFO - Policy Network: state_dim=16, action_dim=4, continuous=True
2024-07-20 16:28:38,331 - AirSimEnvLogger - INFO - Visual input: 144x256x3
2024-07-20 16:28:38,379 - AirSimEnvLogger - INFO - Total input size: 110608
2024-07-20 16:28:38,426 - AirSimEnvLogger - INFO - Critic Network: state_dim=15
2024-07-20 16:28:40,481 - AirSimEnvLogger - INFO - PPOAgent initialized successfully.
2024-07-20 16:30:30,118 - AirSimEnvLogger - INFO - Initializing AirSimEnv
2024-07-20 16:30:30,119 - AirSimEnvLogger - INFO - Configuration: {
  "learning_rate": 0.0001,
  "gamma": 0.99,
  "tau": 0.95,
  "batch_size": 64,
  "num_timesteps": 2000000,
  "ppo": {
    "learning_rate": 0.0003,
    "n_steps": 2048,
    "batch_size": 64,
    "n_epochs": 2000,
    "gamma": 0.99,
    "gae_lambda": 0.95,
    "clip_range": 0.2,
    "ent_coef": 0.01,
    "vf_coef": 0.5,
    "max_grad_norm": 0.5,
    "use_sde": true,
    "sde_sample_freq": 4,
    "tensorboard_log": "logs/tensorboard_logs/ppo_airsim_tensorboard/",
    "verbose": 1,
    "seed": null,
    "device": "auto",
    "continuous": true,
    "save_freq": 10000
  },
  "policy_network": {
    "input_size": 16,
    "hidden_layers": [
      256,
      256
    ],
    "output_size": 4,
    "use_batch_norm": true,
    "use_dropout": true,
    "dropout_rate": 0.2,
    "use_attention": true,
    "num_action_heads": 1
  },
  "critic_network": {
    "input_size": 15,
    "hidden_layers": [
      256,
      256
    ],
    "output_size": 1,
    "use_batch_norm": true,
    "use_dropout": true,
    "dropout_rate": 0.2,
    "use_attention": true
  },
  "environment": {
    "env_name": "Africa_001",
    "reward_threshold": 250,
    "max_env_steps": 1000,
    "state_dim": 15,
    "action_dim": 4,
    "reward_scale": 20,
    "proximity_threshold": 5.0,
    "collision_penalty": 25,
    "height_target": -10,
    "height_tolerance": 1.0,
    "height_penalty": 1,
    "movement_penalty": 0.5,
    "smoothness_penalty": 0.5,
    "duration": 0.1,
    "exploration_area": {
      "x_min": -1000,
      "x_max": 1000,
      "y_min": -1000,
      "y_max": 1000,
      "z_min": -100,
      "z_max": 100
    }
  },
  "exploration": {
    "strategy": "epsilon_decay",
    "initial_epsilon": 1.0,
    "min_epsilon": 0.05,
    "epsilon_decay_rate": 0.995
  },
  "model_checkpointing": {
    "checkpoint_interval": 10,
    "save_best_only": true,
    "checkpoint_dir": "models/checkpoints"
  },
  "logging": {
    "log_interval": 10,
    "log_dir": "logs/",
    "tensorboard": true,
    "tensorboard_log_dir": "logs/tensorboard_logs",
    "model_save_path": "models/saved_models"
  },
  "advanced_training_techniques": {
    "gradient_clipping": 0.5,
    "use_gae": true,
    "gae_lambda": 0.95,
    "normalize_advantages": true
  },
  "early_stopping": {
    "patience": 5
  },
  "reward_adjustments": {
    "collision_penalty": 50,
    "reward_threshold": 250
  },
  "shared_components": {
    "residual_block": {
      "input_dim": 128,
      "hidden_dim": 128,
      "dropout_rate": 0.2
    },
    "attention_layer": {
      "input_dim": 128,
      "hidden_dim": 128
    }
  },
  "icm": {
    "state_dim": 16,
    "action_dim": 3,
    "image_channels": 3,
    "image_height": 144,
    "image_width": 256,
    "cnn": {
      "conv1": {
        "out_channels": 32,
        "kernel_size": 8,
        "stride": 4
      },
      "conv2": {
        "out_channels": 64,
        "kernel_size": 4,
        "stride": 2
      },
      "conv3": {
        "out_channels": 64,
        "kernel_size": 3,
        "stride": 1
      }
    },
    "state_encoder": {
      "hidden_dim": 128
    },
    "forward_model": {
      "hidden_dim": 256
    },
    "inverse_model": {
      "hidden_dim": 256
    }
  },
  "predictive_model": {
    "learning_rate": 0.0001,
    "hidden_layers": [
      256,
      256
    ]
  },
  "hrl": {
    "use_hierarchical": true,
    "high_level_policy": {
      "input_size": 15,
      "hidden_layers": [
        256,
        256
      ],
      "output_size": 4
    },
    "sub_goal_dim": 3,
    "low_level_policy": {
      "input_size": 18,
      "hidden_layers": [
        256,
        256
      ],
      "output_size": 4
    }
  },
  "curriculum_learning": {
    "use_curriculum": true,
    "initial_difficulty": 1,
    "difficulty_increment": 1,
    "difficulty_threshold": 200
  },
  "multi_agent": {
    "use_multi_agent": true,
    "num_agents": 2,
    "hidden_layers": [
      256,
      256
    ]
  }
}
2024-07-20 16:30:31,217 - AirSimEnvLogger - INFO - DataVisualizer initialized with Seaborn style set to 'whitegrid'.
2024-07-20 16:30:31,262 - AirSimEnvLogger - INFO - PPOAgent initialization started.
2024-07-20 16:30:31,310 - AirSimEnvLogger - INFO - State dimension: 16
2024-07-20 16:30:31,355 - AirSimEnvLogger - INFO - Visual dimensions: 84x84x4
2024-07-20 16:30:31,404 - AirSimEnvLogger - INFO - Using device: cpu
2024-07-20 16:30:34,692 - AirSimEnvLogger - INFO - Policy Network: state_dim=16, action_dim=4, continuous=True
2024-07-20 16:30:34,755 - AirSimEnvLogger - INFO - Visual input: 144x256x3
2024-07-20 16:30:34,801 - AirSimEnvLogger - INFO - Total input size: 110608
2024-07-20 16:30:34,850 - AirSimEnvLogger - INFO - Critic Network: state_dim=15
2024-07-20 16:30:36,486 - AirSimEnvLogger - INFO - PPOAgent initialized successfully.
2024-07-20 16:35:58,390 - AirSimEnvLogger - INFO - Initializing AirSimEnv
2024-07-20 16:35:58,392 - AirSimEnvLogger - INFO - Configuration: {
  "learning_rate": 0.0001,
  "gamma": 0.99,
  "tau": 0.95,
  "batch_size": 64,
  "num_timesteps": 2000000,
  "ppo": {
    "learning_rate": 0.0003,
    "n_steps": 2048,
    "batch_size": 64,
    "n_epochs": 2000,
    "gamma": 0.99,
    "gae_lambda": 0.95,
    "clip_range": 0.2,
    "ent_coef": 0.01,
    "vf_coef": 0.5,
    "max_grad_norm": 0.5,
    "use_sde": true,
    "sde_sample_freq": 4,
    "tensorboard_log": "logs/tensorboard_logs/ppo_airsim_tensorboard/",
    "verbose": 1,
    "seed": null,
    "device": "auto",
    "continuous": true,
    "save_freq": 10000
  },
  "policy_network": {
    "input_size": 16,
    "hidden_layers": [
      256,
      256
    ],
    "output_size": 4,
    "use_batch_norm": true,
    "use_dropout": true,
    "dropout_rate": 0.2,
    "use_attention": true,
    "num_action_heads": 1
  },
  "critic_network": {
    "input_size": 15,
    "hidden_layers": [
      256,
      256
    ],
    "output_size": 1,
    "use_batch_norm": true,
    "use_dropout": true,
    "dropout_rate": 0.2,
    "use_attention": true
  },
  "environment": {
    "env_name": "Africa_001",
    "reward_threshold": 250,
    "max_env_steps": 1000,
    "state_dim": 15,
    "action_dim": 4,
    "reward_scale": 20,
    "proximity_threshold": 5.0,
    "collision_penalty": 25,
    "height_target": -10,
    "height_tolerance": 1.0,
    "height_penalty": 1,
    "movement_penalty": 0.5,
    "smoothness_penalty": 0.5,
    "duration": 0.1,
    "exploration_area": {
      "x_min": -1000,
      "x_max": 1000,
      "y_min": -1000,
      "y_max": 1000,
      "z_min": -100,
      "z_max": 100
    }
  },
  "exploration": {
    "strategy": "epsilon_decay",
    "initial_epsilon": 1.0,
    "min_epsilon": 0.05,
    "epsilon_decay_rate": 0.995
  },
  "model_checkpointing": {
    "checkpoint_interval": 10,
    "save_best_only": true,
    "checkpoint_dir": "models/checkpoints"
  },
  "logging": {
    "log_interval": 10,
    "log_dir": "logs/",
    "tensorboard": true,
    "tensorboard_log_dir": "logs/tensorboard_logs",
    "model_save_path": "models/saved_models"
  },
  "advanced_training_techniques": {
    "gradient_clipping": 0.5,
    "use_gae": true,
    "gae_lambda": 0.95,
    "normalize_advantages": true
  },
  "early_stopping": {
    "patience": 5
  },
  "reward_adjustments": {
    "collision_penalty": 50,
    "reward_threshold": 250
  },
  "shared_components": {
    "residual_block": {
      "input_dim": 128,
      "hidden_dim": 128,
      "dropout_rate": 0.2
    },
    "attention_layer": {
      "input_dim": 128,
      "hidden_dim": 128
    }
  },
  "icm": {
    "state_dim": 16,
    "action_dim": 3,
    "image_channels": 3,
    "image_height": 144,
    "image_width": 256,
    "cnn": {
      "conv1": {
        "out_channels": 32,
        "kernel_size": 8,
        "stride": 4
      },
      "conv2": {
        "out_channels": 64,
        "kernel_size": 4,
        "stride": 2
      },
      "conv3": {
        "out_channels": 64,
        "kernel_size": 3,
        "stride": 1
      }
    },
    "state_encoder": {
      "hidden_dim": 128
    },
    "forward_model": {
      "hidden_dim": 256
    },
    "inverse_model": {
      "hidden_dim": 256
    }
  },
  "predictive_model": {
    "learning_rate": 0.0001,
    "hidden_layers": [
      256,
      256
    ]
  },
  "hrl": {
    "use_hierarchical": true,
    "high_level_policy": {
      "input_size": 15,
      "hidden_layers": [
        256,
        256
      ],
      "output_size": 4
    },
    "sub_goal_dim": 3,
    "low_level_policy": {
      "input_size": 18,
      "hidden_layers": [
        256,
        256
      ],
      "output_size": 4
    }
  },
  "curriculum_learning": {
    "use_curriculum": true,
    "initial_difficulty": 1,
    "difficulty_increment": 1,
    "difficulty_threshold": 200
  },
  "multi_agent": {
    "use_multi_agent": true,
    "num_agents": 2,
    "hidden_layers": [
      256,
      256
    ]
  }
}
2024-07-20 16:35:59,568 - AirSimEnvLogger - INFO - DataVisualizer initialized with Seaborn style set to 'whitegrid'.
2024-07-20 16:35:59,614 - AirSimEnvLogger - INFO - PPOAgent initialization started.
2024-07-20 16:35:59,661 - AirSimEnvLogger - INFO - State dimension: 16
2024-07-20 16:35:59,709 - AirSimEnvLogger - INFO - Visual dimensions: 84x84x4
2024-07-20 16:35:59,755 - AirSimEnvLogger - INFO - Using device: cpu
2024-07-20 16:36:03,677 - AirSimEnvLogger - INFO - Policy Network: state_dim=16, action_dim=4, continuous=True
2024-07-20 16:36:03,724 - AirSimEnvLogger - INFO - Visual input: 144x256x3
2024-07-20 16:36:03,771 - AirSimEnvLogger - INFO - Total input size: 110608
2024-07-20 16:36:03,818 - AirSimEnvLogger - INFO - Critic Network: state_dim=15
2024-07-20 16:36:05,946 - AirSimEnvLogger - INFO - PPOAgent initialized successfully.
2024-07-20 16:37:50,219 - AirSimEnvLogger - INFO - Initializing AirSimEnv
2024-07-20 16:37:50,220 - AirSimEnvLogger - INFO - Configuration: {
  "learning_rate": 0.0001,
  "gamma": 0.99,
  "tau": 0.95,
  "batch_size": 64,
  "num_timesteps": 2000000,
  "ppo": {
    "learning_rate": 0.0003,
    "n_steps": 2048,
    "batch_size": 64,
    "n_epochs": 2000,
    "gamma": 0.99,
    "gae_lambda": 0.95,
    "clip_range": 0.2,
    "ent_coef": 0.01,
    "vf_coef": 0.5,
    "max_grad_norm": 0.5,
    "use_sde": true,
    "sde_sample_freq": 4,
    "tensorboard_log": "logs/tensorboard_logs/ppo_airsim_tensorboard/",
    "verbose": 1,
    "seed": null,
    "device": "auto",
    "continuous": true,
    "save_freq": 10000
  },
  "policy_network": {
    "input_size": 16,
    "hidden_layers": [
      256,
      256
    ],
    "output_size": 4,
    "use_batch_norm": true,
    "use_dropout": true,
    "dropout_rate": 0.2,
    "use_attention": true,
    "num_action_heads": 1
  },
  "critic_network": {
    "input_size": 15,
    "hidden_layers": [
      256,
      256
    ],
    "output_size": 1,
    "use_batch_norm": true,
    "use_dropout": true,
    "dropout_rate": 0.2,
    "use_attention": true
  },
  "environment": {
    "env_name": "Africa_001",
    "reward_threshold": 250,
    "max_env_steps": 1000,
    "state_dim": 15,
    "action_dim": 4,
    "reward_scale": 20,
    "proximity_threshold": 5.0,
    "collision_penalty": 25,
    "height_target": -10,
    "height_tolerance": 1.0,
    "height_penalty": 1,
    "movement_penalty": 0.5,
    "smoothness_penalty": 0.5,
    "duration": 0.1,
    "exploration_area": {
      "x_min": -1000,
      "x_max": 1000,
      "y_min": -1000,
      "y_max": 1000,
      "z_min": -100,
      "z_max": 100
    }
  },
  "exploration": {
    "strategy": "epsilon_decay",
    "initial_epsilon": 1.0,
    "min_epsilon": 0.05,
    "epsilon_decay_rate": 0.995
  },
  "model_checkpointing": {
    "checkpoint_interval": 10,
    "save_best_only": true,
    "checkpoint_dir": "models/checkpoints"
  },
  "logging": {
    "log_interval": 10,
    "log_dir": "logs/",
    "tensorboard": true,
    "tensorboard_log_dir": "logs/tensorboard_logs",
    "model_save_path": "models/saved_models"
  },
  "advanced_training_techniques": {
    "gradient_clipping": 0.5,
    "use_gae": true,
    "gae_lambda": 0.95,
    "normalize_advantages": true
  },
  "early_stopping": {
    "patience": 5
  },
  "reward_adjustments": {
    "collision_penalty": 50,
    "reward_threshold": 250
  },
  "shared_components": {
    "residual_block": {
      "input_dim": 128,
      "hidden_dim": 128,
      "dropout_rate": 0.2
    },
    "attention_layer": {
      "input_dim": 128,
      "hidden_dim": 128
    }
  },
  "icm": {
    "state_dim": 16,
    "action_dim": 3,
    "image_channels": 3,
    "image_height": 144,
    "image_width": 256,
    "cnn": {
      "conv1": {
        "out_channels": 32,
        "kernel_size": 8,
        "stride": 4
      },
      "conv2": {
        "out_channels": 64,
        "kernel_size": 4,
        "stride": 2
      },
      "conv3": {
        "out_channels": 64,
        "kernel_size": 3,
        "stride": 1
      }
    },
    "state_encoder": {
      "hidden_dim": 128
    },
    "forward_model": {
      "hidden_dim": 256
    },
    "inverse_model": {
      "hidden_dim": 256
    }
  },
  "predictive_model": {
    "learning_rate": 0.0001,
    "hidden_layers": [
      256,
      256
    ]
  },
  "hrl": {
    "use_hierarchical": true,
    "high_level_policy": {
      "input_size": 15,
      "hidden_layers": [
        256,
        256
      ],
      "output_size": 4
    },
    "sub_goal_dim": 3,
    "low_level_policy": {
      "input_size": 18,
      "hidden_layers": [
        256,
        256
      ],
      "output_size": 4
    }
  },
  "curriculum_learning": {
    "use_curriculum": true,
    "initial_difficulty": 1,
    "difficulty_increment": 1,
    "difficulty_threshold": 200
  },
  "multi_agent": {
    "use_multi_agent": true,
    "num_agents": 2,
    "hidden_layers": [
      256,
      256
    ]
  }
}
2024-07-20 16:37:51,394 - AirSimEnvLogger - INFO - DataVisualizer initialized with Seaborn style set to 'whitegrid'.
2024-07-20 16:37:51,440 - AirSimEnvLogger - INFO - PPOAgent initialization started.
2024-07-20 16:37:51,472 - AirSimEnvLogger - INFO - State dimension: 16
2024-07-20 16:37:51,504 - AirSimEnvLogger - INFO - Visual dimensions: 84x84x4
2024-07-20 16:37:51,567 - AirSimEnvLogger - INFO - Using device: cpu
2024-07-20 16:37:54,604 - AirSimEnvLogger - INFO - Policy Network: state_dim=16, action_dim=4, continuous=True
2024-07-20 16:37:54,636 - AirSimEnvLogger - INFO - Visual input: 144x256x3
2024-07-20 16:37:54,683 - AirSimEnvLogger - INFO - Total input size: 110608
2024-07-20 16:37:54,730 - AirSimEnvLogger - INFO - Critic Network: state_dim=15
2024-07-20 16:37:56,939 - AirSimEnvLogger - INFO - PPOAgent initialized successfully.
2024-07-20 16:39:48,918 - AirSimEnvLogger - INFO - Initializing AirSimEnv
2024-07-20 16:39:48,919 - AirSimEnvLogger - INFO - Configuration: {
  "learning_rate": 0.0001,
  "gamma": 0.99,
  "tau": 0.95,
  "batch_size": 64,
  "num_timesteps": 2000000,
  "ppo": {
    "learning_rate": 0.0003,
    "n_steps": 2048,
    "batch_size": 64,
    "n_epochs": 2000,
    "gamma": 0.99,
    "gae_lambda": 0.95,
    "clip_range": 0.2,
    "ent_coef": 0.01,
    "vf_coef": 0.5,
    "max_grad_norm": 0.5,
    "use_sde": true,
    "sde_sample_freq": 4,
    "tensorboard_log": "logs/tensorboard_logs/ppo_airsim_tensorboard/",
    "verbose": 1,
    "seed": null,
    "device": "auto",
    "continuous": true,
    "save_freq": 10000
  },
  "policy_network": {
    "input_size": 16,
    "hidden_layers": [
      256,
      256
    ],
    "output_size": 4,
    "use_batch_norm": true,
    "use_dropout": true,
    "dropout_rate": 0.2,
    "use_attention": true,
    "num_action_heads": 1
  },
  "critic_network": {
    "input_size": 15,
    "hidden_layers": [
      256,
      256
    ],
    "output_size": 1,
    "use_batch_norm": true,
    "use_dropout": true,
    "dropout_rate": 0.2,
    "use_attention": true
  },
  "environment": {
    "env_name": "Africa_001",
    "reward_threshold": 250,
    "max_env_steps": 1000,
    "state_dim": 15,
    "action_dim": 4,
    "reward_scale": 20,
    "proximity_threshold": 5.0,
    "collision_penalty": 25,
    "height_target": -10,
    "height_tolerance": 1.0,
    "height_penalty": 1,
    "movement_penalty": 0.5,
    "smoothness_penalty": 0.5,
    "duration": 0.1,
    "exploration_area": {
      "x_min": -1000,
      "x_max": 1000,
      "y_min": -1000,
      "y_max": 1000,
      "z_min": -100,
      "z_max": 100
    }
  },
  "exploration": {
    "strategy": "epsilon_decay",
    "initial_epsilon": 1.0,
    "min_epsilon": 0.05,
    "epsilon_decay_rate": 0.995
  },
  "model_checkpointing": {
    "checkpoint_interval": 10,
    "save_best_only": true,
    "checkpoint_dir": "models/checkpoints"
  },
  "logging": {
    "log_interval": 10,
    "log_dir": "logs/",
    "tensorboard": true,
    "tensorboard_log_dir": "logs/tensorboard_logs",
    "model_save_path": "models/saved_models"
  },
  "advanced_training_techniques": {
    "gradient_clipping": 0.5,
    "use_gae": true,
    "gae_lambda": 0.95,
    "normalize_advantages": true
  },
  "early_stopping": {
    "patience": 5
  },
  "reward_adjustments": {
    "collision_penalty": 50,
    "reward_threshold": 250
  },
  "shared_components": {
    "residual_block": {
      "input_dim": 128,
      "hidden_dim": 128,
      "dropout_rate": 0.2
    },
    "attention_layer": {
      "input_dim": 128,
      "hidden_dim": 128
    }
  },
  "icm": {
    "state_dim": 16,
    "action_dim": 3,
    "image_channels": 3,
    "image_height": 144,
    "image_width": 256,
    "cnn": {
      "conv1": {
        "out_channels": 32,
        "kernel_size": 8,
        "stride": 4
      },
      "conv2": {
        "out_channels": 64,
        "kernel_size": 4,
        "stride": 2
      },
      "conv3": {
        "out_channels": 64,
        "kernel_size": 3,
        "stride": 1
      }
    },
    "state_encoder": {
      "hidden_dim": 128
    },
    "forward_model": {
      "hidden_dim": 256
    },
    "inverse_model": {
      "hidden_dim": 256
    }
  },
  "predictive_model": {
    "learning_rate": 0.0001,
    "hidden_layers": [
      256,
      256
    ]
  },
  "hrl": {
    "use_hierarchical": true,
    "high_level_policy": {
      "input_size": 15,
      "hidden_layers": [
        256,
        256
      ],
      "output_size": 4
    },
    "sub_goal_dim": 3,
    "low_level_policy": {
      "input_size": 18,
      "hidden_layers": [
        256,
        256
      ],
      "output_size": 4
    }
  },
  "curriculum_learning": {
    "use_curriculum": true,
    "initial_difficulty": 1,
    "difficulty_increment": 1,
    "difficulty_threshold": 200
  },
  "multi_agent": {
    "use_multi_agent": true,
    "num_agents": 2,
    "hidden_layers": [
      256,
      256
    ]
  }
}
2024-07-20 16:39:50,023 - AirSimEnvLogger - INFO - DataVisualizer initialized with Seaborn style set to 'whitegrid'.
2024-07-20 16:39:50,070 - AirSimEnvLogger - INFO - PPOAgent initialization started.
2024-07-20 16:39:50,133 - AirSimEnvLogger - INFO - State dimension: 16
2024-07-20 16:39:50,180 - AirSimEnvLogger - INFO - Visual dimensions: 84x84x4
2024-07-20 16:39:50,227 - AirSimEnvLogger - INFO - Using device: cpu
2024-07-20 16:39:54,019 - AirSimEnvLogger - INFO - Policy Network: state_dim=16, action_dim=4, continuous=True
2024-07-20 16:39:54,067 - AirSimEnvLogger - INFO - Visual input: 144x256x3
2024-07-20 16:39:54,098 - AirSimEnvLogger - INFO - Total input size: 110608
2024-07-20 16:39:54,145 - AirSimEnvLogger - INFO - Critic Network: state_dim=15
2024-07-20 16:39:56,131 - AirSimEnvLogger - INFO - PPOAgent initialized successfully.
2024-07-20 16:41:33,290 - AirSimEnvLogger - INFO - Initializing AirSimEnv
2024-07-20 16:41:33,292 - AirSimEnvLogger - INFO - Configuration: {
  "learning_rate": 0.0001,
  "gamma": 0.99,
  "tau": 0.95,
  "batch_size": 64,
  "num_timesteps": 2000000,
  "ppo": {
    "learning_rate": 0.0003,
    "n_steps": 2048,
    "batch_size": 64,
    "n_epochs": 2000,
    "gamma": 0.99,
    "gae_lambda": 0.95,
    "clip_range": 0.2,
    "ent_coef": 0.01,
    "vf_coef": 0.5,
    "max_grad_norm": 0.5,
    "use_sde": true,
    "sde_sample_freq": 4,
    "tensorboard_log": "logs/tensorboard_logs/ppo_airsim_tensorboard/",
    "verbose": 1,
    "seed": null,
    "device": "auto",
    "continuous": true,
    "save_freq": 10000
  },
  "policy_network": {
    "input_size": 16,
    "hidden_layers": [
      256,
      256
    ],
    "output_size": 4,
    "use_batch_norm": true,
    "use_dropout": true,
    "dropout_rate": 0.2,
    "use_attention": true,
    "num_action_heads": 1
  },
  "critic_network": {
    "input_size": 15,
    "hidden_layers": [
      256,
      256
    ],
    "output_size": 1,
    "use_batch_norm": true,
    "use_dropout": true,
    "dropout_rate": 0.2,
    "use_attention": true
  },
  "environment": {
    "env_name": "Africa_001",
    "reward_threshold": 250,
    "max_env_steps": 1000,
    "state_dim": 15,
    "action_dim": 4,
    "reward_scale": 20,
    "proximity_threshold": 5.0,
    "collision_penalty": 25,
    "height_target": -10,
    "height_tolerance": 1.0,
    "height_penalty": 1,
    "movement_penalty": 0.5,
    "smoothness_penalty": 0.5,
    "duration": 0.1,
    "exploration_area": {
      "x_min": -1000,
      "x_max": 1000,
      "y_min": -1000,
      "y_max": 1000,
      "z_min": -100,
      "z_max": 100
    }
  },
  "exploration": {
    "strategy": "epsilon_decay",
    "initial_epsilon": 1.0,
    "min_epsilon": 0.05,
    "epsilon_decay_rate": 0.995
  },
  "model_checkpointing": {
    "checkpoint_interval": 10,
    "save_best_only": true,
    "checkpoint_dir": "models/checkpoints"
  },
  "logging": {
    "log_interval": 10,
    "log_dir": "logs/",
    "tensorboard": true,
    "tensorboard_log_dir": "logs/tensorboard_logs",
    "model_save_path": "models/saved_models"
  },
  "advanced_training_techniques": {
    "gradient_clipping": 0.5,
    "use_gae": true,
    "gae_lambda": 0.95,
    "normalize_advantages": true
  },
  "early_stopping": {
    "patience": 5
  },
  "reward_adjustments": {
    "collision_penalty": 50,
    "reward_threshold": 250
  },
  "shared_components": {
    "residual_block": {
      "input_dim": 128,
      "hidden_dim": 128,
      "dropout_rate": 0.2
    },
    "attention_layer": {
      "input_dim": 128,
      "hidden_dim": 128
    }
  },
  "icm": {
    "state_dim": 16,
    "action_dim": 3,
    "image_channels": 3,
    "image_height": 144,
    "image_width": 256,
    "cnn": {
      "conv1": {
        "out_channels": 32,
        "kernel_size": 8,
        "stride": 4
      },
      "conv2": {
        "out_channels": 64,
        "kernel_size": 4,
        "stride": 2
      },
      "conv3": {
        "out_channels": 64,
        "kernel_size": 3,
        "stride": 1
      }
    },
    "state_encoder": {
      "hidden_dim": 128
    },
    "forward_model": {
      "hidden_dim": 256
    },
    "inverse_model": {
      "hidden_dim": 256
    }
  },
  "predictive_model": {
    "learning_rate": 0.0001,
    "hidden_layers": [
      256,
      256
    ]
  },
  "hrl": {
    "use_hierarchical": true,
    "high_level_policy": {
      "input_size": 15,
      "hidden_layers": [
        256,
        256
      ],
      "output_size": 4
    },
    "sub_goal_dim": 3,
    "low_level_policy": {
      "input_size": 18,
      "hidden_layers": [
        256,
        256
      ],
      "output_size": 4
    }
  },
  "curriculum_learning": {
    "use_curriculum": true,
    "initial_difficulty": 1,
    "difficulty_increment": 1,
    "difficulty_threshold": 200
  },
  "multi_agent": {
    "use_multi_agent": true,
    "num_agents": 2,
    "hidden_layers": [
      256,
      256
    ]
  }
}
2024-07-20 16:41:34,394 - AirSimEnvLogger - INFO - DataVisualizer initialized with Seaborn style set to 'whitegrid'.
2024-07-20 16:41:34,440 - AirSimEnvLogger - INFO - PPOAgent initialization started.
2024-07-20 16:41:34,486 - AirSimEnvLogger - INFO - State dimension: 16
2024-07-20 16:41:34,532 - AirSimEnvLogger - INFO - Visual dimensions: 84x84x4
2024-07-20 16:41:34,578 - AirSimEnvLogger - INFO - Using device: cpu
2024-07-20 16:41:37,852 - AirSimEnvLogger - INFO - Policy Network: state_dim=16, action_dim=4, continuous=True
2024-07-20 16:41:37,899 - AirSimEnvLogger - INFO - Visual input: 144x256x3
2024-07-20 16:41:37,947 - AirSimEnvLogger - INFO - Total input size: 110608
2024-07-20 16:41:37,994 - AirSimEnvLogger - INFO - Critic Network: state_dim=15
2024-07-20 16:41:39,838 - AirSimEnvLogger - INFO - PPOAgent initialized successfully.
2024-07-20 16:44:19,709 - AirSimEnvLogger - INFO - Initializing AirSimEnv
2024-07-20 16:44:19,710 - AirSimEnvLogger - INFO - Configuration: {
  "learning_rate": 0.0001,
  "gamma": 0.99,
  "tau": 0.95,
  "batch_size": 64,
  "num_timesteps": 2000000,
  "ppo": {
    "learning_rate": 0.0003,
    "n_steps": 2048,
    "batch_size": 64,
    "n_epochs": 2000,
    "gamma": 0.99,
    "gae_lambda": 0.95,
    "clip_range": 0.2,
    "ent_coef": 0.01,
    "vf_coef": 0.5,
    "max_grad_norm": 0.5,
    "use_sde": true,
    "sde_sample_freq": 4,
    "tensorboard_log": "logs/tensorboard_logs/ppo_airsim_tensorboard/",
    "verbose": 1,
    "seed": null,
    "device": "auto",
    "continuous": true,
    "save_freq": 10000
  },
  "policy_network": {
    "input_size": 16,
    "hidden_layers": [
      256,
      256
    ],
    "output_size": 4,
    "use_batch_norm": true,
    "use_dropout": true,
    "dropout_rate": 0.2,
    "use_attention": true,
    "num_action_heads": 1
  },
  "critic_network": {
    "input_size": 15,
    "hidden_layers": [
      256,
      256
    ],
    "output_size": 1,
    "use_batch_norm": true,
    "use_dropout": true,
    "dropout_rate": 0.2,
    "use_attention": true
  },
  "environment": {
    "env_name": "Africa_001",
    "reward_threshold": 250,
    "max_env_steps": 1000,
    "state_dim": 15,
    "action_dim": 4,
    "reward_scale": 20,
    "proximity_threshold": 5.0,
    "collision_penalty": 25,
    "height_target": -10,
    "height_tolerance": 1.0,
    "height_penalty": 1,
    "movement_penalty": 0.5,
    "smoothness_penalty": 0.5,
    "duration": 0.1,
    "exploration_area": {
      "x_min": -1000,
      "x_max": 1000,
      "y_min": -1000,
      "y_max": 1000,
      "z_min": -100,
      "z_max": 100
    }
  },
  "exploration": {
    "strategy": "epsilon_decay",
    "initial_epsilon": 1.0,
    "min_epsilon": 0.05,
    "epsilon_decay_rate": 0.995
  },
  "model_checkpointing": {
    "checkpoint_interval": 10,
    "save_best_only": true,
    "checkpoint_dir": "models/checkpoints"
  },
  "logging": {
    "log_interval": 10,
    "log_dir": "logs/",
    "tensorboard": true,
    "tensorboard_log_dir": "logs/tensorboard_logs",
    "model_save_path": "models/saved_models"
  },
  "advanced_training_techniques": {
    "gradient_clipping": 0.5,
    "use_gae": true,
    "gae_lambda": 0.95,
    "normalize_advantages": true
  },
  "early_stopping": {
    "patience": 5
  },
  "reward_adjustments": {
    "collision_penalty": 50,
    "reward_threshold": 250
  },
  "shared_components": {
    "residual_block": {
      "input_dim": 128,
      "hidden_dim": 128,
      "dropout_rate": 0.2
    },
    "attention_layer": {
      "input_dim": 128,
      "hidden_dim": 128
    }
  },
  "icm": {
    "state_dim": 16,
    "action_dim": 3,
    "image_channels": 3,
    "image_height": 144,
    "image_width": 256,
    "cnn": {
      "conv1": {
        "out_channels": 32,
        "kernel_size": 8,
        "stride": 4
      },
      "conv2": {
        "out_channels": 64,
        "kernel_size": 4,
        "stride": 2
      },
      "conv3": {
        "out_channels": 64,
        "kernel_size": 3,
        "stride": 1
      }
    },
    "state_encoder": {
      "hidden_dim": 128
    },
    "forward_model": {
      "hidden_dim": 256
    },
    "inverse_model": {
      "hidden_dim": 256
    }
  },
  "predictive_model": {
    "learning_rate": 0.0001,
    "hidden_layers": [
      256,
      256
    ]
  },
  "hrl": {
    "use_hierarchical": true,
    "high_level_policy": {
      "input_size": 15,
      "hidden_layers": [
        256,
        256
      ],
      "output_size": 4
    },
    "sub_goal_dim": 3,
    "low_level_policy": {
      "input_size": 18,
      "hidden_layers": [
        256,
        256
      ],
      "output_size": 4
    }
  },
  "curriculum_learning": {
    "use_curriculum": true,
    "initial_difficulty": 1,
    "difficulty_increment": 1,
    "difficulty_threshold": 200
  },
  "multi_agent": {
    "use_multi_agent": true,
    "num_agents": 2,
    "hidden_layers": [
      256,
      256
    ]
  }
}
2024-07-20 16:44:20,963 - AirSimEnvLogger - INFO - DataVisualizer initialized with Seaborn style set to 'whitegrid'.
2024-07-20 16:44:21,008 - AirSimEnvLogger - INFO - PPOAgent initialization started.
2024-07-20 16:44:21,055 - AirSimEnvLogger - INFO - State dimension: 16
2024-07-20 16:44:21,102 - AirSimEnvLogger - INFO - Visual dimensions: 84x84x4
2024-07-20 16:44:21,149 - AirSimEnvLogger - INFO - Using device: cpu
2024-07-20 16:44:24,541 - AirSimEnvLogger - INFO - Policy Network: state_dim=16, action_dim=4, continuous=True
2024-07-20 16:44:24,588 - AirSimEnvLogger - INFO - Visual input: 144x256x3
2024-07-20 16:44:24,650 - AirSimEnvLogger - INFO - Total input size: 110608
2024-07-20 16:44:24,697 - AirSimEnvLogger - INFO - Critic Network: state_dim=15
2024-07-20 16:44:26,656 - AirSimEnvLogger - INFO - PPOAgent initialized successfully.
2024-07-20 16:47:00,125 - AirSimEnvLogger - INFO - Initializing AirSimEnv
2024-07-20 16:47:00,126 - AirSimEnvLogger - INFO - Configuration: {
  "learning_rate": 0.0001,
  "gamma": 0.99,
  "tau": 0.95,
  "batch_size": 64,
  "num_timesteps": 2000000,
  "ppo": {
    "learning_rate": 0.0003,
    "n_steps": 2048,
    "batch_size": 64,
    "n_epochs": 2000,
    "gamma": 0.99,
    "gae_lambda": 0.95,
    "clip_range": 0.2,
    "ent_coef": 0.01,
    "vf_coef": 0.5,
    "max_grad_norm": 0.5,
    "use_sde": true,
    "sde_sample_freq": 4,
    "tensorboard_log": "logs/tensorboard_logs/ppo_airsim_tensorboard/",
    "verbose": 1,
    "seed": null,
    "device": "auto",
    "continuous": true,
    "save_freq": 10000
  },
  "policy_network": {
    "input_size": 16,
    "hidden_layers": [
      256,
      256
    ],
    "output_size": 4,
    "use_batch_norm": true,
    "use_dropout": true,
    "dropout_rate": 0.2,
    "use_attention": true,
    "num_action_heads": 1
  },
  "critic_network": {
    "input_size": 15,
    "hidden_layers": [
      256,
      256
    ],
    "output_size": 1,
    "use_batch_norm": true,
    "use_dropout": true,
    "dropout_rate": 0.2,
    "use_attention": true
  },
  "environment": {
    "env_name": "Africa_001",
    "reward_threshold": 250,
    "max_env_steps": 1000,
    "state_dim": 15,
    "action_dim": 4,
    "reward_scale": 20,
    "proximity_threshold": 5.0,
    "collision_penalty": 25,
    "height_target": -10,
    "height_tolerance": 1.0,
    "height_penalty": 1,
    "movement_penalty": 0.5,
    "smoothness_penalty": 0.5,
    "duration": 0.1,
    "exploration_area": {
      "x_min": -1000,
      "x_max": 1000,
      "y_min": -1000,
      "y_max": 1000,
      "z_min": -100,
      "z_max": 100
    }
  },
  "exploration": {
    "strategy": "epsilon_decay",
    "initial_epsilon": 1.0,
    "min_epsilon": 0.05,
    "epsilon_decay_rate": 0.995
  },
  "model_checkpointing": {
    "checkpoint_interval": 10,
    "save_best_only": true,
    "checkpoint_dir": "models/checkpoints"
  },
  "logging": {
    "log_interval": 10,
    "log_dir": "logs/",
    "tensorboard": true,
    "tensorboard_log_dir": "logs/tensorboard_logs",
    "model_save_path": "models/saved_models"
  },
  "advanced_training_techniques": {
    "gradient_clipping": 0.5,
    "use_gae": true,
    "gae_lambda": 0.95,
    "normalize_advantages": true
  },
  "early_stopping": {
    "patience": 5
  },
  "reward_adjustments": {
    "collision_penalty": 50,
    "reward_threshold": 250
  },
  "shared_components": {
    "residual_block": {
      "input_dim": 128,
      "hidden_dim": 128,
      "dropout_rate": 0.2
    },
    "attention_layer": {
      "input_dim": 128,
      "hidden_dim": 128
    }
  },
  "icm": {
    "state_dim": 16,
    "action_dim": 3,
    "image_channels": 3,
    "image_height": 144,
    "image_width": 256,
    "cnn": {
      "conv1": {
        "out_channels": 32,
        "kernel_size": 8,
        "stride": 4
      },
      "conv2": {
        "out_channels": 64,
        "kernel_size": 4,
        "stride": 2
      },
      "conv3": {
        "out_channels": 64,
        "kernel_size": 3,
        "stride": 1
      }
    },
    "state_encoder": {
      "hidden_dim": 128
    },
    "forward_model": {
      "hidden_dim": 256
    },
    "inverse_model": {
      "hidden_dim": 256
    }
  },
  "predictive_model": {
    "learning_rate": 0.0001,
    "hidden_layers": [
      256,
      256
    ]
  },
  "hrl": {
    "use_hierarchical": true,
    "high_level_policy": {
      "input_size": 15,
      "hidden_layers": [
        256,
        256
      ],
      "output_size": 4
    },
    "sub_goal_dim": 3,
    "low_level_policy": {
      "input_size": 18,
      "hidden_layers": [
        256,
        256
      ],
      "output_size": 4
    }
  },
  "curriculum_learning": {
    "use_curriculum": true,
    "initial_difficulty": 1,
    "difficulty_increment": 1,
    "difficulty_threshold": 200
  },
  "multi_agent": {
    "use_multi_agent": true,
    "num_agents": 2,
    "hidden_layers": [
      256,
      256
    ]
  }
}
2024-07-20 16:47:01,331 - AirSimEnvLogger - INFO - DataVisualizer initialized with Seaborn style set to 'whitegrid'.
2024-07-20 16:47:01,392 - AirSimEnvLogger - INFO - PPOAgent initialization started.
2024-07-20 16:47:01,440 - AirSimEnvLogger - INFO - State dimension: 16
2024-07-20 16:47:01,487 - AirSimEnvLogger - INFO - Visual dimensions: 84x84x4
2024-07-20 16:47:01,533 - AirSimEnvLogger - INFO - Using device: cpu
2024-07-20 16:47:04,856 - AirSimEnvLogger - INFO - Policy Network: state_dim=16, action_dim=4, continuous=True
2024-07-20 16:47:04,904 - AirSimEnvLogger - INFO - Visual input: 144x256x3
2024-07-20 16:47:04,951 - AirSimEnvLogger - INFO - Total input size: 110608
2024-07-20 16:47:04,999 - AirSimEnvLogger - INFO - Critic Network: state_dim=15
2024-07-20 16:47:07,181 - AirSimEnvLogger - INFO - PPOAgent initialized successfully.
2024-07-20 16:47:12,756 - AirSimEnvLogger - ERROR - Observation shape mismatch. Expected 110608, got 1
2024-07-20 16:51:27,500 - AirSimEnvLogger - INFO - Initializing AirSimEnv
2024-07-20 16:51:27,501 - AirSimEnvLogger - INFO - Configuration: {
  "learning_rate": 0.0001,
  "gamma": 0.99,
  "tau": 0.95,
  "batch_size": 64,
  "num_timesteps": 2000000,
  "ppo": {
    "learning_rate": 0.0003,
    "n_steps": 2048,
    "batch_size": 64,
    "n_epochs": 2000,
    "gamma": 0.99,
    "gae_lambda": 0.95,
    "clip_range": 0.2,
    "ent_coef": 0.01,
    "vf_coef": 0.5,
    "max_grad_norm": 0.5,
    "use_sde": true,
    "sde_sample_freq": 4,
    "tensorboard_log": "logs/tensorboard_logs/ppo_airsim_tensorboard/",
    "verbose": 1,
    "seed": null,
    "device": "auto",
    "continuous": true,
    "save_freq": 10000
  },
  "policy_network": {
    "input_size": 16,
    "hidden_layers": [
      256,
      256
    ],
    "output_size": 4,
    "use_batch_norm": true,
    "use_dropout": true,
    "dropout_rate": 0.2,
    "use_attention": true,
    "num_action_heads": 1
  },
  "critic_network": {
    "input_size": 15,
    "hidden_layers": [
      256,
      256
    ],
    "output_size": 1,
    "use_batch_norm": true,
    "use_dropout": true,
    "dropout_rate": 0.2,
    "use_attention": true
  },
  "environment": {
    "env_name": "Africa_001",
    "reward_threshold": 250,
    "max_env_steps": 1000,
    "state_dim": 15,
    "action_dim": 4,
    "reward_scale": 20,
    "proximity_threshold": 5.0,
    "collision_penalty": 25,
    "height_target": -10,
    "height_tolerance": 1.0,
    "height_penalty": 1,
    "movement_penalty": 0.5,
    "smoothness_penalty": 0.5,
    "duration": 0.1,
    "exploration_area": {
      "x_min": -1000,
      "x_max": 1000,
      "y_min": -1000,
      "y_max": 1000,
      "z_min": -100,
      "z_max": 100
    }
  },
  "exploration": {
    "strategy": "epsilon_decay",
    "initial_epsilon": 1.0,
    "min_epsilon": 0.05,
    "epsilon_decay_rate": 0.995
  },
  "model_checkpointing": {
    "checkpoint_interval": 10,
    "save_best_only": true,
    "checkpoint_dir": "models/checkpoints"
  },
  "logging": {
    "log_interval": 10,
    "log_dir": "logs/",
    "tensorboard": true,
    "tensorboard_log_dir": "logs/tensorboard_logs",
    "model_save_path": "models/saved_models"
  },
  "advanced_training_techniques": {
    "gradient_clipping": 0.5,
    "use_gae": true,
    "gae_lambda": 0.95,
    "normalize_advantages": true
  },
  "early_stopping": {
    "patience": 5
  },
  "reward_adjustments": {
    "collision_penalty": 50,
    "reward_threshold": 250
  },
  "shared_components": {
    "residual_block": {
      "input_dim": 128,
      "hidden_dim": 128,
      "dropout_rate": 0.2
    },
    "attention_layer": {
      "input_dim": 128,
      "hidden_dim": 128
    }
  },
  "icm": {
    "state_dim": 16,
    "action_dim": 3,
    "image_channels": 3,
    "image_height": 144,
    "image_width": 256,
    "cnn": {
      "conv1": {
        "out_channels": 32,
        "kernel_size": 8,
        "stride": 4
      },
      "conv2": {
        "out_channels": 64,
        "kernel_size": 4,
        "stride": 2
      },
      "conv3": {
        "out_channels": 64,
        "kernel_size": 3,
        "stride": 1
      }
    },
    "state_encoder": {
      "hidden_dim": 128
    },
    "forward_model": {
      "hidden_dim": 256
    },
    "inverse_model": {
      "hidden_dim": 256
    }
  },
  "predictive_model": {
    "learning_rate": 0.0001,
    "hidden_layers": [
      256,
      256
    ]
  },
  "hrl": {
    "use_hierarchical": true,
    "high_level_policy": {
      "input_size": 15,
      "hidden_layers": [
        256,
        256
      ],
      "output_size": 4
    },
    "sub_goal_dim": 3,
    "low_level_policy": {
      "input_size": 18,
      "hidden_layers": [
        256,
        256
      ],
      "output_size": 4
    }
  },
  "curriculum_learning": {
    "use_curriculum": true,
    "initial_difficulty": 1,
    "difficulty_increment": 1,
    "difficulty_threshold": 200
  },
  "multi_agent": {
    "use_multi_agent": true,
    "num_agents": 2,
    "hidden_layers": [
      256,
      256
    ]
  }
}
2024-07-20 16:51:28,576 - AirSimEnvLogger - INFO - DataVisualizer initialized with Seaborn style set to 'whitegrid'.
2024-07-20 16:51:28,621 - AirSimEnvLogger - INFO - PPOAgent initialization started.
2024-07-20 16:51:28,667 - AirSimEnvLogger - INFO - State dimension: 16
2024-07-20 16:51:28,713 - AirSimEnvLogger - INFO - Visual dimensions: 84x84x4
2024-07-20 16:51:28,759 - AirSimEnvLogger - INFO - Using device: cpu
2024-07-20 16:51:32,152 - AirSimEnvLogger - INFO - Policy Network: state_dim=16, action_dim=4, continuous=True
2024-07-20 16:51:32,199 - AirSimEnvLogger - INFO - Visual input: 144x256x3
2024-07-20 16:51:32,245 - AirSimEnvLogger - INFO - Total input size: 110608
2024-07-20 16:51:32,291 - AirSimEnvLogger - INFO - Critic Network: state_dim=15
2024-07-20 16:51:34,124 - AirSimEnvLogger - INFO - PPOAgent initialized successfully.
2024-07-20 16:51:40,012 - AirSimEnvLogger - INFO - Initial observation: type=<class 'numpy.ndarray'>, shape=(1, 110608)
2024-07-20 16:51:40,059 - AirSimEnvLogger - INFO - Observation before select_action: type=<class 'numpy.ndarray'>, shape=(1, 110608)
2024-07-20 16:51:47,397 - AirSimEnvLogger - INFO - Next observation: type=<class 'numpy.ndarray'>, shape=(1, 110608)
2024-07-20 16:51:47,444 - AirSimEnvLogger - ERROR - Observation shape mismatch. Expected 110608, got 1
2024-07-20 16:54:35,363 - AirSimEnvLogger - INFO - Initializing AirSimEnv
2024-07-20 16:54:35,365 - AirSimEnvLogger - INFO - Configuration: {
  "learning_rate": 0.0001,
  "gamma": 0.99,
  "tau": 0.95,
  "batch_size": 64,
  "num_timesteps": 2000000,
  "ppo": {
    "learning_rate": 0.0003,
    "n_steps": 2048,
    "batch_size": 64,
    "n_epochs": 2000,
    "gamma": 0.99,
    "gae_lambda": 0.95,
    "clip_range": 0.2,
    "ent_coef": 0.01,
    "vf_coef": 0.5,
    "max_grad_norm": 0.5,
    "use_sde": true,
    "sde_sample_freq": 4,
    "tensorboard_log": "logs/tensorboard_logs/ppo_airsim_tensorboard/",
    "verbose": 1,
    "seed": null,
    "device": "auto",
    "continuous": true,
    "save_freq": 10000
  },
  "policy_network": {
    "input_size": 16,
    "hidden_layers": [
      256,
      256
    ],
    "output_size": 4,
    "use_batch_norm": true,
    "use_dropout": true,
    "dropout_rate": 0.2,
    "use_attention": true,
    "num_action_heads": 1
  },
  "critic_network": {
    "input_size": 15,
    "hidden_layers": [
      256,
      256
    ],
    "output_size": 1,
    "use_batch_norm": true,
    "use_dropout": true,
    "dropout_rate": 0.2,
    "use_attention": true
  },
  "environment": {
    "env_name": "Africa_001",
    "reward_threshold": 250,
    "max_env_steps": 1000,
    "state_dim": 15,
    "action_dim": 4,
    "reward_scale": 20,
    "proximity_threshold": 5.0,
    "collision_penalty": 25,
    "height_target": -10,
    "height_tolerance": 1.0,
    "height_penalty": 1,
    "movement_penalty": 0.5,
    "smoothness_penalty": 0.5,
    "duration": 0.1,
    "exploration_area": {
      "x_min": -1000,
      "x_max": 1000,
      "y_min": -1000,
      "y_max": 1000,
      "z_min": -100,
      "z_max": 100
    }
  },
  "exploration": {
    "strategy": "epsilon_decay",
    "initial_epsilon": 1.0,
    "min_epsilon": 0.05,
    "epsilon_decay_rate": 0.995
  },
  "model_checkpointing": {
    "checkpoint_interval": 10,
    "save_best_only": true,
    "checkpoint_dir": "models/checkpoints"
  },
  "logging": {
    "log_interval": 10,
    "log_dir": "logs/",
    "tensorboard": true,
    "tensorboard_log_dir": "logs/tensorboard_logs",
    "model_save_path": "models/saved_models"
  },
  "advanced_training_techniques": {
    "gradient_clipping": 0.5,
    "use_gae": true,
    "gae_lambda": 0.95,
    "normalize_advantages": true
  },
  "early_stopping": {
    "patience": 5
  },
  "reward_adjustments": {
    "collision_penalty": 50,
    "reward_threshold": 250
  },
  "shared_components": {
    "residual_block": {
      "input_dim": 128,
      "hidden_dim": 128,
      "dropout_rate": 0.2
    },
    "attention_layer": {
      "input_dim": 128,
      "hidden_dim": 128
    }
  },
  "icm": {
    "state_dim": 16,
    "action_dim": 3,
    "image_channels": 3,
    "image_height": 144,
    "image_width": 256,
    "cnn": {
      "conv1": {
        "out_channels": 32,
        "kernel_size": 8,
        "stride": 4
      },
      "conv2": {
        "out_channels": 64,
        "kernel_size": 4,
        "stride": 2
      },
      "conv3": {
        "out_channels": 64,
        "kernel_size": 3,
        "stride": 1
      }
    },
    "state_encoder": {
      "hidden_dim": 128
    },
    "forward_model": {
      "hidden_dim": 256
    },
    "inverse_model": {
      "hidden_dim": 256
    }
  },
  "predictive_model": {
    "learning_rate": 0.0001,
    "hidden_layers": [
      256,
      256
    ]
  },
  "hrl": {
    "use_hierarchical": true,
    "high_level_policy": {
      "input_size": 15,
      "hidden_layers": [
        256,
        256
      ],
      "output_size": 4
    },
    "sub_goal_dim": 3,
    "low_level_policy": {
      "input_size": 18,
      "hidden_layers": [
        256,
        256
      ],
      "output_size": 4
    }
  },
  "curriculum_learning": {
    "use_curriculum": true,
    "initial_difficulty": 1,
    "difficulty_increment": 1,
    "difficulty_threshold": 200
  },
  "multi_agent": {
    "use_multi_agent": true,
    "num_agents": 2,
    "hidden_layers": [
      256,
      256
    ]
  }
}
2024-07-20 16:54:36,482 - AirSimEnvLogger - INFO - DataVisualizer initialized with Seaborn style set to 'whitegrid'.
2024-07-20 16:54:36,513 - AirSimEnvLogger - INFO - PPOAgent initialization started.
2024-07-20 16:54:36,560 - AirSimEnvLogger - INFO - State dimension: 16
2024-07-20 16:54:36,607 - AirSimEnvLogger - INFO - Visual dimensions: 84x84x4
2024-07-20 16:54:36,640 - AirSimEnvLogger - INFO - Using device: cpu
2024-07-20 16:54:39,863 - AirSimEnvLogger - INFO - Policy Network: state_dim=16, action_dim=4, continuous=True
2024-07-20 16:54:39,894 - AirSimEnvLogger - INFO - Visual input: 144x256x3
2024-07-20 16:54:39,942 - AirSimEnvLogger - INFO - Total input size: 110608
2024-07-20 16:54:39,989 - AirSimEnvLogger - INFO - Critic Network: state_dim=15
2024-07-20 16:54:42,128 - AirSimEnvLogger - INFO - PPOAgent initialized successfully.
2024-07-20 16:54:47,559 - AirSimEnvLogger - INFO - Initial observation: type=<class 'numpy.ndarray'>, shape=(1, 110608)
2024-07-20 16:54:47,605 - AirSimEnvLogger - INFO - Observation before select_action: type=<class 'numpy.ndarray'>, shape=(1, 110608)
2024-07-20 16:54:54,753 - AirSimEnvLogger - INFO - Next observation: type=<class 'numpy.ndarray'>, shape=(1, 110608)
2024-07-20 16:54:54,786 - AirSimEnvLogger - INFO - Epoch 0, Iteration 0: Reward: [0.]
2024-07-20 16:54:55,721 - AirSimEnvLogger - INFO - Model saved at e:\Project\Drone\models/checkpoints\ppo_agent_epoch_0.pt
2024-07-20 16:54:56,425 - AirSimEnvLogger - INFO - Checkpoint saved at epoch 0
2024-07-20 16:55:02,239 - AirSimEnvLogger - INFO - Initial observation: type=<class 'numpy.ndarray'>, shape=(1, 110608)
2024-07-20 16:55:02,286 - AirSimEnvLogger - INFO - Observation before select_action: type=<class 'numpy.ndarray'>, shape=(1, 110608)
2024-07-20 16:55:09,544 - AirSimEnvLogger - INFO - Next observation: type=<class 'numpy.ndarray'>, shape=(1, 110608)
2024-07-20 16:55:09,591 - AirSimEnvLogger - INFO - Epoch 1, Iteration 0: Reward: [0.]
2024-07-20 16:55:15,213 - AirSimEnvLogger - INFO - Initial observation: type=<class 'numpy.ndarray'>, shape=(1, 110608)
2024-07-20 16:55:15,260 - AirSimEnvLogger - INFO - Observation before select_action: type=<class 'numpy.ndarray'>, shape=(1, 110608)
2024-07-20 16:55:23,114 - AirSimEnvLogger - INFO - Next observation: type=<class 'numpy.ndarray'>, shape=(1, 110608)
2024-07-20 16:55:23,162 - AirSimEnvLogger - INFO - Epoch 2, Iteration 0: Reward: [0.]
2024-07-20 16:55:28,638 - AirSimEnvLogger - INFO - Initial observation: type=<class 'numpy.ndarray'>, shape=(1, 110608)
2024-07-20 16:55:28,686 - AirSimEnvLogger - INFO - Observation before select_action: type=<class 'numpy.ndarray'>, shape=(1, 110608)
2024-07-20 16:55:34,673 - AirSimEnvLogger - INFO - Next observation: type=<class 'numpy.ndarray'>, shape=(1, 110608)
2024-07-20 16:55:34,720 - AirSimEnvLogger - INFO - Epoch 3, Iteration 0: Reward: [0.]
2024-07-20 16:55:40,231 - AirSimEnvLogger - INFO - Initial observation: type=<class 'numpy.ndarray'>, shape=(1, 110608)
2024-07-20 16:55:40,278 - AirSimEnvLogger - INFO - Observation before select_action: type=<class 'numpy.ndarray'>, shape=(1, 110608)
2024-07-20 16:55:47,149 - AirSimEnvLogger - INFO - Next observation: type=<class 'numpy.ndarray'>, shape=(1, 110608)
2024-07-20 16:55:47,195 - AirSimEnvLogger - INFO - Epoch 4, Iteration 0: Reward: [0.]
2024-07-20 16:55:53,312 - AirSimEnvLogger - INFO - Initial observation: type=<class 'numpy.ndarray'>, shape=(1, 110608)
2024-07-20 16:55:53,358 - AirSimEnvLogger - INFO - Observation before select_action: type=<class 'numpy.ndarray'>, shape=(1, 110608)
2024-07-20 16:56:00,972 - AirSimEnvLogger - INFO - Next observation: type=<class 'numpy.ndarray'>, shape=(1, 110608)
2024-07-20 16:56:01,019 - AirSimEnvLogger - INFO - Epoch 5, Iteration 0: Reward: [0.]
2024-07-20 16:56:01,081 - AirSimEnvLogger - INFO - Early stopping triggered after 6 epochs.
2024-07-20 17:14:38,090 - AirSimEnvLogger - INFO - Initializing AirSimEnv
2024-07-20 17:14:38,090 - AirSimEnvLogger - INFO - Configuration: {
  "learning_rate": 0.0001,
  "gamma": 0.99,
  "tau": 0.95,
  "batch_size": 64,
  "num_timesteps": 2000000,
  "ppo": {
    "learning_rate": 0.0003,
    "n_steps": 2048,
    "batch_size": 64,
    "n_epochs": 2000,
    "gamma": 0.99,
    "gae_lambda": 0.95,
    "clip_range": 0.2,
    "ent_coef": 0.01,
    "vf_coef": 0.5,
    "max_grad_norm": 0.5,
    "use_sde": true,
    "sde_sample_freq": 4,
    "tensorboard_log": "logs/tensorboard_logs/ppo_airsim_tensorboard/",
    "verbose": 1,
    "seed": null,
    "device": "auto",
    "continuous": true,
    "save_freq": 10000,
    "max_steps_per_episode": 1000
  },
  "policy_network": {
    "input_size": 16,
    "hidden_layers": [
      256,
      256
    ],
    "output_size": 4,
    "use_batch_norm": true,
    "use_dropout": true,
    "dropout_rate": 0.2,
    "use_attention": true,
    "num_action_heads": 1
  },
  "critic_network": {
    "input_size": 15,
    "hidden_layers": [
      256,
      256
    ],
    "output_size": 1,
    "use_batch_norm": true,
    "use_dropout": true,
    "dropout_rate": 0.2,
    "use_attention": true
  },
  "environment": {
    "env_name": "Africa_001",
    "reward_threshold": 250,
    "max_env_steps": 1000,
    "state_dim": 15,
    "action_dim": 4,
    "reward_scale": 20,
    "proximity_threshold": 5.0,
    "collision_penalty": 25,
    "height_target": -10,
    "height_tolerance": 1.0,
    "height_penalty": 1,
    "movement_penalty": 0.1,
    "smoothness_penalty": 0.1,
    "duration": 0.1,
    "exploration_area": {
      "x_min": -1000,
      "x_max": 1000,
      "y_min": -1000,
      "y_max": 1000,
      "z_min": -100,
      "z_max": 100
    }
  },
  "exploration": {
    "strategy": "epsilon_decay",
    "initial_epsilon": 1.0,
    "min_epsilon": 0.05,
    "epsilon_decay_rate": 0.9995
  },
  "model_checkpointing": {
    "checkpoint_interval": 10,
    "save_best_only": true,
    "checkpoint_dir": "models/checkpoints"
  },
  "logging": {
    "log_interval": 10,
    "log_dir": "logs/",
    "tensorboard": true,
    "tensorboard_log_dir": "logs/tensorboard_logs",
    "model_save_path": "models/saved_models"
  },
  "advanced_training_techniques": {
    "gradient_clipping": 0.5,
    "use_gae": true,
    "gae_lambda": 0.95,
    "normalize_advantages": true
  },
  "early_stopping": {
    "patience": 10
  },
  "reward_adjustments": {
    "collision_penalty": 50,
    "reward_threshold": 250
  },
  "shared_components": {
    "residual_block": {
      "input_dim": 128,
      "hidden_dim": 128,
      "dropout_rate": 0.2
    },
    "attention_layer": {
      "input_dim": 128,
      "hidden_dim": 128
    }
  },
  "icm": {
    "state_dim": 16,
    "action_dim": 3,
    "image_channels": 3,
    "image_height": 144,
    "image_width": 256,
    "cnn": {
      "conv1": {
        "out_channels": 32,
        "kernel_size": 8,
        "stride": 4
      },
      "conv2": {
        "out_channels": 64,
        "kernel_size": 4,
        "stride": 2
      },
      "conv3": {
        "out_channels": 64,
        "kernel_size": 3,
        "stride": 1
      }
    },
    "state_encoder": {
      "hidden_dim": 128
    },
    "forward_model": {
      "hidden_dim": 256
    },
    "inverse_model": {
      "hidden_dim": 256
    }
  },
  "predictive_model": {
    "learning_rate": 0.0001,
    "hidden_layers": [
      256,
      256
    ]
  },
  "hrl": {
    "use_hierarchical": true,
    "high_level_policy": {
      "input_size": 15,
      "hidden_layers": [
        256,
        256
      ],
      "output_size": 4
    },
    "sub_goal_dim": 3,
    "low_level_policy": {
      "input_size": 18,
      "hidden_layers": [
        256,
        256
      ],
      "output_size": 4
    }
  },
  "curriculum_learning": {
    "use_curriculum": true,
    "initial_difficulty": 1,
    "difficulty_increment": 1,
    "difficulty_threshold": 200
  },
  "multi_agent": {
    "use_multi_agent": true,
    "num_agents": 2,
    "hidden_layers": [
      256,
      256
    ]
  }
}
2024-07-20 17:14:39,266 - AirSimEnvLogger - INFO - DataVisualizer initialized with Seaborn style set to 'whitegrid'.
2024-07-20 17:14:39,313 - AirSimEnvLogger - INFO - PPOAgent initialization started.
2024-07-20 17:14:39,359 - AirSimEnvLogger - INFO - State dimension: 16
2024-07-20 17:14:39,405 - AirSimEnvLogger - INFO - Visual dimensions: 84x84x4
2024-07-20 17:14:39,452 - AirSimEnvLogger - INFO - Using device: cpu
2024-07-20 17:14:43,079 - AirSimEnvLogger - INFO - Policy Network: state_dim=16, action_dim=4, continuous=True
2024-07-20 17:14:43,127 - AirSimEnvLogger - INFO - Visual input: 144x256x3
2024-07-20 17:14:43,174 - AirSimEnvLogger - INFO - Total input size: 110608
2024-07-20 17:14:43,221 - AirSimEnvLogger - INFO - Critic Network: state_dim=15
2024-07-20 17:14:45,413 - AirSimEnvLogger - INFO - PPOAgent initialized successfully.
2024-07-20 17:18:53,664 - AirSimEnvLogger - INFO - Initializing AirSimEnv
2024-07-20 17:18:53,665 - AirSimEnvLogger - INFO - Configuration: {
  "learning_rate": 0.0001,
  "gamma": 0.99,
  "tau": 0.95,
  "batch_size": 64,
  "num_timesteps": 2000000,
  "ppo": {
    "learning_rate": 0.0003,
    "n_steps": 2048,
    "batch_size": 64,
    "n_epochs": 2000,
    "gamma": 0.99,
    "gae_lambda": 0.95,
    "clip_range": 0.2,
    "ent_coef": 0.01,
    "vf_coef": 0.5,
    "max_grad_norm": 0.5,
    "use_sde": true,
    "sde_sample_freq": 4,
    "tensorboard_log": "logs/tensorboard_logs/ppo_airsim_tensorboard/",
    "verbose": 1,
    "seed": null,
    "device": "auto",
    "continuous": true,
    "save_freq": 10000,
    "max_steps_per_episode": 1000
  },
  "policy_network": {
    "input_size": 16,
    "hidden_layers": [
      256,
      256
    ],
    "output_size": 4,
    "use_batch_norm": true,
    "use_dropout": true,
    "dropout_rate": 0.2,
    "use_attention": true,
    "num_action_heads": 1
  },
  "critic_network": {
    "input_size": 15,
    "hidden_layers": [
      256,
      256
    ],
    "output_size": 1,
    "use_batch_norm": true,
    "use_dropout": true,
    "dropout_rate": 0.2,
    "use_attention": true
  },
  "environment": {
    "env_name": "Africa_001",
    "reward_threshold": 250,
    "max_env_steps": 1000,
    "state_dim": 15,
    "action_dim": 4,
    "reward_scale": 20,
    "proximity_threshold": 5.0,
    "collision_penalty": 25,
    "height_target": -10,
    "height_tolerance": 1.0,
    "height_penalty": 1,
    "movement_penalty": 0.1,
    "smoothness_penalty": 0.1,
    "duration": 0.1,
    "exploration_area": {
      "x_min": -1000,
      "x_max": 1000,
      "y_min": -1000,
      "y_max": 1000,
      "z_min": -100,
      "z_max": 100
    }
  },
  "exploration": {
    "strategy": "epsilon_decay",
    "initial_epsilon": 1.0,
    "min_epsilon": 0.05,
    "epsilon_decay_rate": 0.9995
  },
  "model_checkpointing": {
    "checkpoint_interval": 10,
    "save_best_only": true,
    "checkpoint_dir": "models/checkpoints"
  },
  "logging": {
    "log_interval": 10,
    "log_dir": "logs/",
    "tensorboard": true,
    "tensorboard_log_dir": "logs/tensorboard_logs",
    "model_save_path": "models/saved_models"
  },
  "advanced_training_techniques": {
    "gradient_clipping": 0.5,
    "use_gae": true,
    "gae_lambda": 0.95,
    "normalize_advantages": true
  },
  "early_stopping": {
    "patience": 10
  },
  "reward_adjustments": {
    "collision_penalty": 50,
    "reward_threshold": 250
  },
  "shared_components": {
    "residual_block": {
      "input_dim": 128,
      "hidden_dim": 128,
      "dropout_rate": 0.2
    },
    "attention_layer": {
      "input_dim": 128,
      "hidden_dim": 128
    }
  },
  "icm": {
    "state_dim": 16,
    "action_dim": 3,
    "image_channels": 3,
    "image_height": 144,
    "image_width": 256,
    "cnn": {
      "conv1": {
        "out_channels": 32,
        "kernel_size": 8,
        "stride": 4
      },
      "conv2": {
        "out_channels": 64,
        "kernel_size": 4,
        "stride": 2
      },
      "conv3": {
        "out_channels": 64,
        "kernel_size": 3,
        "stride": 1
      }
    },
    "state_encoder": {
      "hidden_dim": 128
    },
    "forward_model": {
      "hidden_dim": 256
    },
    "inverse_model": {
      "hidden_dim": 256
    }
  },
  "predictive_model": {
    "learning_rate": 0.0001,
    "hidden_layers": [
      256,
      256
    ]
  },
  "hrl": {
    "use_hierarchical": true,
    "high_level_policy": {
      "input_size": 15,
      "hidden_layers": [
        256,
        256
      ],
      "output_size": 4
    },
    "sub_goal_dim": 3,
    "low_level_policy": {
      "input_size": 18,
      "hidden_layers": [
        256,
        256
      ],
      "output_size": 4
    }
  },
  "curriculum_learning": {
    "use_curriculum": true,
    "initial_difficulty": 1,
    "difficulty_increment": 1,
    "difficulty_threshold": 200
  },
  "multi_agent": {
    "use_multi_agent": true,
    "num_agents": 2,
    "hidden_layers": [
      256,
      256
    ]
  }
}
2024-07-20 17:18:54,864 - AirSimEnvLogger - INFO - DataVisualizer initialized with Seaborn style set to 'whitegrid'.
2024-07-20 17:18:54,910 - AirSimEnvLogger - INFO - PPOAgent initialization started.
2024-07-20 17:18:54,956 - AirSimEnvLogger - INFO - State dimension: 16
2024-07-20 17:18:55,004 - AirSimEnvLogger - INFO - Visual dimensions: 84x84x4
2024-07-20 17:18:55,054 - AirSimEnvLogger - INFO - Using device: cpu
2024-07-20 17:18:58,951 - AirSimEnvLogger - INFO - Policy Network: state_dim=16, action_dim=4, continuous=True
2024-07-20 17:18:58,997 - AirSimEnvLogger - INFO - Visual input: 144x256x3
2024-07-20 17:18:59,045 - AirSimEnvLogger - INFO - Total input size: 110608
2024-07-20 17:18:59,091 - AirSimEnvLogger - INFO - Critic Network: state_dim=15
2024-07-20 17:19:01,105 - AirSimEnvLogger - INFO - PPOAgent initialized successfully.
2024-07-20 17:19:01,199 - AirSimEnvLogger - INFO - Loading checkpoint from e:\Project\Drone\models/checkpoints\ppo_agent_checkpoint.pt
2024-07-20 17:19:03,633 - AirSimEnvLogger - ERROR - Error loading checkpoint: 'policy_state_dict'
2024-07-20 17:19:09,088 - AirSimEnvLogger - INFO - Initial observation: type=<class 'numpy.ndarray'>, shape=(1, 110608)
2024-07-20 17:19:16,410 - AirSimEnvLogger - INFO - Step 0: Action: [-0.6751496   0.14314269 -0.94446456 -0.22348812], Reward: [0.]
2024-07-20 17:19:16,457 - AirSimEnvLogger - INFO - Epoch 0, Step 0: Reward: [0.]
2024-07-20 17:19:16,584 - AirSimEnvLogger - INFO - Episode ended after 1 steps with total reward: [0.]
2024-07-20 17:19:16,630 - AirSimEnvLogger - ERROR - An error occurred: update() takes 1 positional argument but 2 were given
2024-07-20 17:19:23,002 - AirSimEnvLogger - INFO - Environment closed.
2024-07-20 17:19:23,126 - AirSimEnvLogger - INFO - Training completed and models saved.
2024-07-20 17:22:52,744 - AirSimEnvLogger - INFO - Initializing AirSimEnv
2024-07-20 17:22:52,746 - AirSimEnvLogger - INFO - Configuration: {
  "learning_rate": 0.0001,
  "gamma": 0.99,
  "tau": 0.95,
  "batch_size": 64,
  "num_timesteps": 2000000,
  "ppo": {
    "learning_rate": 0.0003,
    "n_steps": 2048,
    "batch_size": 64,
    "n_epochs": 2000,
    "gamma": 0.99,
    "gae_lambda": 0.95,
    "clip_range": 0.2,
    "ent_coef": 0.01,
    "vf_coef": 0.5,
    "max_grad_norm": 0.5,
    "use_sde": true,
    "sde_sample_freq": 4,
    "tensorboard_log": "logs/tensorboard_logs/ppo_airsim_tensorboard/",
    "verbose": 1,
    "seed": null,
    "device": "auto",
    "continuous": true,
    "save_freq": 10000,
    "max_steps_per_episode": 1000
  },
  "policy_network": {
    "input_size": 16,
    "hidden_layers": [
      256,
      256
    ],
    "output_size": 4,
    "use_batch_norm": true,
    "use_dropout": true,
    "dropout_rate": 0.2,
    "use_attention": true,
    "num_action_heads": 1
  },
  "critic_network": {
    "input_size": 15,
    "hidden_layers": [
      256,
      256
    ],
    "output_size": 1,
    "use_batch_norm": true,
    "use_dropout": true,
    "dropout_rate": 0.2,
    "use_attention": true
  },
  "environment": {
    "env_name": "Africa_001",
    "reward_threshold": 250,
    "max_env_steps": 1000,
    "state_dim": 15,
    "action_dim": 4,
    "reward_scale": 20,
    "proximity_threshold": 5.0,
    "collision_penalty": 25,
    "height_target": -10,
    "height_tolerance": 1.0,
    "height_penalty": 1,
    "movement_penalty": 0.1,
    "smoothness_penalty": 0.1,
    "duration": 0.1,
    "exploration_area": {
      "x_min": -1000,
      "x_max": 1000,
      "y_min": -1000,
      "y_max": 1000,
      "z_min": -100,
      "z_max": 100
    }
  },
  "exploration": {
    "strategy": "epsilon_decay",
    "initial_epsilon": 1.0,
    "min_epsilon": 0.05,
    "epsilon_decay_rate": 0.9995
  },
  "model_checkpointing": {
    "checkpoint_interval": 10,
    "save_best_only": true,
    "checkpoint_dir": "models/checkpoints"
  },
  "logging": {
    "log_interval": 10,
    "log_dir": "logs/",
    "tensorboard": true,
    "tensorboard_log_dir": "logs/tensorboard_logs",
    "model_save_path": "models/saved_models"
  },
  "advanced_training_techniques": {
    "gradient_clipping": 0.5,
    "use_gae": true,
    "gae_lambda": 0.95,
    "normalize_advantages": true
  },
  "early_stopping": {
    "patience": 10
  },
  "reward_adjustments": {
    "collision_penalty": 50,
    "reward_threshold": 250
  },
  "shared_components": {
    "residual_block": {
      "input_dim": 128,
      "hidden_dim": 128,
      "dropout_rate": 0.2
    },
    "attention_layer": {
      "input_dim": 128,
      "hidden_dim": 128
    }
  },
  "icm": {
    "state_dim": 16,
    "action_dim": 3,
    "image_channels": 3,
    "image_height": 144,
    "image_width": 256,
    "cnn": {
      "conv1": {
        "out_channels": 32,
        "kernel_size": 8,
        "stride": 4
      },
      "conv2": {
        "out_channels": 64,
        "kernel_size": 4,
        "stride": 2
      },
      "conv3": {
        "out_channels": 64,
        "kernel_size": 3,
        "stride": 1
      }
    },
    "state_encoder": {
      "hidden_dim": 128
    },
    "forward_model": {
      "hidden_dim": 256
    },
    "inverse_model": {
      "hidden_dim": 256
    }
  },
  "predictive_model": {
    "learning_rate": 0.0001,
    "hidden_layers": [
      256,
      256
    ]
  },
  "hrl": {
    "use_hierarchical": true,
    "high_level_policy": {
      "input_size": 15,
      "hidden_layers": [
        256,
        256
      ],
      "output_size": 4
    },
    "sub_goal_dim": 3,
    "low_level_policy": {
      "input_size": 18,
      "hidden_layers": [
        256,
        256
      ],
      "output_size": 4
    }
  },
  "curriculum_learning": {
    "use_curriculum": true,
    "initial_difficulty": 1,
    "difficulty_increment": 1,
    "difficulty_threshold": 200
  },
  "multi_agent": {
    "use_multi_agent": true,
    "num_agents": 2,
    "hidden_layers": [
      256,
      256
    ]
  }
}
2024-07-20 17:22:53,855 - AirSimEnvLogger - INFO - DataVisualizer initialized with Seaborn style set to 'whitegrid'.
2024-07-20 17:22:53,900 - AirSimEnvLogger - INFO - PPOAgent initialization started.
2024-07-20 17:22:53,947 - AirSimEnvLogger - INFO - State dimension: 16
2024-07-20 17:22:53,994 - AirSimEnvLogger - INFO - Visual dimensions: 84x84x4
2024-07-20 17:22:54,042 - AirSimEnvLogger - INFO - Using device: cpu
2024-07-20 17:22:57,558 - AirSimEnvLogger - INFO - Policy Network: state_dim=16, action_dim=4, continuous=True
2024-07-20 17:22:57,606 - AirSimEnvLogger - INFO - Visual input: 144x256x3
2024-07-20 17:22:57,622 - AirSimEnvLogger - INFO - Total input size: 110608
2024-07-20 17:22:57,669 - AirSimEnvLogger - INFO - Critic Network: state_dim=15
2024-07-20 17:22:59,692 - AirSimEnvLogger - INFO - PPOAgent initialized successfully.
2024-07-20 17:22:59,803 - AirSimEnvLogger - INFO - Loading checkpoint from e:\Project\Drone\models/checkpoints\ppo_agent_checkpoint.pt
2024-07-20 17:23:02,196 - AirSimEnvLogger - ERROR - Error loading checkpoint: 'policy_state_dict'
2024-07-20 17:23:08,939 - AirSimEnvLogger - INFO - Initial observation: type=<class 'numpy.ndarray'>, shape=(1, 110608)
2024-07-20 17:23:16,692 - AirSimEnvLogger - INFO - Step 0: Action: [ 0.06489728 -0.8386281   0.78343797 -0.9156666 ], Reward: [0.]
2024-07-20 17:23:16,738 - AirSimEnvLogger - INFO - Epoch 0, Step 0: Reward: [0.]
2024-07-20 17:23:16,881 - AirSimEnvLogger - INFO - Episode ended after 1 steps with total reward: [0.]
2024-07-20 17:23:16,928 - AirSimEnvLogger - ERROR - An error occurred: update() takes 1 positional argument but 2 were given
2024-07-20 17:23:23,236 - AirSimEnvLogger - INFO - Environment closed.
2024-07-20 17:23:23,360 - AirSimEnvLogger - INFO - Training completed and models saved.
2024-07-21 01:48:33,744 - AirSimEnvLogger - INFO - Initializing AirSimEnv
2024-07-21 01:48:33,745 - AirSimEnvLogger - INFO - Configuration: {
  "learning_rate": 0.0001,
  "gamma": 0.99,
  "tau": 0.95,
  "batch_size": 64,
  "num_timesteps": 2000000,
  "ppo": {
    "learning_rate": 0.0003,
    "n_steps": 2048,
    "batch_size": 64,
    "n_epochs": 2000,
    "gamma": 0.99,
    "gae_lambda": 0.95,
    "clip_range": 0.2,
    "ent_coef": 0.01,
    "vf_coef": 0.5,
    "max_grad_norm": 0.5,
    "use_sde": true,
    "sde_sample_freq": 4,
    "tensorboard_log": "logs/tensorboard_logs/ppo_airsim_tensorboard/",
    "verbose": 1,
    "seed": null,
    "device": "auto",
    "continuous": true,
    "save_freq": 10000,
    "max_steps_per_episode": 1000
  },
  "policy_network": {
    "input_size": 16,
    "hidden_layers": [
      256,
      256
    ],
    "output_size": 4,
    "use_batch_norm": true,
    "use_dropout": true,
    "dropout_rate": 0.2,
    "use_attention": true,
    "num_action_heads": 1
  },
  "critic_network": {
    "input_size": 15,
    "hidden_layers": [
      256,
      256
    ],
    "output_size": 1,
    "use_batch_norm": true,
    "use_dropout": true,
    "dropout_rate": 0.2,
    "use_attention": true
  },
  "environment": {
    "env_name": "Africa_001",
    "reward_threshold": 250,
    "max_env_steps": 1000,
    "state_dim": 15,
    "action_dim": 4,
    "reward_scale": 20,
    "proximity_threshold": 5.0,
    "collision_penalty": 25,
    "height_target": -10,
    "height_tolerance": 1.0,
    "height_penalty": 1,
    "movement_penalty": 0.1,
    "smoothness_penalty": 0.1,
    "duration": 0.1,
    "exploration_area": {
      "x_min": -1000,
      "x_max": 1000,
      "y_min": -1000,
      "y_max": 1000,
      "z_min": -100,
      "z_max": 100
    }
  },
  "exploration": {
    "strategy": "epsilon_decay",
    "initial_epsilon": 1.0,
    "min_epsilon": 0.05,
    "epsilon_decay_rate": 0.9995
  },
  "model_checkpointing": {
    "checkpoint_interval": 10,
    "save_best_only": true,
    "checkpoint_dir": "models/checkpoints"
  },
  "logging": {
    "log_interval": 10,
    "log_dir": "logs/",
    "tensorboard": true,
    "tensorboard_log_dir": "logs/tensorboard_logs",
    "model_save_path": "models/saved_models"
  },
  "advanced_training_techniques": {
    "gradient_clipping": 0.5,
    "use_gae": true,
    "gae_lambda": 0.95,
    "normalize_advantages": true
  },
  "early_stopping": {
    "patience": 10
  },
  "reward_adjustments": {
    "collision_penalty": 50,
    "reward_threshold": 250
  },
  "shared_components": {
    "residual_block": {
      "input_dim": 128,
      "hidden_dim": 128,
      "dropout_rate": 0.2
    },
    "attention_layer": {
      "input_dim": 128,
      "hidden_dim": 128
    }
  },
  "icm": {
    "state_dim": 16,
    "action_dim": 3,
    "image_channels": 3,
    "image_height": 144,
    "image_width": 256,
    "cnn": {
      "conv1": {
        "out_channels": 32,
        "kernel_size": 8,
        "stride": 4
      },
      "conv2": {
        "out_channels": 64,
        "kernel_size": 4,
        "stride": 2
      },
      "conv3": {
        "out_channels": 64,
        "kernel_size": 3,
        "stride": 1
      }
    },
    "state_encoder": {
      "hidden_dim": 128
    },
    "forward_model": {
      "hidden_dim": 256
    },
    "inverse_model": {
      "hidden_dim": 256
    }
  },
  "predictive_model": {
    "learning_rate": 0.0001,
    "hidden_layers": [
      256,
      256
    ]
  },
  "hrl": {
    "use_hierarchical": true,
    "high_level_policy": {
      "input_size": 15,
      "hidden_layers": [
        256,
        256
      ],
      "output_size": 4
    },
    "sub_goal_dim": 3,
    "low_level_policy": {
      "input_size": 18,
      "hidden_layers": [
        256,
        256
      ],
      "output_size": 4
    }
  },
  "curriculum_learning": {
    "use_curriculum": true,
    "initial_difficulty": 1,
    "difficulty_increment": 1,
    "difficulty_threshold": 200
  },
  "multi_agent": {
    "use_multi_agent": true,
    "num_agents": 2,
    "hidden_layers": [
      256,
      256
    ]
  }
}
2024-07-21 01:48:34,900 - AirSimEnvLogger - INFO - DataVisualizer initialized with Seaborn style set to 'whitegrid'.
2024-07-21 01:48:34,946 - AirSimEnvLogger - INFO - PPOAgent initialization started.
2024-07-21 01:48:34,993 - AirSimEnvLogger - INFO - State dimension: 16
2024-07-21 01:48:35,039 - AirSimEnvLogger - INFO - Visual dimensions: 84x84x4
2024-07-21 01:48:35,074 - AirSimEnvLogger - INFO - Using device: cpu
2024-07-21 01:48:38,382 - AirSimEnvLogger - INFO - Policy Network: state_dim=16, action_dim=4, continuous=True
2024-07-21 01:48:38,429 - AirSimEnvLogger - INFO - Visual input: 144x256x3
2024-07-21 01:48:38,476 - AirSimEnvLogger - INFO - Total input size: 110608
2024-07-21 01:48:38,523 - AirSimEnvLogger - INFO - Critic Network: state_dim=15
2024-07-21 01:48:40,685 - AirSimEnvLogger - INFO - PPOAgent initialized successfully.
2024-07-21 01:48:40,794 - AirSimEnvLogger - INFO - Loading checkpoint from e:\Project\Drone\models/checkpoints\ppo_agent_checkpoint.pt
2024-07-21 01:48:43,918 - AirSimEnvLogger - INFO - Model loaded successfully
2024-07-21 01:48:44,715 - AirSimEnvLogger - ERROR - Error loading checkpoint: loaded state dict contains a parameter group that doesn't match the size of optimizer's group
2024-07-21 01:48:50,942 - AirSimEnvLogger - INFO - Initial observation: type=<class 'numpy.ndarray'>, shape=(1, 110608)
2024-07-21 01:48:58,767 - AirSimEnvLogger - INFO - Step 0: Action: [-0.73091024  2.0194864  -0.7248467  -0.03698759], Reward: [0.]
2024-07-21 01:48:58,813 - AirSimEnvLogger - INFO - Epoch 0, Step 0: Reward: [0.]
2024-07-21 01:48:58,940 - AirSimEnvLogger - INFO - Episode ended after 1 steps with total reward: [0.]
2024-07-21 01:48:58,971 - AirSimEnvLogger - ERROR - An error occurred: update() takes 1 positional argument but 2 were given
2024-07-21 01:49:05,388 - AirSimEnvLogger - INFO - Environment closed.
2024-07-21 01:49:05,512 - AirSimEnvLogger - INFO - Training completed and models saved.
2024-07-21 01:57:10,589 - AirSimEnvLogger - INFO - Initializing AirSimEnv
2024-07-21 01:57:10,590 - AirSimEnvLogger - INFO - Configuration: {
  "learning_rate": 0.0001,
  "gamma": 0.99,
  "tau": 0.95,
  "batch_size": 64,
  "num_timesteps": 2000000,
  "ppo": {
    "learning_rate": 0.0003,
    "n_steps": 2048,
    "batch_size": 64,
    "n_epochs": 2000,
    "gamma": 0.99,
    "gae_lambda": 0.95,
    "clip_range": 0.2,
    "ent_coef": 0.01,
    "vf_coef": 0.5,
    "max_grad_norm": 0.5,
    "use_sde": true,
    "sde_sample_freq": 4,
    "tensorboard_log": "logs/tensorboard_logs/ppo_airsim_tensorboard/",
    "verbose": 1,
    "seed": null,
    "device": "auto",
    "continuous": true,
    "save_freq": 10000,
    "max_steps_per_episode": 1000
  },
  "policy_network": {
    "input_size": 16,
    "hidden_layers": [
      256,
      256
    ],
    "output_size": 4,
    "use_batch_norm": true,
    "use_dropout": true,
    "dropout_rate": 0.2,
    "use_attention": true,
    "num_action_heads": 1
  },
  "critic_network": {
    "input_size": 15,
    "hidden_layers": [
      256,
      256
    ],
    "output_size": 1,
    "use_batch_norm": true,
    "use_dropout": true,
    "dropout_rate": 0.2,
    "use_attention": true
  },
  "environment": {
    "env_name": "Africa_001",
    "reward_threshold": 250,
    "max_env_steps": 1000,
    "state_dim": 15,
    "action_dim": 4,
    "reward_scale": 20,
    "proximity_threshold": 5.0,
    "collision_penalty": 25,
    "height_target": -10,
    "height_tolerance": 1.0,
    "height_penalty": 1,
    "movement_penalty": 0.1,
    "smoothness_penalty": 0.1,
    "duration": 0.1,
    "exploration_area": {
      "x_min": -1000,
      "x_max": 1000,
      "y_min": -1000,
      "y_max": 1000,
      "z_min": -100,
      "z_max": 100
    }
  },
  "exploration": {
    "strategy": "epsilon_decay",
    "initial_epsilon": 1.0,
    "min_epsilon": 0.05,
    "epsilon_decay_rate": 0.9995
  },
  "model_checkpointing": {
    "checkpoint_interval": 10,
    "save_best_only": true,
    "checkpoint_dir": "models/checkpoints"
  },
  "logging": {
    "log_interval": 10,
    "log_dir": "logs/",
    "tensorboard": true,
    "tensorboard_log_dir": "logs/tensorboard_logs",
    "model_save_path": "models/saved_models"
  },
  "advanced_training_techniques": {
    "gradient_clipping": 0.5,
    "use_gae": true,
    "gae_lambda": 0.95,
    "normalize_advantages": true
  },
  "early_stopping": {
    "patience": 10
  },
  "reward_adjustments": {
    "collision_penalty": 50,
    "reward_threshold": 250
  },
  "shared_components": {
    "residual_block": {
      "input_dim": 128,
      "hidden_dim": 128,
      "dropout_rate": 0.2
    },
    "attention_layer": {
      "input_dim": 128,
      "hidden_dim": 128
    }
  },
  "icm": {
    "state_dim": 16,
    "action_dim": 3,
    "image_channels": 3,
    "image_height": 144,
    "image_width": 256,
    "cnn": {
      "conv1": {
        "out_channels": 32,
        "kernel_size": 8,
        "stride": 4
      },
      "conv2": {
        "out_channels": 64,
        "kernel_size": 4,
        "stride": 2
      },
      "conv3": {
        "out_channels": 64,
        "kernel_size": 3,
        "stride": 1
      }
    },
    "state_encoder": {
      "hidden_dim": 128
    },
    "forward_model": {
      "hidden_dim": 256
    },
    "inverse_model": {
      "hidden_dim": 256
    }
  },
  "predictive_model": {
    "learning_rate": 0.0001,
    "hidden_layers": [
      256,
      256
    ]
  },
  "hrl": {
    "use_hierarchical": true,
    "high_level_policy": {
      "input_size": 15,
      "hidden_layers": [
        256,
        256
      ],
      "output_size": 4
    },
    "sub_goal_dim": 3,
    "low_level_policy": {
      "input_size": 18,
      "hidden_layers": [
        256,
        256
      ],
      "output_size": 4
    }
  },
  "curriculum_learning": {
    "use_curriculum": true,
    "initial_difficulty": 1,
    "difficulty_increment": 1,
    "difficulty_threshold": 200
  },
  "multi_agent": {
    "use_multi_agent": true,
    "num_agents": 2,
    "hidden_layers": [
      256,
      256
    ]
  }
}
2024-07-21 01:57:11,699 - AirSimEnvLogger - INFO - DataVisualizer initialized with Seaborn style set to 'whitegrid'.
2024-07-21 01:57:11,744 - AirSimEnvLogger - INFO - PPOAgent initialization started.
2024-07-21 01:57:11,792 - AirSimEnvLogger - INFO - State dimension: 16
2024-07-21 01:57:11,841 - AirSimEnvLogger - INFO - Visual dimensions: 84x84x4
2024-07-21 01:57:11,888 - AirSimEnvLogger - INFO - Using device: cpu
2024-07-21 01:57:15,549 - AirSimEnvLogger - INFO - Policy Network: state_dim=16, action_dim=4, continuous=True
2024-07-21 01:57:15,596 - AirSimEnvLogger - INFO - Visual input: 144x256x3
2024-07-21 01:57:15,643 - AirSimEnvLogger - INFO - Total input size: 110608
2024-07-21 01:57:15,690 - AirSimEnvLogger - INFO - Critic Network: state_dim=15
2024-07-21 01:57:18,018 - AirSimEnvLogger - INFO - PPOAgent initialized successfully.
2024-07-21 01:57:18,127 - AirSimEnvLogger - INFO - Loading checkpoint from e:\Project\Drone\models/checkpoints\ppo_agent_checkpoint.pt
2024-07-21 01:57:21,109 - AirSimEnvLogger - INFO - Model loaded successfully
2024-07-21 01:57:22,405 - AirSimEnvLogger - ERROR - Error loading checkpoint: loaded state dict contains a parameter group that doesn't match the size of optimizer's group
2024-07-21 01:57:28,409 - AirSimEnvLogger - INFO - Initial observation: type=<class 'numpy.ndarray'>, shape=(1, 110608)
2024-07-21 01:57:35,905 - AirSimEnvLogger - INFO - Step 0: Action: [-1.1003934  -0.36182606 -0.02972917  0.32090262], Reward: [0.]
2024-07-21 01:57:35,936 - AirSimEnvLogger - INFO - Epoch 0, Step 0: Reward: [0.]
2024-07-21 01:57:36,044 - AirSimEnvLogger - INFO - Episode ended after 1 steps with total reward: [0.]
2024-07-21 01:57:36,092 - AirSimEnvLogger - ERROR - An error occurred: update() takes 1 positional argument but 2 were given
2024-07-21 01:57:42,832 - AirSimEnvLogger - INFO - Environment closed.
2024-07-21 01:57:42,956 - AirSimEnvLogger - INFO - Training completed and models saved.
2024-07-21 02:16:00,048 - AirSimEnvLogger - INFO - Initializing AirSimEnv
2024-07-21 02:16:00,049 - AirSimEnvLogger - INFO - Configuration: {
  "learning_rate": 0.0001,
  "gamma": 0.99,
  "tau": 0.95,
  "batch_size": 64,
  "num_timesteps": 2000000,
  "ppo": {
    "learning_rate": 0.0003,
    "n_steps": 2048,
    "batch_size": 64,
    "n_epochs": 2000,
    "gamma": 0.99,
    "gae_lambda": 0.95,
    "clip_range": 0.2,
    "ent_coef": 0.01,
    "vf_coef": 0.5,
    "max_grad_norm": 0.5,
    "use_sde": true,
    "sde_sample_freq": 4,
    "tensorboard_log": "logs/tensorboard_logs/ppo_airsim_tensorboard/",
    "verbose": 1,
    "seed": null,
    "device": "auto",
    "continuous": true,
    "save_freq": 10000
  },
  "environment": {
    "env_name": "Africa_001",
    "reward_threshold": 250,
    "max_episode_steps": 1000,
    "state_dim": 16,
    "action_dim": 4,
    "reward_scale": 20,
    "proximity_threshold": 5.0,
    "collision_penalty": 25,
    "height_target": -10,
    "height_tolerance": 1.0,
    "height_penalty": 1,
    "movement_penalty": 0.1,
    "smoothness_penalty": 0.1,
    "duration": 0.1,
    "exploration_area": {
      "x_min": -1000,
      "x_max": 1000,
      "y_min": -1000,
      "y_max": 1000,
      "z_min": -100,
      "z_max": 100
    }
  },
  "policy_network": {
    "input_size": 16,
    "hidden_layers": [
      256,
      256
    ],
    "output_size": 4,
    "use_batch_norm": true,
    "use_dropout": true,
    "dropout_rate": 0.2,
    "use_attention": true,
    "num_action_heads": 1
  },
  "critic_network": {
    "input_size": 16,
    "hidden_layers": [
      256,
      256
    ],
    "output_size": 1,
    "use_batch_norm": true,
    "use_dropout": true,
    "dropout_rate": 0.2,
    "use_attention": true
  },
  "exploration": {
    "strategy": "epsilon_decay",
    "initial_epsilon": 1.0,
    "min_epsilon": 0.05,
    "epsilon_decay_rate": 0.9995
  },
  "model_checkpointing": {
    "checkpoint_interval": 10,
    "save_best_only": true,
    "checkpoint_dir": "models/checkpoints"
  },
  "logging": {
    "log_interval": 10,
    "log_dir": "logs/",
    "tensorboard": true,
    "tensorboard_log_dir": "logs/tensorboard_logs",
    "model_save_path": "models/saved_models"
  },
  "advanced_training_techniques": {
    "gradient_clipping": 0.5,
    "use_gae": true,
    "gae_lambda": 0.95,
    "normalize_advantages": true
  },
  "early_stopping": {
    "patience": 10
  },
  "reward_adjustments": {
    "collision_penalty": 50,
    "reward_threshold": 250
  },
  "shared_components": {
    "residual_block": {
      "input_dim": 128,
      "hidden_dim": 128,
      "dropout_rate": 0.2
    },
    "attention_layer": {
      "input_dim": 128,
      "hidden_dim": 128
    }
  },
  "icm": {
    "state_dim": 16,
    "action_dim": 4,
    "image_channels": 3,
    "image_height": 144,
    "image_width": 256,
    "cnn": {
      "conv1": {
        "out_channels": 32,
        "kernel_size": 8,
        "stride": 4
      },
      "conv2": {
        "out_channels": 64,
        "kernel_size": 4,
        "stride": 2
      },
      "conv3": {
        "out_channels": 64,
        "kernel_size": 3,
        "stride": 1
      }
    },
    "state_encoder": {
      "hidden_dim": 128
    },
    "forward_model": {
      "hidden_dim": 256
    },
    "inverse_model": {
      "hidden_dim": 256
    }
  },
  "predictive_model": {
    "learning_rate": 0.0001,
    "hidden_layers": [
      256,
      256
    ]
  },
  "hrl": {
    "use_hierarchical": true,
    "high_level_policy": {
      "input_size": 16,
      "hidden_layers": [
        256,
        256
      ],
      "output_size": 4
    },
    "sub_goal_dim": 3,
    "low_level_policy": {
      "input_size": 19,
      "hidden_layers": [
        256,
        256
      ],
      "output_size": 4
    }
  },
  "curriculum_learning": {
    "use_curriculum": true,
    "initial_difficulty": 1,
    "difficulty_increment": 1,
    "difficulty_threshold": 200
  },
  "multi_agent": {
    "use_multi_agent": true,
    "num_agents": 2,
    "hidden_layers": [
      256,
      256
    ]
  }
}
2024-07-21 02:16:01,103 - AirSimEnvLogger - INFO - DataVisualizer initialized with Seaborn style set to 'whitegrid'.
2024-07-21 02:16:01,166 - AirSimEnvLogger - INFO - Using device: cpu
2024-07-21 02:16:04,441 - AirSimEnvLogger - INFO - Policy Network: state_dim=16, action_dim=4, continuous=True
2024-07-21 02:16:04,488 - AirSimEnvLogger - INFO - Visual input: 144x256x3
2024-07-21 02:16:04,535 - AirSimEnvLogger - INFO - Total input size: 110608
2024-07-21 02:16:04,582 - AirSimEnvLogger - INFO - Critic Network: state_dim=16
2024-07-21 02:16:06,588 - AirSimEnvLogger - INFO - PPOAgent initialized successfully.
2024-07-21 02:16:06,636 - AirSimEnvLogger - INFO - State dimension: 16
2024-07-21 02:16:06,683 - AirSimEnvLogger - INFO - Visual dimensions: 84x84x4
2024-07-21 02:16:06,714 - AirSimEnvLogger - INFO - Using device: cpu
2024-07-21 02:16:09,951 - AirSimEnvLogger - INFO - Policy Network: state_dim=16, action_dim=4, continuous=True
2024-07-21 02:16:09,997 - AirSimEnvLogger - INFO - Visual input: 144x256x3
2024-07-21 02:16:10,043 - AirSimEnvLogger - INFO - Total input size: 110608
2024-07-21 02:16:10,107 - AirSimEnvLogger - INFO - Critic Network: state_dim=16
2024-07-21 02:16:12,983 - AirSimEnvLogger - INFO - PPOAgent initialized successfully.
2024-07-21 02:16:13,077 - AirSimEnvLogger - INFO - Loading checkpoint from e:\Project\Drone\models/checkpoints\ppo_agent_checkpoint.pt
2024-07-21 02:16:15,402 - AirSimEnvLogger - INFO - Model loaded successfully
2024-07-21 02:16:16,372 - AirSimEnvLogger - ERROR - Error loading checkpoint: 'optimizer_state_dict'
2024-07-21 02:16:21,078 - AirSimEnvLogger - INFO - Environment reset and takeoff completed.
2024-07-21 02:16:21,641 - AirSimEnvLogger - INFO - Initial observation: type=<class 'numpy.ndarray'>, shape=(1, 110608)
2024-07-21 02:16:21,752 - AirSimEnvLogger - ERROR - An error occurred: cannot reshape array of size 0 into shape (144,256,3)
2024-07-21 02:16:27,926 - AirSimEnvLogger - INFO - Environment closed.
2024-07-21 02:16:28,067 - AirSimEnvLogger - INFO - Training completed and models saved.
2024-07-21 02:22:13,857 - AirSimEnvLogger - INFO - Initializing AirSimEnv
2024-07-21 02:22:13,859 - AirSimEnvLogger - INFO - Configuration: {
  "learning_rate": 0.0001,
  "gamma": 0.99,
  "tau": 0.95,
  "batch_size": 64,
  "num_timesteps": 2000000,
  "ppo": {
    "learning_rate": 0.0003,
    "n_steps": 2048,
    "batch_size": 64,
    "n_epochs": 2000,
    "gamma": 0.99,
    "gae_lambda": 0.95,
    "clip_range": 0.2,
    "ent_coef": 0.01,
    "vf_coef": 0.5,
    "max_grad_norm": 0.5,
    "use_sde": true,
    "sde_sample_freq": 4,
    "tensorboard_log": "logs/tensorboard_logs/ppo_airsim_tensorboard/",
    "verbose": 1,
    "seed": null,
    "device": "auto",
    "continuous": true,
    "save_freq": 10000
  },
  "environment": {
    "env_name": "Africa_001",
    "reward_threshold": 250,
    "max_episode_steps": 1000,
    "state_dim": 16,
    "action_dim": 4,
    "reward_scale": 20,
    "proximity_threshold": 5.0,
    "collision_penalty": 25,
    "height_target": -10,
    "height_tolerance": 1.0,
    "height_penalty": 1,
    "movement_penalty": 0.1,
    "smoothness_penalty": 0.1,
    "duration": 0.1,
    "exploration_area": {
      "x_min": -1000,
      "x_max": 1000,
      "y_min": -1000,
      "y_max": 1000,
      "z_min": -100,
      "z_max": 100
    }
  },
  "policy_network": {
    "input_size": 16,
    "hidden_layers": [
      256,
      256
    ],
    "output_size": 4,
    "use_batch_norm": true,
    "use_dropout": true,
    "dropout_rate": 0.2,
    "use_attention": true,
    "num_action_heads": 1
  },
  "critic_network": {
    "input_size": 16,
    "hidden_layers": [
      256,
      256
    ],
    "output_size": 1,
    "use_batch_norm": true,
    "use_dropout": true,
    "dropout_rate": 0.2,
    "use_attention": true
  },
  "exploration": {
    "strategy": "epsilon_decay",
    "initial_epsilon": 1.0,
    "min_epsilon": 0.05,
    "epsilon_decay_rate": 0.9995
  },
  "model_checkpointing": {
    "checkpoint_interval": 10,
    "save_best_only": true,
    "checkpoint_dir": "models/checkpoints"
  },
  "logging": {
    "log_interval": 10,
    "log_dir": "logs/",
    "tensorboard": true,
    "tensorboard_log_dir": "logs/tensorboard_logs",
    "model_save_path": "models/saved_models"
  },
  "advanced_training_techniques": {
    "gradient_clipping": 0.5,
    "use_gae": true,
    "gae_lambda": 0.95,
    "normalize_advantages": true
  },
  "early_stopping": {
    "patience": 10
  },
  "reward_adjustments": {
    "collision_penalty": 50,
    "reward_threshold": 250
  },
  "shared_components": {
    "residual_block": {
      "input_dim": 128,
      "hidden_dim": 128,
      "dropout_rate": 0.2
    },
    "attention_layer": {
      "input_dim": 128,
      "hidden_dim": 128
    }
  },
  "icm": {
    "state_dim": 16,
    "action_dim": 4,
    "image_channels": 3,
    "image_height": 144,
    "image_width": 256,
    "cnn": {
      "conv1": {
        "out_channels": 32,
        "kernel_size": 8,
        "stride": 4
      },
      "conv2": {
        "out_channels": 64,
        "kernel_size": 4,
        "stride": 2
      },
      "conv3": {
        "out_channels": 64,
        "kernel_size": 3,
        "stride": 1
      }
    },
    "state_encoder": {
      "hidden_dim": 128
    },
    "forward_model": {
      "hidden_dim": 256
    },
    "inverse_model": {
      "hidden_dim": 256
    }
  },
  "predictive_model": {
    "learning_rate": 0.0001,
    "hidden_layers": [
      256,
      256
    ]
  },
  "hrl": {
    "use_hierarchical": true,
    "high_level_policy": {
      "input_size": 16,
      "hidden_layers": [
        256,
        256
      ],
      "output_size": 4
    },
    "sub_goal_dim": 3,
    "low_level_policy": {
      "input_size": 19,
      "hidden_layers": [
        256,
        256
      ],
      "output_size": 4
    }
  },
  "curriculum_learning": {
    "use_curriculum": true,
    "initial_difficulty": 1,
    "difficulty_increment": 1,
    "difficulty_threshold": 200
  },
  "multi_agent": {
    "use_multi_agent": true,
    "num_agents": 2,
    "hidden_layers": [
      256,
      256
    ]
  }
}
2024-07-21 02:22:15,056 - AirSimEnvLogger - INFO - DataVisualizer initialized with Seaborn style set to 'whitegrid'.
2024-07-21 02:22:15,102 - AirSimEnvLogger - INFO - Using device: cpu
2024-07-21 02:22:18,756 - AirSimEnvLogger - INFO - Policy Network: state_dim=16, action_dim=4, continuous=True
2024-07-21 02:22:18,802 - AirSimEnvLogger - INFO - Visual input: 144x256x3
2024-07-21 02:22:18,848 - AirSimEnvLogger - INFO - Total input size: 110608
2024-07-21 02:22:18,895 - AirSimEnvLogger - INFO - Critic Network: state_dim=16
2024-07-21 02:22:20,908 - AirSimEnvLogger - INFO - PPOAgent initialized successfully.
2024-07-21 02:22:20,955 - AirSimEnvLogger - INFO - State dimension: 16
2024-07-21 02:22:21,001 - AirSimEnvLogger - INFO - Visual dimensions: 84x84x4
2024-07-21 02:22:21,048 - AirSimEnvLogger - INFO - Using device: cpu
2024-07-21 02:22:24,370 - AirSimEnvLogger - INFO - Policy Network: state_dim=16, action_dim=4, continuous=True
2024-07-21 02:22:24,417 - AirSimEnvLogger - INFO - Visual input: 144x256x3
2024-07-21 02:22:24,463 - AirSimEnvLogger - INFO - Total input size: 110608
2024-07-21 02:22:24,509 - AirSimEnvLogger - INFO - Critic Network: state_dim=16
2024-07-21 02:22:28,205 - AirSimEnvLogger - INFO - PPOAgent initialized successfully.
2024-07-21 02:22:28,316 - AirSimEnvLogger - INFO - Loading checkpoint from e:\Project\Drone\models/checkpoints\ppo_agent_checkpoint.pt
2024-07-21 02:22:31,087 - AirSimEnvLogger - INFO - Model loaded successfully
2024-07-21 02:22:32,048 - AirSimEnvLogger - INFO - Resuming training from epoch 1
2024-07-21 02:22:36,820 - AirSimEnvLogger - INFO - Environment reset and takeoff completed.
2024-07-21 02:22:37,584 - AirSimEnvLogger - INFO - Initial observation: type=<class 'numpy.ndarray'>, shape=(1, 110608)
2024-07-21 02:22:39,302 - AirSimEnvLogger - INFO - Error in step function: too many values to unpack (expected 3)
2024-07-21 02:22:43,967 - AirSimEnvLogger - INFO - Environment reset and takeoff completed.
2024-07-21 02:22:44,675 - AirSimEnvLogger - ERROR - An error occurred: add() missing 1 required positional argument: 'goal'
2024-07-21 02:22:51,403 - AirSimEnvLogger - INFO - Environment closed.
2024-07-21 02:22:51,545 - AirSimEnvLogger - INFO - Training completed and models saved.
2024-07-21 04:37:25,171 - AirSimEnvLogger - INFO - Initializing AirSimEnv
2024-07-21 04:37:25,174 - AirSimEnvLogger - INFO - Configuration: {
  "learning_rate": 0.0001,
  "gamma": 0.99,
  "tau": 0.95,
  "batch_size": 64,
  "num_timesteps": 2000000,
  "ppo": {
    "learning_rate": 0.0003,
    "n_steps": 2048,
    "batch_size": 64,
    "n_epochs": 2000,
    "gamma": 0.99,
    "gae_lambda": 0.95,
    "clip_range": 0.2,
    "ent_coef": 0.01,
    "vf_coef": 0.5,
    "max_grad_norm": 0.5,
    "use_sde": true,
    "sde_sample_freq": 4,
    "tensorboard_log": "logs/tensorboard_logs/ppo_airsim_tensorboard/",
    "verbose": 1,
    "seed": null,
    "device": "auto",
    "continuous": true,
    "save_freq": 10000
  },
  "environment": {
    "env_name": "Africa_001",
    "reward_threshold": 250,
    "max_episode_steps": 1000,
    "state_dim": 16,
    "action_dim": 4,
    "reward_scale": 20,
    "proximity_threshold": 5.0,
    "collision_penalty": 25,
    "height_target": -10,
    "height_tolerance": 1.0,
    "height_penalty": 1,
    "movement_penalty": 0.1,
    "smoothness_penalty": 0.1,
    "duration": 0.1,
    "exploration_area": {
      "x_min": -1000,
      "x_max": 1000,
      "y_min": -1000,
      "y_max": 1000,
      "z_min": -100,
      "z_max": 100
    }
  },
  "policy_network": {
    "input_size": 16,
    "hidden_layers": [
      256,
      256
    ],
    "output_size": 4,
    "use_batch_norm": true,
    "use_dropout": true,
    "dropout_rate": 0.2,
    "use_attention": true,
    "num_action_heads": 1
  },
  "critic_network": {
    "input_size": 16,
    "hidden_layers": [
      256,
      256
    ],
    "output_size": 1,
    "use_batch_norm": true,
    "use_dropout": true,
    "dropout_rate": 0.2,
    "use_attention": true
  },
  "exploration": {
    "strategy": "epsilon_decay",
    "initial_epsilon": 1.0,
    "min_epsilon": 0.05,
    "epsilon_decay_rate": 0.9995
  },
  "model_checkpointing": {
    "checkpoint_interval": 10,
    "save_best_only": true,
    "checkpoint_dir": "models/checkpoints"
  },
  "logging": {
    "log_interval": 10,
    "log_dir": "logs/",
    "tensorboard": true,
    "tensorboard_log_dir": "logs/tensorboard_logs",
    "model_save_path": "models/saved_models"
  },
  "advanced_training_techniques": {
    "gradient_clipping": 0.5,
    "use_gae": true,
    "gae_lambda": 0.95,
    "normalize_advantages": true
  },
  "early_stopping": {
    "patience": 10
  },
  "reward_adjustments": {
    "collision_penalty": 50,
    "reward_threshold": 250
  },
  "shared_components": {
    "residual_block": {
      "input_dim": 128,
      "hidden_dim": 128,
      "dropout_rate": 0.2
    },
    "attention_layer": {
      "input_dim": 128,
      "hidden_dim": 128
    }
  },
  "icm": {
    "state_dim": 16,
    "action_dim": 4,
    "image_channels": 3,
    "image_height": 144,
    "image_width": 256,
    "cnn": {
      "conv1": {
        "out_channels": 32,
        "kernel_size": 8,
        "stride": 4
      },
      "conv2": {
        "out_channels": 64,
        "kernel_size": 4,
        "stride": 2
      },
      "conv3": {
        "out_channels": 64,
        "kernel_size": 3,
        "stride": 1
      }
    },
    "state_encoder": {
      "hidden_dim": 128
    },
    "forward_model": {
      "hidden_dim": 256
    },
    "inverse_model": {
      "hidden_dim": 256
    }
  },
  "predictive_model": {
    "learning_rate": 0.0001,
    "hidden_layers": [
      256,
      256
    ]
  },
  "hrl": {
    "use_hierarchical": true,
    "high_level_policy": {
      "input_size": 16,
      "hidden_layers": [
        256,
        256
      ],
      "output_size": 4
    },
    "sub_goal_dim": 3,
    "low_level_policy": {
      "input_size": 19,
      "hidden_layers": [
        256,
        256
      ],
      "output_size": 4
    }
  },
  "curriculum_learning": {
    "use_curriculum": true,
    "initial_difficulty": 1,
    "difficulty_increment": 1,
    "difficulty_threshold": 200
  },
  "multi_agent": {
    "use_multi_agent": true,
    "num_agents": 2,
    "hidden_layers": [
      256,
      256
    ]
  }
}
2024-07-21 04:37:26,271 - AirSimEnvLogger - INFO - DataVisualizer initialized with Seaborn style set to 'whitegrid'.
2024-07-21 04:37:26,317 - AirSimEnvLogger - INFO - Using device: cpu
2024-07-21 04:37:29,695 - AirSimEnvLogger - INFO - Policy Network: state_dim=16, action_dim=4, continuous=True
2024-07-21 04:37:29,742 - AirSimEnvLogger - INFO - Visual input: 144x256x3
2024-07-21 04:37:29,789 - AirSimEnvLogger - INFO - Total input size: 110608
2024-07-21 04:37:29,837 - AirSimEnvLogger - INFO - Critic Network: state_dim=16
2024-07-21 04:37:31,874 - AirSimEnvLogger - INFO - PPOAgent initialized successfully.
2024-07-21 04:37:31,921 - AirSimEnvLogger - INFO - State dimension: 16
2024-07-21 04:37:31,968 - AirSimEnvLogger - INFO - Visual dimensions: 84x84x4
2024-07-21 04:37:32,014 - AirSimEnvLogger - INFO - Using device: cpu
2024-07-21 04:37:35,680 - AirSimEnvLogger - INFO - Policy Network: state_dim=16, action_dim=4, continuous=True
2024-07-21 04:37:35,727 - AirSimEnvLogger - INFO - Visual input: 144x256x3
2024-07-21 04:37:35,774 - AirSimEnvLogger - INFO - Total input size: 110608
2024-07-21 04:37:35,821 - AirSimEnvLogger - INFO - Critic Network: state_dim=16
2024-07-21 04:37:39,558 - AirSimEnvLogger - INFO - PPOAgent initialized successfully.
2024-07-21 04:37:39,666 - AirSimEnvLogger - INFO - Loading checkpoint from e:\Project\Drone\models/checkpoints\ppo_agent_checkpoint.pt
2024-07-21 04:37:42,566 - AirSimEnvLogger - INFO - Model loaded successfully
2024-07-21 04:37:43,083 - AirSimEnvLogger - INFO - Resuming training from epoch 1
2024-07-21 04:37:48,332 - AirSimEnvLogger - INFO - Environment reset and takeoff completed.
2024-07-21 04:37:48,906 - AirSimEnvLogger - INFO - Initial observation: type=<class 'numpy.ndarray'>, shape=(1, 110608)
2024-07-21 04:37:50,599 - AirSimEnvLogger - INFO - Error in step function: too many values to unpack (expected 3)
2024-07-21 04:37:55,147 - AirSimEnvLogger - INFO - Environment reset and takeoff completed.
2024-07-21 04:37:55,848 - AirSimEnvLogger - ERROR - An error occurred: add() missing 1 required positional argument: 'goal'
2024-07-21 04:38:02,360 - AirSimEnvLogger - INFO - Environment closed.
2024-07-21 04:38:02,484 - AirSimEnvLogger - INFO - Training completed and models saved.
2024-07-21 08:21:49,101 - AirSimEnvLogger - INFO - Initialized with state_dim: 16, action_dim: 4
2024-07-21 08:21:49,121 - AirSimEnvLogger - INFO - Initializing AirSimEnv
2024-07-21 08:21:49,122 - AirSimEnvLogger - INFO - Configuration: {
  "learning_rate": 0.0001,
  "gamma": 0.99,
  "tau": 0.95,
  "batch_size": 64,
  "num_timesteps": 2000000,
  "ppo": {
    "learning_rate": 0.0003,
    "n_steps": 2048,
    "batch_size": 64,
    "n_epochs": 2000,
    "gamma": 0.99,
    "gae_lambda": 0.95,
    "clip_range": 0.2,
    "ent_coef": 0.01,
    "vf_coef": 0.5,
    "max_grad_norm": 0.5,
    "use_sde": true,
    "sde_sample_freq": 4,
    "tensorboard_log": "logs/tensorboard_logs/ppo_airsim_tensorboard/",
    "verbose": 1,
    "seed": null,
    "device": "auto",
    "continuous": true,
    "save_freq": 10000
  },
  "environment": {
    "env_name": "Africa_001",
    "reward_threshold": 250,
    "max_episode_steps": 1000,
    "state_dim": 16,
    "action_dim": 4,
    "reward_scale": 20,
    "proximity_threshold": 5.0,
    "collision_penalty": 25,
    "height_target": -10,
    "height_tolerance": 1.0,
    "height_penalty": 1,
    "movement_penalty": 0.1,
    "smoothness_penalty": 0.1,
    "duration": 0.1,
    "exploration_area": {
      "x_min": -1000,
      "x_max": 1000,
      "y_min": -1000,
      "y_max": 1000,
      "z_min": -100,
      "z_max": 100
    }
  },
  "policy_network": {
    "input_size": 16,
    "hidden_layers": [
      256,
      256
    ],
    "output_size": 4,
    "use_batch_norm": true,
    "use_dropout": true,
    "dropout_rate": 0.2,
    "use_attention": true,
    "num_action_heads": 1
  },
  "critic_network": {
    "input_size": 16,
    "hidden_layers": [
      256,
      256
    ],
    "output_size": 1,
    "use_batch_norm": true,
    "use_dropout": true,
    "dropout_rate": 0.2,
    "use_attention": true
  },
  "exploration": {
    "strategy": "epsilon_decay",
    "initial_epsilon": 1.0,
    "min_epsilon": 0.05,
    "epsilon_decay_rate": 0.9995
  },
  "model_checkpointing": {
    "checkpoint_interval": 10,
    "save_best_only": true,
    "checkpoint_dir": "models/checkpoints"
  },
  "logging": {
    "log_interval": 10,
    "log_dir": "logs/",
    "tensorboard": true,
    "tensorboard_log_dir": "logs/tensorboard_logs",
    "model_save_path": "models/saved_models"
  },
  "advanced_training_techniques": {
    "gradient_clipping": 0.5,
    "use_gae": true,
    "gae_lambda": 0.95,
    "normalize_advantages": true
  },
  "early_stopping": {
    "patience": 10
  },
  "reward_adjustments": {
    "collision_penalty": 50,
    "reward_threshold": 250
  },
  "shared_components": {
    "residual_block": {
      "input_dim": 128,
      "hidden_dim": 128,
      "dropout_rate": 0.2
    },
    "attention_layer": {
      "input_dim": 128,
      "hidden_dim": 128
    }
  },
  "icm": {
    "state_dim": 16,
    "action_dim": 4,
    "image_channels": 3,
    "image_height": 144,
    "image_width": 256,
    "cnn": {
      "conv1": {
        "out_channels": 32,
        "kernel_size": 8,
        "stride": 4
      },
      "conv2": {
        "out_channels": 64,
        "kernel_size": 4,
        "stride": 2
      },
      "conv3": {
        "out_channels": 64,
        "kernel_size": 3,
        "stride": 1
      }
    },
    "state_encoder": {
      "hidden_dim": 128
    },
    "forward_model": {
      "hidden_dim": 256
    },
    "inverse_model": {
      "hidden_dim": 256
    }
  },
  "predictive_model": {
    "learning_rate": 0.0001,
    "hidden_layers": [
      256,
      256
    ]
  },
  "hrl": {
    "use_hierarchical": true,
    "high_level_policy": {
      "input_size": 16,
      "hidden_layers": [
        256,
        256
      ],
      "output_size": 4
    },
    "sub_goal_dim": 3,
    "low_level_policy": {
      "input_size": 19,
      "hidden_layers": [
        256,
        256
      ],
      "output_size": 4
    }
  },
  "curriculum_learning": {
    "use_curriculum": true,
    "initial_difficulty": 1,
    "difficulty_increment": 1,
    "difficulty_threshold": 200
  },
  "multi_agent": {
    "use_multi_agent": true,
    "num_agents": 2,
    "hidden_layers": [
      256,
      256
    ]
  }
}
2024-07-21 08:21:54,762 - AirSimEnvLogger - INFO - Environment reset and takeoff completed.
2024-07-21 08:21:55,404 - AirSimEnvLogger - INFO - Reset completed. Observation keys: dict_keys(['state', 'visual'])
2024-07-21 08:21:55,451 - AirSimEnvLogger - INFO - State shape: (16,), Visual shape: (144, 256, 3)
2024-07-21 08:21:55,484 - AirSimEnvLogger - ERROR - Error in step function: too many values to unpack (expected 3)
2024-07-21 08:21:55,531 - AirSimEnvLogger - ERROR - Action shape: (4,), Current state shape: (16,), Current image shape: (144, 256, 3)
2024-07-21 08:21:55,577 - AirSimEnvLogger - ERROR - An error occurred: too many values to unpack (expected 3)
2024-07-21 08:22:01,234 - AirSimEnvLogger - INFO - Environment closed.
2024-07-21 08:46:11,480 - AirSimEnvLogger - INFO - Initialized with state_dim: 16, action_dim: 4
2024-07-21 08:46:11,503 - AirSimEnvLogger - INFO - Initializing AirSimEnv
2024-07-21 08:46:11,504 - AirSimEnvLogger - INFO - Configuration: {
  "learning_rate": 0.0001,
  "gamma": 0.99,
  "tau": 0.95,
  "batch_size": 64,
  "num_timesteps": 2000000,
  "ppo": {
    "learning_rate": 0.0003,
    "n_steps": 2048,
    "batch_size": 64,
    "n_epochs": 2000,
    "gamma": 0.99,
    "gae_lambda": 0.95,
    "clip_range": 0.2,
    "ent_coef": 0.01,
    "vf_coef": 0.5,
    "max_grad_norm": 0.5,
    "use_sde": true,
    "sde_sample_freq": 4,
    "tensorboard_log": "logs/tensorboard_logs/ppo_airsim_tensorboard/",
    "verbose": 1,
    "seed": null,
    "device": "auto",
    "continuous": true,
    "save_freq": 10000
  },
  "environment": {
    "env_name": "Africa_001",
    "reward_threshold": 250,
    "max_episode_steps": 1000,
    "state_dim": 16,
    "action_dim": 4,
    "reward_scale": 20,
    "proximity_threshold": 5.0,
    "collision_penalty": 25,
    "height_target": -10,
    "height_tolerance": 1.0,
    "height_penalty": 1,
    "movement_penalty": 0.1,
    "smoothness_penalty": 0.1,
    "duration": 0.1,
    "exploration_area": {
      "x_min": -1000,
      "x_max": 1000,
      "y_min": -1000,
      "y_max": 1000,
      "z_min": -100,
      "z_max": 100
    }
  },
  "policy_network": {
    "input_size": 16,
    "hidden_layers": [
      256,
      256
    ],
    "output_size": 4,
    "use_batch_norm": true,
    "use_dropout": true,
    "dropout_rate": 0.2,
    "use_attention": true,
    "num_action_heads": 1
  },
  "critic_network": {
    "input_size": 16,
    "hidden_layers": [
      256,
      256
    ],
    "output_size": 1,
    "use_batch_norm": true,
    "use_dropout": true,
    "dropout_rate": 0.2,
    "use_attention": true
  },
  "exploration": {
    "strategy": "epsilon_decay",
    "initial_epsilon": 1.0,
    "min_epsilon": 0.05,
    "epsilon_decay_rate": 0.9995
  },
  "model_checkpointing": {
    "checkpoint_interval": 10,
    "save_best_only": true,
    "checkpoint_dir": "models/checkpoints"
  },
  "logging": {
    "log_interval": 10,
    "log_dir": "logs/",
    "tensorboard": true,
    "tensorboard_log_dir": "logs/tensorboard_logs",
    "model_save_path": "models/saved_models"
  },
  "advanced_training_techniques": {
    "gradient_clipping": 0.5,
    "use_gae": true,
    "gae_lambda": 0.95,
    "normalize_advantages": true
  },
  "early_stopping": {
    "patience": 10
  },
  "reward_adjustments": {
    "collision_penalty": 50,
    "reward_threshold": 250
  },
  "shared_components": {
    "residual_block": {
      "input_dim": 128,
      "hidden_dim": 128,
      "dropout_rate": 0.2
    },
    "attention_layer": {
      "input_dim": 128,
      "hidden_dim": 128
    }
  },
  "icm": {
    "state_dim": 16,
    "action_dim": 4,
    "image_channels": 3,
    "image_height": 144,
    "image_width": 256,
    "cnn": {
      "conv1": {
        "out_channels": 32,
        "kernel_size": 8,
        "stride": 4
      },
      "conv2": {
        "out_channels": 64,
        "kernel_size": 4,
        "stride": 2
      },
      "conv3": {
        "out_channels": 64,
        "kernel_size": 3,
        "stride": 1
      }
    },
    "state_encoder": {
      "hidden_dim": 128
    },
    "forward_model": {
      "hidden_dim": 256
    },
    "inverse_model": {
      "hidden_dim": 256
    }
  },
  "predictive_model": {
    "learning_rate": 0.0001,
    "hidden_layers": [
      256,
      256
    ]
  },
  "hrl": {
    "use_hierarchical": true,
    "high_level_policy": {
      "input_size": 16,
      "hidden_layers": [
        256,
        256
      ],
      "output_size": 4
    },
    "sub_goal_dim": 3,
    "low_level_policy": {
      "input_size": 19,
      "hidden_layers": [
        256,
        256
      ],
      "output_size": 4
    }
  },
  "curriculum_learning": {
    "use_curriculum": true,
    "initial_difficulty": 1,
    "difficulty_increment": 1,
    "difficulty_threshold": 200
  },
  "multi_agent": {
    "use_multi_agent": true,
    "num_agents": 2,
    "hidden_layers": [
      256,
      256
    ]
  }
}
2024-07-21 08:46:17,407 - AirSimEnvLogger - INFO - Environment reset and takeoff completed.
2024-07-21 08:46:18,115 - AirSimEnvLogger - INFO - Reset completed. Observation keys: dict_keys(['state', 'visual'])
2024-07-21 08:46:18,161 - AirSimEnvLogger - INFO - State shape: (16,), Visual shape: (144, 256, 3)
2024-07-21 08:46:18,305 - AirSimEnvLogger - ERROR - Error in step function: too many values to unpack (expected 3)
2024-07-21 08:46:18,365 - AirSimEnvLogger - ERROR - Action shape: (4,), Current state shape: (16,), Current image shape: (144, 256, 3)
2024-07-21 08:46:18,412 - AirSimEnvLogger - ERROR - An error occurred: too many values to unpack (expected 3)
2024-07-21 08:46:24,251 - AirSimEnvLogger - INFO - Environment closed.
2024-07-21 11:38:13,872 - AirSimEnvLogger - INFO - Initialized with state_dim: 16, action_dim: 4
2024-07-21 11:38:13,889 - AirSimEnvLogger - INFO - Initializing AirSimEnv
2024-07-21 11:38:13,890 - AirSimEnvLogger - INFO - Configuration: {
  "learning_rate": 0.0001,
  "gamma": 0.99,
  "tau": 0.95,
  "batch_size": 64,
  "num_timesteps": 2000000,
  "ppo": {
    "learning_rate": 0.0003,
    "n_steps": 2048,
    "batch_size": 64,
    "n_epochs": 2000,
    "gamma": 0.99,
    "gae_lambda": 0.95,
    "clip_range": 0.2,
    "ent_coef": 0.01,
    "vf_coef": 0.5,
    "max_grad_norm": 0.5,
    "use_sde": true,
    "sde_sample_freq": 4,
    "tensorboard_log": "logs/tensorboard_logs/ppo_airsim_tensorboard/",
    "verbose": 1,
    "seed": null,
    "device": "auto",
    "continuous": true,
    "save_freq": 10000
  },
  "environment": {
    "env_name": "Africa_001",
    "reward_threshold": 250,
    "max_episode_steps": 1000,
    "state_dim": 16,
    "action_dim": 4,
    "reward_scale": 20,
    "proximity_threshold": 5.0,
    "collision_penalty": 25,
    "height_target": -10,
    "height_tolerance": 1.0,
    "height_penalty": 1,
    "movement_penalty": 0.1,
    "smoothness_penalty": 0.1,
    "duration": 0.1,
    "exploration_area": {
      "x_min": -1000,
      "x_max": 1000,
      "y_min": -1000,
      "y_max": 1000,
      "z_min": -100,
      "z_max": 100
    }
  },
  "policy_network": {
    "input_size": 16,
    "hidden_layers": [
      256,
      256
    ],
    "output_size": 4,
    "use_batch_norm": true,
    "use_dropout": true,
    "dropout_rate": 0.2,
    "use_attention": true,
    "num_action_heads": 1
  },
  "critic_network": {
    "input_size": 16,
    "hidden_layers": [
      256,
      256
    ],
    "output_size": 1,
    "use_batch_norm": true,
    "use_dropout": true,
    "dropout_rate": 0.2,
    "use_attention": true
  },
  "exploration": {
    "strategy": "epsilon_decay",
    "initial_epsilon": 1.0,
    "min_epsilon": 0.05,
    "epsilon_decay_rate": 0.9995
  },
  "model_checkpointing": {
    "checkpoint_interval": 10,
    "save_best_only": true,
    "checkpoint_dir": "models/checkpoints"
  },
  "logging": {
    "log_interval": 10,
    "log_dir": "logs/",
    "tensorboard": true,
    "tensorboard_log_dir": "logs/tensorboard_logs",
    "model_save_path": "models/saved_models"
  },
  "advanced_training_techniques": {
    "gradient_clipping": 0.5,
    "use_gae": true,
    "gae_lambda": 0.95,
    "normalize_advantages": true
  },
  "early_stopping": {
    "patience": 10
  },
  "reward_adjustments": {
    "collision_penalty": 50,
    "reward_threshold": 250
  },
  "shared_components": {
    "residual_block": {
      "input_dim": 128,
      "hidden_dim": 128,
      "dropout_rate": 0.2
    },
    "attention_layer": {
      "input_dim": 128,
      "hidden_dim": 128
    }
  },
  "icm": {
    "state_dim": 16,
    "action_dim": 4,
    "image_channels": 3,
    "image_height": 144,
    "image_width": 256,
    "cnn": {
      "conv1": {
        "out_channels": 32,
        "kernel_size": 8,
        "stride": 4
      },
      "conv2": {
        "out_channels": 64,
        "kernel_size": 4,
        "stride": 2
      },
      "conv3": {
        "out_channels": 64,
        "kernel_size": 3,
        "stride": 1
      }
    },
    "state_encoder": {
      "hidden_dim": 128
    },
    "forward_model": {
      "hidden_dim": 256
    },
    "inverse_model": {
      "hidden_dim": 256
    }
  },
  "predictive_model": {
    "learning_rate": 0.0001,
    "hidden_layers": [
      256,
      256
    ]
  },
  "hrl": {
    "use_hierarchical": true,
    "high_level_policy": {
      "input_size": 16,
      "hidden_layers": [
        256,
        256
      ],
      "output_size": 4
    },
    "sub_goal_dim": 3,
    "low_level_policy": {
      "input_size": 19,
      "hidden_layers": [
        256,
        256
      ],
      "output_size": 4
    }
  },
  "curriculum_learning": {
    "use_curriculum": true,
    "initial_difficulty": 1,
    "difficulty_increment": 1,
    "difficulty_threshold": 200
  },
  "multi_agent": {
    "use_multi_agent": true,
    "num_agents": 2,
    "hidden_layers": [
      256,
      256
    ]
  }
}
2024-07-21 11:38:19,947 - AirSimEnvLogger - INFO - Environment reset and takeoff completed.
2024-07-21 11:38:20,358 - AirSimEnvLogger - INFO - Reset completed. Observation keys: dict_keys(['state', 'visual'])
2024-07-21 11:38:20,422 - AirSimEnvLogger - INFO - State shape: (16,), Visual shape: (144, 256, 3)
2024-07-21 11:38:20,517 - AirSimEnvLogger - ERROR - Error in step function: too many values to unpack (expected 3)
2024-07-21 11:38:20,563 - AirSimEnvLogger - ERROR - Action shape: (4,), Current state shape: (16,), Current image shape: (144, 256, 3)
2024-07-21 11:38:20,609 - AirSimEnvLogger - ERROR - An error occurred: too many values to unpack (expected 3)
2024-07-21 11:38:26,293 - AirSimEnvLogger - INFO - Environment closed.
2024-07-21 11:47:43,852 - AirSimEnvLogger - INFO - Initialized with state_dim: 16, action_dim: 4
2024-07-21 11:47:43,873 - AirSimEnvLogger - INFO - Initializing AirSimEnv
2024-07-21 11:47:43,874 - AirSimEnvLogger - INFO - Configuration: {
  "learning_rate": 0.0001,
  "gamma": 0.99,
  "tau": 0.95,
  "batch_size": 64,
  "num_timesteps": 2000000,
  "ppo": {
    "learning_rate": 0.0003,
    "n_steps": 2048,
    "batch_size": 64,
    "n_epochs": 2000,
    "gamma": 0.99,
    "gae_lambda": 0.95,
    "clip_range": 0.2,
    "ent_coef": 0.01,
    "vf_coef": 0.5,
    "max_grad_norm": 0.5,
    "use_sde": true,
    "sde_sample_freq": 4,
    "tensorboard_log": "logs/tensorboard_logs/ppo_airsim_tensorboard/",
    "verbose": 1,
    "seed": null,
    "device": "auto",
    "continuous": true,
    "save_freq": 10000
  },
  "environment": {
    "env_name": "Africa_001",
    "reward_threshold": 250,
    "max_episode_steps": 1000,
    "state_dim": 16,
    "action_dim": 4,
    "reward_scale": 20,
    "proximity_threshold": 5.0,
    "collision_penalty": 25,
    "height_target": -10,
    "height_tolerance": 1.0,
    "height_penalty": 1,
    "movement_penalty": 0.1,
    "smoothness_penalty": 0.1,
    "duration": 0.1,
    "exploration_area": {
      "x_min": -1000,
      "x_max": 1000,
      "y_min": -1000,
      "y_max": 1000,
      "z_min": -100,
      "z_max": 100
    }
  },
  "policy_network": {
    "input_size": 16,
    "hidden_layers": [
      256,
      256
    ],
    "output_size": 4,
    "use_batch_norm": true,
    "use_dropout": true,
    "dropout_rate": 0.2,
    "use_attention": true,
    "num_action_heads": 1
  },
  "critic_network": {
    "input_size": 16,
    "hidden_layers": [
      256,
      256
    ],
    "output_size": 1,
    "use_batch_norm": true,
    "use_dropout": true,
    "dropout_rate": 0.2,
    "use_attention": true
  },
  "exploration": {
    "strategy": "epsilon_decay",
    "initial_epsilon": 1.0,
    "min_epsilon": 0.05,
    "epsilon_decay_rate": 0.9995
  },
  "model_checkpointing": {
    "checkpoint_interval": 10,
    "save_best_only": true,
    "checkpoint_dir": "models/checkpoints"
  },
  "logging": {
    "log_interval": 10,
    "log_dir": "logs/",
    "tensorboard": true,
    "tensorboard_log_dir": "logs/tensorboard_logs",
    "model_save_path": "models/saved_models"
  },
  "advanced_training_techniques": {
    "gradient_clipping": 0.5,
    "use_gae": true,
    "gae_lambda": 0.95,
    "normalize_advantages": true
  },
  "early_stopping": {
    "patience": 10
  },
  "reward_adjustments": {
    "collision_penalty": 50,
    "reward_threshold": 250
  },
  "shared_components": {
    "residual_block": {
      "input_dim": 128,
      "hidden_dim": 128,
      "dropout_rate": 0.2
    },
    "attention_layer": {
      "input_dim": 128,
      "hidden_dim": 128
    }
  },
  "icm": {
    "state_dim": 16,
    "action_dim": 4,
    "image_channels": 3,
    "image_height": 144,
    "image_width": 256,
    "cnn": {
      "conv1": {
        "out_channels": 32,
        "kernel_size": 8,
        "stride": 4
      },
      "conv2": {
        "out_channels": 64,
        "kernel_size": 4,
        "stride": 2
      },
      "conv3": {
        "out_channels": 64,
        "kernel_size": 3,
        "stride": 1
      }
    },
    "state_encoder": {
      "hidden_dim": 128
    },
    "forward_model": {
      "hidden_dim": 256
    },
    "inverse_model": {
      "hidden_dim": 256
    }
  },
  "predictive_model": {
    "learning_rate": 0.0001,
    "hidden_layers": [
      256,
      256
    ]
  },
  "hrl": {
    "use_hierarchical": true,
    "high_level_policy": {
      "input_size": 16,
      "hidden_layers": [
        256,
        256
      ],
      "output_size": 4
    },
    "sub_goal_dim": 3,
    "low_level_policy": {
      "input_size": 19,
      "hidden_layers": [
        256,
        256
      ],
      "output_size": 4
    }
  },
  "curriculum_learning": {
    "use_curriculum": true,
    "initial_difficulty": 1,
    "difficulty_increment": 1,
    "difficulty_threshold": 200
  },
  "multi_agent": {
    "use_multi_agent": true,
    "num_agents": 2,
    "hidden_layers": [
      256,
      256
    ]
  }
}
2024-07-21 11:47:49,523 - AirSimEnvLogger - INFO - Environment reset and takeoff completed.
2024-07-21 11:47:50,182 - AirSimEnvLogger - INFO - Reset completed. Observation keys: dict_keys(['state', 'visual'])
2024-07-21 11:47:50,228 - AirSimEnvLogger - INFO - State shape: (16,), Visual shape: (144, 256, 3)
2024-07-21 11:47:50,292 - AirSimEnvLogger - ERROR - Error in step function: too many values to unpack (expected 3)
2024-07-21 11:47:50,336 - AirSimEnvLogger - ERROR - Action shape: (4,), Current state shape: (16,), Current image shape: (144, 256, 3)
2024-07-21 11:47:50,383 - AirSimEnvLogger - ERROR - An error occurred: too many values to unpack (expected 3)
2024-07-21 11:47:56,658 - AirSimEnvLogger - INFO - Environment closed.
2024-07-21 11:53:42,440 - AirSimEnvLogger - INFO - Initialized with state_dim: 16, action_dim: 4
2024-07-21 11:53:42,458 - AirSimEnvLogger - INFO - Initializing AirSimEnv
2024-07-21 11:53:42,459 - AirSimEnvLogger - INFO - Configuration: {
  "learning_rate": 0.0001,
  "gamma": 0.99,
  "tau": 0.95,
  "batch_size": 64,
  "num_timesteps": 2000000,
  "ppo": {
    "learning_rate": 0.0003,
    "n_steps": 2048,
    "batch_size": 64,
    "n_epochs": 2000,
    "gamma": 0.99,
    "gae_lambda": 0.95,
    "clip_range": 0.2,
    "ent_coef": 0.01,
    "vf_coef": 0.5,
    "max_grad_norm": 0.5,
    "use_sde": true,
    "sde_sample_freq": 4,
    "tensorboard_log": "logs/tensorboard_logs/ppo_airsim_tensorboard/",
    "verbose": 1,
    "seed": null,
    "device": "auto",
    "continuous": true,
    "save_freq": 10000
  },
  "environment": {
    "env_name": "Africa_001",
    "reward_threshold": 250,
    "max_episode_steps": 1000,
    "state_dim": 16,
    "action_dim": 4,
    "reward_scale": 20,
    "proximity_threshold": 5.0,
    "collision_penalty": 25,
    "height_target": -10,
    "height_tolerance": 1.0,
    "height_penalty": 1,
    "movement_penalty": 0.1,
    "smoothness_penalty": 0.1,
    "duration": 0.1,
    "exploration_area": {
      "x_min": -1000,
      "x_max": 1000,
      "y_min": -1000,
      "y_max": 1000,
      "z_min": -100,
      "z_max": 100
    }
  },
  "policy_network": {
    "input_size": 16,
    "hidden_layers": [
      256,
      256
    ],
    "output_size": 4,
    "use_batch_norm": true,
    "use_dropout": true,
    "dropout_rate": 0.2,
    "use_attention": true,
    "num_action_heads": 1
  },
  "critic_network": {
    "input_size": 16,
    "hidden_layers": [
      256,
      256
    ],
    "output_size": 1,
    "use_batch_norm": true,
    "use_dropout": true,
    "dropout_rate": 0.2,
    "use_attention": true
  },
  "exploration": {
    "strategy": "epsilon_decay",
    "initial_epsilon": 1.0,
    "min_epsilon": 0.05,
    "epsilon_decay_rate": 0.9995
  },
  "model_checkpointing": {
    "checkpoint_interval": 10,
    "save_best_only": true,
    "checkpoint_dir": "models/checkpoints"
  },
  "logging": {
    "log_interval": 10,
    "log_dir": "logs/",
    "tensorboard": true,
    "tensorboard_log_dir": "logs/tensorboard_logs",
    "model_save_path": "models/saved_models"
  },
  "advanced_training_techniques": {
    "gradient_clipping": 0.5,
    "use_gae": true,
    "gae_lambda": 0.95,
    "normalize_advantages": true
  },
  "early_stopping": {
    "patience": 10
  },
  "reward_adjustments": {
    "collision_penalty": 50,
    "reward_threshold": 250
  },
  "shared_components": {
    "residual_block": {
      "input_dim": 128,
      "hidden_dim": 128,
      "dropout_rate": 0.2
    },
    "attention_layer": {
      "input_dim": 128,
      "hidden_dim": 128
    }
  },
  "icm": {
    "state_dim": 16,
    "action_dim": 4,
    "image_channels": 3,
    "image_height": 144,
    "image_width": 256,
    "cnn": {
      "conv1": {
        "out_channels": 32,
        "kernel_size": 8,
        "stride": 4
      },
      "conv2": {
        "out_channels": 64,
        "kernel_size": 4,
        "stride": 2
      },
      "conv3": {
        "out_channels": 64,
        "kernel_size": 3,
        "stride": 1
      }
    },
    "state_encoder": {
      "hidden_dim": 128
    },
    "forward_model": {
      "hidden_dim": 256
    },
    "inverse_model": {
      "hidden_dim": 256
    }
  },
  "predictive_model": {
    "learning_rate": 0.0001,
    "hidden_layers": [
      256,
      256
    ]
  },
  "hrl": {
    "use_hierarchical": true,
    "high_level_policy": {
      "input_size": 16,
      "hidden_layers": [
        256,
        256
      ],
      "output_size": 4
    },
    "sub_goal_dim": 3,
    "low_level_policy": {
      "input_size": 19,
      "hidden_layers": [
        256,
        256
      ],
      "output_size": 4
    }
  },
  "curriculum_learning": {
    "use_curriculum": true,
    "initial_difficulty": 1,
    "difficulty_increment": 1,
    "difficulty_threshold": 200
  },
  "multi_agent": {
    "use_multi_agent": true,
    "num_agents": 2,
    "hidden_layers": [
      256,
      256
    ]
  }
}
2024-07-21 11:53:48,552 - AirSimEnvLogger - INFO - Environment reset and takeoff completed.
2024-07-21 11:53:49,228 - AirSimEnvLogger - INFO - Reset completed. Observation keys: dict_keys(['state', 'visual'])
2024-07-21 11:53:49,274 - AirSimEnvLogger - INFO - State shape: (16,), Visual shape: (144, 256, 3)
2024-07-21 11:53:52,830 - AirSimEnvLogger - ERROR - Error in step function: Given groups=1, weight of size [32, 3, 8, 8], expected input[1, 256, 3, 144] to have 3 channels, but got 256 channels instead
2024-07-21 11:53:52,875 - AirSimEnvLogger - ERROR - Action shape: (4,), Current state shape: (16,), Current image shape: (144, 256, 3)
2024-07-21 11:53:52,922 - AirSimEnvLogger - ERROR - An error occurred: Given groups=1, weight of size [32, 3, 8, 8], expected input[1, 256, 3, 144] to have 3 channels, but got 256 channels instead
2024-07-21 11:53:58,765 - AirSimEnvLogger - INFO - Environment closed.
2024-07-21 11:57:01,651 - AirSimEnvLogger - INFO - Initialized with state_dim: 16, action_dim: 4
2024-07-21 11:57:01,668 - AirSimEnvLogger - INFO - Initializing AirSimEnv
2024-07-21 11:57:01,669 - AirSimEnvLogger - INFO - Configuration: {
  "learning_rate": 0.0001,
  "gamma": 0.99,
  "tau": 0.95,
  "batch_size": 64,
  "num_timesteps": 2000000,
  "ppo": {
    "learning_rate": 0.0003,
    "n_steps": 2048,
    "batch_size": 64,
    "n_epochs": 2000,
    "gamma": 0.99,
    "gae_lambda": 0.95,
    "clip_range": 0.2,
    "ent_coef": 0.01,
    "vf_coef": 0.5,
    "max_grad_norm": 0.5,
    "use_sde": true,
    "sde_sample_freq": 4,
    "tensorboard_log": "logs/tensorboard_logs/ppo_airsim_tensorboard/",
    "verbose": 1,
    "seed": null,
    "device": "auto",
    "continuous": true,
    "save_freq": 10000
  },
  "environment": {
    "env_name": "Africa_001",
    "reward_threshold": 250,
    "max_episode_steps": 1000,
    "state_dim": 16,
    "action_dim": 4,
    "reward_scale": 20,
    "proximity_threshold": 5.0,
    "collision_penalty": 25,
    "height_target": -10,
    "height_tolerance": 1.0,
    "height_penalty": 1,
    "movement_penalty": 0.1,
    "smoothness_penalty": 0.1,
    "duration": 0.1,
    "exploration_area": {
      "x_min": -1000,
      "x_max": 1000,
      "y_min": -1000,
      "y_max": 1000,
      "z_min": -100,
      "z_max": 100
    }
  },
  "policy_network": {
    "input_size": 16,
    "hidden_layers": [
      256,
      256
    ],
    "output_size": 4,
    "use_batch_norm": true,
    "use_dropout": true,
    "dropout_rate": 0.2,
    "use_attention": true,
    "num_action_heads": 1
  },
  "critic_network": {
    "input_size": 16,
    "hidden_layers": [
      256,
      256
    ],
    "output_size": 1,
    "use_batch_norm": true,
    "use_dropout": true,
    "dropout_rate": 0.2,
    "use_attention": true
  },
  "exploration": {
    "strategy": "epsilon_decay",
    "initial_epsilon": 1.0,
    "min_epsilon": 0.05,
    "epsilon_decay_rate": 0.9995
  },
  "model_checkpointing": {
    "checkpoint_interval": 10,
    "save_best_only": true,
    "checkpoint_dir": "models/checkpoints"
  },
  "logging": {
    "log_interval": 10,
    "log_dir": "logs/",
    "tensorboard": true,
    "tensorboard_log_dir": "logs/tensorboard_logs",
    "model_save_path": "models/saved_models"
  },
  "advanced_training_techniques": {
    "gradient_clipping": 0.5,
    "use_gae": true,
    "gae_lambda": 0.95,
    "normalize_advantages": true
  },
  "early_stopping": {
    "patience": 10
  },
  "reward_adjustments": {
    "collision_penalty": 50,
    "reward_threshold": 250
  },
  "shared_components": {
    "residual_block": {
      "input_dim": 128,
      "hidden_dim": 128,
      "dropout_rate": 0.2
    },
    "attention_layer": {
      "input_dim": 128,
      "hidden_dim": 128
    }
  },
  "icm": {
    "state_dim": 16,
    "action_dim": 4,
    "image_channels": 3,
    "image_height": 144,
    "image_width": 256,
    "cnn": {
      "conv1": {
        "out_channels": 32,
        "kernel_size": 8,
        "stride": 4
      },
      "conv2": {
        "out_channels": 64,
        "kernel_size": 4,
        "stride": 2
      },
      "conv3": {
        "out_channels": 64,
        "kernel_size": 3,
        "stride": 1
      }
    },
    "state_encoder": {
      "hidden_dim": 128
    },
    "forward_model": {
      "hidden_dim": 256
    },
    "inverse_model": {
      "hidden_dim": 256
    }
  },
  "predictive_model": {
    "learning_rate": 0.0001,
    "hidden_layers": [
      256,
      256
    ]
  },
  "hrl": {
    "use_hierarchical": true,
    "high_level_policy": {
      "input_size": 16,
      "hidden_layers": [
        256,
        256
      ],
      "output_size": 4
    },
    "sub_goal_dim": 3,
    "low_level_policy": {
      "input_size": 19,
      "hidden_layers": [
        256,
        256
      ],
      "output_size": 4
    }
  },
  "curriculum_learning": {
    "use_curriculum": true,
    "initial_difficulty": 1,
    "difficulty_increment": 1,
    "difficulty_threshold": 200
  },
  "multi_agent": {
    "use_multi_agent": true,
    "num_agents": 2,
    "hidden_layers": [
      256,
      256
    ]
  }
}
2024-07-21 11:57:07,583 - AirSimEnvLogger - INFO - Environment reset and takeoff completed.
2024-07-21 11:57:08,178 - AirSimEnvLogger - INFO - Reset completed. Observation keys: dict_keys(['state', 'visual'])
2024-07-21 11:57:08,226 - AirSimEnvLogger - INFO - State shape: (16,), Visual shape: (3, 144, 256)
2024-07-21 11:57:11,777 - AirSimEnvLogger - ERROR - Error in step function: Given groups=1, weight of size [32, 3, 8, 8], expected input[1, 256, 3, 144] to have 3 channels, but got 256 channels instead
2024-07-21 11:57:11,822 - AirSimEnvLogger - ERROR - Action shape: (4,), Current state shape: (16,), Current image shape: (3, 144, 256)
2024-07-21 11:57:11,886 - AirSimEnvLogger - ERROR - An error occurred: Given groups=1, weight of size [32, 3, 8, 8], expected input[1, 256, 3, 144] to have 3 channels, but got 256 channels instead
2024-07-21 11:57:17,702 - AirSimEnvLogger - INFO - Environment closed.
2024-07-21 12:01:13,433 - AirSimEnvLogger - INFO - Initialized with state_dim: 16, action_dim: 4
2024-07-21 12:01:13,448 - AirSimEnvLogger - INFO - Initializing AirSimEnv
2024-07-21 12:01:13,449 - AirSimEnvLogger - INFO - Configuration: {
  "learning_rate": 0.0001,
  "gamma": 0.99,
  "tau": 0.95,
  "batch_size": 64,
  "num_timesteps": 2000000,
  "ppo": {
    "learning_rate": 0.0003,
    "n_steps": 2048,
    "batch_size": 64,
    "n_epochs": 2000,
    "gamma": 0.99,
    "gae_lambda": 0.95,
    "clip_range": 0.2,
    "ent_coef": 0.01,
    "vf_coef": 0.5,
    "max_grad_norm": 0.5,
    "use_sde": true,
    "sde_sample_freq": 4,
    "tensorboard_log": "logs/tensorboard_logs/ppo_airsim_tensorboard/",
    "verbose": 1,
    "seed": null,
    "device": "auto",
    "continuous": true,
    "save_freq": 10000
  },
  "environment": {
    "env_name": "Africa_001",
    "reward_threshold": 250,
    "max_episode_steps": 1000,
    "state_dim": 16,
    "action_dim": 4,
    "reward_scale": 20,
    "proximity_threshold": 5.0,
    "collision_penalty": 25,
    "height_target": -10,
    "height_tolerance": 1.0,
    "height_penalty": 1,
    "movement_penalty": 0.1,
    "smoothness_penalty": 0.1,
    "duration": 0.1,
    "exploration_area": {
      "x_min": -1000,
      "x_max": 1000,
      "y_min": -1000,
      "y_max": 1000,
      "z_min": -100,
      "z_max": 100
    }
  },
  "policy_network": {
    "input_size": 16,
    "hidden_layers": [
      256,
      256
    ],
    "output_size": 4,
    "use_batch_norm": true,
    "use_dropout": true,
    "dropout_rate": 0.2,
    "use_attention": true,
    "num_action_heads": 1
  },
  "critic_network": {
    "input_size": 16,
    "hidden_layers": [
      256,
      256
    ],
    "output_size": 1,
    "use_batch_norm": true,
    "use_dropout": true,
    "dropout_rate": 0.2,
    "use_attention": true
  },
  "exploration": {
    "strategy": "epsilon_decay",
    "initial_epsilon": 1.0,
    "min_epsilon": 0.05,
    "epsilon_decay_rate": 0.9995
  },
  "model_checkpointing": {
    "checkpoint_interval": 10,
    "save_best_only": true,
    "checkpoint_dir": "models/checkpoints"
  },
  "logging": {
    "log_interval": 10,
    "log_dir": "logs/",
    "tensorboard": true,
    "tensorboard_log_dir": "logs/tensorboard_logs",
    "model_save_path": "models/saved_models"
  },
  "advanced_training_techniques": {
    "gradient_clipping": 0.5,
    "use_gae": true,
    "gae_lambda": 0.95,
    "normalize_advantages": true
  },
  "early_stopping": {
    "patience": 10
  },
  "reward_adjustments": {
    "collision_penalty": 50,
    "reward_threshold": 250
  },
  "shared_components": {
    "residual_block": {
      "input_dim": 128,
      "hidden_dim": 128,
      "dropout_rate": 0.2
    },
    "attention_layer": {
      "input_dim": 128,
      "hidden_dim": 128
    }
  },
  "icm": {
    "state_dim": 16,
    "action_dim": 4,
    "image_channels": 3,
    "image_height": 144,
    "image_width": 256,
    "cnn": {
      "conv1": {
        "out_channels": 32,
        "kernel_size": 8,
        "stride": 4
      },
      "conv2": {
        "out_channels": 64,
        "kernel_size": 4,
        "stride": 2
      },
      "conv3": {
        "out_channels": 64,
        "kernel_size": 3,
        "stride": 1
      }
    },
    "state_encoder": {
      "hidden_dim": 128
    },
    "forward_model": {
      "hidden_dim": 256
    },
    "inverse_model": {
      "hidden_dim": 256
    }
  },
  "predictive_model": {
    "learning_rate": 0.0001,
    "hidden_layers": [
      256,
      256
    ]
  },
  "hrl": {
    "use_hierarchical": true,
    "high_level_policy": {
      "input_size": 16,
      "hidden_layers": [
        256,
        256
      ],
      "output_size": 4
    },
    "sub_goal_dim": 3,
    "low_level_policy": {
      "input_size": 19,
      "hidden_layers": [
        256,
        256
      ],
      "output_size": 4
    }
  },
  "curriculum_learning": {
    "use_curriculum": true,
    "initial_difficulty": 1,
    "difficulty_increment": 1,
    "difficulty_threshold": 200
  },
  "multi_agent": {
    "use_multi_agent": true,
    "num_agents": 2,
    "hidden_layers": [
      256,
      256
    ]
  }
}
2024-07-21 12:01:19,392 - AirSimEnvLogger - INFO - Environment reset and takeoff completed.
2024-07-21 12:01:20,036 - AirSimEnvLogger - INFO - Reset completed. Observation keys: dict_keys(['state', 'visual'])
2024-07-21 12:01:20,083 - AirSimEnvLogger - INFO - State shape: (16,), Visual shape: (144, 256, 3)
2024-07-21 12:01:23,413 - AirSimEnvLogger - INFO - Reward breakdown - Distance: -8.564591112450163, Velocity: -0.7487530248370736, Collision: 0, Height: -1.0, Movement: -0.05465858611399911, Smoothness: -0.0, Curiosity: 2.8080787658691406, Exploration: 0, Total: -8.04039410054553
2024-07-21 12:01:23,570 - AirSimEnvLogger - INFO - Action: [-0.33219174  0.33687115  0.22935419  0.14939626], Velocity: (-0.33219173550605774, 0.3368711471557617, 0.22935418784618378), Duration: 0.5, Reward: -8.04039410054553, Done: False
2024-07-21 12:01:23,695 - AirSimEnvLogger - INFO - Step completed. Observation keys: dict_keys(['state', 'visual'])
2024-07-21 12:01:23,742 - AirSimEnvLogger - INFO - State shape: (16,), Visual shape: (144, 256, 3)
2024-07-21 12:01:25,145 - AirSimEnvLogger - ERROR - Error in step function: Given groups=1, weight of size [32, 3, 8, 8], expected input[1, 144, 256, 3] to have 3 channels, but got 144 channels instead
2024-07-21 12:01:25,191 - AirSimEnvLogger - ERROR - Action shape: (4,), Current state shape: (16,), Current image shape: (144, 256, 3)
2024-07-21 12:01:25,238 - AirSimEnvLogger - ERROR - An error occurred: Given groups=1, weight of size [32, 3, 8, 8], expected input[1, 144, 256, 3] to have 3 channels, but got 144 channels instead
2024-07-21 12:01:31,056 - AirSimEnvLogger - INFO - Environment closed.
2024-07-21 12:05:14,216 - AirSimEnvLogger - INFO - Initialized with state_dim: 16, action_dim: 4
2024-07-21 12:05:14,236 - AirSimEnvLogger - INFO - Initializing AirSimEnv
2024-07-21 12:05:14,238 - AirSimEnvLogger - INFO - Configuration: {
  "learning_rate": 0.0001,
  "gamma": 0.99,
  "tau": 0.95,
  "batch_size": 64,
  "num_timesteps": 2000000,
  "ppo": {
    "learning_rate": 0.0003,
    "n_steps": 2048,
    "batch_size": 64,
    "n_epochs": 2000,
    "gamma": 0.99,
    "gae_lambda": 0.95,
    "clip_range": 0.2,
    "ent_coef": 0.01,
    "vf_coef": 0.5,
    "max_grad_norm": 0.5,
    "use_sde": true,
    "sde_sample_freq": 4,
    "tensorboard_log": "logs/tensorboard_logs/ppo_airsim_tensorboard/",
    "verbose": 1,
    "seed": null,
    "device": "auto",
    "continuous": true,
    "save_freq": 10000
  },
  "environment": {
    "env_name": "Africa_001",
    "reward_threshold": 250,
    "max_episode_steps": 1000,
    "state_dim": 16,
    "action_dim": 4,
    "reward_scale": 20,
    "proximity_threshold": 5.0,
    "collision_penalty": 25,
    "height_target": -10,
    "height_tolerance": 1.0,
    "height_penalty": 1,
    "movement_penalty": 0.1,
    "smoothness_penalty": 0.1,
    "duration": 0.1,
    "exploration_area": {
      "x_min": -1000,
      "x_max": 1000,
      "y_min": -1000,
      "y_max": 1000,
      "z_min": -100,
      "z_max": 100
    }
  },
  "policy_network": {
    "input_size": 16,
    "hidden_layers": [
      256,
      256
    ],
    "output_size": 4,
    "use_batch_norm": true,
    "use_dropout": true,
    "dropout_rate": 0.2,
    "use_attention": true,
    "num_action_heads": 1
  },
  "critic_network": {
    "input_size": 16,
    "hidden_layers": [
      256,
      256
    ],
    "output_size": 1,
    "use_batch_norm": true,
    "use_dropout": true,
    "dropout_rate": 0.2,
    "use_attention": true
  },
  "exploration": {
    "strategy": "epsilon_decay",
    "initial_epsilon": 1.0,
    "min_epsilon": 0.05,
    "epsilon_decay_rate": 0.9995
  },
  "model_checkpointing": {
    "checkpoint_interval": 10,
    "save_best_only": true,
    "checkpoint_dir": "models/checkpoints"
  },
  "logging": {
    "log_interval": 10,
    "log_dir": "logs/",
    "tensorboard": true,
    "tensorboard_log_dir": "logs/tensorboard_logs",
    "model_save_path": "models/saved_models"
  },
  "advanced_training_techniques": {
    "gradient_clipping": 0.5,
    "use_gae": true,
    "gae_lambda": 0.95,
    "normalize_advantages": true
  },
  "early_stopping": {
    "patience": 10
  },
  "reward_adjustments": {
    "collision_penalty": 50,
    "reward_threshold": 250
  },
  "shared_components": {
    "residual_block": {
      "input_dim": 128,
      "hidden_dim": 128,
      "dropout_rate": 0.2
    },
    "attention_layer": {
      "input_dim": 128,
      "hidden_dim": 128
    }
  },
  "icm": {
    "state_dim": 16,
    "action_dim": 4,
    "image_channels": 3,
    "image_height": 144,
    "image_width": 256,
    "cnn": {
      "conv1": {
        "out_channels": 32,
        "kernel_size": 8,
        "stride": 4
      },
      "conv2": {
        "out_channels": 64,
        "kernel_size": 4,
        "stride": 2
      },
      "conv3": {
        "out_channels": 64,
        "kernel_size": 3,
        "stride": 1
      }
    },
    "state_encoder": {
      "hidden_dim": 128
    },
    "forward_model": {
      "hidden_dim": 256
    },
    "inverse_model": {
      "hidden_dim": 256
    }
  },
  "predictive_model": {
    "learning_rate": 0.0001,
    "hidden_layers": [
      256,
      256
    ]
  },
  "hrl": {
    "use_hierarchical": true,
    "high_level_policy": {
      "input_size": 16,
      "hidden_layers": [
        256,
        256
      ],
      "output_size": 4
    },
    "sub_goal_dim": 3,
    "low_level_policy": {
      "input_size": 19,
      "hidden_layers": [
        256,
        256
      ],
      "output_size": 4
    }
  },
  "curriculum_learning": {
    "use_curriculum": true,
    "initial_difficulty": 1,
    "difficulty_increment": 1,
    "difficulty_threshold": 200
  },
  "multi_agent": {
    "use_multi_agent": true,
    "num_agents": 2,
    "hidden_layers": [
      256,
      256
    ]
  }
}
2024-07-21 12:05:20,260 - AirSimEnvLogger - INFO - Environment reset and takeoff completed.
2024-07-21 12:05:20,951 - AirSimEnvLogger - INFO - Reset completed. Observation keys: dict_keys(['state', 'visual'])
2024-07-21 12:05:20,999 - AirSimEnvLogger - INFO - State shape: (16,), Visual shape: (144, 256, 3)
2024-07-21 12:05:24,247 - AirSimEnvLogger - INFO - Reward breakdown - Distance: -8.562581797020766, Velocity: -0.7213800585285658, Collision: 0, Height: -1.0, Movement: -0.036873639236088544, Smoothness: -0.0, Curiosity: 2.6111888885498047, Exploration: 0, Total: -8.121364745933755
2024-07-21 12:05:24,374 - AirSimEnvLogger - INFO - Action: [-0.04855201  0.21641499  0.2492695  -0.15696655], Velocity: (-0.0485520102083683, 0.21641498804092407, 0.249269500374794), Duration: 0.5, Reward: -8.121364745933755, Done: False
2024-07-21 12:05:24,466 - AirSimEnvLogger - INFO - Step completed. Observation keys: dict_keys(['state', 'visual'])
2024-07-21 12:05:24,496 - AirSimEnvLogger - INFO - State shape: (16,), Visual shape: (144, 256, 3)
2024-07-21 12:05:27,727 - AirSimEnvLogger - INFO - Predictive model loss: 0.16551268100738525
2024-07-21 12:05:30,381 - AirSimEnvLogger - INFO - Reward breakdown - Distance: -9.285528611888406, Velocity: -0.7423710061651981, Collision: 0, Height: -1.0, Movement: -0.056681087033244475, Smoothness: -0.0, Curiosity: 1.3654018640518188, Exploration: 0.20686721872107217, Total: -9.438307847904204
2024-07-21 12:05:30,521 - AirSimEnvLogger - INFO - Action: [ 0.28252394  0.09873154 -0.19764202 -0.43891286], Velocity: (0.28252394311130047, 0.09873153641819954, -0.197642020881176), Duration: 0.5, Reward: -9.438307847904204, Done: False
2024-07-21 12:05:30,644 - AirSimEnvLogger - INFO - Step completed. Observation keys: dict_keys(['state', 'visual'])
2024-07-21 12:05:30,690 - AirSimEnvLogger - INFO - State shape: (16,), Visual shape: (144, 256, 3)
2024-07-21 12:05:33,608 - AirSimEnvLogger - INFO - Predictive model loss: 0.06223369389772415
2024-07-21 12:05:36,609 - AirSimEnvLogger - INFO - Reward breakdown - Distance: -9.645481225915528, Velocity: -0.17357158750781104, Collision: 0, Height: -1.0, Movement: -0.026120221250409137, Smoothness: -0.0, Curiosity: 0.22464507818222046, Exploration: 0.12151869393393436, Total: -10.098252763916578
2024-07-21 12:05:36,766 - AirSimEnvLogger - INFO - Action: [-0.0750543  -0.06174243 -0.23198318 -0.07046364], Velocity: (-0.0750542962923646, -0.06174243055284023, -0.23198318108916283), Duration: 0.5, Reward: -10.098252763916578, Done: False
2024-07-21 12:05:36,891 - AirSimEnvLogger - INFO - Step completed. Observation keys: dict_keys(['state', 'visual'])
2024-07-21 12:05:36,938 - AirSimEnvLogger - INFO - State shape: (16,), Visual shape: (144, 256, 3)
2024-07-21 12:05:39,865 - AirSimEnvLogger - INFO - Predictive model loss: 0.009303624741733074
2024-07-21 12:05:43,021 - AirSimEnvLogger - INFO - Reward breakdown - Distance: -9.66062098625972, Velocity: -0.09457262194864097, Collision: 0, Height: -1.0, Movement: -0.04896442336249299, Smoothness: -0.0, Curiosity: 0.4550994038581848, Exploration: 0.08403885122412189, Total: -9.968446267396374
2024-07-21 12:05:43,177 - AirSimEnvLogger - INFO - Action: [ 0.09469322 -0.41042608  0.23457971 -0.08548366], Velocity: (0.09469322441145778, -0.4104260830208659, 0.23457971401512623), Duration: 0.5, Reward: -9.968446267396374, Done: False
2024-07-21 12:05:43,287 - AirSimEnvLogger - INFO - Step completed. Observation keys: dict_keys(['state', 'visual'])
2024-07-21 12:05:43,335 - AirSimEnvLogger - INFO - State shape: (16,), Visual shape: (144, 256, 3)
2024-07-21 12:05:46,086 - AirSimEnvLogger - INFO - Predictive model loss: 0.008951655589044094
2024-07-21 12:05:49,260 - AirSimEnvLogger - INFO - Reward breakdown - Distance: -9.855388223198615, Velocity: -0.02012770113830831, Collision: 0, Height: -1.0, Movement: -0.015787600536381348, Smoothness: -0.0, Curiosity: 0.06849487870931625, Exploration: 0.027462953343989262, Total: -10.32729080379795
2024-07-21 12:05:49,418 - AirSimEnvLogger - INFO - Action: [ 0.03613084 -0.06577113  0.01276366  0.13831356], Velocity: (0.036130844382569194, -0.06577113410457969, 0.012763657607138157), Duration: 0.5, Reward: -10.32729080379795, Done: False
2024-07-21 12:05:49,542 - AirSimEnvLogger - INFO - Step completed. Observation keys: dict_keys(['state', 'visual'])
2024-07-21 12:05:49,590 - AirSimEnvLogger - INFO - State shape: (16,), Visual shape: (144, 256, 3)
2024-07-21 12:05:52,509 - AirSimEnvLogger - INFO - Predictive model loss: 0.0024183958303183317
2024-07-21 12:05:55,600 - AirSimEnvLogger - INFO - Reward breakdown - Distance: -10.081345008991372, Velocity: -0.06293115989736559, Collision: 0, Height: -1.0, Movement: -0.03912590026503393, Smoothness: -0.0, Curiosity: 0.15231895446777344, Exploration: 0.04702684426064854, Total: -10.531158332880542
2024-07-21 12:05:55,757 - AirSimEnvLogger - INFO - Action: [-0.18150984  0.17424092 -0.23569969  0.18499606], Velocity: (-0.1815098380902782, 0.17424091626890004, -0.23569969413802028), Duration: 0.5, Reward: -10.531158332880542, Done: False
2024-07-21 12:05:55,883 - AirSimEnvLogger - INFO - Step completed. Observation keys: dict_keys(['state', 'visual'])
2024-07-21 12:05:55,930 - AirSimEnvLogger - INFO - State shape: (16,), Visual shape: (144, 256, 3)
2024-07-21 12:05:58,310 - AirSimEnvLogger - INFO - Predictive model loss: 0.004216683097183704
2024-07-21 12:06:01,980 - AirSimEnvLogger - INFO - Reward breakdown - Distance: -9.907882028995951, Velocity: -0.11148868980613293, Collision: 0, Height: -1.0, Movement: -0.05528792045401895, Smoothness: -0.0, Curiosity: 0.34646469354629517, Exploration: 0.024172865086072866, Total: -10.291088246154057
2024-07-21 12:06:02,150 - AirSimEnvLogger - INFO - Action: [-0.28261986  0.40791385  0.21282844 -0.11879301], Velocity: (-0.2826198565890081, 0.40791384840849787, 0.21282843709923327), Duration: 0.5, Reward: -10.291088246154057, Done: False
2024-07-21 12:06:02,275 - AirSimEnvLogger - INFO - Step completed. Observation keys: dict_keys(['state', 'visual'])
2024-07-21 12:06:02,339 - AirSimEnvLogger - INFO - State shape: (16,), Visual shape: (144, 256, 3)
